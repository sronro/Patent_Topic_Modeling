ccopy_reg
_reconstructor
p0
(cpandas.core.frame
DataFrame
p1
c__builtin__
object
p2
Ntp3
Rp4
(dp5
S'_metadata'
p6
(lp7
sS'_typ'
p8
S'dataframe'
p9
sS'_data'
p10
g0
(cpandas.core.internals
BlockManager
p11
g2
Ntp12
Rp13
((lp14
cpandas.core.indexes.base
_new_Index
p15
(cpandas.core.indexes.base
Index
p16
(dp17
S'data'
p18
cnumpy.core.multiarray
_reconstruct
p19
(cnumpy
ndarray
p20
(I0
tp21
S'b'
p22
tp23
Rp24
(I1
(I10
tp25
cnumpy
dtype
p26
(S'O8'
p27
I0
I1
tp28
Rp29
(I3
S'|'
p30
NNNI-1
I-1
I63
tp31
bI00
(lp32
S'id'
p33
aS'title'
p34
aS'assignee'
p35
aS'inventor/author'
p36
aS'priority date'
p37
aS'filing/creation date'
p38
aS'publication date'
p39
aS'grant date'
p40
aS'result link'
p41
aS'text'
p42
atp43
bsS'name'
p44
Nstp45
Rp46
acpandas.core.indexes.datetimes
_new_DatetimeIndex
p47
(cpandas.core.indexes.datetimes
DatetimeIndex
p48
(dp49
S'tz'
p50
NsS'freq'
p51
Nsg18
g19
(g20
(I0
tp52
g22
tp53
Rp54
(I1
(I975
tp55
g26
(S'M8'
p56
I0
I1
tp57
Rp58
(I4
S'<'
p59
NNNI-1
I-1
I0
((dp60
(S'ns'
p61
I1
I1
I1
tp62
tp63
tp64
bI00
S'\x00\x00\xaa*ee{\x12\x00\x00<\xb6\x14\xcaW\x13\x00\x00.\x88\xc8d\xdc\x12\x00\x00\xe6\xbeH4\xcb\x12\x00\x00;\xb0\x16\xa7p\x13\x00\x00\x9d\xa09L\x84\x12\x00\x00\x1b\xed\xf4\xbb\x8e\x12\x00\x00\xc8Ch\xe1\xf1\x12\x00\x00MX8o\xeb\x12\x00\x00\xff}\x10\xaf\x83\x12\x00\x00\x190\x8a\n\x0f\x13\x00\x00\xff\x1b3\xd8 \x13\x00\x00l(\xa8y\xfa\x12\x00\x00\xef\xe1\xea,\xd7\x12\x00\x00\xd0\xc2\xe9\x8dy\x12\x00\x00MX8o\xeb\x12\x00\x00MX8o\xeb\x12\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00\xddL\x15\xa7p\x12\x00\x00\x11bw\xc98\x13\x00\x00&k$\x8f\xb7\x12\x00\x00&k$\x8f\xb7\x12\x00\x00=\xbc\x12\xed>\x13\x00\x00U&K\xb0\xc1\x12\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\x11bw\xc98\x13\x00\x00\xa1\xa5\xe5\x95\x0c\x13\x00\x00\xf2Bv*\xdb\x12\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\xa3bPG\x8c\x12\x00\x00\x83\xdbs\xae\xe4\x12\x00\x00\xe6\xbeH4\xcb\x12\x00\x00\x15zoU\xd5\x12\x00\x00\x8bG\xa9\x18X\x13\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00\xa8m\xfa\xb3\xfb\x12\x00\x00\x97-\xb4\xe5\xca\x12\x00\x00\xb5F\xb7aA\x13\x00\x00\xe2W\xbf\x13\xe0\x12\x00\x00\xc7\x9fG\x95m\x12\x00\x00\x8b\xf8\x17\x84\t\x13\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00w\xf5h\xe1q\x13\x00\x00\xfd\x0f7\x92R\x13\x00\x00\xbeiYZM\x13\x00\x00\xbcp\xa9V\x93\x12\x00\x00\x8d\x04\x14\xca\xd7\x12\x00\x00`\xa4z\x83\xea\x12\x00\x00\x05@\'\xaa\x8b\x12\x00\x00\xc4>\xbc\x97i\x12\x00\x00T\xd1\xbb\xf8\x8b\x12\x00\x00S\x1aOj\xf3\x12\x00\x00\\\xdb\x13\x8c\x9c\x13\x00\x00V{\xdag\xf7\x12\x00\x00~\x1f[\xd6\xc3\x12\x00\x00t\xa7)&\x82\x12\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00\x11bw\xc98\x13\x00\x00\xacr\xa6\xfd\x83\x13\x00\x00\xec\x1e\x82Xp\x13\x00\x00\xa8m\xfa\xb3\xfb\x12\x00\x00\xa2\xfatMB\x13\x00\x00\xa0\xeex\x07t\x13\x00\x00\x94}\x97Sx\x12\x00\x00.97\xd0\x8d\x12\x00\x00Y+\xf7\xf9I\x13\x00\x00\x97\xcb\xd6\x0eh\x13\x00\x00\x17$\x8e\xc4@\x13\x00\x00(\x15C\xfe"\x13\x00\x00;a\x85\x12"\x13\x00\x00T\xd1\xbb\xf8\x8b\x12\x00\x00\xe9ne\xc6\x1d\x13\x00\x00U&K\xb0\xc1\x12\x00\x00W\xd0i\x1f-\x13\x00\x000\xe3U?\xf9\x12\x00\x00yP\xf6\xbb\x8e\x13\x00\x00\x83y\x96\xd7\x81\x13\x00\x00\x82$\x07 L\x13\x00\x00\x9c8^R:\x13\x00\x00\xffj\xc4lo\x13\x00\x00\x81\x80\xe6\xd3\xc7\x12\x00\x00\xe9ne\xc6\x1d\x13\x00\x00>s\x7f{\xd7\x12\x00\x008b\xd7\xeb\x80\x12\x00\x00\\\xee_\xce\xb0\x12\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00p\xde\xc2.4\x13\x00\x00MX8o\xeb\x12\x00\x00\x19\xe1\xf8u\xc0\x12\x00\x008\x00\xfa\x14\x1e\x13\x00\x00%\x16\x95\xd7\x81\x12\x00\x00\xef\x92Y\x98\x88\x12\x00\x00*\xbfam\x8e\x13\x00\x00\\\xdb\x13\x8c\x9c\x13\x00\x00MX8o\xeb\x12\x00\x00\\\xee_\xce\xb0\x12\x00\x00\\\xee_\xce\xb0\x12\x00\x00\xdf\x94V?y\x13\x00\x00(\xb3e\'\xc0\x13\x00\x00\xce\xa3\xa1\x05\x97\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00d\xa9&\xcdr\x13\x00\x00]\x92\x80\x1a5\x13\x00\x00\xff\x1b3\xd8 \x13\x00\x00\x1e\xec\xa2\xe2/\x13\x00\x00\x99&d\xe9\x84\x13\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00\xc51nx<\x13\x00\x00\xf2\xf3\xe4\x95\x8c\x12\x00\x00\xde\xa1\xa4^\xa6\x12\x00\x00MX8o\xeb\x12\x00\x00\xa2\xab\xe3\xb8\xf3\x12\x00\x009\xb7f\xa3\xb6\x12\x00\x00\xe1>u\xae\xe4\x13\x00\x00\x0fi\xc7\xc5~\x12\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00\xeds\x11\x10\xa6\x13\x00\x00\xb6L\xb5\x84(\x13\x00\x00E;\x94\x99\xc6\x12\x00\x00;\xb0\x16\xa7p\x13\x00\x00\x9d\xdc~\x9e\xbe\x13\x00\x009\xb7f\xa3\xb6\x12\x00\x00\xb2G\t;\xa0\x12\x00\x00\xa2I\x06\xe2\x90\x13\x00\x00Qp0\xfb\x87\x12\x00\x00\x17$\x8e\xc4@\x13\x00\x00\x17$\x8e\xc4@\x13\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\xd1\x17yE\xaf\x12\x00\x00\x95pI4K\x13\x00\x00\xfed\xc6I\x88\x13\x00\x00\xbc\x0e\xcc\x7f0\x13\x00\x00m\xcc\xc8\xc5~\x13\x00\x00a[\xe7\x11\x83\x12\x00\x00\xa9`\xac\x94\xce\x13\x00\x00x\xac\xd5o\n\x13\x00\x00<\xc9`\x0cl\x12\x00\x00a[\xe7\x11\x83\x12\x00\x00x\xac\xd5o\n\x13\x00\x00\x17\x86k\x9b\xa3\x12\x00\x00\xaa\x17\x19#g\x13\x00\x00dZ\x958$\x13\x00\x00H:B\xc0g\x13\x00\x00vQH\x95\xed\x12\x00\x00\xd0\xc2\xe9\x8dy\x12\x00\x00\x82$\x07 L\x13\x00\x00\\\xee_\xce\xb0\x12\x00\x00]C\xef\x85\xe6\x12\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x00\xdf\xf63\x16\xdc\x12\x00\x00\x11\xb1\x08^\x87\x13\x00\x00\xea\xd6@\xc0g\x12\x00\x00a\xaax\xa6\xd1\x12\x00\x00j~\x89\n\x8f\x12\x00\x00\x8eY\xa3\x81\r\x13\x00\x00w\xf5h\xe1q\x13\x00\x00\x7ft\xea\x8d\xf9\x12\x00\x00S\xb8q\x93\x90\x13\x00\x00\x18\xdb\xfaR\xd9\x12\x00\x00\x17\x86k\x9b\xa3\x12\x00\x00\xbcp\xa9V\x93\x12\x00\x00,\xde\xa9\xf5p\x12\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00bN\x99\xf2U\x13\x00\x00\xc9\xfa\xd4o\x8a\x12\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00W\xd0i\x1f-\x13\x00\x00gl\x8f\xa1\xd9\x12\x00\x00&k$\x8f\xb7\x12\x00\x00\xa2I\x06\xe2\x90\x13\x00\x00\xfdq\x14i\xb5\x12\x00\x00\x8dS\xa5^&\x13\x00\x00\xb6\xea\xd7\xad\xc5\x13\x00\x00\\\x8c\x82\xf7M\x13\x00\x00\xa3\x00sp)\x13\x00\x00.\xd7Y\xf9*\x13\x00\x00\xcd\xb0\xef$\xc4\x12\x00\x00yP\xf6\xbb\x8e\x13\x00\x00\xb1\xf2y\x83j\x12\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x00\x11bw\xc98\x13\x00\x00c\x05\x06\x81\xee\x12\x00\x00\xf1\xed\xe6r\xa5\x12\x00\x00f\xb5"\x13A\x13\x00\x00Y+\xf7\xf9I\x13\x00\x00\x9c8^R:\x13\x00\x00S\xb8q\x93\x90\x13\x00\x00x]D\xdb\xbb\x12\x00\x00|\x13_\x90\xf5\x12\x00\x00\xca\x9e\xf5\xbb\x0e\x13\x00\x00D5\x96v\xdf\x12\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00)\xcc\xaf\x8c\xbb\x12\x00\x00d\xa9&\xcdr\x13\x00\x00\xb5F\xb7aA\x13\x00\x00\xfd\x0f7\x92R\x13\x00\x00\xf7\x9c\xb1+\x99\x13\x00\x00#\n\x99\x91\xb3\x12\x00\x00MX8o\xeb\x12\x00\x00$_(I\xe9\x12\x00\x00MX8o\xeb\x12\x00\x00\x0fi\xc7\xc5~\x12\x00\x00cT\x97\x15=\x13\x00\x00\xd7\xd9\x8f@\xb7\x12\x00\x00\x14\x12\x94[\x8b\x13\x00\x00\xaa*ee{\x12\x00\x00\xad)\x13\x8c\x1c\x13\x00\x00%\x16\x95\xd7\x81\x12\x00\x00\x190\x8a\n\x0f\x13\x00\x00\x1a\x85\x19\xc2D\x13\x00\x00"\xa2\xbd\x97i\x13\x00\x00\xf6\xa9\xffJ\xc6\x12\x00\x00\x96vGW2\x13\x00\x00#\xf7LO\x9f\x13\x00\x00cT\x97\x15=\x13\x00\x00\x14\xc3\x02\xc7<\x13\x00\x00\x06\xe4G\xf6\x0f\x13\x00\x00;\xb0\x16\xa7p\x13\x00\x00$_(I\xe9\x12\x00\x00\xe4\x01\xde\x82K\x13\x00\x00\x999\xb0+\x99\x12\x00\x00\n\x9ab\xabI\x13\x00\x00wWF\xb8\xd4\x12\x00\x008O\x8b\xa9l\x13\x00\x00\xba\xb3>\xa5\x13\x13\x00\x00\xa5\xbd\xdd!\xa9\x12\x00\x00\xa6\xc3\xdbD\x90\x12\x00\x00\x83\xc8\'l\xd0\x13\x00\x00s\xddpU\xd5\x13\x00\x00+\xd8\xab\xd2\x89\x12\x00\x00\x1a\x85\x19\xc2D\x13\x00\x00\xfdq\x14i\xb5\x12\x00\x00\x13ns\x0f\x07\x13\x00\x00K\xae\x19\x00\x80\x12\x00\x00\xf0\x98W\xbbo\x12\x00\x00\x04\x89\xba\x1b\xf3\x12\x00\x00\x19\xce\xac3\xac\x13\x00\x00h#\xfc/r\x12\x00\x00X8E\x19w\x12\x00\x007I\x8d\x86\x85\x13\x00\x00Q]\xe4\xb8s\x13\x00\x00:\x0c\xf6Z\xec\x12\x00\x00s?N,8\x13\x00\x00\x88H\xfb\xf1\xb6\x12\x00\x00\xe7bi\x80O\x13\x00\x00>\x11\xa2\xa4t\x13\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00\xee*~\x9e>\x13\x00\x00\x0f\x07\xea\xee\x1b\x13\x00\x00\xf0\x85\x0by[\x13\x00\x00<\xc9`\x0cl\x12\x00\x00/\x8e\xc6\x87\xc3\x12\x00\x00\x9e\xe2|\xc1\xa5\x13\x00\x00^6\xa1f\xb9\x13\x00\x00\xd7w\xb2iT\x13\x00\x00\x11bw\xc98\x13\x00\x00\xa9s\xf8\xd6\xe2\x12\x00\x00\xa9$gB\x94\x12\x00\x00\xa2I\x06\xe2\x90\x13\x00\x00\x9c8^R:\x13\x00\x00\x8d\x04\x14\xca\xd7\x12\x00\x00\x81\x1e\t\xfdd\x13\x00\x00\xbcp\xa9V\x93\x12\x00\x00,\xde\xa9\xf5p\x12\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x00,\xde\xa9\xf5p\x12\x00\x00\x05\x8f\xb8>\xda\x12\x00\x00\x1a\xe7\xf6\x98\xa7\x12\x00\x00\x14tq2\xee\x12\x00\x00E;\x94\x99\xc6\x12\x00\x00bN\x99\xf2U\x13\x00\x00\xc3\x87O\t\xd1\x12\x00\x00\xdc\xe49\xad&\x13\x00\x00\xfed\xc6I\x88\x13\x00\x00\xc8\x92\xf9u@\x13\x00\x00MX8o\xeb\x12\x00\x00\xc0&\xc4\x0b\xcd\x12\x00\x00>\x11\xa2\xa4t\x13\x00\x00\x1fA2\x9ae\x13\x00\x00\x9b\x81\xf1\xc3\xa1\x13\x00\x00\xd2\x1dwh\x96\x12\x00\x00:\xbdd\xc6\x9d\x12\x00\x00\xe3\xacN\xcb\x15\x13\x00\x00\xb3\x9c\x98\xf2\xd5\x12\x00\x00\x92\xad\xe0_\xe4\x13\x00\x00s?N,8\x13\x00\x00\xaa\xb5;L\x04\x14\x00\x00s?N,8\x13\x00\x00\xa3bPG\x8c\x12\x00\x00[7\xf3?\x18\x13\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x00\x88\xe6\x1d\x1bT\x13\x00\x00bN\x99\xf2U\x13\x00\x00\xac\xd4\x83\xd4\xe6\x12\x00\x00\xbcp\xa9V\x93\x12\x00\x00\xd4\x16\'lP\x13\x00\x00\xdf\xf63\x16\xdc\x12\x00\x008\x00\xfa\x14\x1e\x13\x00\x00Q]\xe4\xb8s\x13\x00\x00"\xb5\t\xda}\x12\x00\x00.97\xd0\x8d\x12\x00\x00\xe1>u\xae\xe4\x13\x00\x00R\x01\x05\x05\xf8\x13\x00\x00,-;\x8a\xbf\x12\x00\x00\xc4\xdc\xde\xc0\x06\x13\x00\x00]C\xef\x85\xe6\x12\x00\x00>$\xee\xe6\x88\x12\x00\x00\xfdq\x14i\xb5\x12\x00\x00\x13\x0c\x968\xa4\x13\x00\x00\x9d\xdc~\x9e\xbe\x13\x00\x00C/\x98S\xf8\x12\x00\x00gl\x8f\xa1\xd9\x12\x00\x00\x9d\x8d\xed\tp\x13\x00\x00\xb2G\t;\xa0\x12\x00\x00\xd7\xd9\x8f@\xb7\x12\x00\x00O\x02W\xdeV\x13\x00\x00\xfb\xb4\xa9\xb75\x13\x00\x00\x14\x12\x94[\x8b\x13\x00\x00\xb7\xb4\x90~r\x12\x00\x00\x9d\xa09L\x84\x12\x00\x00D5\x96v\xdf\x12\x00\x00\x81\x80\xe6\xd3\xc7\x12\x00\x00x]D\xdb\xbb\x12\x00\x00\x93dM\xee|\x13\x00\x00)\xb9cJ\xa7\x13\x00\x00\x91\xba.\x7f\x11\x13\x00\x00\xffj\xc4lo\x13\x00\x00`B\x9d\xac\x87\x13\x00\x00f\xb5"\x13A\x13\x00\x00\x8bG\xa9\x18X\x13\x00\x00\xdfE\xc5\xaa*\x13\x00\x00\x81\x80\xe6\xd3\xc7\x12\x00\x00\x06F%\xcdr\x12\x00\x00\xee\x8c[u\xa1\x12\x00\x00"\x04\x9bn\xcc\x12\x00\x00`\xa4z\x83\xea\x12\x00\x00\x1f\xa3\x0fq\xc8\x12\x00\x00\x81\x80\xe6\xd3\xc7\x12\x00\x00u\xe9l\x9b\xa3\x13\x00\x00\x8d\x04\x14\xca\xd7\x12\x00\x00\xbf \xc6\xe8\xe5\x12\x00\x00\xfd\x0f7\x92R\x13\x00\x00\xa2\xfatMB\x13\x00\x00s?N,8\x13\x00\x00E;\x94\x99\xc6\x12\x00\x00\x7f%Y\xf9\xaa\x12\x00\x00\x1a\xe7\xf6\x98\xa7\x12\x00\x00;\xb0\x16\xa7p\x13\x00\x00\xb6\xea\xd7\xad\xc5\x13\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00\xcc\x97\xa5\xbf\xc8\x13\x00\x00\xb1A\x0b\x18\xb9\x12\x00\x00:[\x87\xef:\x13\x00\x00\x08?\xd5\xd0,\x13\x00\x00\'\xadg\x04\xd9\x13\x00\x00\xe0\x9aTb`\x13\x00\x00e\xfe\xb5\x84\xa8\x13\x00\x00\xd1\x17yE\xaf\x12\x00\x00-\x82\xcaA\xf5\x12\x00\x00\x16m!6\xa8\x13\x00\x00\xff\xb9U\x01\xbe\x13\x00\x00\xbdv\xa7yz\x12\x00\x00\xb6\xea\xd7\xad\xc5\x13\x00\x00\x11\x13\xe64\xea\x12\x00\x00\xb4@\xb9>Z\x13\x00\x00\xdd\x9b\xa6;\xbf\x12\x00\x00\x8bG\xa9\x18X\x13\x00\x00ba\xe54j\x12\x00\x00\x86<\xff\xab\xe8\x12\x00\x007\\\xd9\xc8\x99\x12\x00\x00\xf0\xd4\x9c\r\xaa\x13\x00\x00\xf35(\x0b\xae\x13\x00\x00\x86<\xff\xab\xe8\x12\x00\x00\xdc\xe49\xad&\x13\x00\x00\x063\xd9\x8a^\x13\x00\x00B)\x9a0\x11\x13\x00\x00^\xfa[\x14\x7f\x12\x00\x00\xb6L\xb5\x84(\x13\x00\x00\xdd9\xc9d\\\x13\x00\x00Y\x8d\xd4\xd0\xac\x12\x00\x00d\xa9&\xcdr\x13\x00\x00V{\xdag\xf7\x12\x00\x00\xf6G"tc\x13\x00\x00X%\xf9\xd6b\x13\x00\x00\x95pI4K\x13\x00\x00\xbfoW}4\x13\x00\x00\xec\x1e\x82Xp\x13\x00\x00\xfd\x0f7\x92R\x13\x00\x00MX8o\xeb\x12\x00\x00\xca\xed\x86P]\x13\x00\x00\x16\xcf\xfe\x0c\x0b\x13\x00\x00yP\xf6\xbb\x8e\x13\x00\x00MX8o\xeb\x12\x00\x00\xb5\x95H\xf6\x8f\x13\x00\x00\xb3M\x07^\x87\x12\x00\x00\xae\xcd3\xd8\xa0\x13\x00\x00\x8b\xe5\xcbA\xf5\x13\x00\x00\xb7\xa1D<^\x13\x00\x00MX8o\xeb\x12\x00\x00\x8b\xf8\x17\x84\t\x13\x00\x00\xe1>u\xae\xe4\x13\x00\x00Y+\xf7\xf9I\x13\x00\x00<\xc9`\x0cl\x12\x00\x00,-;\x8a\xbf\x12\x00\x00\xad)\x13\x8c\x1c\x13\x00\x00\x95!\xb8\x9f\xfc\x12\x00\x00\x90\x03\xc2\xf0x\x13\x00\x00\x80z\xe8\xb0\xe0\x12\x00\x00U\x13\xffm\xad\x13\x00\x00{\xbe\xcf\xd8\xbf\x12\x00\x00\xc9\xe7\x88-v\x13\x00\x00d\xa9&\xcdr\x13\x00\x00c\xb6t\xec\x9f\x12\x00\x00\xd5\xbaG\xb8\xd4\x13\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\x86\xda!\xd5\x85\x13\x00\x00a\xaax\xa6\xd1\x12\x00\x00N\xfcX\xbbo\x13\x00\x00\xec\x1e\x82Xp\x13\x00\x00\xee*~\x9e>\x13\x00\x00e\xaf$\xf0Y\x13\x00\x00\xfck\x16F\xce\x12\x00\x00;\x12\xf4}\xd3\x12\x00\x00@\x7f{\xc1\xa5\x12\x00\x00\x1c\x91\x15\x08\x13\x13\x00\x00\xf6\xa9\xffJ\xc6\x12\x00\x00\xeds\x11\x10\xa6\x13\x00\x00E(HW\xb2\x13\x00\x00\xc4\xc9\x92~\xf2\x13\x00\x00\xc3\x87O\t\xd1\x12\x00\x00\x02\xdf\x9b\xac\x87\x12\x00\x00&\tG\xb8T\x13\x00\x00=\xbc\x12\xed>\x13\x00\x00\x06\x95\xb6a\xc1\x12\x00\x00\xdd9\xc9d\\\x13\x00\x00\xe5Vm:\x81\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00<\xb6\x14\xcaW\x13\x00\x00\xfbe\x18#\xe7\x12\x00\x00\x8cM\xa7;?\x13\x00\x00<\xc9`\x0cl\x12\x00\x00\xbfoW}4\x13\x00\x00\xa0\x9f\xe7r%\x13\x00\x00\x9d\xdc~\x9e\xbe\x13\x00\x00\x08?\xd5\xd0,\x13\x00\x00\xdd9\xc9d\\\x13\x00\x00\x11bw\xc98\x13\x00\x00?\xc8\x0e3\r\x13\x00\x00\xe1\x020\\\xaa\x12\x00\x00\x83y\x96\xd7\x81\x13\x00\x00@\x7f{\xc1\xa5\x12\x00\x00\xc1\xdd0\x9ae\x12\x00\x00\xc9\x85\xabV\x13\x14\x00\x008\xb1h\x80\xcf\x12\x00\x00\x1f\x90\xc3.\xb4\x13\x00\x00\xf7\xebB\xc0\xe7\x13\x00\x00\xca\x9e\xf5\xbb\x0e\x13\x00\x005\x9fn\x17\x1a\x13\x00\x00p@\xa0\x05\x97\x12\x00\x00\x84\x7f\x94\xfah\x13\x00\x00s?N,8\x13\x00\x00"\xa2\xbd\x97i\x13\x00\x00\x92q\x9b\r\xaa\x12\x00\x007\xabj]\xe8\x12\x00\x00U\xc4m\xd9^\x13\x00\x00\xf6G"tc\x13\x00\x00d\xf8\xb7a\xc1\x13\x00\x00Rc\xe2\xdbZ\x13\x00\x00j\t`\xf1\x17\x14\x00\x00\xfdq\x14i\xb5\x12\x00\x00^\x852\xfb\x07\x14\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x00\xd7df\'@\x14\x00\x00uKJr\x06\x13\x00\x00\xcdN\x12Na\x13\x00\x00\x13\x0c\x968\xa4\x13\x00\x00O\x02W\xdeV\x13\x00\x00V\x19\xfd\x90\x94\x13\x00\x00bN\x99\xf2U\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xcc[`m\x8e\x12\x00\x00\xda\xd8=gX\x13\x00\x00\xf3\x97\x05\xe2\x10\x13\x00\x00MX8o\xeb\x12\x00\x00\x00q\xc2\x8fV\x13\x00\x00d\xa9&\xcdr\x13\x00\x00Rc\xe2\xdbZ\x13\x00\x00np\xe9\x11\x03\x14\x00\x00\xcd\xec4w\xfe\x13\x00\x00\xf4\x9d\x03\x05\xf8\x12\x00\x00\xd9\x83\xae\xaf"\x13\x00\x00 \xe5R\xe6\xe9\x13\x00\x00\xd8jdJ\'\x14\x00\x00\x85rF\xdb;\x14\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x00PW\xe6\x95\x8c\x13\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00W\xd0i\x1f-\x13\x00\x00\xcfZ\x0e\x94/\x13\x00\x00\x999\xb0+\x99\x12\x00\x00<\x05\xa6^\xa6\x13\x00\x00\xb1\xdf-AV\x13\x00\x00\xbcp\xa9V\x93\x12\x00\x00\r\xfb\xed\xa8M\x13\x00\x00\xae\x1c\xc5l\xef\x13\x00\x00\xd5\xbaG\xb8\xd4\x13\x00\x00\x9a,b\x0cl\x13\x00\x00\xcf\xf80\xbd\xcc\x13\x00\x00y\xb2\xd3\x92\xf1\x12\x00\x00Q\x0eS$%\x13\x00\x00\x9d\xa09L\x84\x12\x00\x00\xa1\xa5\xe5\x95\x0c\x13\x00\x00\xfd\x0f7\x92R\x13\x00\x00\xd9!\xd1\xd8\xbf\x13\x00\x00r\x88\xe1\x9d\x9f\x13\x00\x00\x88\xe6\x1d\x1bT\x13\x00\x00]C\xef\x85\xe6\x12\x00\x00s?N,8\x13\x00\x00z\x07cJ\'\x13\x00\x00\n\xe9\xf3?\x98\x13\x00\x00\x92\xad\xe0_\xe4\x13\x00\x00E(HW\xb2\x13\x00\x00A\xd4\ny\xdb\x12\x00\x00H:B\xc0g\x13\x00\x00\xf9\n\x8bH\xca\x12\x00\x00\\\x8c\x82\xf7M\x13\x00\x00l\x15\\7\xe6\x13\x00\x00\x88H\xfb\xf1\xb6\x12\x00\x00d\xa9&\xcdr\x13\x00\x00\xd0\xc2\xe9\x8dy\x12\x00\x00\xcc\x97\xa5\xbf\xc8\x13\x00\x00\xe7\x13\xd8\xeb\x00\x13\x00\x00s?N,8\x13\x00\x00}h\xeeG+\x13\x00\x00\xa0\x01\xc5I\x88\x12\x00\x00\n8\x85\xd4\xe6\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00\xb0(\xc1\xb2\xbd\x13\x00\x00\xc0&\xc4\x0b\xcd\x12\x00\x00\xfck\x16F\xce\x12\x00\x00\xa0\xeex\x07t\x13\x00\x00\x00\xc0S$\xa5\x13\x00\x00\xd8jdJ\'\x14\x00\x00\xe3\xacN\xcb\x15\x13\x00\x00\r\xe8\xa1f9\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xa0\xeex\x07t\x13\x00\x00L\xf0\\u\xa1\x13\x00\x00\xe7\x00\x8c\xa9\xec\x13\x00\x00\xa1\xf4v*[\x13\x00\x00- \xedj\x92\x13\x00\x00$L\xdc\x06\xd5\x13\x00\x00\xad)\x13\x8c\x1c\x13\x00\x00N\xfcX\xbbo\x13\x00\x00\x92q\x9b\r\xaa\x12\x00\x00\x07\x9b\xb4\x84\xa8\x12\x00\x00\x86\xda!\xd5\x85\x13\x00\x00- \xedj\x92\x13\x00\x00\xb0(\xc1\xb2\xbd\x13\x00\x00~[\xa0(\xfe\x13\x00\x00\x9e\x80\x9f\xeaB\x14\x00\x00\xcf\xf80\xbd\xcc\x13\x00\x00\x96c\xfb\x14\x1e\x14\x00\x00\xf7\xebB\xc0\xe7\x13\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00E\xd9\xb6\xc2c\x13\x00\x00\xf35(\x0b\xae\x13\x00\x00\xe08w\x8b\xfd\x13\x00\x00\x1a6\x88-\xf6\x12\x00\x00+\xc5_\x90u\x13\x00\x00\xce\xf22\x9a\xe5\x13\x00\x00H\xd8d\xe9\x04\x14\x00\x00{\xfa\x14+\xfa\x13\x00\x00\x14\xc3\x02\xc7<\x13\x00\x00Y\xb6\xcd\xe0\xd2\x14\x00\x00\x11O+\x87$\x14\x00\x00\xa6N\xb2+\x19\x14\x00\x00u\x87\x8f\xc4@\x14\x00\x00Z\xcf\x17F\xce\x13\x00\x00\xb9\x9a\xf4?\x18\x14\x00\x00\xed\x1149C\x14\x00\x00\x92q\x9b\r\xaa\x12\x00\x00+v\xce\xfb&\x13\x00\x00!:\xe2\x9d\x1f\x14\x00\x00N\x9a{\xe4\x0c\x14\x00\x00.u|"\xc8\x13\x00\x00\x18\x17@\xa5\x13\x14\x00\x00k\xc0\xcc\x7f\xb0\x13\x00\x00E;\x94\x99\xc6\x12\x00\x00\x0b\x8d\x14\x8c\x1c\x14\x00\x00V\x19\xfd\x90\x94\x13\x00\x00 \xf8\x9e(\xfe\x12\x00\x00cT\x97\x15=\x13\x00\x00\x0c\xa6^\xf1\x17\x13\x00\x00\xd3\x10)Ii\x13\x00\x00\x08\x8efe{\x13\x00\x00&k$\x8f\xb7\x12\x00\x00\xad\xc75\xb5\xb9\x13\x00\x00\xb0(\xc1\xb2\xbd\x13\x00\x00\x88\x84@D\xf1\x13\x00\x00\xa7\x18k\xfc\xc5\x12\x00\x00Gp\x89\xef\xba\x14\x00\x00\x16m!6\xa8\x13\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00G\xd2f\xc6\x1d\x14\x00\x00U\xc4m\xd9^\x13\x00\x00\x94\x1b\xba|\x15\x13\x00\x00\x85rF\xdb;\x14\x00\x00\x81\xbc+&\x02\x14\x00\x00\x8cM\xa7;?\x13\x00\x00\xad\x16\xc7I\x08\x14\x00\x00\x84\xce%\x8f\xb7\x13\x00\x00\xa7\xa3A\xe3N\x14\x00\x00\xb6L\xb5\x84(\x13\x00\x003\x80&\x8f7\x14\x00\x00\x9f7\x0cy\xdb\x13\x00\x00w\xa6\xd7L#\x13\x00\x00\xa4\xa4\x93\xbc\xad\x13\x00\x00U\xc4m\xd9^\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00q \x06\xa4U\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xf35(\x0b\xae\x13\x00\x00!:\xe2\x9d\x1f\x14\x00\x00MX8o\xeb\x12\x00\x00\x8f\xae29C\x13\x00\x0031\x95\xfa\xe8\x13\x00\x00\x1d"\xea\x11\x83\x14\x00\x004\x86$\xb2\x1e\x14\x00\x00I\xdeb\x0c\xec\x13\x00\x00c\xb6t\xec\x9f\x12\x00\x00\xc6\x99Ir\x86\x12\x00\x00\xb0\xd9/\x1eo\x13\x00\x00\xaa\xc8\x87\x8e\x18\x13\x00\x00\x9c%\x12\x10&\x14\x00\x00\xca\xed\x86P]\x13\x00\x00\\*\xa5 \xeb\x13\x00\x00\xa9\xfe\xce\xbdk\x14\x00\x00\x95\xd2&\x0b\xae\x12\x00\x00\xe5\xf4\x8fc\x1e\x14\x00\x00\xa8\xa9?\x066\x14\x00\x00D5\x96v\xdf\x12\x00\x00\x9c%\x12\x10&\x14\x00\x00V\xb7\x1f\xba1\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00$_(I\xe9\x12\x00\x00\x91\xf6s\xd1K\x14\x00\x00\xfdq\x14i\xb5\x12\x00\x00N\xad\xc7&!\x13\x00\x00\xc9\x98\xf7\x98\'\x13\x00\x00\x00\xc0S$\xa5\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xb3v\x00n\xad\x14\x00\x00\xb2!q\xb6w\x14\x00\x00\xfc\xa7[\x98\x08\x14\x00\x00\x19\xce\xac3\xac\x13\x00\x00bN\x99\xf2U\x13\x00\x00L\x8e\x7f\x9e>\x14\x00\x00\xfa\x9b_R:\x14\x00\x00\xc3\x87O\t\xd1\x12\x00\x00vQH\x95\xed\x12\x00\x00\x98 f\xc6\x9d\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xdav`\x90\xf5\x13\x00\x00\xbaQa\xce\xb0\x13\x00\x00\xba\xa0\xf2b\xff\x13\x00\x00\x99&d\xe9\x84\x13\x00\x00\xc5\x1e"6(\x14\x00\x00\xa1\xe1*\xe8F\x14\x00\x00\xaekV\x01>\x14\x00\x00\x8c\x9c8\xd0\x8d\x13\x00\x00\xe2\x93\x04f\x1a\x14\x00\x00]\x7f4\xd8 \x14\x00\x00b\xb0v\xc9\xb8\x12\x00\x00\xaa\xb5;L\x04\x14\x00\x00x\xe8\x1a\xc2D\x14\x00\x005\x8c"\xd5\x05\x14\x00\x00\xf7:\xd4T6\x14\x00\x00O\xb3\xc5I\x08\x13\x00\x00\xdd9\xc9d\\\x13\x00\x00L\x8e\x7f\x9e>\x14\x00\x00\xd1\xa2O,8\x14\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x00\xcd\x9d\xa3\xe2\xaf\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\x92\xfcq\xf42\x14\x00\x006\xe1\xb1\x8c;\x14\x00\x00\xd9\x83\xae\xaf"\x13\x00\x00~[\xa0(\xfe\x13\x00\x00\x16\x0bD_E\x14\x00\x00}h\xeeG+\x13\x00\x00\xba\xa0\xf2b\xff\x13\x00\x00\x85rF\xdb;\x14\x00\x00\xda\xc5\xf1$D\x14\x00\x00"@\xe0\xc0\x06\x14\x00\x00MX8o\xeb\x12\x00\x00SV\x94\xbc-\x14\x00\x00\x91XQ\xa8\xae\x13\x00\x00:H;\xad&\x14\x00\x00GG\x90\xdf\x94\x12\x00\x00\xa4B\xb6\xe5J\x14\x00\x00\xc4\x18$\x13A\x14\x00\x00\xc4\x18$\x13A\x14\x00\x00\xd0\xaf\x9dKe\x13\x00\x00e\xaf$\xf0Y\x13\x00\x00\xdd\x9b\xa6;\xbf\x12\x00\x00<\xb6\x14\xcaW\x13\x00\x00eMG\x19\xf7\x13\x00\x00\x03\xbf\x01KF\x14\x00\x00\x05\xdeI\xd3(\x13\x00\x00\xebg\x15\xca\xd7\x13\x00\x00\x16\x0bD_E\x14\x00\x00f\xa2\xd6\xd0,\x14\x00\x00\xb2\xd2\xdf!)\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xb6L\xb5\x84(\x13\x00\x00w\xf5h\xe1q\x13\x00\x00|\x00\x13N\xe1\x13\x00\x00\x0e\xb2Z7\xe6\x12\x00\x00\xbb\xf5\x81\x1a5\x14\x00\x00\xbe\x07|\x83\xea\x13\x00\x00\xbe\x07|\x83\xea\x13\x00\x00\xea\xd6@\xc0g\x12\x00\x00\xd8\xccA!\x8a\x13\x00\x00d\xf8\xb7a\xc1\x13\x00\x00\xdb\x8f\xaa\xf5\xf0\x12\x00\x00G\xd2f\xc6\x1d\x14\x00\x00RP\x96\x99F\x14\x00\x00\x0c\x93\x12\xaf\x03\x14\x00\x00\xff\x1b3\xd8 \x13\x00\x00\xc7y\xaf\x10E\x14\x00\x00|O\xa4\xe2/\x14\x00\x00\xde?\xc7\x87C\x13\x00\x00}U\xa2\x05\x17\x14\x00\x00\xd6\x0f\xd7o\n\x14\x00\x00\xc8\x92\xf9u@\x13\x00\x00\xfc\t9ok\x13\x00\x00%\xa1k\xbe\n\x14\x00\x00\xdf\xe3\xe7\xd3\xc7\x13\x00\x00H\xd8d\xe9\x04\x14\x00\x00\x1d\x84\xc7\xe8\xe5\x13\x00\x00%\xa1k\xbe\n\x14\x00\x00|O\xa4\xe2/\x14\x00\x0047\x93\x1d\xd0\x13\x00\x00g\xa8\xd4\xf3\x13\x14\x00\x00\x9b\x81\xf1\xc3\xa1\x13\x00\x00\xb7\xf0\xd5\xd0\xac\x13\x00\x00|O\xa4\xe2/\x14\x00\x00\xaa\xb5;L\x04\x14\x00\x00\xed7\xcc\xbdk\x12\x00\x00JF>\x066\x13\x00\x00\x9d+\x103\r\x14\x00\x00\xcc\xf9\x82\x96+\x13\x00\x00\xdf\xe3\xe7\xd3\xc7\x13\x00\x00\x16\xcf\xfe\x0c\x0b\x13\x00\x00\x19l\xcf\\I\x14\x00\x00\xbf\xbe\xe8\x11\x83\x13\x00\x00t2\x00\r\x0b\x14\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x00\x99&d\xe9\x84\x13\x00\x00\xd1\xa2O,8\x14\x00\x00\x99&d\xe9\x84\x13\x00\x00m.\xa6\x9c\xe1\x12\x00\x00U\xb1!\x97J\x14\x00\x00{I\xa6\xbfH\x14\x00\x00\xc2n\x05\xa4\xd5\x13\x00\x00g\xa8\xd4\xf3\x13\x14\x00\x00\xd1\x04-\x03\x9b\x13\x00\x00&\xf6\xfau@\x14\x00\x00\xdav`\x90\xf5\x13\x00\x00\xcbB\x16\x08\x93\x13\x00\x00\xfbe\x18#\xe7\x12\x00\x00\xd2Y\xbc\xba\xd0\x13\x00\x00\xc4\x18$\x13A\x14\x00\x00\'^\xd6o\x8a\x13\x00\x00yP\xf6\xbb\x8e\x13\x00\x00\xfbR\xcc\xe0\xd2\x13\x00\x00r&\x04\xc7<\x14\x00\x00r&\x04\xc7<\x14\x00\x00G\xe5\xb2\x082\x13\x00\x00q\x82\xe3z\xb8\x13\x00\x00O\xef\n\x9cB\x14\x00\x00H\xd8d\xe9\x04\x14\x00\x004\x86$\xb2\x1e\x14\x00\x00\x02jr\x93\x10\x14\x00\x00U\xb1!\x97J\x14\x00\x00\x8b\xf8\x17\x84\t\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00$_(I\xe9\x12\x00\x00\xb4\xde\xdbg\xf7\x13\x00\x005\x8c"\xd5\x05\x14\x00\x00^\x852\xfb\x07\x14\x00\x00i\xb4\xd09\xe2\x13\x00\x00\x1c\xe0\xa6\x9ca\x13\x00\x00\xa2\x98\x97v\xdf\x13\x00\x005*E\xfe\xa2\x14\x00\x00\xb7\xf0\xd5\xd0\xac\x13\x00\x00\x9e\xf5\xc8\x03\xba\x12\x00\x00\x95\x0el]\xe8\x13\x00\x00\'^\xd6o\x8a\x13\x00\x00\x1d\x97\x13+\xfa\x12\x00\x00Q\xfb\x06\xe2\x10\x14\x00\x00\xf0\xd4\x9c\r\xaa\x13\x00\x007I\x8d\x86\x85\x13\x00\x00Z\xcf\x17F\xce\x13\x00\x00\xe4\x01\xde\x82K\x13\x00\x00\xe4\x9f\x00\xac\xe8\x13\x00\x00\xa5\xf9"t\xe3\x13\x00\x00\x7f\xb0/\xe03\x14\x00\x00)W\x86sD\x14\x00\x00\xe8hg\xa36\x13\x00\x00h\xfdc\xabI\x14\x00\x00\xd4\x03\xdb)<\x14\x00\x00\xd4\x16\'lP\x13\x00\x00\x03\xbf\x01KF\x14\x00\x00-\xbe\x0f\x94/\x14\x00\x006\xf4\xfd\xceO\x13\x00\x00\xdf\xe3\xe7\xd3\xc7\x13\x00\x001\xd6\x07 \xcc\x13\x00\x00\xf6\x96\xb3\x08\xb2\x13\x00\x00\xd9pbm\x0e\x14\x00\x00\x0b>\x83\xf7\xcd\x13\x00\x00P\xa6w*\xdb\x13\x00\x00\xfed\xc6I\x88\x13\x00\x00\x18\xdb\xfaR\xd9\x12\x00\x00\xf0\xd4\x9c\r\xaa\x13\x00\x00\xa4B\xb6\xe5J\x14\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00\xad\x16\xc7I\x08\x14\x00\x00\x87/\xb1\x8c\xbb\x13\x00\x00\x8f\x9b\xe6\xf6.\x14\x00\x00\x16\xcf\xfe\x0c\x0b\x13\x00\x00\xe0\x9aTb`\x13\x00\x00\xa9`\xac\x94\xce\x13\x00\x00X\xc3\x1b\x00\x00\x14\x00\x00\xbfoW}4\x13\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00u\x87\x8f\xc4@\x14\x00\x00\x18\x17@\xa5\x13\x14\x00\x00\x11\xb1\x08^\x87\x13\x00\x00\xe1\xef\xe3\x19\x96\x13\x00\x00\x10\xbeV}\xb4\x12\x00\x00^6\xa1f\xb9\x13\x00\x00\x13\x0c\x968\xa4\x13\x00\x00q \x06\xa4U\x14\x00\x00j\xba\xce\\\xc9\x13\x00\x0031\x95\xfa\xe8\x13\x00\x00\x1a6\x88-\xf6\x12\x00\x00\xe6\xab\xfc\xf1\xb6\x13\x00\x00\xab\n\xcb\x03:\x14\x00\x00%\xa1k\xbe\n\x14\x00\x00u\x87\x8f\xc4@\x14\x00\x00\xf8\xf1@\xe3\xce\x13\x00\x00\xb3\x89L\xb0\xc1\x13\x00\x00\x80g\x9cn\xcc\x13\x00\x00\xb3\x89L\xb0\xc1\x13\x00\x00_O\xeb\xcb\xb4\x12\x00\x005\x8c"\xd5\x05\x14\x00\x00E\x8a%.\x15\x13\x00\x00\n\xe9\xf3?\x98\x13\x00\x00\xe1\x8d\x06C3\x14\x00\x00yP\xf6\xbb\x8e\x13\x00\x00\xb7\xa1D<^\x13\x00\x00\xc4\xdc\xde\xc0\x06\x13\x00\x00d\xa9&\xcdr\x13\x00\x00\x7f\x12\r\xb7\x96\x13\x00\x003\xe2\x03f\x9a\x13\x00\x00\xdfE\xc5\xaa*\x13\x00\x00\xaa\xb5;L\x04\x14\x00\x00\xb8Ee\x88\xe2\x13\x00\x00\xed7\xcc\xbdk\x12\x00\x00\x81\xcfwh\x16\x13\x00\x00\xbe\xcb61\xb0\x12\x00\x00\x87~B!\n\x14\x00\x00\xbe\x07|\x83\xea\x13\x00\x00\xd0\xc2\xe9\x8dy\x12\x00\x00]C\xef\x85\xe6\x12\x00\x00\x8aT\xf77\x85\x12\x00\x00u\xe9l\x9b\xa3\x13\x00\x005=\x91@\xb7\x13\x00\x00JF>\x066\x13\x00\x00\xb7\xa1D<^\x13\x00\x00\x1b\xed\xf4\xbb\x8e\x12\x00\x00\x01dtp)\x14\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00x\xe8\x1a\xc2D\x14\x00\x00\xe5\xf4\x8fc\x1e\x14\x00\x00\x01\xc6QG\x8c\x13\x00\x00\'^\xd6o\x8a\x13\x00\x00]\x7f4\xd8 \x14\x00\x00\xf7:\xd4T6\x14\x00\x00N\xfcX\xbbo\x13\x00\x00JF>\x066\x13\x00\x00o\'V\xa0\x9b\x13\x00\x00\x99\xc4\x86\x12"\x14\x00\x00cT\x97\x15=\x13\x00\x00P\x08U\x01>\x13\x00\x00\xc8\x92\xf9u@\x13\x00\x002\xdc\x05C\xb3\x13\x00\x00xJ\xf8\x98\xa7\x13\x00\x00!:\xe2\x9d\x1f\x14\x00\x00\r\xfb\xed\xa8M\x13\x00\x00\xde,{E/\x14\x00\x00K9\xf0\xe6\x08\x14\x00\x00\xc2\xbd\x968$\x14\x00\x00\x85#\xb5F\xed\x13\x00\x00=Z5\x16\xdc\x13\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x00x\xe8\x1a\xc2D\x14\x00\x00\xd9pbm\x0e\x14\x00\x00\xf8@\xd2w\x1d\x14\x00\x00\x7f\xb0/\xe03\x14\x00\x00\x00\xc0S$\xa5\x13\x00\x00\xf7:\xd4T6\x14\x00\x00\x9c%\x12\x10&\x14\x00\x00w\x93\x8b\n\x0f\x14\x00\x00\xfbR\xcc\xe0\xd2\x13\x00\x00{\\\xf2\x01]\x13\x00\x00f\xa2\xd6\xd0,\x14\x00\x00\xd8jdJ\'\x14\x00\x00\xf7\xebB\xc0\xe7\x13\x00\x00r&\x04\xc7<\x14\x00\x00x\xe8\x1a\xc2D\x14\x00\x00\xff\x08\xe7\x95\x0c\x14\x00\x00\xe6\xab\xfc\xf1\xb6\x13\x00\x00G\xd2f\xc6\x1d\x14\x00\x00\xb9Kc\xab\xc9\x13\x00\x00\x08\x8efe{\x13\x00\x00\xd2Y\xbc\xba\xd0\x13\x00\x00\x86\xda!\xd5\x85\x13\x00\x00\xa1\xe1*\xe8F\x14\x00\x00V{\xdag\xf7\x12\x00\x00\xe2\x93\x04f\x1a\x14\x00\x00cAK\xd3(\x14\x00\x00JF>\x066\x13\x00\x00\xb9\xfc\xd1\x16{\x13\x00\x00\xa1\xe1*\xe8F\x14\x00\x00\xfd^\xc8&\xa1\x13\x00\x00\xf2~\xbb|\x15\x14\x00\x00P\xa6w*\xdb\x13\x00\x00\x99u\xf5}\xd3\x13\x00\x00RP\x96\x99F\x14\x00\x00\x80g\x9cn\xcc\x13\x00\x00\x84\x1d\xb7#\x06\x14\x00\x00\x86\xda!\xd5\x85\x13\x00\x00\xf4;&.\x95\x13\x00\x00p-T\xc3\x82\x13\x00\x00u\x87\x8f\xc4@\x14\x00\x00%\xa1k\xbe\n\x14\x00\x00#\x95ox<\x14\x00\x00\x9d+\x103\r\x14\x00\x00\x95\xd2&\x0b\xae\x12\x00\x00\xad\x16\xc7I\x08\x14\x00\x002+\x97\xd7\x01\x14\x00\x00\xa5H\xb4\x082\x14\x00\x00\xcf\xf80\xbd\xcc\x13\x00\x00\x1b\x8b\x17\xe5+\x13\x00\x00\xef\x7f\rVt\x13\x00\x00\x0e\xee\x9f\x89 \x14\x00\x00G\xd2f\xc6\x1d\x14\x00\x00G\xd2f\xc6\x1d\x14\x00\x00)\x08\xf5\xde\xf5\x13\x00\x00\x91XQ\xa8\xae\x13\x00\x00\\*\xa5 \xeb\x13\x00\x00\x08\xdd\xf7\xf9\xc9\x13\x00\x00\xa6\xff \x97\xca\x13\x00\x00\xfa\x10\x89k\xb1\x12\x00\x00(d\xd4\x92q\x13\x00\x00f\xa2\xd6\xd0,\x14'
p65
tp66
bsg44
g37
stp67
Rp68
a(lp69
g19
(g20
(I0
tp70
g22
tp71
Rp72
(I1
(I4
I975
tp73
g58
I00
S'\x00\x00\xaa*ee{\x12\x00\x00<\xb6\x14\xcaW\x13\x00\x00.\x88\xc8d\xdc\x12\x00\x00\xe6\xbeH4\xcb\x12\x00\x00;\xb0\x16\xa7p\x13\x00\x00\x9d\xa09L\x84\x12\x00\x00\x1b\xed\xf4\xbb\x8e\x12\x00\x00\xc8Ch\xe1\xf1\x12\x00\x00MX8o\xeb\x12\x00\x00\xff}\x10\xaf\x83\x12\x00\x00\x190\x8a\n\x0f\x13\x00\x00\xff\x1b3\xd8 \x13\x00\x00l(\xa8y\xfa\x12\x00\x00\xef\xe1\xea,\xd7\x12\x00\x00\xd0\xc2\xe9\x8dy\x12\x00\x00MX8o\xeb\x12\x00\x00MX8o\xeb\x12\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00\xddL\x15\xa7p\x12\x00\x00\x11bw\xc98\x13\x00\x00&k$\x8f\xb7\x12\x00\x00&k$\x8f\xb7\x12\x00\x00=\xbc\x12\xed>\x13\x00\x00U&K\xb0\xc1\x12\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\x11bw\xc98\x13\x00\x00\xa1\xa5\xe5\x95\x0c\x13\x00\x00\xf2Bv*\xdb\x12\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\xa3bPG\x8c\x12\x00\x00\x83\xdbs\xae\xe4\x12\x00\x00\xe6\xbeH4\xcb\x12\x00\x00\x15zoU\xd5\x12\x00\x00\x8bG\xa9\x18X\x13\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00\xa8m\xfa\xb3\xfb\x12\x00\x00\x97-\xb4\xe5\xca\x12\x00\x00\xb5F\xb7aA\x13\x00\x00\xe2W\xbf\x13\xe0\x12\x00\x00\xc7\x9fG\x95m\x12\x00\x00\x8b\xf8\x17\x84\t\x13\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00w\xf5h\xe1q\x13\x00\x00\xfd\x0f7\x92R\x13\x00\x00\xbeiYZM\x13\x00\x00\xbcp\xa9V\x93\x12\x00\x00\x8d\x04\x14\xca\xd7\x12\x00\x00`\xa4z\x83\xea\x12\x00\x00\x05@\'\xaa\x8b\x12\x00\x00\xc4>\xbc\x97i\x12\x00\x00T\xd1\xbb\xf8\x8b\x12\x00\x00S\x1aOj\xf3\x12\x00\x00\\\xdb\x13\x8c\x9c\x13\x00\x00V{\xdag\xf7\x12\x00\x00~\x1f[\xd6\xc3\x12\x00\x00t\xa7)&\x82\x12\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00\x11bw\xc98\x13\x00\x00\xacr\xa6\xfd\x83\x13\x00\x00\xec\x1e\x82Xp\x13\x00\x00\xa8m\xfa\xb3\xfb\x12\x00\x00\xa2\xfatMB\x13\x00\x00\xa0\xeex\x07t\x13\x00\x00\x94}\x97Sx\x12\x00\x00.97\xd0\x8d\x12\x00\x00Y+\xf7\xf9I\x13\x00\x00\x97\xcb\xd6\x0eh\x13\x00\x00\x17$\x8e\xc4@\x13\x00\x00(\x15C\xfe"\x13\x00\x00;a\x85\x12"\x13\x00\x00T\xd1\xbb\xf8\x8b\x12\x00\x00\xe9ne\xc6\x1d\x13\x00\x00U&K\xb0\xc1\x12\x00\x00W\xd0i\x1f-\x13\x00\x000\xe3U?\xf9\x12\x00\x00yP\xf6\xbb\x8e\x13\x00\x00\x83y\x96\xd7\x81\x13\x00\x00\x82$\x07 L\x13\x00\x00\x9c8^R:\x13\x00\x00\xffj\xc4lo\x13\x00\x00\x81\x80\xe6\xd3\xc7\x12\x00\x00\xe9ne\xc6\x1d\x13\x00\x00>s\x7f{\xd7\x12\x00\x008b\xd7\xeb\x80\x12\x00\x00\\\xee_\xce\xb0\x12\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00p\xde\xc2.4\x13\x00\x00MX8o\xeb\x12\x00\x00\x19\xe1\xf8u\xc0\x12\x00\x008\x00\xfa\x14\x1e\x13\x00\x00%\x16\x95\xd7\x81\x12\x00\x00\xef\x92Y\x98\x88\x12\x00\x00*\xbfam\x8e\x13\x00\x00\\\xdb\x13\x8c\x9c\x13\x00\x00MX8o\xeb\x12\x00\x00\\\xee_\xce\xb0\x12\x00\x00\\\xee_\xce\xb0\x12\x00\x00\xdf\x94V?y\x13\x00\x00(\xb3e\'\xc0\x13\x00\x00\xce\xa3\xa1\x05\x97\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00d\xa9&\xcdr\x13\x00\x00]\x92\x80\x1a5\x13\x00\x00\xff\x1b3\xd8 \x13\x00\x00\x1e\xec\xa2\xe2/\x13\x00\x00\x99&d\xe9\x84\x13\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00\xc51nx<\x13\x00\x00\xf2\xf3\xe4\x95\x8c\x12\x00\x00\xde\xa1\xa4^\xa6\x12\x00\x00MX8o\xeb\x12\x00\x00\xa2\xab\xe3\xb8\xf3\x12\x00\x009\xb7f\xa3\xb6\x12\x00\x00\xe1>u\xae\xe4\x13\x00\x00\x0fi\xc7\xc5~\x12\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00\xeds\x11\x10\xa6\x13\x00\x00\xb6L\xb5\x84(\x13\x00\x00E;\x94\x99\xc6\x12\x00\x00;\xb0\x16\xa7p\x13\x00\x00\x9d\xdc~\x9e\xbe\x13\x00\x009\xb7f\xa3\xb6\x12\x00\x00\xb2G\t;\xa0\x12\x00\x00\xa2I\x06\xe2\x90\x13\x00\x00Qp0\xfb\x87\x12\x00\x00\x17$\x8e\xc4@\x13\x00\x00\x17$\x8e\xc4@\x13\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\xd1\x17yE\xaf\x12\x00\x00\x95pI4K\x13\x00\x00\xfed\xc6I\x88\x13\x00\x00\xbc\x0e\xcc\x7f0\x13\x00\x00m\xcc\xc8\xc5~\x13\x00\x00a[\xe7\x11\x83\x12\x00\x00\xa9`\xac\x94\xce\x13\x00\x00x\xac\xd5o\n\x13\x00\x00<\xc9`\x0cl\x12\x00\x00a[\xe7\x11\x83\x12\x00\x00x\xac\xd5o\n\x13\x00\x00\x17\x86k\x9b\xa3\x12\x00\x00\xaa\x17\x19#g\x13\x00\x00dZ\x958$\x13\x00\x00H:B\xc0g\x13\x00\x00vQH\x95\xed\x12\x00\x00\xd0\xc2\xe9\x8dy\x12\x00\x00\x82$\x07 L\x13\x00\x00\\\xee_\xce\xb0\x12\x00\x00]C\xef\x85\xe6\x12\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x00\xdf\xf63\x16\xdc\x12\x00\x00\x11\xb1\x08^\x87\x13\x00\x00\xea\xd6@\xc0g\x12\x00\x00a\xaax\xa6\xd1\x12\x00\x00j~\x89\n\x8f\x12\x00\x00\x8eY\xa3\x81\r\x13\x00\x00w\xf5h\xe1q\x13\x00\x00\x7ft\xea\x8d\xf9\x12\x00\x00S\xb8q\x93\x90\x13\x00\x00\x18\xdb\xfaR\xd9\x12\x00\x00\x17\x86k\x9b\xa3\x12\x00\x00\xbcp\xa9V\x93\x12\x00\x00,\xde\xa9\xf5p\x12\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00bN\x99\xf2U\x13\x00\x00\xc9\xfa\xd4o\x8a\x12\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00W\xd0i\x1f-\x13\x00\x00gl\x8f\xa1\xd9\x12\x00\x00&k$\x8f\xb7\x12\x00\x00\xa2I\x06\xe2\x90\x13\x00\x00\xfdq\x14i\xb5\x12\x00\x00\x8dS\xa5^&\x13\x00\x00\xb6\xea\xd7\xad\xc5\x13\x00\x00\\\x8c\x82\xf7M\x13\x00\x00\xa3\x00sp)\x13\x00\x00.\xd7Y\xf9*\x13\x00\x00\xcd\xb0\xef$\xc4\x12\x00\x00yP\xf6\xbb\x8e\x13\x00\x00\xb1\xf2y\x83j\x12\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x00\x11bw\xc98\x13\x00\x00c\x05\x06\x81\xee\x12\x00\x00\xf1\xed\xe6r\xa5\x12\x00\x00f\xb5"\x13A\x13\x00\x00Y+\xf7\xf9I\x13\x00\x00\x9c8^R:\x13\x00\x00S\xb8q\x93\x90\x13\x00\x00x]D\xdb\xbb\x12\x00\x00|\x13_\x90\xf5\x12\x00\x00\xca\x9e\xf5\xbb\x0e\x13\x00\x00D5\x96v\xdf\x12\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00)\xcc\xaf\x8c\xbb\x12\x00\x00d\xa9&\xcdr\x13\x00\x00\xb5F\xb7aA\x13\x00\x00\xfd\x0f7\x92R\x13\x00\x00\xf7\x9c\xb1+\x99\x13\x00\x00#\n\x99\x91\xb3\x12\x00\x00MX8o\xeb\x12\x00\x00$_(I\xe9\x12\x00\x00MX8o\xeb\x12\x00\x00\x0fi\xc7\xc5~\x12\x00\x00cT\x97\x15=\x13\x00\x00\xd7\xd9\x8f@\xb7\x12\x00\x00\x14\x12\x94[\x8b\x13\x00\x00\xaa*ee{\x12\x00\x00\xad)\x13\x8c\x1c\x13\x00\x00%\x16\x95\xd7\x81\x12\x00\x00\x190\x8a\n\x0f\x13\x00\x00\x1a\x85\x19\xc2D\x13\x00\x00"\xa2\xbd\x97i\x13\x00\x00\xf6\xa9\xffJ\xc6\x12\x00\x00\x96vGW2\x13\x00\x00#\xf7LO\x9f\x13\x00\x00cT\x97\x15=\x13\x00\x00\x14\xc3\x02\xc7<\x13\x00\x00\x06\xe4G\xf6\x0f\x13\x00\x00;\xb0\x16\xa7p\x13\x00\x00$_(I\xe9\x12\x00\x00\xe4\x01\xde\x82K\x13\x00\x00\x999\xb0+\x99\x12\x00\x00\n\x9ab\xabI\x13\x00\x00wWF\xb8\xd4\x12\x00\x008O\x8b\xa9l\x13\x00\x00\xba\xb3>\xa5\x13\x13\x00\x00\xa5\xbd\xdd!\xa9\x12\x00\x00\xa6\xc3\xdbD\x90\x12\x00\x00\x83\xc8\'l\xd0\x13\x00\x00s\xddpU\xd5\x13\x00\x00+\xd8\xab\xd2\x89\x12\x00\x00\x1a\x85\x19\xc2D\x13\x00\x00\xfdq\x14i\xb5\x12\x00\x00\x13ns\x0f\x07\x13\x00\x00K\xae\x19\x00\x80\x12\x00\x00\xf0\x98W\xbbo\x12\x00\x00\x04\x89\xba\x1b\xf3\x12\x00\x00\x19\xce\xac3\xac\x13\x00\x00h#\xfc/r\x12\x00\x00X8E\x19w\x12\x00\x007I\x8d\x86\x85\x13\x00\x00Q]\xe4\xb8s\x13\x00\x00:\x0c\xf6Z\xec\x12\x00\x00s?N,8\x13\x00\x00\x88H\xfb\xf1\xb6\x12\x00\x00\xe7bi\x80O\x13\x00\x00>\x11\xa2\xa4t\x13\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00\xee*~\x9e>\x13\x00\x00\x0f\x07\xea\xee\x1b\x13\x00\x00\xf0\x85\x0by[\x13\x00\x00<\xc9`\x0cl\x12\x00\x00/\x8e\xc6\x87\xc3\x12\x00\x00\x9e\xe2|\xc1\xa5\x13\x00\x00^6\xa1f\xb9\x13\x00\x00\xd7w\xb2iT\x13\x00\x00\x11bw\xc98\x13\x00\x00\xa9s\xf8\xd6\xe2\x12\x00\x00\xa9$gB\x94\x12\x00\x00\xa2I\x06\xe2\x90\x13\x00\x00\x9c8^R:\x13\x00\x00\x8d\x04\x14\xca\xd7\x12\x00\x00\x81\x1e\t\xfdd\x13\x00\x00\xbcp\xa9V\x93\x12\x00\x00,\xde\xa9\xf5p\x12\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x00,\xde\xa9\xf5p\x12\x00\x00\x05\x8f\xb8>\xda\x12\x00\x00\x1a\xe7\xf6\x98\xa7\x12\x00\x00\x14tq2\xee\x12\x00\x00E;\x94\x99\xc6\x12\x00\x00bN\x99\xf2U\x13\x00\x00\xc3\x87O\t\xd1\x12\x00\x00\xdc\xe49\xad&\x13\x00\x00\xfed\xc6I\x88\x13\x00\x00\xc8\x92\xf9u@\x13\x00\x00MX8o\xeb\x12\x00\x00\xc0&\xc4\x0b\xcd\x12\x00\x00>\x11\xa2\xa4t\x13\x00\x00\x1fA2\x9ae\x13\x00\x00\x9b\x81\xf1\xc3\xa1\x13\x00\x00\xd2\x1dwh\x96\x12\x00\x00:\xbdd\xc6\x9d\x12\x00\x00\xe3\xacN\xcb\x15\x13\x00\x00\xb3\x9c\x98\xf2\xd5\x12\x00\x00\x92\xad\xe0_\xe4\x13\x00\x00s?N,8\x13\x00\x00\xaa\xb5;L\x04\x14\x00\x00s?N,8\x13\x00\x00\xa3bPG\x8c\x12\x00\x00[7\xf3?\x18\x13\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x00\x88\xe6\x1d\x1bT\x13\x00\x00bN\x99\xf2U\x13\x00\x00\xac\xd4\x83\xd4\xe6\x12\x00\x00\xbcp\xa9V\x93\x12\x00\x00\xd4\x16\'lP\x13\x00\x00\xdf\xf63\x16\xdc\x12\x00\x008\x00\xfa\x14\x1e\x13\x00\x00Q]\xe4\xb8s\x13\x00\x00"\xb5\t\xda}\x12\x00\x00.97\xd0\x8d\x12\x00\x00\xe1>u\xae\xe4\x13\x00\x00R\x01\x05\x05\xf8\x13\x00\x00,-;\x8a\xbf\x12\x00\x00\xc4\xdc\xde\xc0\x06\x13\x00\x00]C\xef\x85\xe6\x12\x00\x00>$\xee\xe6\x88\x12\x00\x00\xfdq\x14i\xb5\x12\x00\x00\x13\x0c\x968\xa4\x13\x00\x00\x9d\xdc~\x9e\xbe\x13\x00\x00C/\x98S\xf8\x12\x00\x00gl\x8f\xa1\xd9\x12\x00\x00\x9d\x8d\xed\tp\x13\x00\x00\xb2G\t;\xa0\x12\x00\x00\xd7\xd9\x8f@\xb7\x12\x00\x00O\x02W\xdeV\x13\x00\x00\xfb\xb4\xa9\xb75\x13\x00\x00\x14\x12\x94[\x8b\x13\x00\x00\xb7\xb4\x90~r\x12\x00\x00\x9d\xa09L\x84\x12\x00\x00D5\x96v\xdf\x12\x00\x00\x81\x80\xe6\xd3\xc7\x12\x00\x00x]D\xdb\xbb\x12\x00\x00\x93dM\xee|\x13\x00\x00)\xb9cJ\xa7\x13\x00\x00\x91\xba.\x7f\x11\x13\x00\x00\xffj\xc4lo\x13\x00\x00`B\x9d\xac\x87\x13\x00\x00f\xb5"\x13A\x13\x00\x00\x8bG\xa9\x18X\x13\x00\x00\xdfE\xc5\xaa*\x13\x00\x00\x81\x80\xe6\xd3\xc7\x12\x00\x00\x06F%\xcdr\x12\x00\x00\xee\x8c[u\xa1\x12\x00\x00"\x04\x9bn\xcc\x12\x00\x00`\xa4z\x83\xea\x12\x00\x00\x1f\xa3\x0fq\xc8\x12\x00\x00\x81\x80\xe6\xd3\xc7\x12\x00\x00u\xe9l\x9b\xa3\x13\x00\x00\x8d\x04\x14\xca\xd7\x12\x00\x00\xbf \xc6\xe8\xe5\x12\x00\x00\xfd\x0f7\x92R\x13\x00\x00\xa2\xfatMB\x13\x00\x00s?N,8\x13\x00\x00E;\x94\x99\xc6\x12\x00\x00\x7f%Y\xf9\xaa\x12\x00\x00\x1a\xe7\xf6\x98\xa7\x12\x00\x00;\xb0\x16\xa7p\x13\x00\x00\xb6\xea\xd7\xad\xc5\x13\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00\xcc\x97\xa5\xbf\xc8\x13\x00\x00\xb1A\x0b\x18\xb9\x12\x00\x00:[\x87\xef:\x13\x00\x00\x08?\xd5\xd0,\x13\x00\x00\'\xadg\x04\xd9\x13\x00\x00\xe0\x9aTb`\x13\x00\x00e\xfe\xb5\x84\xa8\x13\x00\x00\xd1\x17yE\xaf\x12\x00\x00-\x82\xcaA\xf5\x12\x00\x00\x16m!6\xa8\x13\x00\x00\xff\xb9U\x01\xbe\x13\x00\x00\xbdv\xa7yz\x12\x00\x00\xb6\xea\xd7\xad\xc5\x13\x00\x00\x11\x13\xe64\xea\x12\x00\x00\xb4@\xb9>Z\x13\x00\x00\xdd\x9b\xa6;\xbf\x12\x00\x00\x8bG\xa9\x18X\x13\x00\x00ba\xe54j\x12\x00\x00\x86<\xff\xab\xe8\x12\x00\x007\\\xd9\xc8\x99\x12\x00\x00\xf0\xd4\x9c\r\xaa\x13\x00\x00\xf35(\x0b\xae\x13\x00\x00\x86<\xff\xab\xe8\x12\x00\x00\xdc\xe49\xad&\x13\x00\x00\x063\xd9\x8a^\x13\x00\x00B)\x9a0\x11\x13\x00\x00^\xfa[\x14\x7f\x12\x00\x00\xb6L\xb5\x84(\x13\x00\x00\xdd9\xc9d\\\x13\x00\x00Y\x8d\xd4\xd0\xac\x12\x00\x00d\xa9&\xcdr\x13\x00\x00V{\xdag\xf7\x12\x00\x00\xf6G"tc\x13\x00\x00X%\xf9\xd6b\x13\x00\x00\x95pI4K\x13\x00\x00\xbfoW}4\x13\x00\x00\xec\x1e\x82Xp\x13\x00\x00\xfd\x0f7\x92R\x13\x00\x00MX8o\xeb\x12\x00\x00\xca\xed\x86P]\x13\x00\x00\x16\xcf\xfe\x0c\x0b\x13\x00\x00yP\xf6\xbb\x8e\x13\x00\x00MX8o\xeb\x12\x00\x00\xb5\x95H\xf6\x8f\x13\x00\x00\xb3M\x07^\x87\x12\x00\x00\xae\xcd3\xd8\xa0\x13\x00\x00\x8b\xe5\xcbA\xf5\x13\x00\x00\xb7\xa1D<^\x13\x00\x00MX8o\xeb\x12\x00\x00\x8b\xf8\x17\x84\t\x13\x00\x00\xe1>u\xae\xe4\x13\x00\x00Y+\xf7\xf9I\x13\x00\x00<\xc9`\x0cl\x12\x00\x00,-;\x8a\xbf\x12\x00\x00\xad)\x13\x8c\x1c\x13\x00\x00\x95!\xb8\x9f\xfc\x12\x00\x00\x90\x03\xc2\xf0x\x13\x00\x00\x80z\xe8\xb0\xe0\x12\x00\x00U\x13\xffm\xad\x13\x00\x00{\xbe\xcf\xd8\xbf\x12\x00\x00\xc9\xe7\x88-v\x13\x00\x00d\xa9&\xcdr\x13\x00\x00c\xb6t\xec\x9f\x12\x00\x00\xd5\xbaG\xb8\xd4\x13\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\x86\xda!\xd5\x85\x13\x00\x00a\xaax\xa6\xd1\x12\x00\x00N\xfcX\xbbo\x13\x00\x00\xec\x1e\x82Xp\x13\x00\x00\xee*~\x9e>\x13\x00\x00e\xaf$\xf0Y\x13\x00\x00\xfck\x16F\xce\x12\x00\x00;\x12\xf4}\xd3\x12\x00\x00@\x7f{\xc1\xa5\x12\x00\x00\x1c\x91\x15\x08\x13\x13\x00\x00\xf6\xa9\xffJ\xc6\x12\x00\x00\xeds\x11\x10\xa6\x13\x00\x00E(HW\xb2\x13\x00\x00\xc4\xc9\x92~\xf2\x13\x00\x00\xc3\x87O\t\xd1\x12\x00\x00\x02\xdf\x9b\xac\x87\x12\x00\x00&\tG\xb8T\x13\x00\x00=\xbc\x12\xed>\x13\x00\x00\x06\x95\xb6a\xc1\x12\x00\x00\xdd9\xc9d\\\x13\x00\x00\xe5Vm:\x81\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00<\xb6\x14\xcaW\x13\x00\x00\xfbe\x18#\xe7\x12\x00\x00\x8cM\xa7;?\x13\x00\x00<\xc9`\x0cl\x12\x00\x00\xbfoW}4\x13\x00\x00\xa0\x9f\xe7r%\x13\x00\x00\x9d\xdc~\x9e\xbe\x13\x00\x00\x08?\xd5\xd0,\x13\x00\x00\xdd9\xc9d\\\x13\x00\x00\x11bw\xc98\x13\x00\x00?\xc8\x0e3\r\x13\x00\x00\xe1\x020\\\xaa\x12\x00\x00\x83y\x96\xd7\x81\x13\x00\x00@\x7f{\xc1\xa5\x12\x00\x00\xc1\xdd0\x9ae\x12\x00\x00\xc9\x85\xabV\x13\x14\x00\x008\xb1h\x80\xcf\x12\x00\x00\x1f\x90\xc3.\xb4\x13\x00\x00\xf7\xebB\xc0\xe7\x13\x00\x00\xca\x9e\xf5\xbb\x0e\x13\x00\x005\x9fn\x17\x1a\x13\x00\x00p@\xa0\x05\x97\x12\x00\x00\x84\x7f\x94\xfah\x13\x00\x00s?N,8\x13\x00\x00"\xa2\xbd\x97i\x13\x00\x00\x92q\x9b\r\xaa\x12\x00\x007\xabj]\xe8\x12\x00\x00U\xc4m\xd9^\x13\x00\x00\xf6G"tc\x13\x00\x00d\xf8\xb7a\xc1\x13\x00\x00Rc\xe2\xdbZ\x13\x00\x00j\t`\xf1\x17\x14\x00\x00\xfdq\x14i\xb5\x12\x00\x00^\x852\xfb\x07\x14\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x00\xd7df\'@\x14\x00\x00uKJr\x06\x13\x00\x00\xcdN\x12Na\x13\x00\x00\x13\x0c\x968\xa4\x13\x00\x00O\x02W\xdeV\x13\x00\x00V\x19\xfd\x90\x94\x13\x00\x00bN\x99\xf2U\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xcc[`m\x8e\x12\x00\x00\xda\xd8=gX\x13\x00\x00\xf3\x97\x05\xe2\x10\x13\x00\x00MX8o\xeb\x12\x00\x00\x00q\xc2\x8fV\x13\x00\x00d\xa9&\xcdr\x13\x00\x00Rc\xe2\xdbZ\x13\x00\x00np\xe9\x11\x03\x14\x00\x00\xcd\xec4w\xfe\x13\x00\x00\xf4\x9d\x03\x05\xf8\x12\x00\x00\xd9\x83\xae\xaf"\x13\x00\x00 \xe5R\xe6\xe9\x13\x00\x00\xd8jdJ\'\x14\x00\x00\x85rF\xdb;\x14\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x00PW\xe6\x95\x8c\x13\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00W\xd0i\x1f-\x13\x00\x00\xcfZ\x0e\x94/\x13\x00\x00\x999\xb0+\x99\x12\x00\x00<\x05\xa6^\xa6\x13\x00\x00\xb1\xdf-AV\x13\x00\x00\xbcp\xa9V\x93\x12\x00\x00\r\xfb\xed\xa8M\x13\x00\x00\xae\x1c\xc5l\xef\x13\x00\x00\xd5\xbaG\xb8\xd4\x13\x00\x00\x9a,b\x0cl\x13\x00\x00\xcf\xf80\xbd\xcc\x13\x00\x00y\xb2\xd3\x92\xf1\x12\x00\x00Q\x0eS$%\x13\x00\x00\x9d\xa09L\x84\x12\x00\x00\xa1\xa5\xe5\x95\x0c\x13\x00\x00\xfd\x0f7\x92R\x13\x00\x00\xd9!\xd1\xd8\xbf\x13\x00\x00r\x88\xe1\x9d\x9f\x13\x00\x00\x88\xe6\x1d\x1bT\x13\x00\x00]C\xef\x85\xe6\x12\x00\x00s?N,8\x13\x00\x00z\x07cJ\'\x13\x00\x00\n\xe9\xf3?\x98\x13\x00\x00\x92\xad\xe0_\xe4\x13\x00\x00E(HW\xb2\x13\x00\x00A\xd4\ny\xdb\x12\x00\x00H:B\xc0g\x13\x00\x00\xf9\n\x8bH\xca\x12\x00\x00\\\x8c\x82\xf7M\x13\x00\x00l\x15\\7\xe6\x13\x00\x00\x88H\xfb\xf1\xb6\x12\x00\x00d\xa9&\xcdr\x13\x00\x00\xd0\xc2\xe9\x8dy\x12\x00\x00\xcc\x97\xa5\xbf\xc8\x13\x00\x00\xe7\x13\xd8\xeb\x00\x13\x00\x00s?N,8\x13\x00\x00}h\xeeG+\x13\x00\x00\xa0\x01\xc5I\x88\x12\x00\x00\n8\x85\xd4\xe6\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00\xb0(\xc1\xb2\xbd\x13\x00\x00\xc0&\xc4\x0b\xcd\x12\x00\x00\xfck\x16F\xce\x12\x00\x00\xa0\xeex\x07t\x13\x00\x00\x00\xc0S$\xa5\x13\x00\x00\xd8jdJ\'\x14\x00\x00\xe3\xacN\xcb\x15\x13\x00\x00\r\xe8\xa1f9\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xa0\xeex\x07t\x13\x00\x00L\xf0\\u\xa1\x13\x00\x00\xe7\x00\x8c\xa9\xec\x13\x00\x00\xa1\xf4v*[\x13\x00\x00- \xedj\x92\x13\x00\x00$L\xdc\x06\xd5\x13\x00\x00\xad)\x13\x8c\x1c\x13\x00\x00N\xfcX\xbbo\x13\x00\x00\x92q\x9b\r\xaa\x12\x00\x00\x07\x9b\xb4\x84\xa8\x12\x00\x00\x86\xda!\xd5\x85\x13\x00\x00- \xedj\x92\x13\x00\x00\xb0(\xc1\xb2\xbd\x13\x00\x00~[\xa0(\xfe\x13\x00\x00\x9e\x80\x9f\xeaB\x14\x00\x00\xcf\xf80\xbd\xcc\x13\x00\x00\x96c\xfb\x14\x1e\x14\x00\x00\xf7\xebB\xc0\xe7\x13\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00E\xd9\xb6\xc2c\x13\x00\x00\xf35(\x0b\xae\x13\x00\x00\xe08w\x8b\xfd\x13\x00\x00\x1a6\x88-\xf6\x12\x00\x00+\xc5_\x90u\x13\x00\x00\xce\xf22\x9a\xe5\x13\x00\x00H\xd8d\xe9\x04\x14\x00\x00{\xfa\x14+\xfa\x13\x00\x00\x14\xc3\x02\xc7<\x13\x00\x00Y\xb6\xcd\xe0\xd2\x14\x00\x00\x11O+\x87$\x14\x00\x00\xa6N\xb2+\x19\x14\x00\x00u\x87\x8f\xc4@\x14\x00\x00Z\xcf\x17F\xce\x13\x00\x00\xb9\x9a\xf4?\x18\x14\x00\x00\xed\x1149C\x14\x00\x00\x92q\x9b\r\xaa\x12\x00\x00+v\xce\xfb&\x13\x00\x00!:\xe2\x9d\x1f\x14\x00\x00N\x9a{\xe4\x0c\x14\x00\x00.u|"\xc8\x13\x00\x00\x18\x17@\xa5\x13\x14\x00\x00k\xc0\xcc\x7f\xb0\x13\x00\x00E;\x94\x99\xc6\x12\x00\x00\x0b\x8d\x14\x8c\x1c\x14\x00\x00V\x19\xfd\x90\x94\x13\x00\x00 \xf8\x9e(\xfe\x12\x00\x00cT\x97\x15=\x13\x00\x00\x0c\xa6^\xf1\x17\x13\x00\x00\xd3\x10)Ii\x13\x00\x00\x08\x8efe{\x13\x00\x00&k$\x8f\xb7\x12\x00\x00\xad\xc75\xb5\xb9\x13\x00\x00\xb0(\xc1\xb2\xbd\x13\x00\x00\x88\x84@D\xf1\x13\x00\x00\xa7\x18k\xfc\xc5\x12\x00\x00Gp\x89\xef\xba\x14\x00\x00\x16m!6\xa8\x13\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00G\xd2f\xc6\x1d\x14\x00\x00U\xc4m\xd9^\x13\x00\x00\x94\x1b\xba|\x15\x13\x00\x00\x85rF\xdb;\x14\x00\x00\x81\xbc+&\x02\x14\x00\x00\x8cM\xa7;?\x13\x00\x00\xad\x16\xc7I\x08\x14\x00\x00\x84\xce%\x8f\xb7\x13\x00\x00\xa7\xa3A\xe3N\x14\x00\x00\xb6L\xb5\x84(\x13\x00\x003\x80&\x8f7\x14\x00\x00\x9f7\x0cy\xdb\x13\x00\x00w\xa6\xd7L#\x13\x00\x00\xa4\xa4\x93\xbc\xad\x13\x00\x00U\xc4m\xd9^\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00q \x06\xa4U\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xf35(\x0b\xae\x13\x00\x00!:\xe2\x9d\x1f\x14\x00\x00MX8o\xeb\x12\x00\x00\x8f\xae29C\x13\x00\x0031\x95\xfa\xe8\x13\x00\x00\x1d"\xea\x11\x83\x14\x00\x004\x86$\xb2\x1e\x14\x00\x00I\xdeb\x0c\xec\x13\x00\x00c\xb6t\xec\x9f\x12\x00\x00\xc6\x99Ir\x86\x12\x00\x00\xb0\xd9/\x1eo\x13\x00\x00\xaa\xc8\x87\x8e\x18\x13\x00\x00\x9c%\x12\x10&\x14\x00\x00\xca\xed\x86P]\x13\x00\x00\\*\xa5 \xeb\x13\x00\x00\xa9\xfe\xce\xbdk\x14\x00\x00\x95\xd2&\x0b\xae\x12\x00\x00\xe5\xf4\x8fc\x1e\x14\x00\x00\xa8\xa9?\x066\x14\x00\x00D5\x96v\xdf\x12\x00\x00\x9c%\x12\x10&\x14\x00\x00V\xb7\x1f\xba1\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00$_(I\xe9\x12\x00\x00\x91\xf6s\xd1K\x14\x00\x00\xfdq\x14i\xb5\x12\x00\x00N\xad\xc7&!\x13\x00\x00\xc9\x98\xf7\x98\'\x13\x00\x00\x00\xc0S$\xa5\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xb3v\x00n\xad\x14\x00\x00\xb2!q\xb6w\x14\x00\x00\xfc\xa7[\x98\x08\x14\x00\x00\x19\xce\xac3\xac\x13\x00\x00bN\x99\xf2U\x13\x00\x00L\x8e\x7f\x9e>\x14\x00\x00\xfa\x9b_R:\x14\x00\x00\xc3\x87O\t\xd1\x12\x00\x00vQH\x95\xed\x12\x00\x00\x98 f\xc6\x9d\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xdav`\x90\xf5\x13\x00\x00\xbaQa\xce\xb0\x13\x00\x00\xba\xa0\xf2b\xff\x13\x00\x00\x99&d\xe9\x84\x13\x00\x00\xc5\x1e"6(\x14\x00\x00\xa1\xe1*\xe8F\x14\x00\x00\xaekV\x01>\x14\x00\x00\x8c\x9c8\xd0\x8d\x13\x00\x00\xe2\x93\x04f\x1a\x14\x00\x00]\x7f4\xd8 \x14\x00\x00b\xb0v\xc9\xb8\x12\x00\x00\xaa\xb5;L\x04\x14\x00\x00x\xe8\x1a\xc2D\x14\x00\x005\x8c"\xd5\x05\x14\x00\x00\xf7:\xd4T6\x14\x00\x00O\xb3\xc5I\x08\x13\x00\x00\xdd9\xc9d\\\x13\x00\x00L\x8e\x7f\x9e>\x14\x00\x00\xd1\xa2O,8\x14\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x00\xcd\x9d\xa3\xe2\xaf\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\x92\xfcq\xf42\x14\x00\x006\xe1\xb1\x8c;\x14\x00\x00\xd9\x83\xae\xaf"\x13\x00\x00~[\xa0(\xfe\x13\x00\x00\x16\x0bD_E\x14\x00\x00}h\xeeG+\x13\x00\x00\xba\xa0\xf2b\xff\x13\x00\x00\x85rF\xdb;\x14\x00\x00\xda\xc5\xf1$D\x14\x00\x00"@\xe0\xc0\x06\x14\x00\x00MX8o\xeb\x12\x00\x00SV\x94\xbc-\x14\x00\x00\x91XQ\xa8\xae\x13\x00\x00:H;\xad&\x14\x00\x00GG\x90\xdf\x94\x12\x00\x00\xa4B\xb6\xe5J\x14\x00\x00\xc4\x18$\x13A\x14\x00\x00\xc4\x18$\x13A\x14\x00\x00\xd0\xaf\x9dKe\x13\x00\x00e\xaf$\xf0Y\x13\x00\x00\xdd\x9b\xa6;\xbf\x12\x00\x00<\xb6\x14\xcaW\x13\x00\x00eMG\x19\xf7\x13\x00\x00\x03\xbf\x01KF\x14\x00\x00\x05\xdeI\xd3(\x13\x00\x00\xebg\x15\xca\xd7\x13\x00\x00\x16\x0bD_E\x14\x00\x00f\xa2\xd6\xd0,\x14\x00\x00\xb2\xd2\xdf!)\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xb6L\xb5\x84(\x13\x00\x00w\xf5h\xe1q\x13\x00\x00|\x00\x13N\xe1\x13\x00\x00\x0e\xb2Z7\xe6\x12\x00\x00\xbb\xf5\x81\x1a5\x14\x00\x00\xbe\x07|\x83\xea\x13\x00\x00\xbe\x07|\x83\xea\x13\x00\x00\xea\xd6@\xc0g\x12\x00\x00\xd8\xccA!\x8a\x13\x00\x00d\xf8\xb7a\xc1\x13\x00\x00\xdb\x8f\xaa\xf5\xf0\x12\x00\x00G\xd2f\xc6\x1d\x14\x00\x00RP\x96\x99F\x14\x00\x00\x0c\x93\x12\xaf\x03\x14\x00\x00\xff\x1b3\xd8 \x13\x00\x00\xc7y\xaf\x10E\x14\x00\x00|O\xa4\xe2/\x14\x00\x00\xde?\xc7\x87C\x13\x00\x00}U\xa2\x05\x17\x14\x00\x00\xd6\x0f\xd7o\n\x14\x00\x00\xc8\x92\xf9u@\x13\x00\x00\xfc\t9ok\x13\x00\x00%\xa1k\xbe\n\x14\x00\x00\xdf\xe3\xe7\xd3\xc7\x13\x00\x00H\xd8d\xe9\x04\x14\x00\x00\x1d\x84\xc7\xe8\xe5\x13\x00\x00%\xa1k\xbe\n\x14\x00\x00|O\xa4\xe2/\x14\x00\x0047\x93\x1d\xd0\x13\x00\x00g\xa8\xd4\xf3\x13\x14\x00\x00\x9b\x81\xf1\xc3\xa1\x13\x00\x00\xb7\xf0\xd5\xd0\xac\x13\x00\x00|O\xa4\xe2/\x14\x00\x00\xaa\xb5;L\x04\x14\x00\x00\xed7\xcc\xbdk\x12\x00\x00JF>\x066\x13\x00\x00\x9d+\x103\r\x14\x00\x00\xcc\xf9\x82\x96+\x13\x00\x00\xdf\xe3\xe7\xd3\xc7\x13\x00\x00\x16\xcf\xfe\x0c\x0b\x13\x00\x00\x19l\xcf\\I\x14\x00\x00\xbf\xbe\xe8\x11\x83\x13\x00\x00t2\x00\r\x0b\x14\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x00\x99&d\xe9\x84\x13\x00\x00\xd1\xa2O,8\x14\x00\x00\x99&d\xe9\x84\x13\x00\x00m.\xa6\x9c\xe1\x12\x00\x00U\xb1!\x97J\x14\x00\x00{I\xa6\xbfH\x14\x00\x00\xc2n\x05\xa4\xd5\x13\x00\x00g\xa8\xd4\xf3\x13\x14\x00\x00\xd1\x04-\x03\x9b\x13\x00\x00&\xf6\xfau@\x14\x00\x00\xdav`\x90\xf5\x13\x00\x00\xcbB\x16\x08\x93\x13\x00\x00\xfbe\x18#\xe7\x12\x00\x00\xd2Y\xbc\xba\xd0\x13\x00\x00\xc4\x18$\x13A\x14\x00\x00\'^\xd6o\x8a\x13\x00\x00yP\xf6\xbb\x8e\x13\x00\x00\xfbR\xcc\xe0\xd2\x13\x00\x00r&\x04\xc7<\x14\x00\x00r&\x04\xc7<\x14\x00\x00G\xe5\xb2\x082\x13\x00\x00q\x82\xe3z\xb8\x13\x00\x00O\xef\n\x9cB\x14\x00\x00H\xd8d\xe9\x04\x14\x00\x004\x86$\xb2\x1e\x14\x00\x00\x02jr\x93\x10\x14\x00\x00U\xb1!\x97J\x14\x00\x00\x8b\xf8\x17\x84\t\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00$_(I\xe9\x12\x00\x00\xb4\xde\xdbg\xf7\x13\x00\x005\x8c"\xd5\x05\x14\x00\x00^\x852\xfb\x07\x14\x00\x00i\xb4\xd09\xe2\x13\x00\x00\x1c\xe0\xa6\x9ca\x13\x00\x00\xa2\x98\x97v\xdf\x13\x00\x005*E\xfe\xa2\x14\x00\x00\xb7\xf0\xd5\xd0\xac\x13\x00\x00\x9e\xf5\xc8\x03\xba\x12\x00\x00\x95\x0el]\xe8\x13\x00\x00\'^\xd6o\x8a\x13\x00\x00\x1d\x97\x13+\xfa\x12\x00\x00Q\xfb\x06\xe2\x10\x14\x00\x00\xf0\xd4\x9c\r\xaa\x13\x00\x007I\x8d\x86\x85\x13\x00\x00Z\xcf\x17F\xce\x13\x00\x00\xe4\x01\xde\x82K\x13\x00\x00\xe4\x9f\x00\xac\xe8\x13\x00\x00\xa5\xf9"t\xe3\x13\x00\x00\x7f\xb0/\xe03\x14\x00\x00)W\x86sD\x14\x00\x00\xe8hg\xa36\x13\x00\x00h\xfdc\xabI\x14\x00\x00\xd4\x03\xdb)<\x14\x00\x00\xd4\x16\'lP\x13\x00\x00\x03\xbf\x01KF\x14\x00\x00-\xbe\x0f\x94/\x14\x00\x006\xf4\xfd\xceO\x13\x00\x00\xdf\xe3\xe7\xd3\xc7\x13\x00\x001\xd6\x07 \xcc\x13\x00\x00\xf6\x96\xb3\x08\xb2\x13\x00\x00\xd9pbm\x0e\x14\x00\x00\x0b>\x83\xf7\xcd\x13\x00\x00P\xa6w*\xdb\x13\x00\x00\xfed\xc6I\x88\x13\x00\x00\x18\xdb\xfaR\xd9\x12\x00\x00\xf0\xd4\x9c\r\xaa\x13\x00\x00\xa4B\xb6\xe5J\x14\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00\xad\x16\xc7I\x08\x14\x00\x00\x87/\xb1\x8c\xbb\x13\x00\x00\x8f\x9b\xe6\xf6.\x14\x00\x00\x16\xcf\xfe\x0c\x0b\x13\x00\x00\xe0\x9aTb`\x13\x00\x00\xa9`\xac\x94\xce\x13\x00\x00X\xc3\x1b\x00\x00\x14\x00\x00\xbfoW}4\x13\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00u\x87\x8f\xc4@\x14\x00\x00\x18\x17@\xa5\x13\x14\x00\x00\x11\xb1\x08^\x87\x13\x00\x00\xe1\xef\xe3\x19\x96\x13\x00\x00\x10\xbeV}\xb4\x12\x00\x00^6\xa1f\xb9\x13\x00\x00\x13\x0c\x968\xa4\x13\x00\x00q \x06\xa4U\x14\x00\x00j\xba\xce\\\xc9\x13\x00\x0031\x95\xfa\xe8\x13\x00\x00\x1a6\x88-\xf6\x12\x00\x00\xe6\xab\xfc\xf1\xb6\x13\x00\x00\xab\n\xcb\x03:\x14\x00\x00%\xa1k\xbe\n\x14\x00\x00u\x87\x8f\xc4@\x14\x00\x00\xf8\xf1@\xe3\xce\x13\x00\x00\xb3\x89L\xb0\xc1\x13\x00\x00\x80g\x9cn\xcc\x13\x00\x00\xb3\x89L\xb0\xc1\x13\x00\x00_O\xeb\xcb\xb4\x12\x00\x005\x8c"\xd5\x05\x14\x00\x00E\x8a%.\x15\x13\x00\x00\n\xe9\xf3?\x98\x13\x00\x00\xe1\x8d\x06C3\x14\x00\x00yP\xf6\xbb\x8e\x13\x00\x00\xb7\xa1D<^\x13\x00\x00\xc4\xdc\xde\xc0\x06\x13\x00\x00d\xa9&\xcdr\x13\x00\x00\x7f\x12\r\xb7\x96\x13\x00\x003\xe2\x03f\x9a\x13\x00\x00\xdfE\xc5\xaa*\x13\x00\x00\xaa\xb5;L\x04\x14\x00\x00\xb8Ee\x88\xe2\x13\x00\x00\xed7\xcc\xbdk\x12\x00\x00\x81\xcfwh\x16\x13\x00\x00\xbe\xcb61\xb0\x12\x00\x00\x87~B!\n\x14\x00\x00\xbe\x07|\x83\xea\x13\x00\x00\xd0\xc2\xe9\x8dy\x12\x00\x00]C\xef\x85\xe6\x12\x00\x00\x8aT\xf77\x85\x12\x00\x00u\xe9l\x9b\xa3\x13\x00\x005=\x91@\xb7\x13\x00\x00JF>\x066\x13\x00\x00\xb7\xa1D<^\x13\x00\x00\x1b\xed\xf4\xbb\x8e\x12\x00\x00\x01dtp)\x14\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00x\xe8\x1a\xc2D\x14\x00\x00\xe5\xf4\x8fc\x1e\x14\x00\x00\x01\xc6QG\x8c\x13\x00\x00\'^\xd6o\x8a\x13\x00\x00]\x7f4\xd8 \x14\x00\x00\xf7:\xd4T6\x14\x00\x00N\xfcX\xbbo\x13\x00\x00JF>\x066\x13\x00\x00o\'V\xa0\x9b\x13\x00\x00\x99\xc4\x86\x12"\x14\x00\x00cT\x97\x15=\x13\x00\x00P\x08U\x01>\x13\x00\x00\xc8\x92\xf9u@\x13\x00\x002\xdc\x05C\xb3\x13\x00\x00xJ\xf8\x98\xa7\x13\x00\x00!:\xe2\x9d\x1f\x14\x00\x00\r\xfb\xed\xa8M\x13\x00\x00\xde,{E/\x14\x00\x00K9\xf0\xe6\x08\x14\x00\x00\xc2\xbd\x968$\x14\x00\x00\x85#\xb5F\xed\x13\x00\x00=Z5\x16\xdc\x13\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x00x\xe8\x1a\xc2D\x14\x00\x00\xd9pbm\x0e\x14\x00\x00\xf8@\xd2w\x1d\x14\x00\x00\x7f\xb0/\xe03\x14\x00\x00\x00\xc0S$\xa5\x13\x00\x00\xf7:\xd4T6\x14\x00\x00\x9c%\x12\x10&\x14\x00\x00w\x93\x8b\n\x0f\x14\x00\x00\xfbR\xcc\xe0\xd2\x13\x00\x00{\\\xf2\x01]\x13\x00\x00f\xa2\xd6\xd0,\x14\x00\x00\xd8jdJ\'\x14\x00\x00\xf7\xebB\xc0\xe7\x13\x00\x00r&\x04\xc7<\x14\x00\x00x\xe8\x1a\xc2D\x14\x00\x00\xff\x08\xe7\x95\x0c\x14\x00\x00\xe6\xab\xfc\xf1\xb6\x13\x00\x00G\xd2f\xc6\x1d\x14\x00\x00\xb9Kc\xab\xc9\x13\x00\x00\x08\x8efe{\x13\x00\x00\xd2Y\xbc\xba\xd0\x13\x00\x00\x86\xda!\xd5\x85\x13\x00\x00\xa1\xe1*\xe8F\x14\x00\x00V{\xdag\xf7\x12\x00\x00\xe2\x93\x04f\x1a\x14\x00\x00cAK\xd3(\x14\x00\x00JF>\x066\x13\x00\x00\xb9\xfc\xd1\x16{\x13\x00\x00\xa1\xe1*\xe8F\x14\x00\x00\xfd^\xc8&\xa1\x13\x00\x00\xf2~\xbb|\x15\x14\x00\x00P\xa6w*\xdb\x13\x00\x00\x99u\xf5}\xd3\x13\x00\x00RP\x96\x99F\x14\x00\x00\x80g\x9cn\xcc\x13\x00\x00\x84\x1d\xb7#\x06\x14\x00\x00\x86\xda!\xd5\x85\x13\x00\x00\xf4;&.\x95\x13\x00\x00p-T\xc3\x82\x13\x00\x00u\x87\x8f\xc4@\x14\x00\x00%\xa1k\xbe\n\x14\x00\x00#\x95ox<\x14\x00\x00\x9d+\x103\r\x14\x00\x00\x95\xd2&\x0b\xae\x12\x00\x00\xad\x16\xc7I\x08\x14\x00\x002+\x97\xd7\x01\x14\x00\x00\xa5H\xb4\x082\x14\x00\x00\xcf\xf80\xbd\xcc\x13\x00\x00\x1b\x8b\x17\xe5+\x13\x00\x00\xef\x7f\rVt\x13\x00\x00\x0e\xee\x9f\x89 \x14\x00\x00G\xd2f\xc6\x1d\x14\x00\x00G\xd2f\xc6\x1d\x14\x00\x00)\x08\xf5\xde\xf5\x13\x00\x00\x91XQ\xa8\xae\x13\x00\x00\\*\xa5 \xeb\x13\x00\x00\x08\xdd\xf7\xf9\xc9\x13\x00\x00\xa6\xff \x97\xca\x13\x00\x00\xfa\x10\x89k\xb1\x12\x00\x00(d\xd4\x92q\x13\x00\x00f\xa2\xd6\xd0,\x14\x00\x00\xaa*ee{\x12\x00\x00<\xb6\x14\xcaW\x13\x00\x00.\x88\xc8d\xdc\x12\x00\x00v\xa0\xd9)<\x13\x00\x00e\xfe\xb5\x84\xa8\x13\x00\x00\x9d\xa09L\x84\x12\x00\x00\x1b\xed\xf4\xbb\x8e\x12\x00\x00\xc8Ch\xe1\xf1\x12\x00\x00/,\xe9\xb0`\x13\x00\x00\xff}\x10\xaf\x83\x12\x00\x00\x190\x8a\n\x0f\x13\x00\x00\xff\x1b3\xd8 \x13\x00\x00l(\xa8y\xfa\x12\x00\x00\xef\xe1\xea,\xd7\x12\x00\x00\xd0\xc2\xe9\x8dy\x12\x00\x00MX8o\xeb\x12\x00\x00MX8o\xeb\x12\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00\x82\x86\xe4\xf6\xae\x12\x00\x00\x11bw\xc98\x13\x00\x00v\xa0\xd9)<\x13\x00\x00&k$\x8f\xb7\x12\x00\x00\xe0\xe9\xe5\xf6\xae\x13\x00\x00U&K\xb0\xc1\x12\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\x11bw\xc98\x13\x00\x00\xa6\xb0\x8f\x02|\x13\x00\x00\xf2Bv*\xdb\x12\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00\xf7\xfe\x8e\x02\xfc\x12\x00\x00\x83\xdbs\xae\xe4\x12\x00\x00\x11\x13\xe64\xea\x12\x00\x00\x15zoU\xd5\x12\x00\x00\x8bG\xa9\x18X\x13\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00\xa8m\xfa\xb3\xfb\x12\x00\x00\x97-\xb4\xe5\xca\x12\x00\x00\xd7w\xb2iT\x13\x00\x003\x93r\xd1K\x13\x00\x00\xc7\x9fG\x95m\x12\x00\x00\x8b\xf8\x17\x84\t\x13\x00\x00\x8a\xa3\x88\xcc\xd3\x12\x00\x00w\xf5h\xe1q\x13\x00\x00\xfd\x0f7\x92R\x13\x00\x00\xbeiYZM\x13\x00\x00\xbcp\xa9V\x93\x12\x00\x00[7\xf3?\x18\x13\x00\x00`\xa4z\x83\xea\x12\x00\x00\x05@\'\xaa\x8b\x12\x00\x00\xc4>\xbc\x97i\x12\x00\x00T\xd1\xbb\xf8\x8b\x12\x00\x00S\x1aOj\xf3\x12\x00\x00\xa4\xa4\x93\xbc\xad\x13\x00\x00V{\xdag\xf7\x12\x00\x00~\x1f[\xd6\xc3\x12\x00\x00t\xa7)&\x82\x12\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00\x11bw\xc98\x13\x00\x00\xacr\xa6\xfd\x83\x13\x00\x00\xec\x1e\x82Xp\x13\x00\x00\xa8m\xfa\xb3\xfb\x12\x00\x00\xa2\xfatMB\x13\x00\x00C\x1cL\x11\xe4\x13\x00\x007\xabj]\xe8\x12\x00\x00.97\xd0\x8d\x12\x00\x00\x0fV{\x83j\x13\x00\x00\x9c\xd6\x80{\xd7\x13\x00\x00\x17$\x8e\xc4@\x13\x00\x00\xa2I\x06\xe2\x90\x13\x00\x00\x8f\xfd\xc3\xcd\x91\x13\x00\x00T\xd1\xbb\xf8\x8b\x12\x00\x00\xe9ne\xc6\x1d\x13\x00\x00\xa9\xc2\x89k1\x13\x00\x00W\xd0i\x1f-\x13\x00\x00\xd3\x10)Ii\x13\x00\x00yP\xf6\xbb\x8e\x13\x00\x00\xcd\xec4w\xfe\x13\x00\x00\x82$\x07 L\x13\x00\x00\xd0\xaf\x9dKe\x13\x00\x00\xffj\xc4lo\x13\x00\x00\xf2\x91\x07\xbf)\x13\x00\x00Be\xdf\x82K\x14\x00\x00>s\x7f{\xd7\x12\x00\x008b\xd7\xeb\x80\x12\x00\x00\\\xee_\xce\xb0\x12\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00p\xde\xc2.4\x13\x00\x00uKJr\x06\x13\x00\x00m}710\x13\x00\x008\x00\xfa\x14\x1e\x13\x00\x00y\xb2\xd3\x92\xf1\x12\x00\x00\xef\x92Y\x98\x88\x12\x00\x00\x87~B!\n\x14\x00\x00\\\xdb\x13\x8c\x9c\x13\x00\x00\xf0\x85\x0by[\x13\x00\x00\\\xee_\xce\xb0\x12\x00\x00\\\xee_\xce\xb0\x12\x00\x00\xdf\x94V?y\x13\x00\x00\x11O+\x87$\x14\x00\x00\xce\xa3\xa1\x05\x97\x13\x00\x00\xf9\xbb\xf9\xb3{\x12\x00\x00\xc9\xe7\x88-v\x13\x00\x00]\x92\x80\x1a5\x13\x00\x00\xff\x1b3\xd8 \x13\x00\x00\x04\'\xddD\x90\x13\x00\x00\x99&d\xe9\x84\x13\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00h_A\x82\xac\x13\x00\x00\xf2\xf3\xe4\x95\x8c\x12\x00\x00\x81\xcfwh\x16\x13\x00\x00MX8o\xeb\x12\x00\x00\xa2\xab\xe3\xb8\xf3\x12\x00\x009\xb7f\xa3\xb6\x12\x00\x00\xe1>u\xae\xe4\x13\x00\x00\x0fi\xc7\xc5~\x12\x00\x00\xa1\xf4v*[\x13\x00\x00\xeds\x11\x10\xa6\x13\x00\x00\xb6L\xb5\x84(\x13\x00\x00E;\x94\x99\xc6\x12\x00\x00;\xb0\x16\xa7p\x13\x00\x00\x9d\xdc~\x9e\xbe\x13\x00\x00"\x04\x9bn\xcc\x12\x00\x00\xc4\xdc\xde\xc0\x06\x13\x00\x00\xdav`\x90\xf5\x13\x00\x00Qp0\xfb\x87\x12\x00\x00\x17$\x8e\xc4@\x13\x00\x00\x17$\x8e\xc4@\x13\x00\x00\xa1\xf4v*[\x13\x00\x00\x96\xc5\xd8\xeb\x80\x13\x00\x00\xe9\x0c\x88\xef\xba\x13\x00\x00\xa4\xf3$Q\xfc\x13\x00\x00Yz\x88\x8e\x98\x13\x00\x00m\xcc\xc8\xc5~\x13\x00\x00a[\xe7\x11\x83\x12\x00\x00\xa9`\xac\x94\xce\x13\x00\x00x\xac\xd5o\n\x13\x00\x00A\xd4\ny\xdb\x12\x00\x00a[\xe7\x11\x83\x12\x00\x00x\xac\xd5o\n\x13\x00\x00\x17\x86k\x9b\xa3\x12\x00\x00\xc2n\x05\xa4\xd5\x13\x00\x00:\xaa\x18\x84\x89\x13\x00\x00H:B\xc0g\x13\x00\x00vQH\x95\xed\x12\x00\x00a\xaax\xa6\xd1\x12\x00\x00\x82$\x07 L\x13\x00\x00\\\xee_\xce\xb0\x12\x00\x00\xd9\x83\xae\xaf"\x13\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x003\x93r\xd1K\x13\x00\x00eMG\x19\xf7\x13\x00\x00\xa0PV\xde\xd6\x12\x00\x00a\xaax\xa6\xd1\x12\x00\x00 \xf8\x9e(\xfe\x12\x00\x00\xe2\xf5\xe1<}\x13\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00\x7ft\xea\x8d\xf9\x12\x00\x00S\xb8q\x93\x90\x13\x00\x00\x18\xdb\xfaR\xd9\x12\x00\x00\x17\x86k\x9b\xa3\x12\x00\x00MX8o\xeb\x12\x00\x001\xe9Sb\xe0\x12\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00bN\x99\xf2U\x13\x00\x00J\xa8\x1b\xdd\x98\x12\x00\x00u\xfc\xb8\xdd\xb7\x12\x00\x00W\xd0i\x1f-\x13\x00\x00gl\x8f\xa1\xd9\x12\x00\x00&k$\x8f\xb7\x12\x00\x00\x88\x84@D\xf1\x13\x00\x00\xfdq\x14i\xb5\x12\x00\x00\x8dS\xa5^&\x13\x00\x00\xceA\xc4.4\x14\x00\x00\xff\xb9U\x01\xbe\x13\x00\x00<\x05\xa6^\xa6\x13\x00\x00\xbfoW}4\x13\x00\x00\xcd\xb0\xef$\xc4\x12\x00\x00/\xca\x0b\xda\xfd\x13\x00\x00\xb1\xf2y\x83j\x12\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x00\x11bw\xc98\x13\x00\x00\x063\xd9\x8a^\x13\x00\x003\xf5O\xa8\xae\x12\x00\x00f\xb5"\x13A\x13\x00\x00Y+\xf7\xf9I\x13\x00\x00\x9c8^R:\x13\x00\x00\xa7T\xb0N\x00\x14\x00\x00x]D\xdb\xbb\x12\x00\x00|\x13_\x90\xf5\x12\x00\x00\xca\x9e\xf5\xbb\x0e\x13\x00\x00\xdf\x94V?y\x13\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00)\xcc\xaf\x8c\xbb\x12\x00\x00d\xa9&\xcdr\x13\x00\x00\xb5F\xb7aA\x13\x00\x00\xfd\x0f7\x92R\x13\x00\x00\xf7\x9c\xb1+\x99\x13\x00\x00#\n\x99\x91\xb3\x12\x00\x00\x1f\xdfT\xc3\x02\x14\x00\x00$_(I\xe9\x12\x00\x00MX8o\xeb\x12\x00\x00\x0fi\xc7\xc5~\x12\x00\x00\xa4\xa4\x93\xbc\xad\x13\x00\x00\xd7\xd9\x8f@\xb7\x12\x00\x00h\xae\xd2\x16\xfb\x13\x00\x00\xaa*ee{\x12\x00\x00\xad)\x13\x8c\x1c\x13\x00\x00%\x16\x95\xd7\x81\x12\x00\x00\xe8hg\xa36\x13\x00\x00\xbd\xb2\xec\xcb\xb4\x13\x00\x00"\xa2\xbd\x97i\x13\x00\x00\xc0uU\xa0\x1b\x13\x00\x00\xcd\x9d\xa3\xe2\xaf\x13\x00\x00#\xf7LO\x9f\x13\x00\x00cT\x97\x15=\x13\x00\x00\xb7\xf0\xd5\xd0\xac\x13\x00\x00\x06\xe4G\xf6\x0f\x13\x00\x00\xfed\xc6I\x88\x13\x00\x00x\xfbf\x04Y\x13\x00\x00\xe4\x01\xde\x82K\x13\x00\x00\xe1\xa0R\x85G\x13\x00\x00\x84\xce%\x8f\xb7\x13\x00\x00\x1a\x85\x19\xc2D\x13\x00\x00.u|"\xc8\x13\x00\x00\xba\xb3>\xa5\x13\x13\x00\x00\xaa\xc8\x87\x8e\x18\x13\x00\x00\xa6\xc3\xdbD\x90\x12\x00\x00}U\xa2\x05\x17\x14\x00\x00s\xddpU\xd5\x13\x00\x00\x97-\xb4\xe5\xca\x12\x00\x00\x85\xd4#\xb2\x9e\x13\x00\x00Q\x0eS$%\x13\x00\x00\x13ns\x0f\x07\x13\x00\x00\'\xc0\xb3F\xed\x12\x00\x00\xf0\x98W\xbbo\x12\x00\x00\xa7\xb6\x8d%c\x13\x00\x00\x19\xce\xac3\xac\x13\x00\x00h#\xfc/r\x12\x00\x00\xac\xd4\x83\xd4\xe6\x12\x00\x00*\xbfam\x8e\x13\x00\x00\xa5\xf9"t\xe3\x13\x00\x00:\x0c\xf6Z\xec\x12\x00\x00\xd4e\xb8\x00\x9f\x13\x00\x00\x88H\xfb\xf1\xb6\x12\x00\x00\xe7bi\x80O\x13\x00\x00>\x11\xa2\xa4t\x13\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00\xee*~\x9e>\x13\x00\x00\xd2\n+&\x82\x13\x00\x00\xf5\x90\xb5\xe5\xca\x13\x00\x00.\x88\xc8d\xdc\x12\x00\x00/\x8e\xc6\x87\xc3\x12\x00\x00\xf2~\xbb|\x15\x14\x00\x00^6\xa1f\xb9\x13\x00\x00z\xa5\x85s\xc4\x13\x00\x00\x11bw\xc98\x13\x00\x00\xa9s\xf8\xd6\xe2\x12\x00\x00\xa9$gB\x94\x12\x00\x00\x88\x84@D\xf1\x13\x00\x00\xf0\xd4\x9c\r\xaa\x13\x00\x00\r\xfb\xed\xa8M\x13\x00\x00$L\xdc\x06\xd5\x13\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x001\xe9Sb\xe0\x12\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x001\xe9Sb\xe0\x12\x00\x00\x05\x8f\xb8>\xda\x12\x00\x00\x1a\xe7\xf6\x98\xa7\x12\x00\x00{\\\xf2\x01]\x13\x00\x00E;\x94\x99\xc6\x12\x00\x00bN\x99\xf2U\x13\x00\x00\xc3\x87O\t\xd1\x12\x00\x00\x7f\x12\r\xb7\x96\x13\x00\x009\xf3\xab\xf5\xf0\x13\x00\x00\xc8\x92\xf9u@\x13\x00\x00MX8o\xeb\x12\x00\x00\x14\xc3\x02\xc7<\x13\x00\x00>\x11\xa2\xa4t\x13\x00\x00\x97\xcb\xd6\x0eh\x13\x00\x00>\xaf\xc4\xcd\x11\x14\x00\x00\xd2\x1dwh\x96\x12\x00\x00\xaf5\x0f\xd2\xea\x12\x00\x00\xe3\xacN\xcb\x15\x13\x00\x00\xb3\x9c\x98\xf2\xd5\x12\x00\x00\x92\xad\xe0_\xe4\x13\x00\x00s?N,8\x13\x00\x00\xaa\xb5;L\x04\x14\x00\x003\xe2\x03f\x9a\x13\x00\x00\xa3bPG\x8c\x12\x00\x00\xfed\xc6I\x88\x13\x00\x00\x0f\xb8XZ\xcd\x12\x00\x00\x88\xe6\x1d\x1bT\x13\x00\x00\x05|l\xfc\xc5\x13\x00\x00\x00q\xc2\x8fV\x13\x00\x00\xbcp\xa9V\x93\x12\x00\x00\xd4\x16\'lP\x13\x00\x00\xdf\xf63\x16\xdc\x12\x00\x008\x00\xfa\x14\x1e\x13\x00\x00\xf4\x8a\xb7\xc2\xe3\x13\x00\x00"\xb5\t\xda}\x12\x00\x00\x18y\x1d|v\x13\x00\x00\xe1>u\xae\xe4\x13\x00\x00R\x01\x05\x05\xf8\x13\x00\x00\xcfZ\x0e\x94/\x13\x00\x00\xc4\xdc\xde\xc0\x06\x13\x00\x00\xfd\xc0\xa5\xfd\x03\x13\x00\x00j\xcd\x1a\x9f\xdd\x12\x00\x00\xfdq\x14i\xb5\x12\x00\x00\x13\x0c\x968\xa4\x13\x00\x00~[\xa0(\xfe\x13\x00\x00\x97\xcb\xd6\x0eh\x13\x00\x0002\xe7\xd3G\x13\x00\x00\x9d\x8d\xed\tp\x13\x00\x00\x06\xe4G\xf6\x0f\x13\x00\x00z\x07cJ\'\x13\x00\x00O\x02W\xdeV\x13\x00\x00\xfb\xb4\xa9\xb75\x13\x00\x00\x14\x12\x94[\x8b\x13\x00\x00\xb7\xb4\x90~r\x12\x00\x00\x9d\xa09L\x84\x12\x00\x00D5\x96v\xdf\x12\x00\x007\xabj]\xe8\x12\x00\x00x]D\xdb\xbb\x12\x00\x00)\x08\xf5\xde\xf5\x13\x00\x00)\xb9cJ\xa7\x13\x00\x00\x91\xba.\x7f\x11\x13\x00\x00\xffj\xc4lo\x13\x00\x00`B\x9d\xac\x87\x13\x00\x00\t\xe3\xf5\x1c\xb1\x13\x00\x00\x8bG\xa9\x18X\x13\x00\x00\x9d+\x103\r\x14\x00\x00$\xae\xb9\xdd7\x13\x00\x00\xa9s\xf8\xd6\xe2\x12\x00\x00\xd1\x17yE\xaf\x12\x00\x00"\x04\x9bn\xcc\x12\x00\x00\x03\xd2M\x8dZ\x13\x00\x00\x1f\xa3\x0fq\xc8\x12\x00\x00\xd5\x1c%\x8f7\x13\x00\x00u\xe9l\x9b\xa3\x13\x00\x00\x8d\x04\x14\xca\xd7\x12\x00\x00\xbf \xc6\xe8\xe5\x12\x00\x00\xb3\x89L\xb0\xc1\x13\x00\x00\xa2\xfatMB\x13\x00\x00{\\\xf2\x01]\x13\x00\x00E;\x94\x99\xc6\x12\x00\x00\xd3\xc1\x97\xb4\x1a\x13\x00\x00\xf9\n\x8bH\xca\x12\x00\x00\xa8\xa9?\x066\x14\x00\x00Y\x18\xab\xb75\x14\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00\xcc\x97\xa5\xbf\xc8\x13\x00\x00To\xde!)\x13\x00\x00\x9e\xe2|\xc1\xa5\x13\x00\x00\xabl\xa8\xda\x9c\x13\x00\x00\xec\x0b6\x16\\\x14\x00\x00\x83\xc8\'l\xd0\x13\x00\x00ov\xe74\xea\x13\x00\x00\xd1\x17yE\xaf\x12\x00\x00\x95pI4K\x13\x00\x00\x16m!6\xa8\x13\x00\x00\xff\xb9U\x01\xbe\x13\x00\x00\xbdv\xa7yz\x12\x00\x00\x08\xdd\xf7\xf9\xc9\x13\x00\x00\x11\x13\xe64\xea\x12\x00\x00.u|"\xc8\x13\x00\x00\xdd\x9b\xa6;\xbf\x12\x00\x00\xb6\xea\xd7\xad\xc5\x13\x00\x00ba\xe54j\x12\x00\x00\x86<\xff\xab\xe8\x12\x00\x007\\\xd9\xc8\x99\x12\x00\x00\xf0\xd4\x9c\r\xaa\x13\x00\x00\xf35(\x0b\xae\x13\x00\x00M\xa7\xc9\x03:\x13\x00\x00\xdc\xe49\xad&\x13\x00\x001\xd6\x07 \xcc\x13\x00\x00B)\x9a0\x11\x13\x00\x00^6\xa1f\xb9\x13\x00\x00\xb6L\xb5\x84(\x13\x00\x00Wn\x8cH\xca\x13\x00\x00\xc0uU\xa0\x1b\x13\x00\x00d\xa9&\xcdr\x13\x00\x00V{\xdag\xf7\x12\x00\x00\xf6G"tc\x13\x00\x00X%\xf9\xd6b\x13\x00\x00\x95pI4K\x13\x00\x00\xbfoW}4\x13\x00\x00\x8fLUb\xe0\x13\x00\x00\xea\xc3\xf4}S\x13\x00\x00\xf9F\xd0\x9a\x04\x14\x00\x00\xca\xed\x86P]\x13\x00\x00\x16\xcf\xfe\x0c\x0b\x13\x00\x00\xae\x1c\xc5l\xef\x13\x00\x00\x01\xc6QG\x8c\x13\x00\x00\x8e\xf7\xc5\xaa\xaa\x13\x00\x00\xde\xf05\xf3\xf4\x12\x00\x00N\x9a{\xe4\x0c\x14\x00\x00}\xa43\x9ae\x14\x00\x00\xa6N\xb2+\x19\x14\x00\x00Rc\xe2\xdbZ\x13\x00\x00\xccH\x14+z\x13\x00\x00\xe1>u\xae\xe4\x13\x00\x00\xad\xc75\xb5\xb9\x13\x00\x00\xf2Bv*\xdb\x12\x00\x00\xcfZ\x0e\x94/\x13\x00\x00\xad)\x13\x8c\x1c\x13\x00\x00\x97\xcb\xd6\x0eh\x13\x00\x00s\xddpU\xd5\x13\x00\x00\x80z\xe8\xb0\xe0\x12\x00\x00U\x13\xffm\xad\x13\x00\x00A\xd4\ny\xdb\x12\x00\x00C\x1cL\x11\xe4\x13\x00\x00d\xa9&\xcdr\x13\x00\x00c\xb6t\xec\x9f\x12\x00\x00\xda\xc5\xf1$D\x14\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00\xcb\xf3\x84sD\x13\x00\x00\x86\xda!\xd5\x85\x13\x00\x00=\xbc\x12\xed>\x13\x00\x00fSE<\xde\x13\x00\x00\xec\x1e\x82Xp\x13\x00\x00\xee*~\x9e>\x13\x00\x00e\xaf$\xf0Y\x13\x00\x00\xfck\x16F\xce\x12\x00\x00\xe7\x13\xd8\xeb\x00\x13\x00\x00\xa6\x12m\xd9\xde\x12\x00\x00\x1c\x91\x15\x08\x13\x13\x00\x00\x99\xd7\xd2T6\x13\x00\x00\xeds\x11\x10\xa6\x13\x00\x00E(HW\xb2\x13\x00\x00\xefl\xc1\x13`\x14\x00\x00\xc3\x87O\t\xd1\x12\x00\x00\x07\xeaE\x19\xf7\x12\x00\x00gYC_\xc5\x13\x00\x00\xa4\xa4\x93\xbc\xad\x13\x00\x00\x1e\xec\xa2\xe2/\x13\x00\x00Wn\x8cH\xca\x13\x00\x00\xe5Vm:\x81\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00<\xb6\x14\xcaW\x13\x00\x00\xfbe\x18#\xe7\x12\x00\x00\x8cM\xa7;?\x13\x00\x00\xf2Bv*\xdb\x12\x00\x00\xbfoW}4\x13\x00\x00\xa0\x9f\xe7r%\x13\x00\x00\xceA\xc4.4\x14\x00\x00\xabl\xa8\xda\x9c\x13\x00\x00Wn\x8cH\xca\x13\x00\x00\x11bw\xc98\x13\x00\x00>\x11\xa2\xa4t\x13\x00\x00\xe1\x020\\\xaa\x12\x00\x00\x83y\x96\xd7\x81\x13\x00\x00\x15\x18\x92~r\x13\x00\x00\xa3bPG\x8c\x12\x00\x00\xc9\x85\xabV\x13\x14\x00\x00o\x893w\xfe\x12\x00\x00\x1f\x90\xc3.\xb4\x13\x00\x00\xe9\xaa\xaa\x18X\x14\x00\x00\xe2\xf5\xe1<}\x13\x00\x00\xd8\xccA!\x8a\x13\x00\x00\x07\xeaE\x19\xf7\x12\x00\x00\'\xadg\x04\xd9\x13\x00\x00\xd5k\xb6#\x86\x13\x00\x00"\xa2\xbd\x97i\x13\x00\x00\x92q\x9b\r\xaa\x12\x00\x007\xabj]\xe8\x12\x00\x00U\xc4m\xd9^\x13\x00\x00\xf6G"tc\x13\x00\x00v\xdc\x1e|v\x14\x00\x00Rc\xe2\xdbZ\x13\x00\x00j\t`\xf1\x17\x14\x00\x00\xfdq\x14i\xb5\x12\x00\x00PD\x9aSx\x14\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x00\xd7df\'@\x14\x00\x00zV\xf4\xdeu\x13\x00\x00\xcdN\x12Na\x13\x00\x00\xc3\xc3\x94[\x0b\x14\x00\x00O\x02W\xdeV\x13\x00\x00V\x19\xfd\x90\x94\x13\x00\x00\x12\x06\x98\x15\xbd\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00Y\xdcee\xfb\x12\x00\x00&X\xd8L\xa3\x13\x00\x00\x96\xc5\xd8\xeb\x80\x13\x00\x00\x8e\xa84\x16\\\x13\x00\x00\x00q\xc2\x8fV\x13\x00\x00d\xa9&\xcdr\x13\x00\x00\xdb\xcb\xefG+\x14\x00\x00np\xe9\x11\x03\x14\x00\x00,\xb8\x11qH\x14\x00\x00=\xbc\x12\xed>\x13\x00\x00\xd9\x83\xae\xaf"\x13\x00\x00 \xe5R\xe6\xe9\x13\x00\x00\xd8jdJ\'\x14\x00\x00\x85rF\xdb;\x14\x00\x00\xc80\x1c\x9f\xdd\x13\x00\x00\xa4\xf3$Q\xfc\x13\x00\x00\xdd\xd7\xeb\x8d\xf9\x13\x00\x00W\xd0i\x1f-\x13\x00\x00\xcfZ\x0e\x94/\x13\x00\x00\x999\xb0+\x99\x12\x00\x00<\x05\xa6^\xa6\x13\x00\x00\xb6\xea\xd7\xad\xc5\x13\x00\x00\x10\r\xe8\x11\x03\x13\x00\x00\xd6\xc0E\xdb\xbb\x13\x00\x00[$\xa7\xfd\x03\x14\x00\x00\xd5\xbaG\xb8\xd4\x13\x00\x00\x9a,b\x0cl\x13\x00\x00\xcf\xf80\xbd\xcc\x13\x00\x00y\xb2\xd3\x92\xf1\x12\x00\x00\xa5\xaa\x91\xdf\x94\x13\x00\x00\x9d\xa09L\x84\x12\x00\x00\xa1\xa5\xe5\x95\x0c\x13\x00\x00\xb0(\xc1\xb2\xbd\x13\x00\x00\xd9!\xd1\xd8\xbf\x13\x00\x00r\x88\xe1\x9d\x9f\x13\x00\x00\x88\xe6\x1d\x1bT\x13\x00\x00]C\xef\x85\xe6\x12\x00\x00s?N,8\x13\x00\x000\x81xh\x96\x13\x00\x00\xaa\xb5;L\x04\x14\x00\x00\x92\xad\xe0_\xe4\x13\x00\x00E(HW\xb2\x13\x00\x00A\xd4\ny\xdb\x12\x00\x00H:B\xc0g\x13\x00\x00\xf9\n\x8bH\xca\x12\x00\x00\xff\xb9U\x01\xbe\x13\x00\x00\xe6I\x1f\x1bT\x14\x00\x00\x88H\xfb\xf1\xb6\x12\x00\x00d\xa9&\xcdr\x13\x00\x00$_(I\xe9\x12\x00\x00:H;\xad&\x14\x00\x00\xe7\x13\xd8\xeb\x00\x13\x00\x00s?N,8\x13\x00\x00}h\xeeG+\x13\x00\x00\xf4\x9d\x03\x05\xf8\x12\x00\x00\x0fC/AV\x14\x00\x00\xaf5\x0f\xd2\xea\x12\x00\x00\xb0(\xc1\xb2\xbd\x13\x00\x00\xc0&\xc4\x0b\xcd\x12\x00\x00\xfck\x16F\xce\x12\x00\x00\xa0\xeex\x07t\x13\x00\x00z\xf4\x16\x08\x13\x14\x00\x00\xea\xff9\xd0\x8d\x14\x00\x00\xe3\xacN\xcb\x15\x13\x00\x00\r\xe8\xa1f9\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\x18\x17@\xa5\x13\x14\x00\x00\x18\x17@\xa5\x13\x14\x00\x00\xa0\xeex\x07t\x13\x00\x00Q\xfb\x06\xe2\x10\x14\x00\x00\xe7\x00\x8c\xa9\xec\x13\x00\x00\xa1\xf4v*[\x13\x00\x00- \xedj\x92\x13\x00\x00$L\xdc\x06\xd5\x13\x00\x00\xad)\x13\x8c\x1c\x13\x00\x00S\x07\x03(\xdf\x13\x00\x00\x92q\x9b\r\xaa\x12\x00\x00\x07\x9b\xb4\x84\xa8\x12\x00\x00\x86\xda!\xd5\x85\x13\x00\x00- \xedj\x92\x13\x00\x00\xb0(\xc1\xb2\xbd\x13\x00\x00~[\xa0(\xfe\x13\x00\x00\x9e\x80\x9f\xeaB\x14\x00\x00\xd4\x03\xdb)<\x14\x00\x00\x96c\xfb\x14\x1e\x14\x00\x00\xf7\xebB\xc0\xe7\x13\x00\x00Rc\xe2\xdbZ\x13\x00\x00E\xd9\xb6\xc2c\x13\x00\x00\xf35(\x0b\xae\x13\x00\x00\xe08w\x8b\xfd\x13\x00\x00\x1a6\x88-\xf6\x12\x00\x00\xce\xf22\x9a\xe5\x13\x00\x00\xce\xf22\x9a\xe5\x13\x00\x00$\xea\xfe/r\x14\x00\x00{\xfa\x14+\xfa\x13\x00\x00\xb7\xf0\xd5\xd0\xac\x13\x00\x00Y\xb6\xcd\xe0\xd2\x14\x00\x00I|\x855\x89\x14\x00\x00\xa6N\xb2+\x19\x14\x00\x00\xc9#\xce\x7f\xb0\x14\x00\x00Z\xcf\x17F\xce\x13\x00\x00\xfa\xea\xf0\xe6\x88\x14\x00\x00\xed\x1149C\x14\x00\x00\x1c\x91\x15\x08\x13\x13\x00\x00+v\xce\xfb&\x13\x00\x00!:\xe2\x9d\x1f\x14\x00\x00N\x9a{\xe4\x0c\x14\x00\x00.u|"\xc8\x13\x00\x00\x18\x17@\xa5\x13\x14\x00\x00k\xc0\xcc\x7f\xb0\x13\x00\x00E;\x94\x99\xc6\x12\x00\x00\x0b\x8d\x14\x8c\x1c\x14\x00\x00V\x19\xfd\x90\x94\x13\x00\x00 \xf8\x9e(\xfe\x12\x00\x00cT\x97\x15=\x13\x00\x00\x0c\xa6^\xf1\x17\x13\x00\x00\xd3\x10)Ii\x13\x00\x00\x08\x8efe{\x13\x00\x00q\xd1t\x0f\x07\x14\x00\x00\xad\xc75\xb5\xb9\x13\x00\x00SV\x94\xbc-\x14\x00\x00\x88\x84@D\xf1\x13\x00\x00\xa9\xc2\x89k1\x13\x00\x00Gp\x89\xef\xba\x14\x00\x00\x16m!6\xa8\x13\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00G\xd2f\xc6\x1d\x14\x00\x00U\xc4m\xd9^\x13\x00\x00\x94\x1b\xba|\x15\x13\x00\x00(\xa0\x19\xe5\xab\x14\x00\x00\x81\xbc+&\x02\x14\x00\x00\xcd\x9d\xa3\xe2\xaf\x13\x00\x00\xad\x16\xc7I\x08\x14\x00\x00:H;\xad&\x14\x00\x00\xe9\xaa\xaa\x18X\x14\x00\x00\xb6L\xb5\x84(\x13\x00\x003\x80&\x8f7\x14\x00\x00\x02jr\x93\x10\x14\x00\x00|\xb1\x81\xb9\x92\x13\x00\x00\xa4\xa4\x93\xbc\xad\x13\x00\x00U\xc4m\xd9^\x13\x00\x00\x18\x17@\xa5\x13\x14\x00\x00q \x06\xa4U\x14\x00\x00\x18\x17@\xa5\x13\x14\x00\x00\xf35(\x0b\xae\x13\x00\x00!:\xe2\x9d\x1f\x14\x00\x00\xd8jdJ\'\x14\x00\x00\xa3O\x04\x05x\x13\x00\x00u\x87\x8f\xc4@\x14\x00\x00\x1d"\xea\x11\x83\x14\x00\x00Y\x18\xab\xb75\x14\x00\x00I\xdeb\x0c\xec\x13\x00\x00\xa1\xa5\xe5\x95\x0c\x13\x00\x00\xfe\xc6\xa3 \xeb\x12\x00\x00\xb0\xd9/\x1eo\x13\x00\x00\xd5k\xb6#\x86\x13\x00\x00\x9c%\x12\x10&\x14\x00\x00\x08\xdd\xf7\xf9\xc9\x13\x00\x00\\*\xa5 \xeb\x13\x00\x00\xa9\xfe\xce\xbdk\x14\x00\x00\x95\xd2&\x0b\xae\x12\x00\x00u\xd6 Y\x8f\x14\x00\x00#\x95ox<\x14\x00\x00\xccH\x14+z\x13\x00\x00\x8e\xe4yh\x96\x14\x00\x00V\xb7\x1f\xba1\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\r\xfb\xed\xa8M\x13\x00\x00\x91\xf6s\xd1K\x14\x00\x00\xa0\x9f\xe7r%\x13\x00\x00*\xbfam\x8e\x13\x00\x00\xc9\x98\xf7\x98\'\x13\x00\x00\xae\x1c\xc5l\xef\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xb3v\x00n\xad\x14\x00\x00\xb2!q\xb6w\x14\x00\x00\xf5\xdfFz\x19\x14\x00\x00\x19\xce\xac3\xac\x13\x00\x00\x12\x06\x98\x15\xbd\x13\x00\x00\xb3v\x00n\xad\x14\x00\x00\xfa\x9b_R:\x14\x00\x00\x17$\x8e\xc4@\x13\x00\x00Y+\xf7\xf9I\x13\x00\x00\x98 f\xc6\x9d\x13\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xdav`\x90\xf5\x13\x00\x00\xbaQa\xce\xb0\x13\x00\x00\x1bx\xcb\xa2\x17\x14\x00\x00\xb7\xf0\xd5\xd0\xac\x13\x00\x00\xc5\x1e"6(\x14\x00\x00\xf9\xe4\xf2\xc3\xa1\x14\x00\x00\xaekV\x01>\x14\x00\x00\x8c\x9c8\xd0\x8d\x13\x00\x00\xfa\xea\xf0\xe6\x88\x14\x00\x00]\x7f4\xd8 \x14\x00\x00Q\x0eS$%\x13\x00\x00\xaa\xb5;L\x04\x14\x00\x00x\xe8\x1a\xc2D\x14\x00\x00\x1bx\xcb\xa2\x17\x14\x00\x00\xf7:\xd4T6\x14\x00\x00zV\xf4\xdeu\x13\x00\x00\xdd9\xc9d\\\x13\x00\x00L\x8e\x7f\x9e>\x14\x00\x00\xd1\xa2O,8\x14\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x00!:\xe2\x9d\x1f\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\x84\xbb\xd9L\xa3\x14\x00\x006\xe1\xb1\x8c;\x14\x00\x00|\xb1\x81\xb9\x92\x13\x00\x00~[\xa0(\xfe\x13\x00\x00.b0\xe0\xb3\x14\x00\x00}h\xeeG+\x13\x00\x00]\xce\xc5lo\x14\x00\x00\xd9\x0e\x85\x96\xab\x14\x00\x00\xda\xc5\xf1$D\x14\x00\x00\xb2!q\xb6w\x14\x00\x00MX8o\xeb\x12\x00\x00U\x00\xb3+\x99\x14\x00\x00\x91XQ\xa8\xae\x13\x00\x00:H;\xad&\x14\x00\x00GG\x90\xdf\x94\x12\x00\x00Zm:ok\x14\x00\x00\xc4\x18$\x13A\x14\x00\x00\xc4\x18$\x13A\x14\x00\x00\x0eP}`\x83\x13\x00\x00e\xaf$\xf0Y\x13\x00\x0018\xe5\xf6.\x13\x00\x00\x90RS\x85\xc7\x13\x00\x00eMG\x19\xf7\x13\x00\x00\x1c\xcdZZM\x14\x00\x00\x05\xdeI\xd3(\x13\x00\x00\xebg\x15\xca\xd7\x13\x00\x00\x93Q\x01\xach\x14\x00\x00k\xad\x80=\x9c\x14\x00\x00\xb2\xd2\xdf!)\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\x17$\x8e\xc4@\x13\x00\x00#\xe4\x00\r\x8b\x14\x00\x00{I\xa6\xbfH\x14\x00\x00bN\x99\xf2U\x13\x00\x00\xbb\xf5\x81\x1a5\x14\x00\x00\xe4\xee\x91@7\x14\x00\x00\xe4\xee\x91@7\x14\x00\x00\xea\xd6@\xc0g\x12\x00\x00\x19\xce\xac3\xac\x13\x00\x00d\xf8\xb7a\xc1\x13\x00\x00\xf3\xe6\x96v_\x13\x00\x00_)SG\x8c\x14\x00\x00\xf5}i\xa3\xb6\x14\x00\x00\x0c\x93\x12\xaf\x03\x14\x00\x00\x04\'\xddD\x90\x13\x00\x00\xc7y\xaf\x10E\x14\x00\x00\xe4\xee\x91@7\x14\x00\x00\t\xe3\xf5\x1c\xb1\x13\x00\x00o\x14\n^\x87\x14\x00\x00M\xe3\x0eVt\x14\x00\x00\xc8\x92\xf9u@\x13\x00\x00\xfc\t9ok\x13\x00\x00*\xac\x15+z\x14\x00\x003\x80&\x8f7\x14\x00\x00H\xd8d\xe9\x04\x14\x00\x00\x1d\x84\xc7\xe8\xe5\x13\x00\x00%\xa1k\xbe\n\x14\x00\x00|O\xa4\xe2/\x14\x00\x00\xab\n\xcb\x03:\x14\x00\x00\xce\x90U\xc3\x82\x14\x00\x00>\xaf\xc4\xcd\x11\x14\x00\x00\xb7\xf0\xd5\xd0\xac\x13\x00\x00\xd1\xa2O,8\x14\x00\x00\xaa\xb5;L\x04\x14\x00\x00\xc3\x87O\t\xd1\x12\x00\x00\xacr\xa6\xfd\x83\x13\x00\x00\x89(a\x90u\x14\x00\x00\xcc\xf9\x82\x96+\x13\x00\x00\xdf\xe3\xe7\xd3\xc7\x13\x00\x00\x16\xcf\xfe\x0c\x0b\x13\x00\x00\x19l\xcf\\I\x14\x00\x00\xd7\x15\xd5\x92\xf1\x13\x00\x00t2\x00\r\x0b\x14\x00\x00\xae\xe0\x7f\x1a\xb5\x12\x00\x00\xa9`\xac\x94\xce\x13\x00\x00\x87\xcd\xd3\xb5X\x14\x00\x00\xa9`\xac\x94\xce\x13\x00\x00m.\xa6\x9c\xe1\x12\x00\x00U\xb1!\x97J\x14\x00\x00{I\xa6\xbfH\x14\x00\x00\x9e\x80\x9f\xeaB\x14\x00\x00\xce\x90U\xc3\x82\x14\x00\x00\xd1\x04-\x03\x9b\x13\x00\x00&\xf6\xfau@\x14\x00\x00\xdav`\x90\xf5\x13\x00\x00\xd0M\xc0t\x02\x14\x00\x00\xfbe\x18#\xe7\x12\x00\x00\xaa\xb5;L\x04\x14\x00\x00\xc4\x18$\x13A\x14\x00\x00n!X}\xb4\x13\x00\x00yP\xf6\xbb\x8e\x13\x00\x00O\xef\n\x9cB\x14\x00\x00r&\x04\xc7<\x14\x00\x00r&\x04\xc7<\x14\x00\x00\xa8\x0b\x1d\xdd\x98\x13\x00\x00\xeb\xb6\xa6^&\x14\x00\x00O\xef\n\x9cB\x14\x00\x00\xfeQz\x07t\x14\x00\x004\x86$\xb2\x1e\x14\x00\x00\xf4(\xda\xeb\x80\x14\x00\x00U\xb1!\x97J\x14\x00\x00\x90\x03\xc2\xf0x\x13\x00\x00\tE\xd3\xf3\x13\x13\x00\x00$_(I\xe9\x12\x00\x00\xb4\xde\xdbg\xf7\x13\x00\x005\x8c"\xd5\x05\x14\x00\x00\xb2!q\xb6w\x14\x00\x00i\xb4\xd09\xe2\x13\x00\x00!\xebP\t\xd1\x13\x00\x00\xcd;\xc6\x0bM\x14\x00\x005*E\xfe\xa2\x14\x00\x00\xb7\xf0\xd5\xd0\xac\x13\x00\x00\x9e\xf5\xc8\x03\xba\x12\x00\x00\x95\x0el]\xe8\x13\x00\x00\'^\xd6o\x8a\x13\x00\x00\xa0=\n\x9c\xc2\x13\x00\x00Q\xfb\x06\xe2\x10\x14\x00\x00\xf0\xd4\x9c\r\xaa\x13\x00\x007I\x8d\x86\x85\x13\x00\x00Z\xcf\x17F\xce\x13\x00\x00\xe4\x01\xde\x82K\x13\x00\x00\x1a\x10\xf0\xa8\xcd\x14\x00\x00\x0c\xe2\xa3CR\x14\x00\x00\x7f\xb0/\xe03\x14\x00\x00)W\x86sD\x14\x00\x00\xe8hg\xa36\x13\x00\x00\xf5}i\xa3\xb6\x14\x00\x00(\xa0\x19\xe5\xab\x14\x00\x00\xd4\x16\'lP\x13\x00\x00\x03\xbf\x01KF\x14\x00\x00-\xbe\x0f\x94/\x14\x00\x00\xd9!\xd1\xd8\xbf\x13\x00\x00\xa5H\xb4\x082\x14\x00\x000\x1f\x9b\x913\x14\x00\x00p\xcbv\xec\x1f\x14\x00\x00*\xac\x15+z\x14\x00\x00\xab\n\xcb\x03:\x14\x00\x00\xca\xda:\x0eI\x14\x00\x00\\*\xa5 \xeb\x13\x00\x00lw9\x0eI\x13\x00\x00\xc6$ Y\x0f\x14\x00\x00\xa4B\xb6\xe5J\x14\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00\xad\x16\xc7I\x08\x14\x00\x00\x87/\xb1\x8c\xbb\x13\x00\x00\x8f\x9b\xe6\xf6.\x14\x00\x00\x16\xcf\xfe\x0c\x0b\x13\x00\x00"\xde\x02\xea\xa3\x14\x00\x00\xa9`\xac\x94\xce\x13\x00\x00\xd2\xf7\xde\xe3m\x14\x00\x00\xbfoW}4\x13\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00u\x87\x8f\xc4@\x14\x00\x00\x18\x17@\xa5\x13\x14\x00\x00eMG\x19\xf7\x13\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\xb3\xeb)\x87$\x13\x00\x00cAK\xd3(\x14\x00\x00g\xa8\xd4\xf3\x13\x14\x00\x00q \x06\xa4U\x14\x00\x00\\y6\xb59\x14\x00\x0031\x95\xfa\xe8\x13\x00\x00\x1a6\x88-\xf6\x12\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x00[\xc2\xc9&\xa1\x14\x00\x00\xdb\x1a\x81\xdcy\x14\x00\x00u\x87\x8f\xc4@\x14\x00\x00\x88\xd3\xd1\xd8?\x14\x00\x00\xb3\x89L\xb0\xc1\x13\x00\x00\x80g\x9cn\xcc\x13\x00\x00\xb3\x89L\xb0\xc1\x13\x00\x00;a\x85\x12"\x13\x00\x00\'K\x8a-v\x14\x00\x00\x04\xc5\xffm-\x14\x00\x00\n\xe9\xf3?\x98\x13\x00\x00\x06o\x1e\xdd\x98\x14\x00\x00\xc1\x19v\xec\x9f\x13\x00\x00\xcf\xf80\xbd\xcc\x13\x00\x00\xd0\xaf\x9dKe\x13\x00\x00i\xb4\xd09\xe2\x13\x00\x00\xcd\x9d\xa3\xe2\xaf\x13\x00\x003\xe2\x03f\x9a\x13\x00\x00`B\x9d\xac\x87\x13\x00\x00\xaa\xb5;L\x04\x14\x00\x00H\'\xf6}S\x14\x00\x00\xed7\xcc\xbdk\x12\x00\x00\xe8\xb7\xf87\x85\x13\x00\x00a\xf9\t; \x13\x00\x00\x87~B!\n\x14\x00\x00j\t`\xf1\x17\x14\x00\x00$_(I\xe9\x12\x00\x00cAK\xd3(\x14\x00\x00\xde\xf05\xf3\xf4\x12\x00\x00u\xe9l\x9b\xa3\x13\x00\x005=\x91@\xb7\x13\x00\x00JF>\x066\x13\x00\x001\xd6\x07 \xcc\x13\x00\x00 \xf8\x9e(\xfe\x12\x00\x00hL\xf5?\x98\x14\x00\x00n\x835T\x17\x13\x00\x00x\xe8\x1a\xc2D\x14\x00\x00\x88"cm\x8e\x14\x00\x00OQ\xe8r\xa5\x13\x00\x00\'^\xd6o\x8a\x13\x00\x00\xb1\x1bs\x93\x90\x14\x00\x00\xf7:\xd4T6\x14\x00\x00\xf1),\xc5\xdf\x13\x00\x00JF>\x066\x13\x00\x00o\'V\xa0\x9b\x13\x00\x00RP\x96\x99F\x14\x00\x00cT\x97\x15=\x13\x00\x00\xcd\x9d\xa3\xe2\xaf\x13\x00\x00\x86\xda!\xd5\x85\x13\x00\x002\xdc\x05C\xb3\x13\x00\x00}U\xa2\x05\x17\x14\x00\x00!:\xe2\x9d\x1f\x14\x00\x00\xd6\xc0E\xdb\xbb\x13\x00\x00\xde,{E/\x14\x00\x00\xc5m\xb3\xcav\x14\x00\x00\xc2\xbd\x968$\x14\x00\x00\xe9\xaa\xaa\x18X\x14\x00\x00=Z5\x16\xdc\x13\x00\x00\xba\xef\x83\xf7M\x14\x00\x00x\xe8\x1a\xc2D\x14\x00\x00|\x9e5w~\x14\x00\x00\xf8@\xd2w\x1d\x14\x00\x00\xed`\xc5\xcd\x91\x14\x00\x00\xc9\x85\xabV\x13\x14\x00\x00\xf7:\xd4T6\x14\x00\x00\x8e\xe4yh\x96\x14\x00\x00w\x93\x8b\n\x0f\x14\x00\x00\x00^vMB\x14\x00\x00{\\\xf2\x01]\x13\x00\x00\x13\xf9I\xf6\x8f\x14\x00\x00\x9e\xcf0\x7f\x91\x14\x00\x00\xba\xef\x83\xf7M\x14\x00\x00\xb3v\x00n\xad\x14\x00\x00\xcc\x84Y}\xb4\x14\x00\x00\xff\x08\xe7\x95\x0c\x14\x00\x00\x89\xd9\xcf\xfb&\x14\x00\x00G\xd2f\xc6\x1d\x14\x00\x00\xd1\xa2O,8\x14\x00\x00\xda\x14\x83\xb9\x92\x14\x00\x00\xc4\x18$\x13A\x14\x00\x00\x86\xda!\xd5\x85\x13\x00\x00\xa1\xe1*\xe8F\x14\x00\x00\xaa\x17\x19#g\x13\x00\x00\x9c%\x12\x10&\x14\x00\x00&\xf6\xfau@\x14\x00\x00\x89(a\x90u\x14\x00\x00\x8fLUb\xe0\x13\x00\x00\xa1\xe1*\xe8F\x14\x00\x00Q\xfb\x06\xe2\x10\x14\x00\x00\xf2~\xbb|\x15\x14\x00\x00\x19l\xcf\\I\x14\x00\x00O\xef\n\x9cB\x14\x00\x00A\xaer\xf4\xb2\x14\x00\x00\xd4\x03\xdb)<\x14\x00\x00\x84\x1d\xb7#\x06\x14\x00\x00\x86\xda!\xd5\x85\x13\x00\x00\xe7\x00\x8c\xa9\xec\x13\x00\x00\xc1h\x07\x81\xee\x13\x00\x00\x9d\xc92\\\xaa\x14\x00\x00\x17`\xd3\x16{\x14\x00\x00Xa>)\x9d\x14\x00\x00\x9d+\x103\r\x14\x00\x00\xfc\xba\xa7\xda\x1c\x13\x00\x00\xad\x16\xc7I\x08\x14\x00\x002+\x97\xd7\x01\x14\x00\x00\xa5H\xb4\x082\x14\x00\x00J3\xf2\xc3!\x14\x00\x00 \x96\xc1Q\x9b\x13\x00\x00\xebg\x15\xca\xd7\x13\x00\x00,\xb8\x11qH\x14\x00\x00G\xd2f\xc6\x1d\x14\x00\x00G\xd2f\xc6\x1d\x14\x00\x00)\x08\xf5\xde\xf5\x13\x00\x00\x0e\x8c\xc2\xb2\xbd\x14\x00\x00t\x81\x91\xa1Y\x14\x00\x00\xf7:\xd4T6\x14\x00\x00SV\x94\xbc-\x14\x00\x00B)\x9a0\x11\x13\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00,\x07\xa3\x05\x97\x14\x00\x00LR:L\x04\x13\x00\x00\xa7T\xb0N\x00\x14\x00\x00\x86\xda!\xd5\x85\x13\x00\x00\x8c\x9c8\xd0\x8d\x13\x00\x00\xf5\xdfFz\x19\x14\x00\x00\x81\x1e\t\xfdd\x13\x00\x00a\xf9\t; \x13\x00\x00 \x96\xc1Q\x9b\x13\x00\x00\xf7\x9c\xb1+\x99\x13\x00\x00\xfc\t9ok\x13\x00\x00\xfd^\xc8&\xa1\x13\x00\x00}\x06\x11q\xc8\x13\x00\x00\xc4z\x01\xea\xa3\x13\x00\x00&X\xd8L\xa3\x13\x00\x00(\x15C\xfe"\x13\x00\x00Yz\x88\x8e\x98\x13\x00\x00\x83\xc8\'l\xd0\x13\x00\x00\x93\x02p\x17\x1a\x14\x00\x00Q\x0eS$%\x13\x00\x00\x840\x03f\x1a\x13\x00\x00i\xb4\xd09\xe2\x13\x00\x00d\xf8\xb7a\xc1\x13\x00\x00\xa4U\x02(_\x13\x00\x00\xe4\x9f\x00\xac\xe8\x13\x00\x00\xc7=j\xbe\n\x13\x00\x00\xf35(\x0b\xae\x13\x00\x00i\xb4\xd09\xe2\x13\x00\x00\x0cD\x81\x1a\xb5\x13\x00\x00]\xe1\x11\xaf\x83\x13\x00\x00\x97\x1ah\xa3\xb6\x13\x00\x00\x1d\x84\xc7\xe8\xe5\x13\x00\x00\\\x8c\x82\xf7M\x13\x00\x00\x01\xc6QG\x8c\x13\x00\x00>\x11\xa2\xa4t\x13\x00\x00;\xff\xa7;\xbf\x13\x00\x00\xd0M\xc0t\x02\x14\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00&X\xd8L\xa3\x13\x00\x00\xeds\x11\x10\xa6\x13\x00\x00\x15\x18\x92~r\x13\x00\x00\r\x99\x10\xd2\xea\x13\x00\x00\xaf\xd31\xfb\x87\x13\x00\x002>\xe3\x19\x16\x13\x00\x00\xb5\x95H\xf6\x8f\x13\x00\x001\xd6\x07 \xcc\x13\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\xfe\xb3W\xde\xd6\x13\x00\x00\xe8\xb7\xf87\x85\x13\x00\x00\x0b\xef\xf1b\x7f\x13\x00\x00\xdd9\xc9d\\\x13\x00\x008\x00\xfa\x14\x1e\x13\x00\x00\xe0K\xc3\xcd\x11\x13\x00\x00\x99\xd7\xd2T6\x13\x00\x00I\x8f\xd1w\x9d\x13\x00\x00RP\x96\x99F\x14\x00\x00\x08\xdd\xf7\xf9\xc9\x13\x00\x00\x9a,b\x0cl\x13\x00\x00\xd3\x10)Ii\x13\x00\x00;\xff\xa7;\xbf\x13\x00\x00i\xb4\xd09\xe2\x13\x00\x00\x04\xc5\xffm-\x14\x00\x00\x93\x02p\x17\x1a\x14\x00\x00\xeds\x11\x10\xa6\x13\x00\x00\r\x99\x10\xd2\xea\x13\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00\xff\x1b3\xd8 \x13\x00\x00\x96\xc5\xd8\xeb\x80\x13\x00\x00\xb1}Pj\xf3\x13\x00\x00\xef\x1d0\x7f\x11\x14\x00\x00\xe4\x9f\x00\xac\xe8\x13\x00\x00\xa6\xff \x97\xca\x13\x00\x00\xa6\xff \x97\xca\x13\x00\x00M\xa7\xc9\x03:\x13\x00\x00T\r\x01K\xc6\x13\x00\x00q3R\xe6i\x13\x00\x00s\xddpU\xd5\x13\x00\x00\x9b\x81\xf1\xc3\xa1\x13\x00\x00\xeb\xb6\xa6^&\x14\x00\x00\xdb\xcb\xefG+\x14\x00\x00>\xfeUb`\x14\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x004\xd5\xb5Fm\x14\x00\x00\xec\x1e\x82Xp\x13\x00\x00\xd2\xf7\xde\xe3m\x14\x00\x00\xf35(\x0b\xae\x13\x00\x00\xa3\x00sp)\x13\x00\x00)j\xd2\xb5X\x13\x00\x00\x11\xb1\x08^\x87\x13\x00\x00"@\xe0\xc0\x06\x14\x00\x00\xa5\xaa\x91\xdf\x94\x13\x00\x00q3R\xe6i\x13\x00\x00}\x06\x11q\xc8\x13\x00\x00\x17\xc2\xb0\xed\xdd\x13\x00\x00\xbd\x14\xca\xa2\x17\x13\x00\x00\x00^vMB\x14\x00\x00\xf64\xd61O\x14\x00\x00\xa5\xaa\x91\xdf\x94\x13\x00\x00F}\xd7\x0e\xe8\x13\x00\x00)j\xd2\xb5X\x13\x00\x007\xe7\xaf\xaf"\x14\x00\x00\x80\x05\xbf\x97i\x14\x00\x00\xe1\x8d\x06C3\x14\x00\x00\xb5\x95H\xf6\x8f\x13\x00\x00F}\xd7\x0e\xe8\x13\x00\x00i\xb4\xd09\xe2\x13\x00\x00}\x06\x11q\xc8\x13\x00\x00\xc5\xcf\x90\xa1\xd9\x13\x00\x00\xcc\xe66T\x17\x14\x00\x00\xcc\xe66T\x17\x14\x00\x00\x92\xad\xe0_\xe4\x13\x00\x00\x99\xd7\xd2T6\x13\x00\x00\xf7\x9c\xb1+\x99\x13\x00\x00\xd5\xbaG\xb8\xd4\x13\x00\x00I\x8f\xd1w\x9d\x13\x00\x00\xde\x8eX\x1c\x92\x13\x00\x009\x91\xce\x1e\x8e\x14\x00\x00z\x07cJ\'\x13\x00\x00\x94W\xff\xceO\x14\x00\x00\x94W\xff\xceO\x14\x00\x00!\xebP\t\xd1\x13\x00\x00\x07\x88hB\x94\x13\x00\x00\x93\x02p\x17\x1a\x14\x00\x00i\xb4\xd09\xe2\x13\x00\x00\xa4U\x02(_\x13\x00\x00\n\x9ab\xabI\x13\x00\x00\xfa\x9b_R:\x14\x00\x00G\xe5\xb2\x082\x13\x00\x00\xe4\x9f\x00\xac\xe8\x13\x00\x00\xe4\x9f\x00\xac\xe8\x13\x00\x00\x86\xda!\xd5\x85\x13\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00\x05\x1a\x8f%c\x14\x00\x00\x1f.\xe6WQ\x14\x00\x00\xc5\xcf\x90\xa1\xd9\x13\x00\x00{I\xa6\xbfH\x14\x00\x00\xa9\xc2\x89k1\x13\x00\x00\x9f\xd5.\xa2x\x14\x00\x00\xe3Jq\xf4\xb2\x13\x00\x00\tE\xd3\xf3\x13\x13\x00\x00\x1b\xda\xa8yz\x13\x00\x00\xe3Jq\xf4\xb2\x13\x00\x00\\\x8c\x82\xf7M\x13\x00\x00\xc6$ Y\x0f\x14\x00\x00t2\x00\r\x0b\x14\x00\x00\xef\x1d0\x7f\x11\x14\x00\x00g\xf7e\x88b\x14\x00\x00{\\\xf2\x01]\x13\x00\x00H\'\xf6}S\x14\x00\x00\x83\xc8\'l\xd0\x13\x00\x00*\xbfam\x8e\x13\x00\x00\xbe\xa5\x9e\xac\x87\x14\x00\x00]\xe1\x11\xaf\x83\x13\x00\x00\xb3\'o\xd9^\x14\x00\x00\xb7R\xb3\xa7\x0f\x13\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\xeb\xc9\xf2\xa0:\x13\x00\x00\xe6I\x1f\x1bT\x14\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x001\xd6\x07 \xcc\x13\x00\x00\xfa\x9b_R:\x14\x00\x00\x96\xc5\xd8\xeb\x80\x13\x00\x00\\\x8c\x82\xf7M\x13\x00\x00\x14\xc3\x02\xc7<\x13\x00\x00\x840\x03f\x1a\x13\x00\x003\x80&\x8f7\x14\x00\x00~[\xa0(\xfe\x13\x00\x00p\xde\xc2.4\x13\x00\x00D\xd3\xb8\x9f|\x13\x00\x00s\xddpU\xd5\x13\x00\x00&X\xd8L\xa3\x13\x00\x00\xc2\xbd\x968$\x14\x00\x00\xfa\x9b_R:\x14\x00\x00{\\\xf2\x01]\x13\x00\x00\xf8\xf1@\xe3\xce\x13\x00\x00\xd2\xf7\xde\xe3m\x14\x00\x00\xdav`\x90\xf5\x13\x00\x00J\xe4`/\xd3\x13\x00\x00.\x13\x9fKe\x14\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00\xd1\xa2O,8\x14\x00\x00\x82s\x98\xb4\x9a\x13\x00\x00\xff\x08\xe7\x95\x0c\x14\x00\x00i\xb4\xd09\xe2\x13\x00\x00\xce\xa3\xa1\x05\x97\x13\x00\x00\\\x8c\x82\xf7M\x13\x00\x00\r\x99\x10\xd2\xea\x13\x00\x00\xb1}Pj\xf3\x13\x00\x00i\xb4\xd09\xe2\x13\x00\x00\xfa\x9b_R:\x14\x00\x00\xdd9\xc9d\\\x13\x00\x00(\x02\xf7\xbb\x0e\x14\x00\x00ov\xe74\xea\x13\x00\x00 \x96\xc1Q\x9b\x13\x00\x00\x93\x02p\x17\x1a\x14\x00\x00\x82s\x98\xb4\x9a\x13\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00\r\x99\x10\xd2\xea\x13\x00\x00Ub\x90\x02\xfc\x13\x00\x00\x8f\x9b\xe6\xf6.\x14\x00\x00\t2\x87\xb1\xff\x13\x00\x00\x89\xd9\xcf\xfb&\x14\x00\x00|\xb1\x81\xb9\x92\x13\x00\x00\xa5\xaa\x91\xdf\x94\x13\x00\x00z\x07cJ\'\x13\x00\x00"@\xe0\xc0\x06\x14\x00\x00\x15\x05F<^\x14\x00\x00\x7f\xb0/\xe03\x14\x00\x00;\xff\xa7;\xbf\x13\x00\x00T\r\x01K\xc6\x13\x00\x00T\r\x01K\xc6\x13\x00\x00@\xbb\xc0\x13\xe0\x13\x00\x00j\t`\xf1\x17\x14\x00\x00\x18\x17@\xa5\x13\x14\x00\x00 \x96\xc1Q\x9b\x13\x00\x00\xee\xc8\xa0\xc7\xdb\x13\x00\x00\x19l\xcf\\I\x14\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00\xed`\xc5\xcd\x91\x14\x00\x00\x86\xc7\xd5\x92q\x14\x00\x00|\xb1\x81\xb9\x92\x13\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\xfd^\xc8&\xa1\x13\x00\x00\x88\x84@D\xf1\x13\x00\x00(\x02\xf7\xbb\x0e\x14\x00\x00Be\xdf\x82K\x14\x00\x00\x8c\x9c8\xd0\x8d\x13\x00\x00\xae~\xa2CR\x13\x00\x00\xfe\xb3W\xde\xd6\x13\x00\x00\xe2\xe2\x95\xfah\x14\x00\x00\x1a\xc1^\x14\x7f\x14\x00\x00\x82s\x98\xb4\x9a\x13\x00\x006\x92 \xf8\xec\x13\x00\x00\x9a,b\x0cl\x13\x00\x00\t2\x87\xb1\xff\x13\x00\x00Rc\xe2\xdbZ\x13\x00\x00\x15\x05F<^\x14\x00\x00 \x96\xc1Q\x9b\x13\x00\x00\x1a\xc1^\x14\x7f\x14\x00\x00\xc8\x92\xf9u@\x13\x00\x00Q\x0eS$%\x13\x00\x00(\x02\xf7\xbb\x0e\x14\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00\xa5\xaa\x91\xdf\x94\x13\x00\x00@\xbb\xc0\x13\xe0\x13\x00\x004\xd5\xb5Fm\x14\x00\x00\x03pp\xb6\xf7\x13\x00\x00\xe5\xf4\x8fc\x1e\x14\x00\x00b\x8a\xdeD\x90\x14\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00\xdc \x7f\xff`\x14\x00\x00\xf9F\xd0\x9a\x04\x14\x00\x00?f1\\\xaa\x13\x00\x00\x9a,b\x0cl\x13\x00\x00k^\xef\xa8M\x14\x00\x00\x05\x1a\x8f%c\x14\x00\x00Ub\x90\x02\xfc\x13\x00\x00i\xb4\xd09\xe2\x13\x00\x00S\xb8q\x93\x90\x13\x00\x00k"\xaaV\x13\x13\x00\x00\xfa\x9b_R:\x14\x00\x00A\x10P\xcb\x15\x14\x00\x00\xa5\xaa\x91\xdf\x94\x13\x00\x00\x9d+\x103\r\x14\x00\x00\n\x9ab\xabI\x13\x00\x001\xd6\x07 \xcc\x13\x00\x00{\\\xf2\x01]\x13\x00\x00\x840\x03f\x1a\x13\x00\x00\x13[\'\xcd\xf2\x13\x00\x00)j\xd2\xb5X\x13\x00\x00 \x96\xc1Q\x9b\x13\x00\x00\x8c\x9c8\xd0\x8d\x13\x00\x00~[\xa0(\xfe\x13\x00\x00ov\xe74\xea\x13\x00\x00@\xbb\xc0\x13\xe0\x13\x00\x00V\xb7\x1f\xba1\x14\x00\x00\xb5\x95H\xf6\x8f\x13\x00\x00\xa5\xaa\x91\xdf\x94\x13\x00\x00g\n\xb2\xcav\x13\x00\x00\xe5\xf4\x8fc\x1e\x14\x00\x00\xd0M\xc0t\x02\x14\x00\x00Be\xdf\x82K\x14\x00\x00=\xbc\x12\xed>\x13\x00\x00\xe1\xa0R\x85G\x13\x00\x00\xd9!\xd1\xd8\xbf\x13\x00\x00\xbf\xbe\xe8\x11\x83\x13\x00\x009\x91\xce\x1e\x8e\x14\x00\x00eMG\x19\xf7\x13\x00\x00\x9bn\xa5\x81\x8d\x14\x00\x00\xb7?ge\xfb\x13\x00\x00k"\xaaV\x13\x13\x00\x00\x02\x1b\xe1\xfe\xc1\x13\x00\x00{\\\xf2\x01]\x13\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x00Be\xdf\x82K\x14\x00\x00*\xbfam\x8e\x13\x00\x00\x14\xc3\x02\xc7<\x13\x00\x00,i\x80\xdc\xf9\x13\x00\x00\xfd^\xc8&\xa1\x13\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00z\x07cJ\'\x13\x00\x00z\xf4\x16\x08\x13\x14\x00\x009\x91\xce\x1e\x8e\x14\x00\x00\xce\x90U\xc3\x82\x14\x00\x00H:B\xc0g\x13\x00\x00\x00^vMB\x14\x00\x00*\xbfam\x8e\x13\x00\x00\xf8\xf1@\xe3\xce\x13\x00\x00{\\\xf2\x01]\x13\x00\x00k^\xef\xa8M\x14\x00\x007\xe7\xaf\xaf"\x14\x00\x00\x9b\x81\xf1\xc3\xa1\x13\x00\x00\xd8\xccA!\x8a\x13\x00\x00\x93\x02p\x17\x1a\x14\x00\x00\n\x9ab\xabI\x13\x00\x00\xa4U\x02(_\x13\x00\x00\xa7T\xb0N\x00\x14\x00\x00\x17\xc2\xb0\xed\xdd\x13\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\x840\x03f\x1a\x13\x00\x00 \x83u\x0f\x87\x14\x00\x00\xaf\xd31\xfb\x87\x13\x00\x00\xec\x1e\x82Xp\x13\x00\x00eMG\x19\xf7\x13\x00\x00\x89\xd9\xcf\xfb&\x14\x00\x00\xed`\xc5\xcd\x91\x14\x00\x00\x87/\xb1\x8c\xbb\x13\x00\x00W\x0c\xafqg\x14\x00\x00V\xb7\x1f\xba1\x14\x00\x00v\xdc\x1e|v\x14\x00\x00\xd0M\xc0t\x02\x14\x00\x00-\xbe\x0f\x94/\x14\x00\x00\xec\x1e\x82Xp\x13\x00\x00\xad)\x13\x8c\x1c\x13\x00\x003\x93r\xd1K\x13\x00\x00\x1c/81\xb0\x13\x00\x00\xdb\xcb\xefG+\x14\x00\x00\x13[\'\xcd\xf2\x13\x00\x00>\x11\xa2\xa4t\x13\x00\x00Be\xdf\x82K\x14\x00\x00\x0b\xef\xf1b\x7f\x13\x00\x00\x82s\x98\xb4\x9a\x13\x00\x00Ub\x90\x02\xfc\x13\x00\x00\xf1\xc7N\xee|\x14\x00\x00@\xbb\xc0\x13\xe0\x13\x00\x00\xc3%r2n\x13\x00\x00\xd7w\xb2iT\x13\x00\x00\xde\x8eX\x1c\x92\x13\x00\x00a5O\x8dZ\x14\x00\x00\xd2\xf7\xde\xe3m\x14\x00\x00\xa5\xaa\x91\xdf\x94\x13\x00\x00$\xea\xfe/r\x14\x00\x00\xb0(\xc1\xb2\xbd\x13\x00\x00\x92\xad\xe0_\xe4\x13\x00\x00s\xddpU\xd5\x13\x00\x00l\xb3~`\x83\x14\x00\x00K9\xf0\xe6\x08\x14\x00\x00\xbdP\x0f\xf5Q\x14\x00\x00\xcc\xe66T\x17\x14\x00\x00I\x8f\xd1w\x9d\x13\x00\x00\xbdP\x0f\xf5Q\x14\x00\x00\xd6\x0f\xd7o\n\x14\x00\x00(\x15C\xfe"\x13\x00\x00I|\x855\x89\x14\x00\x00|\xb1\x81\xb9\x92\x13\x00\x00\xf9F\xd0\x9a\x04\x14\x00\x00H:B\xc0g\x13\x00\x00\xd0M\xc0t\x02\x14\x00\x00\tE\xd3\xf3\x13\x13\x00\x00ov\xe74\xea\x13\x00\x00\x8f\xae29C\x13\x00\x00\xbdP\x0f\xf5Q\x14\x00\x00\x0fC/AV\x14\x00\x002+\x97\xd7\x01\x14\x00\x00\xf8\xf1@\xe3\xce\x13\x00\x00K9\xf0\xe6\x08\x14\x00\x00\x85rF\xdb;\x14\x00\x00\xbdP\x0f\xf5Q\x14\x00\x00\xcd;\xc6\x0bM\x14\x00\x00"@\xe0\xc0\x06\x14\x00\x00\x03pp\xb6\xf7\x13\x00\x00\xb9\xe9\x85\xd4f\x14\x00\x00\x13[\'\xcd\xf2\x13\x00\x00\x15\x05F<^\x14\x00\x00t2\x00\r\x0b\x14\x00\x00\xb1}Pj\xf3\x13\x00\x00\x9f\xd5.\xa2x\x14\x00\x00\x93\x02p\x17\x1a\x14\x00\x00Ub\x90\x02\xfc\x13\x00\x00\x89\xd9\xcf\xfb&\x14\x00\x00"@\xe0\xc0\x06\x14\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\xd1\xa2O,8\x14\x00\x00\x91XQ\xa8\xae\x13\x00\x00\xd1\xa2O,8\x14\x00\x00\t2\x87\xb1\xff\x13\x00\x00\x19l\xcf\\I\x14\x00\x00N8\x9e\r\xaa\x14\x00\x00#\x95ox<\x14\x00\x00?f1\\\xaa\x13\x00\x00\xe3Jq\xf4\xb2\x13\x00\x009\x91\xce\x1e\x8e\x14\x00\x00\xb1}Pj\xf3\x13\x00\x00\tE\xd3\xf3\x13\x13\x00\x00H:B\xc0g\x13\x00\x00[$\xa7\xfd\x03\x14\x00\x00u\x87\x8f\xc4@\x14\x00\x00\x95\xac\x8e\x86\x85\x14\x00\x00\xd8\xccA!\x8a\x13\x00\x00\xfb\xf0\xee\tp\x14\x00\x00\xfb\xb4\xa9\xb75\x13\x00\x00\xe5\xf4\x8fc\x1e\x14\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00\n\x9ab\xabI\x13\x00\x00\x1a\xc1^\x14\x7f\x14\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00\xaf\xd31\xfb\x87\x13\x00\x00]\xce\xc5lo\x14\x00\x00\xb9\xfc\xd1\x16{\x13\x00\x00!\xd8\x04\xc7\xbc\x14\x00\x00\x93\x02p\x17\x1a\x14\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00\xd0M\xc0t\x02\x14\x00\x00\x0b\xef\xf1b\x7f\x13\x00\x00c\xa3(\xaa\x8b\x13\x00\x00$\xae\xb9\xdd7\x13\x00\x00\x87/\xb1\x8c\xbb\x13\x00\x00\xc3%r2n\x13\x00\x00\\y6\xb59\x14\x00\x00a5O\x8dZ\x14\x00\x00\xaaS^u\xa1\x14\x00\x00\x90\x03\xc2\xf0x\x13\x00\x00\x91XQ\xa8\xae\x13\x00\x00~[\xa0(\xfe\x13\x00\x00\xe4\x9f\x00\xac\xe8\x13\x00\x00t2\x00\r\x0b\x14\x00\x00"@\xe0\xc0\x06\x14\x00\x00\xdb\xcb\xefG+\x14\x00\x00\xc4g\xb5\xa7\x8f\x14\x00\x00S\xa5%Q|\x14\x00\x00S\xb8q\x93\x90\x13\x00\x00\xe4\x9f\x00\xac\xe8\x13\x00\x00\tE\xd3\xf3\x13\x13\x00\x00\x17\xc2\xb0\xed\xdd\x13\x00\x00\xf8\xf1@\xe3\xce\x13\x00\x00\x15\x05F<^\x14\x00\x00s\xddpU\xd5\x13\x00\x00"@\xe0\xc0\x06\x14\x00\x00i\xb4\xd09\xe2\x13\x00\x005=\x91@\xb7\x13\x00\x00\xd7w\xb2iT\x13\x00\x00\xd8\xb9\xf5\xdeu\x14\x00\x00\xa5\xaa\x91\xdf\x94\x13\x00\x00\x8eY\xa3\x81\r\x13\x00\x00\xcf\xe5\xe4z\xb8\x14\x00\x00Z\xcf\x17F\xce\x13\x00\x00\x8a._\xb3\\\x14\x00\x00b\x8a\xdeD\x90\x14\x00\x005=\x91@\xb7\x13\x00\x00+\x14\xf1$\xc4\x13\x00\x00f\xb5"\x13A\x13\x00\x00\xef\x1d0\x7f\x11\x14\x00\x00@\xbb\xc0\x13\xe0\x13\x00\x00\x18\x17@\xa5\x13\x14\x00\x00\x07\x88hB\x94\x13\x00\x00\xfe\xb3W\xde\xd6\x13\x00\x00\xd8\xb9\xf5\xdeu\x14\x00\x00\x9d+\x103\r\x14\x00\x00\x06o\x1e\xdd\x98\x14\x00\x00\xf9F\xd0\x9a\x04\x14\x00\x00\x91E\x05f\x9a\x14\x00\x00\xf4\x8a\xb7\xc2\xe3\x13\x00\x00\xc9#\xce\x7f\xb0\x14\x00\x00 \x83u\x0f\x87\x14\x00\x00?S\xe5\x19\x96\x14\x00\x00\xa2\x98\x97v\xdf\x13\x00\x00 \x83u\x0f\x87\x14\x00\x00k^\xef\xa8M\x14\x00\x00\xa7T\xb0N\x00\x14\x00\x00\x19l\xcf\\I\x14\x00\x00\x06o\x1e\xdd\x98\x14\x00\x00ru\x95[\x8b\x14\x00\x00\xcc\xe66T\x17\x14\x00\x00\xd0M\xc0t\x02\x14\x00\x00^6\xa1f\xb9\x13\x00\x00\xce\xa3\xa1\x05\x97\x13\x00\x00~[\xa0(\xfe\x13\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00\xc3\x12&\xf0Y\x14\x00\x00`\xe0\xbf\xd5$\x14\x00\x00%?\x8e\xe7\xa7\x14\x00\x00\x9b\x81\xf1\xc3\xa1\x13\x00\x00\x03pp\xb6\xf7\x13\x00\x00\x8b\x83\xeej\x92\x14\x00\x00\xba>\x15\x8c\x9c\x14\x00\x00}\xf3\xc4.\xb4\x14\x00\x00\xbe\xa5\x9e\xac\x87\x14\x00\x00\xa8\xa9?\x066\x14\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00s\xddpU\xd5\x13\x00\x00\x9c\xd6\x80{\xd7\x13\x00\x00&X\xd8L\xa3\x13\x00\x00\x90\xf0u\xaed\x14\x00\x00~[\xa0(\xfe\x13\x00\x00\x14\xc3\x02\xc7<\x13\x00\x00\xdav`\x90\xf5\x13\x00\x00q \x06\xa4U\x14\x00\x00\xf7\x89e\xe9\x84\x14\x00\x00A\x10P\xcb\x15\x14\x00\x00\xba>\x15\x8c\x9c\x14\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00\xcf\xf80\xbd\xcc\x13\x00\x00RP\x96\x99F\x14\x00\x00\xb8\x94\xf6\x1c1\x14\x00\x00Ub\x90\x02\xfc\x13\x00\x00\xed`\xc5\xcd\x91\x14\x00\x00\x19l\xcf\\I\x14\x00\x00Ub\x90\x02\xfc\x13\x00\x00\xe1\x8d\x06C3\x14\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x00\x80\x05\xbf\x97i\x14\x00\x00u\x87\x8f\xc4@\x14\x00\x009\x91\xce\x1e\x8e\x14\x00\x00a5O\x8dZ\x14\x00\x00]\xe1\x11\xaf\x83\x13\x00\x00\x1f.\xe6WQ\x14\x00\x00\x15\x18\x92~r\x13\x00\x00\x82\xaf\xdd\x06\xd5\x14\x00\x00b\x8a\xdeD\x90\x14\x00\x00\x83\xc8\'l\xd0\x13\x00\x00f\xa2\xd6\xd0,\x14\x00\x00\xca<\x18\xe5\xab\x13\x00\x00$\xea\xfe/r\x14\x00\x00?f1\\\xaa\x13\x00\x00@\xbb\xc0\x13\xe0\x13\x00\x00J\xe4`/\xd3\x13\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00b\x8a\xdeD\x90\x14\x00\x00\xcc\xf9\x82\x96+\x13\x00\x00W\x0c\xafqg\x14\x00\x00g\n\xb2\xcav\x13\x00\x00\xc6$ Y\x0f\x14\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00k^\xef\xa8M\x14\x00\x000\xbd\xbd\xba\xd0\x14\x00\x00\xc2\xbd\x968$\x14\x00\x00\x01\xb3\x05\x05x\x14\x00\x00\x96\x01\x1e>\xbb\x14\x00\x00\xbf\xfa-d\xbd\x14\x00\x00\x96\x01\x1e>\xbb\x14\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00Be\xdf\x82K\x14\x00\x00\x9bn\xa5\x81\x8d\x14\x00\x00\xf9F\xd0\x9a\x04\x14\x00\x00\xfa\x9b_R:\x14\x00\x00I|\x855\x89\x14\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00\x93\x02p\x17\x1a\x14\x00\x00H\'\xf6}S\x14\x00\x00\xae~\xa2CR\x13\x00\x00\xbb\x93\xa4C\xd2\x14\x00\x00\xfa\x9b_R:\x14\x00\x00W\x0c\xafqg\x14\x00\x00\x17\xafd\xab\xc9\x14\x00\x00\xf93\x84X\xf0\x14\x00\x00v\xdc\x1e|v\x14\x00\x00\x8c\xd8}"\xc8\x14\x00\x00b\x8a\xdeD\x90\x14\x00\x00-\xbe\x0f\x94/\x14\x00\x00\xaaS^u\xa1\x14\x00\x00\x0fC/AV\x14\x00\x00%?\x8e\xe7\xa7\x14\x00\x00m\xcc\xc8\xc5~\x13\x00\x00\xe5\xf4\x8fc\x1e\x14\x00\x00\xa5\x97E\x9d\x80\x14\x00\x00\x9c\xc349\xc3\x14\x00\x00\xd3Ln\x9b\xa3\x14\x00\x00\xf2\x1c\xde\xa5\xb2\x14\x00\x00\xc0O\xbd\x1b\xf3\x14\x00\x00\x07\xc4\xad\x94\xce\x14\x00\x00\x11\xedM\xb0\xc1\x14\x00\x00n]\x9d\xcf\xee\x14\x00\x00\xa6\xec\xd4T\xb6\x14\x00\x00\x11\xedM\xb0\xc1\x14\x00\x00\xc5\xbcD_\xc5\x14\x00\x00\xef\x1d0\x7f\x11\x14\x00\x00\xf8\xf1@\xe3\xce\x13\x00\x00\x8c\xd8}"\xc8\x14\x00\x00D\x0f\xfe\xf1\xb6\x14\x00\x00$\xea\xfe/r\x14\x00\x00\xbf\xfa-d\xbd\x14\x00\x00a5O\x8dZ\x14\x00\x00\xc3%r2n\x13\x00\x00c\xdfm\xfc\xc5\x14\x00\x00#\x95ox<\x14\x00\x00\x19l\xcf\\I\x14\x00\x00\xc8\xce>\xc8z\x14\x00\x00J\xd1\x14\xed\xbe\x14\x00\x00\xef\x1d0\x7f\x11\x14\x00\x00~HT\xe6\xe9\x14\x00\x00\r\x86\xc4\x8f\xd6\x14\x00\x00\x05\x1a\x8f%c\x14\x00\x00\xa9\xfe\xce\xbdk\x14\x00\x00}\xf3\xc4.\xb4\x14\x00\x00\xc3%r2n\x13\x00\x00&\x94\x1d\x9f\xdd\x14\x00\x00\xbdP\x0f\xf5Q\x14\x00\x00\x9a\x19\x16\xcaW\x14\x00\x00\xe37%\xb2\x9e\x14\x00\x00*\xac\x15+z\x14\x00\x00(\x02\xf7\xbb\x0e\x14\x00\x00\xcax]7\xe6\x14\x00\x00\xb0\x15up\xa9\x14\x00\x00\xe4\x9f\x00\xac\xe8\x13\x00\x00K&\xa4\xa4\xf4\x14\x00\x00\x17\xafd\xab\xc9\x14\x00\x00\x87\x1ceJ\xa7\x14\x00\x00!\xebP\t\xd1\x13\x00\x00x\x86=\xeb\xe1\x14\x00\x00\x95\xac\x8e\x86\x85\x14\x00\x00"@\xe0\xc0\x06\x14\x00\x00\xce\x90U\xc3\x82\x14\x00\x00K9\xf0\xe6\x08\x14\x00\x00\x96\x01\x1e>\xbb\x14\x00\x00\x17\xafd\xab\xc9\x14\x00\x00\x96\x01\x1e>\xbb\x14\x00\x00\x16Z\xd5\xf3\x93\x14\x00\x00 \x83u\x0f\x87\x14\x00\x00Be\xdf\x82K\x14\x00\x006\x92 \xf8\xec\x13\x00\x00"-\x94~\xf2\x14\x00\x00\x9c\xc349\xc3\x14\x00\x00\x8c\xd8}"\xc8\x14\x00\x00\xb4|\xfe\x90\x94\x14\x00\x00?S\xe5\x19\x96\x14\x00\x00\xa6\xff \x97\xca\x13\x00\x00j\t`\xf1\x17\x14\x00\x00\x02\x1b\xe1\xfe\xc1\x13\x00\x00\x07\xc4\xad\x94\xce\x14\x00\x00\xbf\xfa-d\xbd\x14\x00\x00\xb4|\xfe\x90\x94\x14\x00\x00K&\xa4\xa4\xf4\x14\x00\x00\x00q\xc2\x8fV\x13\x00\x00\x8c\xd8}"\xc8\x14\x00\x00O\x8d-\xc5\xdf\x14\x00\x007\xe7\xaf\xaf"\x14\x00\x00\x07\xc4\xad\x94\xce\x14\x00\x005*E\xfe\xa2\x14\x00\x00"-\x94~\xf2\x14\x00\x00\xdb\xcb\xefG+\x14\x00\x00\xc5\xbcD_\xc5\x14\x00\x00\xbc\xfb\x7f=\x1c\x14\x00\x00\xa6\xff \x97\xca\x13\x00\x00\xe1\x8d\x06C3\x14\x00\x00\x90\xf0u\xaed\x14\x00\x00+\x01\xa5\xe2\xaf\x14\x00\x00&\x94\x1d\x9f\xdd\x14\x00\x00\xf93\x84X\xf0\x14\x00\x00\xc9#\xce\x7f\xb0\x14\x00\x00\x0fC/AV\x14\x00\x00\x10\x98\xbe\xf8\x8b\x14\x00\x00\xf3qm]\xe8\x14\x00\x00\xa1\x7fM\x11\xe4\x14\x00\x00\xf7\x9c\xb1+\x99\x13\x00\x00\x7f\xb0/\xe03\x14\x00\x00\x84\x1d\xb7#\x06\x14\x00\x00\r\x86\xc4\x8f\xd6\x14\x00\x00\x81ZNO\x9f\x14\x00\x00a5O\x8dZ\x14\x00\x00UOD\xc0\xe7\x14\x00\x00\x04\xc5\xffm-\x14\x00\x000\xbd\xbd\xba\xd0\x14\x00\x00\x97V\xad\xf5\xf0\x14\x00\x00\xf3qm]\xe8\x14\x00\x00\xd1\xa2O,8\x14\x00\x00:\xe6]\xd6\xc3\x14\x00\x00\xb5\xd1\x8dH\xca\x14\x00\x00~[\xa0(\xfe\x13\x00\x00w1\xae3\xac\x14\x00\x00n]\x9d\xcf\xee\x14\x00\x00\xa0*\xbeY\xae\x14\x00\x00O\x8d-\xc5\xdf\x14\x00\x00\x16Z\xd5\xf3\x93\x14\x00\x00"@\xe0\xc0\x06\x14\x00\x00\xf3qm]\xe8\x14\x00\x00\xd0:t2\xee\x14\x00\x00T\xfa\xb4\x08\xb2\x14\x00\x008<?gX\x14\x00\x00\x96\x01\x1e>\xbb\x14\x00\x00\xfd\x9a\ry\xdb\x14\x00\x00\xa1\x7fM\x11\xe4\x14\x00\x00\xdc \x7f\xff`\x14\x00\x00%?\x8e\xe7\xa7\x14\x00\x00n]\x9d\xcf\xee\x14\x00\x00J\xe4`/\xd3\x13\x00\x00%?\x8e\xe7\xa7\x14\x00\x00\xcax]7\xe6\x14\x00\x00Ed\x8d\xa9\xec\x14\x00\x00\xc9#\xce\x7f\xb0\x14\x00\x00)W\x86sD\x14\x00\x00\xab\xa8\xed,\xd7\x14\x00\x008<?gX\x14\x00\x00\xa6\xec\xd4T\xb6\x14\x00\x00=\xbc\x12\xed>\x13\x00\x00\xe9H\xcdA\xf5\x14\x00\x00\x1ck}\x83\xea\x14\x00\x00\x1ck}\x83\xea\x14\x00\x00\xc6$ Y\x0f\x14\x00\x00\xd0M\xc0t\x02\x14\x00\x00H:B\xc0g\x13\x00\x00N8\x9e\r\xaa\x14\x00\x00\xee\xb5T\x85\xc7\x14\x00\x00n]\x9d\xcf\xee\x14\x00\x00!\xebP\t\xd1\x13\x00\x00C\xban:\x81\x14\x00\x00n]\x9d\xcf\xee\x14\x00\x00\x82\xaf\xdd\x06\xd5\x14\x00\x00Y\xb6\xcd\xe0\xd2\x14\x00\x00\x96\x01\x1e>\xbb\x14\x00\x00\x9a\x19\x16\xcaW\x14\x00\x00w1\xae3\xac\x14\x00\x00\x10\x98\xbe\xf8\x8b\x14\x00\x00*\xbfam\x8e\x13\x00\x00&\x94\x1d\x9f\xdd\x14\x00\x00\xb4|\xfe\x90\x94\x14\x00\x00\xb4|\xfe\x90\x94\x14\x00\x00\xca<\x18\xe5\xab\x13\x00\x00\x7f\xb0/\xe03\x14\x00\x00\x80\x05\xbf\x97i\x14\x00\x003\x80&\x8f7\x14\x00\x00c\xdfm\xfc\xc5\x14\x00\x00n]\x9d\xcf\xee\x14\x00\x00^#U$\xa5\x14\x00\x00}\x06\x11q\xc8\x13\x00\x00n]\x9d\xcf\xee\x14\x00\x00\xd4\xa1\xfdR\xd9\x14\x00\x006\x92 \xf8\xec\x13\x00\x00\xe8\xf3=\x8a\xbf\x14\x00\x00\xf2\x1c\xde\xa5\xb2\x14\x00\x00\xe4\x9f\x00\xac\xe8\x13\x00\x00\x84\x1d\xb7#\x06\x14\x00\x00\x1b\x16\xee\xcb\xb4\x14\x00\x00$\xea\xfe/r\x14\x00\x00\xa0*\xbeY\xae\x14\x00\x00\xa7Ad\x0c\xec\x14\x00\x00\x1b\x16\xee\xcb\xb4\x14\x00\x00\xd4\xa1\xfdR\xd9\x14\x00\x00\xc8\xce>\xc8z\x14\x00\x00\xbf\xfa-d\xbd\x14\x00\x00\xd4\xa1\xfdR\xd9\x14\x00\x00\x0fC/AV\x14\x00\x00\xd4\xa1\xfdR\xd9\x14\x00\x00w1\xae3\xac\x14\x00\x00\tE\xd3\xf3\x13\x13\x00\x00\x17\xc2\xb0\xed\xdd\x13\x00\x00D\x0f\xfe\xf1\xb6\x14\x00\x00s\xddpU\xd5\x13\x00\x00$\xea\xfe/r\x14\x00\x00\x1f.\xe6WQ\x14\x00\x00\xc0O\xbd\x1b\xf3\x14\x00\x00+\x01\xa5\xe2\xaf\x14\x00\x00\x1b\x16\xee\xcb\xb4\x14\x00\x00g\xf7e\x88b\x14\x00\x00\x04\xc5\xffm-\x14\x00\x00x\x86=\xeb\xe1\x14\x00\x00\x04\xc5\xffm-\x14\x00\x00\x89\xd9\xcf\xfb&\x14\x00\x00\xc0O\xbd\x1b\xf3\x14\x00\x00\x97V\xad\xf5\xf0\x14\x00\x00\x1a\xc1^\x14\x7f\x14\x00\x00\xbf\xfa-d\xbd\x14\x00\x00\xe6I\x1f\x1bT\x14\x00\x00\x1ck}\x83\xea\x14\x00\x00\x81ZNO\x9f\x14\x00\x00#\x95ox<\x14\x00\x00S\xb8q\x93\x90\x13\x00\x00\xc8\xce>\xc8z\x14\x00\x00\x1ck}\x83\xea\x14\x00\x00\xcc\xe66T\x17\x14\x00\x00\xeb\xb6\xa6^&\x14\x00\x00\xf1\xc7N\xee|\x14\x00\x00\xcax]7\xe6\x14\x00\x00\xcax]7\xe6\x14\x00\x00\xc5\xcf\x90\xa1\xd9\x13\x00\x00\xdc \x7f\xff`\x14\x00\x00!\xd8\x04\xc7\xbc\x14\x00\x00\xa0*\xbeY\xae\x14\x00\x00\xa7Ad\x0c\xec\x14\x00\x00m\x08\x0e\x18\xb9\x14\x00\x00\xc0O\xbd\x1b\xf3\x14\x00\x00\xe3Jq\xf4\xb2\x13\x00\x00\xeb\xc9\xf2\xa0:\x13\x00\x00H\'\xf6}S\x14\x00\x00!\xd8\x04\xc7\xbc\x14\x00\x00\xa0*\xbeY\xae\x14\x00\x00\xc9#\xce\x7f\xb0\x14\x00\x00\xc5\xbcD_\xc5\x14\x00\x00Xa>)\x9d\x14\x00\x00\xe7\x9e\xae\xd2\x89\x14\x00\x00:\xe6]\xd6\xc3\x14\x00\x00?S\xe5\x19\x96\x14\x00\x00\xb6\xea\xd7\xad\xc5\x13\x00\x00\xee\xb5T\x85\xc7\x14\x00\x00\xaf\xc0\xe5\xb8s\x14\x00\x00\x16Z\xd5\xf3\x93\x14\x00\x00m\x08\x0e\x18\xb9\x14\x00\x00g\xf7e\x88b\x14\x00\x00hL\xf5?\x98\x14\x00\x00I|\x855\x89\x14\x00\x00\xeb\xb6\xa6^&\x14\x00\x00n]\x9d\xcf\xee\x14\x00\x00\x10\x98\xbe\xf8\x8b\x14\x00\x00&\x94\x1d\x9f\xdd\x14\x00\x00Ed\x8d\xa9\xec\x14\x00\x00@\xbb\xc0\x13\xe0\x13\x00\x00\xc0O\xbd\x1b\xf3\x14\x00\x00\xcax]7\xe6\x14\x00\x00,i\x80\xdc\xf9\x13\x00\x00n]\x9d\xcf\xee\x14\x00\x00\xd4\xa1\xfdR\xd9\x14\x00\x00\x03pp\xb6\xf7\x13\x00\x00$\xea\xfe/r\x14\x00\x00\xb0\x15up\xa9\x14\x00\x00a5O\x8dZ\x14\x00\x00D\x0f\xfe\xf1\xb6\x14\x00\x00\x9f\xd5.\xa2x\x14\x00\x00\x95\xac\x8e\x86\x85\x14\x00\x00\xd4\xa1\xfdR\xd9\x14\x00\x004\xe8\x01\x89\x81\x13\x00\x00n]\x9d\xcf\xee\x14\x00\x00\xa6\xec\xd4T\xb6\x14\x00\x00b\x8a\xdeD\x90\x14\x00\x00\xc9#\xce\x7f\xb0\x14\x00\x00.\x13\x9fKe\x14\x00\x00\xab\xa8\xed,\xd7\x14\x00\x00\x00^vMB\x14\x00\x00c\xdfm\xfc\xc5\x14\x00\x00\x9f\xd5.\xa2x\x14\x00\x00\xd0:t2\xee\x14\x00\x00\x86\xc7\xd5\x92q\x14\x00\x00i\xa1\x84\xf7\xcd\x14\x00\x00\x1ck}\x83\xea\x14\x00\x00\xbf\xfa-d\xbd\x14\x00\x00\xd4\xa1\xfdR\xd9\x14\x00\x00\xba>\x15\x8c\x9c\x14\x00\x00{\\\xf2\x01]\x13\x00\x00\x05\x1a\x8f%c\x14\x00\x00k^\xef\xa8M\x14\x00\x00_x\xe4\xdb\xda\x14\x00\x00\xa7Ad\x0c\xec\x14\x00\x00\x8b\x83\xeej\x92\x14\x00\x00z\xf4\x16\x08\x13\x14\x00\x00\xb3\'o\xd9^\x14\x00\x00\xa1\x7fM\x11\xe4\x14\x00\x00\x1b\x16\xee\xcb\xb4\x14\x00\x00\x1ck}\x83\xea\x14\x00\x00\xed`\xc5\xcd\x91\x14\x00\x00\xa5\x97E\x9d\x80\x14\x00\x00\x0b\xdc\xa5 k\x14\x00\x00\x9c\xc349\xc3\x14\x00\x004\xd5\xb5Fm\x14\x00\x00\x11\xedM\xb0\xc1\x14\x00\x00\xcf\xe5\xe4z\xb8\x14\x00\x00=\xa9\xc6\xaa*\x14\x00\x00\xfd\x9a\ry\xdb\x14\x00\x00\xe37%\xb2\x9e\x14\x00\x00\x16Z\xd5\xf3\x93\x14\x00\x00\x8a._\xb3\\\x14\x00\x00\xc3\x12&\xf0Y\x14\x00\x00\xbb\x93\xa4C\xd2\x14\x00\x00\xe2\xe2\x95\xfah\x14\x00\x00\xc2\xbd\x968$\x14\x00\x00\xbb\x93\xa4C\xd2\x14\x00\x00\x10\x98\xbe\xf8\x8b\x14\x00\x00Z\xcf\x17F\xce\x13\x00\x00|\x9e5w~\x14\x00\x00\x9d+\x103\r\x14\x00\x00\xf2\x1c\xde\xa5\xb2\x14\x00\x00\xb4|\xfe\x90\x94\x14\x00\x00\xcd;\xc6\x0bM\x14\x00\x00k^\xef\xa8M\x14\x00\x00S\xa5%Q|\x14\x00\x00Be\xdf\x82K\x14\x00\x00^#U$\xa5\x14\x00\x00\xee\xb5T\x85\xc7\x14\x00\x00!\xd8\x04\xc7\xbc\x14\x00\x00\xcd;\xc6\x0bM\x14\x00\x00Y\xb6\xcd\xe0\xd2\x14\x00\x00\x15\x05F<^\x14\x00\x00\xc5\xbcD_\xc5\x14\x00\x00\x8c\xd8}"\xc8\x14\x00\x00~HT\xe6\xe9\x14\x00\x00\x91E\x05f\x9a\x14\x00\x00\xb5\xd1\x8dH\xca\x14\x00\x00O\x8d-\xc5\xdf\x14\x00\x00\x1b\x16\xee\xcb\xb4\x14\x00\x00\xe2\xe2\x95\xfah\x14\x00\x00\xc7y\xaf\x10E\x14\x00\x00\xb5\xd1\x8dH\xca\x14\x00\x00\xcd;\xc6\x0bM\x14\x00\x00\xbb\xa6\xf0\x85\xe6\x13\x00\x00f\xa2\xd6\xd0,\x14\x00\x00^#U$\xa5\x14\x00\x00\x94W\xff\xceO\x14\x00\x00\x8c\xd8}"\xc8\x14\x00\x00\xa4B\xb6\xe5J\x14\x00\x00\xab\xa8\xed,\xd7\x14\x00\x00\xf2\x1c\xde\xa5\xb2\x14\x00\x00\xf0r\xbf6G\x14\x00\x00\xddu\x0e\xb7\x96\x14\x00\x00\xa5\x97E\x9d\x80\x14\x00\x00\xbe\xa5\x9e\xac\x87\x14\x00\x00n]\x9d\xcf\xee\x14\x00\x00D\x0f\xfe\xf1\xb6\x14\x00\x00c\xdfm\xfc\xc5\x14\x00\x00&\x94\x1d\x9f\xdd\x14\x00\x00Xa>)\x9d\x14\x00\x00O\x8d-\xc5\xdf\x14\x00\x00\x07\xc4\xad\x94\xce\x14\x00\x00m\x08\x0e\x18\xb9\x14\x00\x00\xf1\xc7N\xee|\x14\x00\x00/h.\x03\x9b\x14\x00\x00\x82\xaf\xdd\x06\xd5\x14\x00\x000\xbd\xbd\xba\xd0\x14\x00\x00b\x8a\xdeD\x90\x14\x00\x00\xcax]7\xe6\x14\x00\x00n]\x9d\xcf\xee\x14\x00\x00\x1b\x16\xee\xcb\xb4\x14\x00\x00\xb3\'o\xd9^\x14\x00\x00c\xdfm\xfc\xc5\x14\x00\x00v\xdc\x1e|v\x14\x00\x00\x1b\x16\xee\xcb\xb4\x14\x00\x00\xc8\xce>\xc8z\x14\x00\x00-\xbe\x0f\x94/\x14\x00\x00\x97V\xad\xf5\xf0\x14\x00\x00r\x88\xe1\x9d\x9f\x13\x00\x00:\xe6]\xd6\xc3\x14\x00\x000\xbd\xbd\xba\xd0\x14\x00\x00\xddu\x0e\xb7\x96\x14\x00\x00c\xdfm\xfc\xc5\x14\x00\x00\x97V\xad\xf5\xf0\x14\x00\x00\x19l\xcf\\I\x14\x00\x00\xbf\xfa-d\xbd\x14\x00\x00\x95\xac\x8e\x86\x85\x14\x00\x00\xf1\xc7N\xee|\x14\x00\x00n]\x9d\xcf\xee\x14\x00\x00v\xdc\x1e|v\x14\x00\x00\xa0*\xbeY\xae\x14\x00\x00\x82\xaf\xdd\x06\xd5\x14\x00\x00\xd4\xa1\xfdR\xd9\x14\x00\x00\xdb\xcb\xefG+\x14\x00\x00\x1ck}\x83\xea\x14\x00\x00\x1b\x16\xee\xcb\xb4\x14\x00\x00\xcax]7\xe6\x14\x00\x00D\x0f\xfe\xf1\xb6\x14\x00\x00\x00q\xc2\x8fV\x13\x00\x00\xc9#\xce\x7f\xb0\x14\x00\x00N8\x9e\r\xaa\x14\x00\x00\xfd\x9a\ry\xdb\x14\x00\x00v\xdc\x1e|v\x14\x00\x00\xa9\xfe\xce\xbdk\x14\x00\x00\x1b\x16\xee\xcb\xb4\x14\x00\x00\xb5\xd1\x8dH\xca\x14\x00\x00c\xdfm\xfc\xc5\x14\x00\x00c\xdfm\xfc\xc5\x14\x00\x00\x81ZNO\x9f\x14\x00\x00O\x8d-\xc5\xdf\x14\x00\x00\xb4|\xfe\x90\x94\x14\x00\x00M\xe3\x0eVt\x14\x00\x00M\xe3\x0eVt\x14\x00\x00Ub\x90\x02\xfc\x13\x00\x00\x93\x02p\x17\x1a\x14\x00\x00\x82\xaf\xdd\x06\xd5\x14\x00\x00LR:L\x04\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x8c\x9c8\xd0\x8d\x13\x00\x00\xf5\xdfFz\x19\x14\x00\x00\x81\x1e\t\xfdd\x13\x00\x00a\xf9\t; \x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xfc\t9ok\x13\x00\x00\xfd^\xc8&\xa1\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00&X\xd8L\xa3\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00Yz\x88\x8e\x98\x13\x00\x00\x83\xc8\'l\xd0\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00d\xf8\xb7a\xc1\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xc7=j\xbe\n\x13\x00\x00\xf35(\x0b\xae\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x97\x1ah\xa3\xb6\x13\x00\x00\x1d\x84\xc7\xe8\xe5\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00;\xff\xa7;\xbf\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00&X\xd8L\xa3\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xb5\x95H\xf6\x8f\x13\x00\x001\xd6\x07 \xcc\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\xfe\xb3W\xde\xd6\x13\x00\x00\xe8\xb7\xf87\x85\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xdd9\xc9d\\\x13\x00\x008\x00\xfa\x14\x1e\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00RP\x96\x99F\x14\x00\x00\x08\xdd\xf7\xf9\xc9\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xd3\x10)Ii\x13\x00\x00;\xff\xa7;\xbf\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x96\xc5\xd8\xeb\x80\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00M\xa7\xc9\x03:\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xeb\xb6\xa6^&\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00>\xfeUb`\x14\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x004\xd5\xb5Fm\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xf35(\x0b\xae\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x11\xb1\x08^\x87\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xbd\x14\xca\xa2\x17\x13\x00\x00\x00^vMB\x14\x00\x00\xf64\xd61O\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00F}\xd7\x0e\xe8\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xe1\x8d\x06C3\x14\x00\x00\xb5\x95H\xf6\x8f\x13\x00\x00F}\xd7\x0e\xe8\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xcc\xe66T\x17\x14\x00\x00\xcc\xe66T\x17\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xd5\xbaG\xb8\xd4\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xde\x8eX\x1c\x92\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x07\x88hB\x94\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x1f.\xe6WQ\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00{I\xa6\xbfH\x14\x00\x00\xa9\xc2\x89k1\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x1b\xda\xa8yz\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00g\xf7e\x88b\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00H\'\xf6}S\x14\x00\x00\x83\xc8\'l\xd0\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x001\xd6\x07 \xcc\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x96\xc5\xd8\xeb\x80\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x003\x80&\x8f7\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00D\xd3\xb8\x9f|\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00&X\xd8L\xa3\x13\x00\x00\xc2\xbd\x968$\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x82s\x98\xb4\x9a\x13\x00\x00\xff\x08\xe7\x95\x0c\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xdd9\xc9d\\\x13\x00\x00(\x02\xf7\xbb\x0e\x14\x00\x00ov\xe74\xea\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x82s\x98\xb4\x9a\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x8f\x9b\xe6\xf6.\x14\x00\x00\t2\x87\xb1\xff\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x15\x05F<^\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00;\xff\xa7;\xbf\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xed`\xc5\xcd\x91\x14\x00\x00\x86\xc7\xd5\x92q\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\xfd^\xc8&\xa1\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00(\x02\xf7\xbb\x0e\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x8c\x9c8\xd0\x8d\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xfe\xb3W\xde\xd6\x13\x00\x00\xe2\xe2\x95\xfah\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x82s\x98\xb4\x9a\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\t2\x87\xb1\xff\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x15\x05F<^\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xc8\x92\xf9u@\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00(\x02\xf7\xbb\x0e\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x004\xd5\xb5Fm\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00k"\xaaV\x13\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x001\xd6\x07 \xcc\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x13[\'\xcd\xf2\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x8c\x9c8\xd0\x8d\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00ov\xe74\xea\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xb5\x95H\xf6\x8f\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xbf\xbe\xe8\x11\x83\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00eMG\x19\xf7\x13\x00\x00\x9bn\xa5\x81\x8d\x14\x00\x00\xb7?ge\xfb\x13\x00\x00k"\xaaV\x13\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xfd^\xc8&\xa1\x13\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00z\xf4\x16\x08\x13\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xce\x90U\xc3\x82\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00^vMB\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00 \x83u\x0f\x87\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00eMG\x19\xf7\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xed`\xc5\xcd\x91\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x1c/81\xb0\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x13[\'\xcd\xf2\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x82s\x98\xb4\x9a\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xde\x8eX\x1c\x92\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xcc\xe66T\x17\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xd6\x0f\xd7o\n\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00I|\x855\x89\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00ov\xe74\xea\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x002+\x97\xd7\x01\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x85rF\xdb;\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xcd;\xc6\x0bM\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xb9\xe9\x85\xd4f\x14\x00\x00\x13[\'\xcd\xf2\x13\x00\x00\x15\x05F<^\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xeaa\x17\xa7\xf0\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\t2\x87\xb1\xff\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00[$\xa7\xfd\x03\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xfb\xb4\xa9\xb75\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00]\xce\xc5lo\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00!\xd8\x04\xc7\xbc\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00c\xa3(\xaa\x8b\x13\x00\x00$\xae\xb9\xdd7\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\\y6\xb59\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xc4g\xb5\xa7\x8f\x14\x00\x00S\xa5%Q|\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x15\x05F<^\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xd8\xb9\xf5\xdeu\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xcf\xe5\xe4z\xb8\x14\x00\x00Z\xcf\x17F\xce\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x07\x88hB\x94\x13\x00\x00\xfe\xb3W\xde\xd6\x13\x00\x00\xd8\xb9\xf5\xdeu\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x91E\x05f\x9a\x14\x00\x00\xf4\x8a\xb7\xc2\xe3\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00 \x83u\x0f\x87\x14\x00\x00?S\xe5\x19\x96\x14\x00\x00\xa2\x98\x97v\xdf\x13\x00\x00 \x83u\x0f\x87\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00ru\x95[\x8b\x14\x00\x00\xcc\xe66T\x17\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xc3\x12&\xf0Y\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xba>\x15\x8c\x9c\x14\x00\x00}\xf3\xc4.\xb4\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00&X\xd8L\xa3\x13\x00\x00\x90\xf0u\xaed\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00q \x06\xa4U\x14\x00\x00\xf7\x89e\xe9\x84\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xba>\x15\x8c\x9c\x14\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00RP\x96\x99F\x14\x00\x00\xb8\x94\xf6\x1c1\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xed`\xc5\xcd\x91\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xe1\x8d\x06C3\x14\x00\x00\x1e\xd9V\xa0\x1b\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x1f.\xe6WQ\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x83\xc8\'l\xd0\x13\x00\x00f\xa2\xd6\xd0,\x14\x00\x00\xca<\x18\xe5\xab\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xc2\xbd\x968$\x14\x00\x00\x01\xb3\x05\x05x\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x9bn\xa5\x81\x8d\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00I|\x855\x89\x14\x00\x00\xcb\x91\xa7\x9c\xe1\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00H\'\xf6}S\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xbb\x93\xa4C\xd2\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x17\xafd\xab\xc9\x14\x00\x00\xf93\x84X\xf0\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00m\xcc\xc8\xc5~\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xa5\x97E\x9d\x80\x14\x00\x00\x9c\xc349\xc3\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xa6\xec\xd4T\xb6\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xc5\xbcD_\xc5\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00J\xd1\x14\xed\xbe\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00~HT\xe6\xe9\x14\x00\x00\r\x86\xc4\x8f\xd6\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00}\xf3\xc4.\xb4\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x9a\x19\x16\xcaW\x14\x00\x00\xe37%\xb2\x9e\x14\x00\x00*\xac\x15+z\x14\x00\x00(\x02\xf7\xbb\x0e\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xb0\x15up\xa9\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00K&\xa4\xa4\xf4\x14\x00\x00\x17\xafd\xab\xc9\x14\x00\x00\x87\x1ceJ\xa7\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xce\x90U\xc3\x82\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x17\xafd\xab\xc9\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x16Z\xd5\xf3\x93\x14\x00\x00 \x83u\x0f\x87\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00"-\x94~\xf2\x14\x00\x00\x9c\xc349\xc3\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00?S\xe5\x19\x96\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00K&\xa4\xa4\xf4\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x005*E\xfe\xa2\x14\x00\x00"-\x94~\xf2\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xc5\xbcD_\xc5\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xe1\x8d\x06C3\x14\x00\x00\x90\xf0u\xaed\x14\x00\x00+\x01\xa5\xe2\xaf\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xf93\x84X\xf0\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x84\x1d\xb7#\x06\x14\x00\x00\r\x86\xc4\x8f\xd6\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00UOD\xc0\xe7\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x16Z\xd5\xf3\x93\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xd0:t2\xee\x14\x00\x00T\xfa\xb4\x08\xb2\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00)W\x86sD\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xa6\xec\xd4T\xb6\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xee\xb5T\x85\xc7\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x9a\x19\x16\xcaW\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xca<\x18\xe5\xab\x13\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x003\x80&\x8f7\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00^#U$\xa5\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x84\x1d\xb7#\x06\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xa7Ad\x0c\xec\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x1f.\xe6WQ\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00+\x01\xa5\xe2\xaf\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00g\xf7e\x88b\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xcc\xe66T\x17\x14\x00\x00\xeb\xb6\xa6^&\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00!\xd8\x04\xc7\xbc\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xa7Ad\x0c\xec\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00H\'\xf6}S\x14\x00\x00!\xd8\x04\xc7\xbc\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xc5\xbcD_\xc5\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00?S\xe5\x19\x96\x14\x00\x00\xb6\xea\xd7\xad\xc5\x13\x00\x00\xee\xb5T\x85\xc7\x14\x00\x00\xaf\xc0\xe5\xb8s\x14\x00\x00\x16Z\xd5\xf3\x93\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00g\xf7e\x88b\x14\x00\x00hL\xf5?\x98\x14\x00\x00I|\x855\x89\x14\x00\x00\xeb\xb6\xa6^&\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xb0\x15up\xa9\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xa6\xec\xd4T\xb6\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00^vMB\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xd0:t2\xee\x14\x00\x00\x86\xc7\xd5\x92q\x14\x00\x00i\xa1\x84\xf7\xcd\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xba>\x15\x8c\x9c\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00_x\xe4\xdb\xda\x14\x00\x00\xa7Ad\x0c\xec\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00z\xf4\x16\x08\x13\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xed`\xc5\xcd\x91\x14\x00\x00\xa5\x97E\x9d\x80\x14\x00\x00\x0b\xdc\xa5 k\x14\x00\x00\x9c\xc349\xc3\x14\x00\x004\xd5\xb5Fm\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xcf\xe5\xe4z\xb8\x14\x00\x00=\xa9\xc6\xaa*\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xe37%\xb2\x9e\x14\x00\x00\x16Z\xd5\xf3\x93\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xc3\x12&\xf0Y\x14\x00\x00\xbb\x93\xa4C\xd2\x14\x00\x00\xe2\xe2\x95\xfah\x14\x00\x00\xc2\xbd\x968$\x14\x00\x00\xbb\x93\xa4C\xd2\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00Z\xcf\x17F\xce\x13\x00\x00|\x9e5w~\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xcd;\xc6\x0bM\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00S\xa5%Q|\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00^#U$\xa5\x14\x00\x00\xee\xb5T\x85\xc7\x14\x00\x00!\xd8\x04\xc7\xbc\x14\x00\x00\xcd;\xc6\x0bM\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x15\x05F<^\x14\x00\x00\xc5\xbcD_\xc5\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00~HT\xe6\xe9\x14\x00\x00\x91E\x05f\x9a\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xe2\xe2\x95\xfah\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xcd;\xc6\x0bM\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00f\xa2\xd6\xd0,\x14\x00\x00^#U$\xa5\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xa4B\xb6\xe5J\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\xa5\x97E\x9d\x80\x14\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x80'
p74
tp75
bag19
(g20
(I0
tp76
g22
tp77
Rp78
(I1
(I6
I975
tp79
g29
I00
(lp80
S'US8457827B1'
p81
aS'US20150248131A1'
p82
aS'US20140214255A1'
p83
aS'US8818608B2'
p84
aS'US9194168B1'
p85
aS'US8700251B1'
p86
aS'US8527199B1'
p87
aS'US20140303827A1'
p88
aS'US20140297116A1'
p89
aS'US8718861B1'
p90
aS'US8874301B1'
p91
aS'US20150066284A1'
p92
aS'US20140330479A1'
p93
aS'US8880270B1'
p94
aS'US20130238170A1'
p95
aS'US8849494B1'
p96
aS'US8996224B1'
p97
aS'US20150339928A1'
p98
aS'US20130245877A1'
p99
aS'US20130211656A1'
p100
aS'US20150149019A1'
p101
aS'US8954252B1'
p102
aS'US20140088855A1'
p103
aS'US20150166062A1'
p104
aS'US8473144B1'
p105
aS'US8909391B1'
p106
aS'US20150149017A1'
p107
aS'US20150006005A1'
p108
aS'US20140207325A1'
p109
aS'US8930044B1'
p110
aS'US9051043B1'
p111
aS'US20140032034A1'
p112
aS'US20140236414A1'
p113
aS'US20140156182A1'
p114
aS'US8948935B1'
p115
aS'US20150254986A1'
p116
aS'US20150346727A1'
p117
aS'US8880272B1'
p118
aS'US20140336935A1'
p119
aS'US20140148988A1'
p120
aS'US20150178998A1'
p121
aS'US20140222277A1'
p122
aS'US20130197736A1'
p123
aS'US8825259B1'
p124
aS'US8983682B1'
p125
aS'US20150346718A1'
p126
aS'US9079587B1'
p127
aS'US9014905B1'
p128
aS'US8793046B2'
p129
aS'US20140195214A1'
p130
aS'US8676431B1'
p131
aS'US8521352B1'
p132
aS'US20130184926A1'
p133
aS'US20130304514A1'
p134
aS'US20140309833A1'
p135
aS'US9315212B1'
p136
aS'US8977007B1'
p137
aS'US20140129073A1'
p138
aS'US8712624B1'
p139
aS'US8949016B1'
p140
aS'US20150149088A1'
p141
aS'US20160026182A1'
p142
aS'US20150336502A1'
p143
aS'US20140333468A1'
p144
aS'US20150177007A1'
p145
aS'US20150344136A1'
p146
aS'US20130231824A1'
p147
aS'US8781669B1'
p148
aS'US20150202770A1'
p149
aS'US20150312774A1'
p150
aS'US20150170287A1'
p151
aS'US20150070160A1'
p152
aS'US20150073589A1'
p153
aS'US8595037B1'
p154
aS'US20150057903A1'
p155
aS'US20140121883A1'
p156
aS'US20150106010A1'
p157
aS'US20140319272A1'
p158
aS'US9229453B1'
p159
aS'US20160018822A1'
p160
aS'US9390451B1'
p161
aS'US9201421B1'
p162
aS'US9422139B1'
p163
aS'US20140142785A1'
p164
aS'US20160244165A1'
p165
aS'US8909428B1'
p166
aS'US20130261871A1'
p167
aS'US20140067187A1'
p168
aS'US8798841B1'
p169
aS'US20150268665A1'
p170
aS'US20140277896A1'
p171
aS'US20140121930A1'
p172
aS'US20150066296A1'
p173
aS'US20150134178A1'
p174
aS'US8504233B1'
p175
aS'US9302770B2'
p176
aS'US9340228B2'
p177
aS'US20140278029A1'
p178
aS'US9056395B1'
p179
aS'US20140063232A1'
p180
aS'US20150370251A1'
p181
aS'US20160231746A1'
p182
aS'US9260244B1'
p183
aS'US8825265B1'
p184
aS'US9056676B1'
p185
aS'US20150148988A1'
p186
aS'US20150066282A1'
p187
aS'US20150115571A1'
p188
aS'US9189897B1'
p189
aS'US9188985B1'
p190
aS'US20150151725A1'
p191
aS'US20130304279A1'
p192
aS'US20140297067A1'
p193
aS'US9008890B1'
p194
aS'US20140307247A1'
p195
aS'US8831813B1'
p196
aS'US20160358477A1'
p197
aS'US20130253754A1'
p198
aS'US20160137311A1'
p199
aS'US20160139594A1'
p200
aS'US20150091374A1'
p201
aS'US8838321B1'
p202
aS'US20150336524A1'
p203
aS'US20150149022A1'
p204
aS'US20140088814A1'
p205
aS'US20140018979A1'
p206
aS'US20160070265A1'
p207
aS'US20130289858A1'
p208
aS'US20150166059A1'
p209
aS'US20150166069A1'
p210
aS'US20140210646A1'
p211
aS'US20150350614A1'
p212
aS'US20160209220A1'
p213
aS'US9346560B2'
p214
aS'US20150120094A1'
p215
aS'US9321531B1'
p216
aS'US8571743B1'
p217
aS'US20160280267A1'
p218
aS'US20140379247A1'
p219
aS'US20130190985A1'
p220
aS'US8761991B1'
p221
aS'US20140374532A1'
p222
aS'US20140032012A1'
p223
aS'US20150304869A1'
p224
aS'US20150284010A1'
p225
aS'US20150309512A1'
p226
aS'US9395727B1'
p227
aS'US20140081505A1'
p228
aS'US9355423B1'
p229
aS'US8996228B1'
p230
aS'US20140244096A1'
p231
aS'US20160334797A1'
p232
aS'US20140207535A1'
p233
aS'US20160196756A1'
p234
aS'US20130179382A1'
p235
aS'US9081385B1'
p236
aS'US20130314503A1'
p237
aS'US20160153778A1'
p238
aS'US20150346722A1'
p239
aS'US8983705B2'
p240
aS'US20160068103A1'
p241
aS'US8781727B1'
p242
aS'US20140032049A1'
p243
aS'US20130325242A1'
p244
aS'US20130211646A1'
p245
aS'US9274525B1'
p246
aS'US20150242953A1'
p247
aS'US20130297195A1'
p248
aS'US8768539B1'
p249
aS'US20150102154A1'
p250
aS'US8880273B1'
p251
aS'US9221396B1'
p252
aS'US20160068267A1'
p253
aS'US20140081507A1'
p254
aS'US20150088373A1'
p255
aS'US20160247106A1'
p256
aS'US20150210274A1'
p257
aS'US20150100179A1'
p258
aS'US20160214717A1'
p259
aS'US9043069B1'
p260
aS'US20160059889A1'
p261
aS'US8855847B2'
p262
aS'US9158980B1'
p263
aS'US20150149018A1'
p264
aS'US20140288763A1'
p265
aS'US20140032093A1'
p266
aS'US20150179062A1'
p267
aS'US20150203107A1'
p268
aS'US20150149265A1'
p269
aS'US20160071418A1'
p270
aS'US8676427B1'
p271
aS'US9164511B1'
p272
aS'US9062979B1'
p273
aS'US20140303847A1'
p274
aS'US20150338852A1'
p275
aS'US8855904B1'
p276
aS'US20150344038A1'
p277
aS'US20150175070A1'
p278
aS'US20150235557A1'
p279
aS'US9248834B1'
p280
aS'US9120485B1'
p281
aS'US20160001781A1'
p282
aS'US20140257621A1'
p283
aS'US20140277691A1'
p284
aS'US20130253767A1'
p285
aS'US20150266455A1'
p286
aS'US9383753B1'
p287
aS'US20160046290A1'
p288
aS'US8948954B1'
p289
aS'US20150057891A1'
p290
aS'US20150057871A1'
p291
aS'US20150142244A1'
p292
aS'US20150331422A1'
p293
aS'US20150314780A1'
p294
aS'US20140301161A1'
p295
aS'US20150127239A1'
p296
aS'US20160116293A1'
p297
aS'US20150158524A1'
p298
aS'US20150158499A1'
p299
aS'US9523984B1'
p300
aS'US9436182B2'
p301
aS'US20140257661A1'
p302
aS'US9081383B1'
p303
aS'US8874267B1'
p304
aS'US20150198951A1'
p305
aS'US9162753B1'
p306
aS'US20160125746A1'
p307
aS'US8818681B1'
p308
aS'US20140046506A1'
p309
aS'US9014903B1'
p310
aS'US9412278B1'
p311
aS'US20160303969A1'
p312
aS'US8855621B2'
p313
aS'US20150187019A1'
p314
aS'US20140124279A1'
p315
aS'US9121703B1'
p316
aS'US20140074339A1'
p317
aS'US9381916B1'
p318
aS'US20140300479A1'
p319
aS'US20160304198A1'
p320
aS'US8612135B1'
p321
aS'US20130240673A1'
p322
aS'US9164506B1'
p323
aS'US20150344028A1'
p324
aS'US20140263822A1'
p325
aS'US20150142248A1'
p326
aS'US9423498B1'
p327
aS'US20150219464A1'
p328
aS'US20150353085A1'
p329
aS'US20160364823A1'
p330
aS'US20150158528A1'
p331
aS'US20160200317A1'
p332
aS'US20150260526A1'
p333
aS'US20140350725A1'
p334
aS'US20140129075A1'
p335
aS'US20160132705A1'
p336
aS'US20160209845A1'
p337
aS'US20150234045A1'
p338
aS'US20150149023A1'
p339
aS'US20140249693A1'
p340
aS'US8494716B1'
p341
aS'US20160070264A1'
p342
aS'US20150323932A1'
p343
aS'US20140263823A1'
p344
aS'US20150294422A1'
p345
aS'US20140019392A1'
p346
aS'US8983693B2'
p347
aS'US20140081479A1'
p348
aS'US20130211647A1'
p349
aS'US9086481B1'
p350
aS'US20140067164A1'
p351
aS'US20140303814A1'
p352
aS'US8818609B1'
p353
aS'US20150241878A1'
p354
aS'US9063548B1'
p355
aS'US20150136012A1'
p356
aS'US20160039300A1'
p357
aS'US8825226B1'
p358
aS'US20140277894A1'
p359
aS'US20140163730A1'
p360
aS'US20150353082A1'
p361
aS'US20150254988A1'
p362
aS'US20160127931A1'
p363
aS'US20130332008A1'
p364
aS'US20140012465A1'
p365
aS'US20150039173A1'
p366
aS'US8788134B1'
p367
aS'US20160355192A1'
p368
aS'US9096150B2'
p369
aS'US9513632B1'
p370
aS'US9108584B2'
p371
aS'US8494689B1'
p372
aS'US20150045992A1'
p373
aS'US20140077969A1'
p374
aS'US9201426B1'
p375
aS'US20160122038A1'
p376
aS'US20140239602A1'
p377
aS'US20130325202A1'
p378
aS'US20150228195A1'
p379
aS'US8874356B1'
p380
aS'US9201424B1'
p381
aS'US20150350914A1'
p382
aS'US20130253753A1'
p383
aS'US9176500B1'
p384
aS'US20160357192A1'
p385
aS'US9483948B1'
p386
aS'US20140111325A1'
p387
aS'US9307383B1'
p388
aS'US20140244125A1'
p389
aS'US20150088360A1'
p390
aS'US20140081573A1'
p391
aS'US20160129999A1'
p392
aS'US20150370255A1'
p393
aS'US20140320318A1'
p394
aS'US20140225990A1'
p395
aS'US20150339589A1'
p396
aS'US20140018994A1'
p397
aS'US20140088781A1'
p398
aS'US20150246673A1'
p399
aS'US20150131080A1'
p400
aS'US9083425B1'
p401
aS'US20130206921A1'
p402
aS'US9495874B1'
p403
aS'US20140218187A1'
p404
aS'US20140139116A1'
p405
aS'US9097800B1'
p406
aS'US20160001883A1'
p407
aS'US9524648B1'
p408
aS'US20150025731A1'
p409
aS'US20160221683A1'
p410
aS'US20160039541A1'
p411
aS'US20160275801A1'
p412
aS'US20150253775A1'
p413
aS'US20160036558A1'
p414
aS'US20140140575A1'
p415
aS'US20130219294A1'
p416
aS'US20140022051A1'
p417
aS'US8914225B2'
p418
aS'US20160016506A1'
p419
aS'US9085362B1'
p420
aS'US20140156157A1'
p421
aS'US20160125735A1'
p422
aS'US20140195114A1'
p423
aS'US8855849B1'
p424
aS'US20150234387A1'
p425
aS'US20160301698A1'
p426
aS'US20150142246A1'
p427
aS'US20140136187A1'
p428
aS'US20140052323A1'
p429
aS'US8830322B2'
p430
aS'US20160179096A1'
p431
aS'US20160247095A1'
p432
aS'US20140263851A1'
p433
aS'US20160260328A1'
p434
aS'US20150032293A1'
p435
aS'US20150153175A1'
p436
aS'US20150101519A1'
p437
aS'US20160318490A1'
p438
aS'US20150274294A1'
p439
aS'US20160144734A1'
p440
aS'US9186793B1'
p441
aS'US20140309836A1'
p442
aS'US20160150427A1'
p443
aS'US9151628B1'
p444
aS'US20130238181A1'
p445
aS'US9501061B2'
p446
aS'US20140253722A1'
p447
aS'US20150260530A1'
p448
aS'US20140111332A1'
p449
aS'US20150253772A1'
p450
aS'US20130191189A1'
p451
aS'US9063549B1'
p452
aS'US20130342333A1'
p453
aS'US20160146618A1'
p454
aS'US20160161270A1'
p455
aS'US9128190B1'
p456
aS'US20150088358A1'
p457
aS'US20150274178A1'
p458
aS'US9286520B1'
p459
aS'US20160147223A1'
p460
aS'US9336436B1'
p461
aS'US20150266489A1'
p462
aS'US20150217763A1'
p463
aS'US9405293B2'
p464
aS'US9085354B1'
p465
aS'US9384402B1'
p466
aS'US20150286218A1'
p467
aS'US20150203023A1'
p468
aS'US20160282874A1'
p469
aS'US20150336547A1'
p470
aS'US20150233719A1'
p471
aS'US20160003636A1'
p472
aS'US20150266575A1'
p473
aS'US9080866B1'
p474
aS'US20160063987A1'
p475
aS'US20140365228A1'
p476
aS'US20160061612A1'
p477
aS'US9123034B2'
p478
aS'US20160117853A1'
p479
aS'US20170069214A1'
p480
aS'US20160076892A1'
p481
aS'US20140345511A1'
p482
aS'US20140379228A1'
p483
aS'US20160357262A1'
p484
aS'US20150205298A1'
p485
aS'US20130190982A1'
p486
aS'US20140111324A1'
p487
aS'US9134731B2'
p488
aS'US20160091899A1'
p489
aS'US20160327950A1'
p490
aS'US20140229411A1'
p491
aS'US20160252903A1'
p492
aS'US8583520B1'
p493
aS'US20150353094A1'
p494
aS'US20150346724A1'
p495
aS'US20140016858A1'
p496
aS'US20160304122A1'
p497
aS'US20150348112A1'
p498
aS'US20140218527A1'
p499
aS'US9428183B2'
p500
aS'US20140177387A1'
p501
aS'US9646428B1'
p502
aS'US20150339826A1'
p503
aS'US20150158486A1'
p504
aS'US20150251664A1'
p505
aS'US20140193066A1'
p506
aS'US8812186B2'
p507
aS'US8588991B1'
p508
aS'US20150023668A1'
p509
aS'US20140132082A1'
p510
aS'US9278689B1'
p511
aS'US20160176397A1'
p512
aS'US20170038775A1'
p513
aS'US20140172290A1'
p514
aS'US20140365062A1'
p515
aS'US20150237791A1'
p516
aS'US20150163993A1'
p517
aS'US20150286219A1'
p518
aS'US20150266488A1'
p519
aS'US20160018229A1'
p520
aS'US9517767B1'
p521
aS'US9465388B1'
p522
aS'US20140249718A1'
p523
aS'US20150170526A1'
p524
aS'US20130190983A1'
p525
aS'US20150134202A1'
p526
aS'US20150088357A1'
p527
aS'US9384666B1'
p528
aS'US20150103159A1'
p529
aS'US20150266490A1'
p530
aS'US20150149263A1'
p531
aS'US20150012165A1'
p532
aS'US20140052336A1'
p533
aS'US9451020B2'
p534
aS'US20140277788A1'
p535
aS'US20130168497A1'
p536
aS'US9630619B1'
p537
aS'US8989943B2'
p538
aS'US20160189435A1'
p539
aS'US20160364989A1'
p540
aS'US20150012167A1'
p541
aS'US20150051779A1'
p542
aS'US20130338825A1'
p543
aS'US20150307191A1'
p544
aS'US20150142247A1'
p545
aS'US20150316386A1'
p546
aS'US8838322B1'
p547
aS'US9010678B1'
p548
aS'US9449512B2'
p549
aS'US20150293534A1'
p550
aS'US20170008521A1'
p551
aS'US20150261219A1'
p552
aS'US9547986B1'
p553
aS'US9047568B1'
p554
aS'US20170090476A1'
p555
aS'US9494439B1'
p556
aS'US9535423B1'
p557
aS'US9033089B2'
p558
aS'US9494938B1'
p559
aS'US20160129917A1'
p560
aS'US20150246672A1'
p561
aS'US20160116912A1'
p562
aS'US20170010613A1'
p563
aS'US9507346B1'
p564
aS'US9189961B2'
p565
aS'US20150251656A1'
p566
aS'US20150019094A1'
p567
aS'US20140283726A1'
p568
aS'US20150241241A1'
p569
aS'US20150345966A1'
p570
aS'US9373045B1'
p571
aS'US20150379468A1'
p572
aS'US20170057542A1'
p573
aS'US20140321236A1'
p574
aS'US20150221222A1'
p575
aS'US20160370194A1'
p576
aS'US9551992B1'
p577
aS'US9616896B1'
p578
aS'US20160334230A1'
p579
aS'US20160054737A1'
p580
aS'US20150348335A1'
p581
aS'US20150105933A1'
p582
aS'US20150110344A1'
p583
aS'US8880275B1'
p584
aS'US9400500B2'
p585
aS'US20150241880A1'
p586
aS'US20130320212A1'
p587
aS'US20150210279A1'
p588
aS'US9363690B1'
p589
aS'US9488979B1'
p590
aS'US20150321641A1'
p591
aS'US9552564B1'
p592
aS'US9043072B1'
p593
aS'US20150081188A1'
p594
aS'US9315178B1'
p595
aS'US9256852B1'
p596
aS'US20150234384A1'
p597
aS'US9522699B2'
p598
aS'US20160116913A1'
p599
aS'US20150235480A1'
p600
aS'US9261590B1'
p601
aS'US9199553B2'
p602
aS'US20160232795A1'
p603
aS'US20160090100A1'
p604
aS'US20160358475A1'
p605
aS'US20160176398A1'
p606
aS'US20140207336A1'
p607
aS'US9349284B2'
p608
aS'US20140149011A1'
p609
aS'US20170212511A1'
p610
aS'US20160362113A1'
p611
aS'US8994581B1'
p612
aS'US9244462B2'
p613
aS'US8903620B2'
p614
aS'US20160259330A1'
p615
aS'US20140350812A1'
p616
aS'US20150137564A1'
p617
aS'US20150100190A1'
p618
aS'US9043088B2'
p619
aS'US20160362045A1'
p620
aS'US20130267377A1'
p621
aS'US20160221500A1'
p622
aS'US20140160885A1'
p623
aS'US20150298738A1'
p624
aS'US20150345971A1'
p625
aS'US20160129908A1'
p626
aS'US20170199523A1'
p627
aS'US9224053B1'
p628
aS'US9454154B1'
p629
aS'US20170124781A1'
p630
aS'US20170132934A1'
p631
aS'US20170120753A1'
p632
aS'US20150345967A1'
p633
aS'US20160121983A1'
p634
aS'US9511767B1'
p635
aS'US20150259007A1'
p636
aS'US20160068158A1'
p637
aS'US9499202B2'
p638
aS'US9043071B1'
p639
aS'US20150336587A1'
p640
aS'US9355562B1'
p641
aS'US20140041713A1'
p642
aS'US9707960B2'
p643
aS'US20160068156A1'
p644
aS'US20160221573A1'
p645
aS'US9682707B1'
p646
aS'US9796421B1'
p647
aS'US20160273922A1'
p648
aS'US20170166222A1'
p649
aS'US20160362084A1'
p650
aS'US20160033965A1'
p651
aS'US20170036678A1'
p652
aS'US20160161602A1'
p653
aS'US20170057496A1'
p654
aS'US8775013B1'
p655
aS'US20150356665A1'
p656
aS'US9475491B1'
p657
aS'US9663025B2'
p658
aS'US20170043768A1'
p659
aS'US20170097645A1'
p660
aS'US20170315557A1'
p661
aS'US20170193627A1'
p662
aS'US20170146995A1'
p663
aS'US20170297576A1'
p664
aS'US9625904B2'
p665
aS'US20170147959A1'
p666
aS'US9672734B1'
p667
aS'US20150307089A1'
p668
aS'US20150088374A1'
p669
aS'US20170168485A1'
p670
aS'US20170110022A1'
p671
aS'US20160257303A1'
p672
aS'US20170132334A1'
p673
aS'US20160179093A1'
p674
aS'US20140136043A1'
p675
aS'US20170158175A1'
p676
aS'US20160075369A1'
p677
aS'US20160114831A1'
p678
aS'US20160288831A1'
p679
aS'US9654738B1'
p680
aS'US20150309510A1'
p681
aS'US9778653B1'
p682
aS'US9720412B1'
p683
aS'US20160210757A1'
p684
aS'US20160236638A1'
p685
aS'US9616886B2'
p686
aS'US20140131977A1'
p687
aS'US20170241184A1'
p688
aS'US20160144867A1'
p689
aS'US9368026B1'
p690
aS'US9557183B1'
p691
aS'US9457684B2'
p692
aS'US9162569B2'
p693
aS'US20170267256A1'
p694
aS'US9587952B1'
p695
aS'US20150168953A1'
p696
aS'US9809158B2'
p697
aS'US9684306B2'
p698
aS'US9582003B1'
p699
aS'US20150094897A1'
p700
aS'US20170253241A1'
p701
aS'US20160328976A1'
p702
aS'US20150266576A1'
p703
aS'US9481459B2'
p704
aS'US20150274169A1'
p705
aS'US20170123422A1'
p706
aS'US9682609B1'
p707
aS'US20170126810A1'
p708
aS'US9528838B2'
p709
aS'US9493158B2'
p710
aS'US20160121918A1'
p711
aS'US20150187216A1'
p712
aS'US9802638B1'
p713
aS'US9663118B1'
p714
aS'US20170168503A1'
p715
aS'US20160375901A1'
p716
aS'US9535422B2'
p717
aS'US20150073638A1'
p718
aS'US20150329111A1'
p719
aS'US20150046076A1'
p720
aS'US20170192429A1'
p721
aS'US20170129487A1'
p722
aS'US20160378112A1'
p723
aS'US9811085B1'
p724
aS'US20140057237A1'
p725
aS'US20170167881A1'
p726
aS'US20170247040A1'
p727
aS'US20150367886A1'
p728
aS'US20170192423A1'
p729
aS'US9568915B1'
p730
aS'US9804599B2'
p731
aS'US20160016619A1'
p732
aS'US9672446B1'
p733
aS'US20150343900A1'
p734
aS'US20150073658A1'
p735
aS'US9260092B1'
p736
aS'US9400187B2'
p737
aS'US9606539B1'
p738
aS'US20170242442A1'
p739
aS'US9796529B1'
p740
aS'US20170090478A1'
p741
aS'US20160159368A1'
p742
aS'US20160347327A1'
p743
aS'US20170277182A1'
p744
aS'US20170261988A1'
p745
aS'US20140291480A1'
p746
aS'US20160046287A1'
p747
aS'US9139241B1'
p748
aS'US9720415B2'
p749
aS'US20170031015A1'
p750
aS'US20160178382A1'
p751
aS'US9772197B2'
p752
aS'US20160025505A1'
p753
aS'US20170197626A1'
p754
aS'US20170308082A1'
p755
aS'US20170276494A1'
p756
aS'US20160059881A1'
p757
aS'US20170151959A1'
p758
aS'US20170174221A1'
p759
aS'US20150239298A1'
p760
aS'US20170072812A1'
p761
aS'US20170297586A1'
p762
aS'US20170080933A1'
p763
aS'US20170248957A1'
p764
aS'US9529357B1'
p765
aS'US20150266467A1'
p766
aS'US20170277191A1'
p767
aS'US9789880B2'
p768
aS'US9613386B1'
p769
aS'US20160167653A1'
p770
aS'US20170123421A1'
p771
aS'US20170234689A1'
p772
aS'US20170259753A1'
p773
aS'US20160200235A1'
p774
aS'US20170057514A1'
p775
aS'US20170297569A1'
p776
aS'US20150100191A1'
p777
aS'US20170057520A1'
p778
aS'US20170267233A1'
p779
aS'US20170293306A1'
p780
aS'US20170090480A1'
p781
aS'US9310808B2'
p782
aS'US20170221366A1'
p783
aS'US20160167648A1'
p784
aS'US9626874B1'
p785
aS'US20130332061A1'
p786
aS'US20170320500A1'
p787
aS'US20170284819A1'
p788
aS'US20170285642A1'
p789
aS'US20150298694A1'
p790
aS'US20150253536A1'
p791
aS'US20140114521A1'
p792
aS'US20170068245A1'
p793
aS'US9679490B2'
p794
aS'US20170300855A1'
p795
aS'US20150094944A1'
p796
aS'US20160314224A1'
p797
aS'US20170301239A1'
p798
aS'US20170213164A1'
p799
aS'US20170203766A1'
p800
aS'US20170123429A1'
p801
aS'US9368936B1'
p802
aS'US20170072967A1'
p803
aS'US20160349755A1'
p804
aS'US20140244131A1'
p805
aS'US20170240096A1'
p806
aS'US20160375767A1'
p807
aS'US20160375768A1'
p808
aS'US8903607B2'
p809
aS'US20160046230A1'
p810
aS'US20160229252A1'
p811
aS'US9274526B2'
p812
aS'US20170158227A1'
p813
aS'US20170297588A1'
p814
aS'US9576185B1'
p815
aS'US20150064138A1'
p816
aS'US20170297565A1'
p817
aS'US20170225581A1'
p818
aS'US20150183426A1'
p819
aS'US20170139411A1'
p820
aS'US20170097640A1'
p821
aS'US20150166061A1'
p822
aS'US9141109B1'
p823
aS'US20170101032A1'
p824
aS'US20160259335A1'
p825
aS'US20170080900A1'
p826
aS'US9786187B1'
p827
aS'US20170103270A1'
p828
aS'US20170227960A1'
p829
aS'US20160288785A1'
p830
aS'US20170132117A1'
p831
aS'US20170225567A1'
p832
aS'US20160159348A1'
p833
aS'US20170225578A1'
p834
aS'US20170074964A1'
p835
aS'US20130185888A1'
p836
aS'US20150129713A1'
p837
aS'US20170108867A1'
p838
aS'US20150105960A1'
p839
aS'US20160257341A1'
p840
aS'US9349055B1'
p841
aS'US20170315771A1'
p842
aS'US9606535B2'
p843
aS'US20170101130A1'
p844
aS'US9393961B1'
p845
aS'US20160023526A1'
p846
aS'US20170253252A1'
p847
aS'US20160023525A1'
p848
aS'US20160001763A1'
p849
aS'US20170316692A1'
p850
aS'US20170309072A1'
p851
aS'US20160304124A1'
p852
aS'US20170132118A1'
p853
aS'US20160155339A1'
p854
aS'US20170286570A1'
p855
aS'US20170029024A1'
p856
aS'US20160075375A1'
p857
aS'US20140245727A1'
p858
aS'US20160288830A1'
p859
aS'US20170285639A1'
p860
aS'US9187088B1'
p861
aS'US9227632B1'
p862
aS'US20160298758A1'
p863
aS'US20170269940A1'
p864
aS'US20170272943A1'
p865
aS'US20150120142A1'
p866
aS'US20160205146A1'
p867
aS'US9643466B1'
p868
aS'US20170080948A1'
p869
aS'US9785150B2'
p870
aS'US20170113641A1'
p871
aS'US20170311534A1'
p872
aS'US20140379214A1'
p873
aS'US20130313035A1'
p874
aS'US9354034B2'
p875
aS'US9643669B1'
p876
aS'US20170080974A1'
p877
aS'US20170088174A1'
p878
aS'US9669677B2'
p879
aS'US20170023945A1'
p880
aS'US20160339910A1'
p881
aS'US20170154371A1'
p882
aS'US9533683B2'
p883
aS'US8965691B1'
p884
aS'US9676377B2'
p885
aS'US9442487B1'
p886
aS'US9527394B1'
p887
aS'US20170113722A1'
p888
aS'US9393857B1'
p889
aS'US9540043B2'
p890
aS'US9500565B2'
p891
aS'US9227659B2'
p892
aS'US20170302282A1'
p893
aS'US20160347314A1'
p894
aS'US20170240204A1'
p895
aS'US20170291544A1'
p896
aS'US20150137463A1'
p897
aS'US20170316533A1'
p898
aS'US20170270014A1'
p899
aS'US20150226146A1'
p900
aS'US20170297620A1'
p901
aS'US20170225537A1'
p902
aS'US20150217732A1'
p903
aS'US20160257355A1'
p904
aS'US9586620B2'
p905
aS'US20160180714A1'
p906
aS'US20170106865A1'
p907
aS'US20160280262A1'
p908
aS'US20160325721A1'
p909
aS'US20170225679A1'
p910
aS'US20140200770A1'
p911
aS'US20170300063A1'
p912
aS'US9623880B1'
p913
aS'US20160362135A1'
p914
aS'US20170088165A1'
p915
aS'US20160214533A1'
p916
aS'US20170219362A1'
p917
aS'US9305223B1'
p918
aS'US20170158270A1'
p919
aS'US20160280258A1'
p920
aS'US9789905B2'
p921
aS'US9434415B2'
p922
aS'US9694777B2'
p923
aS'US20170282870A1'
p924
aS'US20170129298A1'
p925
aS'US20170227967A1'
p926
aS'US9550497B2'
p927
aS'US20140081522A1'
p928
aS'US20160207528A1'
p929
aS'US20160132055A1'
p930
aS'US9731761B1'
p931
aS'US9783231B2'
p932
aS'US20160368336A1'
p933
aS'US9178258B1'
p934
aS'US20160195877A1'
p935
aS'US20170259817A1'
p936
aS'US20170101080A1'
p937
aS'US20170287320A1'
p938
aS'US9522624B1'
p939
aS'US9475466B2'
p940
aS'US9415646B1'
p941
aS'US9662974B2'
p942
aS'US9422012B2'
p943
aS'US20170144646A1'
p944
aS'US9630617B2'
p945
aS'US9238490B1'
p946
aS'US20170235306A1'
p947
aS'US9558659B1'
p948
aS'US9529364B2'
p949
aS'US20160187884A1'
p950
aS'US9371077B1'
p951
aS'US9707937B2'
p952
aS'US9409529B2'
p953
aS'US9224300B2'
p954
aS'US9707909B2'
p955
aS'US20160347364A1'
p956
aS'US8984706B2'
p957
aS'US9469303B2'
p958
aS'US20150291213A1'
p959
aS'US20170096164A1'
p960
aS'US20160375932A1'
p961
aS'US9334003B2'
p962
aS'US20160131753A1'
p963
aS'US9463798B2'
p964
aS'US20160121883A1'
p965
aS'US9573623B2'
p966
aS'US9677897B2'
p967
aS'US9643604B2'
p968
aS'US9333985B2'
p969
aS'US20170206789A1'
p970
aS'US9381818B2'
p971
aS'US9669820B1'
p972
aS'US20170166237A1'
p973
aS'US9779314B1'
p974
aS'US9546635B2'
p975
aS'US20170174257A1'
p976
aS'US20170247054A1'
p977
aS'US20170101030A1'
p978
aS'US9412028B2'
p979
aS'US20160101701A1'
p980
aS'US20170174210A1'
p981
aS'US9335766B1'
p982
aS'US20150158487A1'
p983
aS'US9242674B2'
p984
aS'US9573515B2'
p985
aS'US20160142685A1'
p986
aS'US20170166205A1'
p987
aS'US9327699B2'
p988
aS'US20170217276A1'
p989
aS'US20170096139A1'
p990
aS'US20160107620A1'
p991
aS'US20170003686A1'
p992
aS'US9475494B1'
p993
aS'US20160332554A1'
p994
aS'US20170297621A1'
p995
aS'US20170106796A1'
p996
aS'US20170158262A1'
p997
aS'US20170240171A1'
p998
aS'US20170021812A1'
p999
aS'US20170247032A1'
p1000
aS'US20170192426A1'
p1001
aS'US20170113745A1'
p1002
aS'US20160297439A1'
p1003
aS'US20170015311A1'
p1004
aS'US20170210414A1'
p1005
aS'US20170197620A1'
p1006
aS'US20160364921A1'
p1007
aS'US20170268280A1'
p1008
aS'US20170302362A1'
p1009
aS'US20170101089A1'
p1010
aS'US20160194194A1'
p1011
aS'US20170158007A1'
p1012
aS'US20160274581A1'
p1013
aS'US20170101097A1'
p1014
aS'US20160293009A1'
p1015
aS'US20160031319A1'
p1016
aS'US20170305423A1'
p1017
aS'US20140316666A1'
p1018
aS'US20170151950A1'
p1019
aS'US20170197485A1'
p1020
aS'US20170004367A1'
p1021
aS'US20170158240A1'
p1022
aS'US20170308084A1'
p1023
aS'US20160114844A1'
p1024
aS'US20170129536A1'
p1025
aS'US20160325757A1'
p1026
aS'US20160297432A1'
p1027
aS'US20170299769A1'
p1028
aS'US20160272001A1'
p1029
aS'US20170084171A1'
p1030
aS'US20170210386A1'
p1031
aS'US20170226947A1'
p1032
aS'US20160018220A1'
p1033
aS'US20170287186A1'
p1034
aS'US20170101102A1'
p1035
aS'US20170267237A1'
p1036
aS'US20170106869A1'
p1037
aS'US20140058581A1'
p1038
aS'US20170087951A1'
p1039
aS'US20170066323A1'
p1040
aS'US20170234988A1'
p1041
aS'US20160272177A1'
p1042
aS'US20160236523A1'
p1043
aS'US20170102707A1'
p1044
aS'US20170174130A1'
p1045
aS'US20170160745A1'
p1046
aS'US20170158225A1'
p1047
aS'US20170028970A1'
p1048
aS'US20170247042A1'
p1049
aS'US20160375907A1'
p1050
aS'US20160264147A1'
p1051
aS'US20160264087A1'
p1052
aS'US20150232119A1'
p1053
aS'US20150339922A1'
p1054
aS'US20170213403A1'
p1055
aS'Modifying behavior of autonomous vehicle based on predicted behavior of other vehicles '
p1056
aS'Remote Assistance for Autonomous Vehicles in Predetermined Situations '
p1057
aS'Modifying behavior of autonomous vehicles based on sensor blind spots and limitations '
p1058
aS'Engaging and disengaging for autonomous driving '
p1059
aS'Unlock and authentication for autonomous vehicles '
p1060
aS'System and method for automatically detecting key behaviors by vehicles '
p1061
aS'Automatic collection of quality control statistics for maps used in autonomous driving '
p1062
aS'Systems and Methods for Transitioning Control of an Autonomous Vehicle to a Driver '
p1063
aS'Self-driving vehicle with integrated active suspension '
p1064
aS'Determining when to drive autonomously '
p1065
aS'Autonomous vehicle with driver presence and physiological monitoring '
p1066
aS'Autonomous vehicle control for impaired driver '
p1067
aS'Predictive Reasoning for Controlling Speed of a Vehicle '
p1068
aS'Location-aware notifications and applications for autonomous vehicles '
p1069
aS'Autonomous vehicle and method for coordinating the paths of multiple autonomous vehicles '
p1070
aS'Data selection by an autonomous vehicle for trajectory modification '
p1071
aS'Detecting that an autonomous vehicle is in a stuck condition '
p1072
aS'Using Autonomous Vehicles in a Taxi Service '
p1073
aS'Actively Modifying a Field of View of an Autonomous Vehicle in View of Constraints '
p1074
aS'Autonomous driving apparatus and method for vehicle '
p1075
aS'Autonomous vehicle identification '
p1076
aS'Pedestrian notifications '
p1077
aS'Determining changes in a driving environment based on vehicle behavior '
p1078
aS'Vehicle control system with traffic driving control '
p1079
aS'Controlling vehicle lateral lane positioning '
p1080
aS'Responsive navigation of an unmanned aerial vehicle to a remedial facility '
p1081
aS'Autonomous vehicle modes '
p1082
aS'Autonomous Unmanned Road Vehicle for Making Deliveries '
p1083
aS'Efficient data flow algorithms for autonomous lane changing, passing and overtaking behaviors '
p1084
aS'Multi-part navigation process by an unmanned aerial vehicle for navigating to a medical situatiion '
p1085
aS'Providing emergency medical services using unmanned aerial vehicles '
p1086
aS'Transportation using network of unmanned aerial vehicles '
p1087
aS'Method to Detect Nearby Aggressive Drivers and Adjust Driving Modes '
p1088
aS'Determining and displaying auto drive lanes in an autonomous vehicle '
p1089
aS'Providing a medical support device via an unmanned aerial vehicle '
p1090
aS'Reporting Road Event Data and Sharing with Other Vehicles '
p1091
aS'Parking Autonomous Vehicles '
p1092
aS'Approach for estimating the geometry of roads and lanes by using vehicle trajectories '
p1093
aS'Methods and Systems for Detecting Weather Conditions Using Vehicle Onboard Sensors '
p1094
aS'Method and system for controlling a vehicle '
p1095
aS'Fault handling in an autonomous vehicle '
p1096
aS'Display systems and methods for autonomous vehicles '
p1097
aS'Vehicle control based on perception uncertainty '
p1098
aS'Detecting lane closures and lane shifts by an autonomous vehicle '
p1099
aS'Unlocking mobile-device and/or unmanned aerial vehicle capability in an emergency situation '
p1100
aS'Autonomous Vehicle Monitoring and Control '
p1101
aS'Autonomous control in a dense vehicle environment '
p1102
aS'Cyclist hand signal detection by an autonomous vehicle '
p1103
aS"Inferring state of traffic signal and other aspects of a vehicle's environment based on surrogate data "
p1104
aS'Automatic driver modeling for integration of human-controlled vehicles into an autonomous vehicle network '
p1105
aS'User interface for displaying object-based indications in an autonomous driving system '
p1106
aS'Controlling a vehicle having inadequate map data '
p1107
aS'Autonomous lane control system '
p1108
aS'Systems and methods for insurance based on monitored characteristics of an autonomous drive mode selection system '
p1109
aS'Mapping active and inactive construction zones for autonomous driving '
p1110
aS'Trailer sensor module and associated method of wireless trailer identification and motion estimation '
p1111
aS'Detecting a vehicle signal through image differencing and filtering '
p1112
aS'Methods and Systems to Aid Autonomous Vehicles Driving Through a Lane Merge '
p1113
aS'Positioning vehicles to improve quality of observations at intersections '
p1114
aS'Systems and methods for determining whether a driving environment has changed '
p1115
aS'In-vehicle path verification '
p1116
aS'Personalized Driving of Autonomously Driven Vehicles '
p1117
aS'Communication between autonomous vehicle and external observers '
p1118
aS'Methods and Systems for Detecting Weather Conditions Including Sunlight Using Vehicle Onboard Sensors '
p1119
aS'Autonomous driver assistance system and autonomous driving method thereof '
p1120
aS'Mobile computing device-based guidance navigation and control for unmanned aerial vehicles and robotic systems '
p1121
aS'Artificial Intelligence Valet Systems and Methods '
p1122
aS'Consideration of risks in active sensing for an autonomous vehicle '
p1123
aS'Sidewalk messaging of an autonomous robot '
p1124
aS'Autonomous robot-assisted indoor wireless coverage characterization platform '
p1125
aS'Insurance applications for autonomous vehicles '
p1126
aS'Method and arrangement for handover warning in a vehicle having autonomous driving capabilities '
p1127
aS'Autonomous mobile picking '
p1128
ag1109
aS'Trailer heading angle using vehicle wheel speed sensors '
p1129
aS'System And Method For Using Gestures In Autonomous Parking '
p1130
aS'Aerial data for vehicle navigation '
p1131
aS'Device and method for use with unmanned aerial vehicles '
p1132
aS'Unified motion planner for autonomous driving vehicle in avoiding the moving obstacle '
p1133
aS'Autonomous vehicle operation '
p1134
aS'Insurance system related to a vehicle-to-vehicle communication system '
p1135
aS'Assisted perception for autonomous vehicles '
p1136
aS'Method of actively controlling winch swing via modulated uptake and release '
p1137
aS'Autonomous mission management '
p1138
aS'Mechanisms for Lowering a Payload to the Ground from a UAV '
p1139
aS'Detecting driver grip on steering wheel '
p1140
aS'Gesture-Based Automotive Controls '
p1141
aS'Construction Zone Detection Using a Plurality of Information Sources '
p1142
aS'System and method for improving sensor visibility of vehicle in autonomous driving mode '
p1143
aS'Vehicle communication using audible signals '
p1144
aS'Dual-state steering wheel/input device '
p1145
aS'Method and Apparatus for Controlling a Parking Process of a Vehicle '
p1146
aS'Trailer identification system for trailer backup assist '
p1147
aS'Autonomous mode vehicle control system and vehicle comprising such a control system '
p1148
aS'Safely navigating on roads through maintaining safe distance from other vehicles '
p1149
aS'Payload-release device and operation thereof '
p1150
aS'Trailer motion and parameter estimation system '
p1151
aS'Methods And Software For Managing Vehicle Priority In A Self-Organizing Traffic Control System '
p1152
aS'Construction zone sign detection using light detection and ranging '
p1153
aS'Construction Zone Sign Detection '
p1154
aS'Method and system for drone deliveries to vehicles in route '
p1155
aS'System And Method To Operate An Automated Vehicle '
p1156
aS'Wireless visualization interface for autonomous ground vehicle signal coverage '
p1157
aS'Approach for consolidating observed vehicle trajectories into a single representative trajectory '
p1158
aS'Systems and methods for UAV docking '
p1159
aS'Methods and Systems for Alerting and Aiding an Emergency Situation '
p1160
aS'Autonomous driving in areas for non-drivers '
p1161
aS'Smart tow '
p1162
aS'Personalized driving ranking and alerting '
p1163
aS'Suggesting a route based on desired amount of driver interaction '
p1164
aS'Systems and methods for implementing a multi-segment braking profile for a vehicle '
p1165
aS'Efficient intersection autonomous driving protocol '
p1166
aS'Vehicle control system '
p1167
aS'Augmented trajectories for autonomous vehicles '
p1168
aS'Methods and Systems for Detecting Weather Conditions Including Wet Surfaces Using Vehicle Onboard Sensors '
p1169
aS'Modifying speed of an autonomous vehicle based on traffic conditions '
p1170
aS'Smart vehicle '
p1171
aS'Robust Method for Detecting Traffic Signals and their Associated States '
p1172
aS'Aerial system and vehicle for continuous operation '
p1173
aS'Remote operation of autonomous vehicle in unexpected environment '
p1174
aS'Contactless Electrical Coupling for a Rotatable LIDAR Device '
p1175
aS'Modifying a vehicle state based on the presence of a special-purpose vehicle '
p1176
aS'Devices and Methods for an Energy-Absorbing End of a Vehicle '
p1177
aS'Methods for dense parking of remotely controlled or autonomous vehicles '
p1178
aS'Driving control exchanging system and method for autonomous vehicle '
p1179
aS'Autonomous airspace flight planning and virtual airspace containment system '
p1180
aS'Multi-sensor environmental mapping '
p1181
aS'Method for controlling and communicating with a swarm of autonomous vehicles using one-touch or one-click gestures from a mobile platform '
p1182
aS'Autonomous vehicle driving support system and autonomous driving method performed by the same '
p1183
aS'Autonomous driving style learning '
p1184
aS'Advanced parking and intersection management system '
p1185
aS'Apparatus and methods for tracking using aerial video '
p1186
aS'Method and system for anticipatory deployment of autonomously controlled vehicles '
p1187
aS'Systems and methods for UAV battery exchange '
p1188
aS'Unmanned aerial vehicle delivery system '
p1189
aS'Bystander interaction during delivery from aerial vehicle '
p1190
aS'Control of vehicles based on auditory signals '
p1191
aS'Steering angle control for multiple features '
p1192
aS'Use of Environmental Information to aid Image Processing for Autonomous Vehicles '
p1193
aS'Lane departure control system '
p1194
aS'Use of uncertainty regarding observations of traffic intersections to modify behavior of a vehicle '
p1195
aS'Modular Vehicle Lift System '
p1196
aS'Tracking on-road vehicles with sensors of different modalities '
p1197
aS'System, apparatus, and method for the measurement, collection, and analysis of radio signals utilizing unmanned aerial vehicles '
p1198
aS'Shared control of semi-autonomous vehicles including collision avoidance in multi-agent scenarios '
p1199
aS'Regional operation modes for autonomous vehicles '
p1200
aS'Single layer shared aperture beam forming network '
p1201
ag1070
aS'Reward system related to a vehicle-to-vehicle communication system '
p1202
aS'Construction zone object detection using light detection and ranging '
p1203
aS'Apparatus and method for cooperative autonomous driving between vehicle and driver '
p1204
aS'Selecting vehicle type for providing transport '
p1205
aS'Method and system for remote control of motor vehicles '
p1206
aS'Piggybacking Unmanned Aerial Vehicle '
p1207
aS'Vehicle with computing means for monitoring and predicting traffic participant objects '
p1208
aS'Lane boundary detection using images '
p1209
aS'Vehicle vision system with front and rear camera integration '
p1210
aS'Trailer parameter identification system '
p1211
aS'Virtual and Augmented Reality Cockpit and Operational Control Systems '
p1212
aS'Methods and systems for detecting weather conditions including fog using vehicle onboard sensors '
p1213
aS'Management of driver and vehicle modes for semi-autonomous driving systems '
p1214
aS'Methods and systems for performing flocking while executing a long-range fleet plan '
p1215
aS'Steering Assist in Driver Initiated Collision Avoidance Maneuver '
p1216
aS'Robotic platform and method for performing multiple functions in agricultural systems '
p1217
aS'Control apparatus of unmanned autonomous operating vehicle '
p1218
aS'Detecting sensor degradation by actively controlling an autonomous vehicle '
p1219
aS'Systems and methods for generating data that is representative of an insurance policy for an autonomous vehicle '
p1220
aS'Autonomous vehicle positioning system for misbehavior detection '
p1221
aS'Automatic device mode based on physical location or user in a vehicle '
p1222
aS'Motor vehicle with captive aircraft '
p1223
aS'System and method for determining position and distance of objects using road fiducials '
p1224
aS'Cross-validating sensors of an autonomous vehicle '
p1225
aS'Context-based flight mode selection '
p1226
aS'Detecting road weather conditions '
p1227
aS'Optical communications and obstacle sensing for autonomous vehicles '
p1228
aS'Managing a fleet of autonomous electric vehicles for on-demand transportation and ancillary services to electrical grid '
p1229
aS'Systems and methods for lane end recognition '
p1230
aS'System and method for dynamic in-vehicle virtual reality '
p1231
aS'Combination of unmanned aerial vehicles and the method and system to engage in multiple applications '
p1232
aS'Methods and systems for scan matching approaches for vehicle heading estimation '
p1233
aS'Differential control user interface for reversing vehicle and trailer system '
p1234
aS'Intelligent navigation system '
p1235
aS'Use of relationship between activities of different traffic signals in a network to improve traffic signal state estimation '
p1236
aS'Wearable computer in an autonomous vehicle '
p1237
aS'Tracked all-terrain vehicle '
p1238
aS'Collision detection system with a plausibiity module '
p1239
aS'Dynamic routing intelligent vehicle enhancement system '
p1240
aS'Autonomous vehicle precipitation detection '
p1241
aS'Controlled parking of autonomous vehicles '
p1242
aS'Vehicle operation assistance '
p1243
aS'Controlling autonomous vehicle using audio data '
p1244
aS'Use of detected objects for image processing '
p1245
aS'Pose estimation using long range features '
p1246
aS'Object avoidance for a trailer backup assist system '
p1247
aS'Sharing Autonomous Vehicles '
p1248
aS'Use of position logs of vehicles to determine presence and behaviors of traffic controls '
p1249
aS'Dangerous Driving Event Reporting '
p1250
aS'Affective user interface in an autonomous vehicle '
p1251
aS'Autonomous vehicle handling annd performance adjustment '
p1252
aS'Predicting trajectories of objects based on contextual information '
p1253
aS'Methods and systems for smooth trajectory generation for a self-driving vehicle '
p1254
aS'System and method for responding to driver state '
p1255
aS'Terrain classification system for a vehicle '
p1256
aS'Automated warehousing using robotic forklifts '
p1257
aS'System and method for vehicle lateral control '
p1258
aS'Systems and Methods for Building Road Models, Driver Models, and Vehicle Models and Making Predictions Therefrom '
p1259
aS'Wide-view LIDAR with areas of special attention '
p1260
aS'Recognition and prediction of lane constraints and construction areas in navigation '
p1261
aS'Modifying vehicle behavior based on confidence in lane estimation '
p1262
aS'Context-aware threat response arbitration '
p1263
aS'Map data creation device, autonomous movement system and autonomous movement control device '
p1264
aS'Apparatus and method for managiing failure in autonomous navigation system '
p1265
aS'Autonomous Vehicle Interface System '
p1266
aS'Mode Transition for an Autonomous Vehicle '
p1267
aS'Marine seismic survey and method using autonomous underwater vehicles and underwater bases '
p1268
aS'Mapping techniques using probe vehicles '
p1269
aS'System and Method to Provide Valet Instructions for a Self-Driving Vehicle '
p1270
aS'Algorithm for steering angle command to torque command conversion '
p1271
aS'Vehicle monitoring system '
p1272
aS'Methods and systems for determining instructions for pulling over an autonomous vehicle '
p1273
aS'Autonomous vehicles '
p1274
aS'Method and system for controlling the behavior of an occupant of a vehicle '
p1275
aS'Enhancing basic roadway-intersection models using high intensity image data '
p1276
aS'Avoiding blind spots of other vehicles '
p1277
aS'Vehicle adapted for autonomous driving and a method for detecting obstructing objects '
p1278
aS'Unmanned aerial vehicle for monitoring infrastructure assets '
p1279
aS'Dynamic collision-avoidance system and method '
p1280
aS'Detecting and responding to tailgaters '
p1281
aS'Method of autonomous movement of a vehicle in a parking area '
p1282
aS'Determination of object heading based on point cloud '
p1283
aS'Authentication systems and methods for generating flight regulations '
p1284
aS'Vehicle occupant emergency system '
p1285
aS'Cellphone controllable car intrusion recording and monitoring reaction system '
p1286
aS'Systems and method for autonomous vehicle data processing '
p1287
aS'Vehicle '
p1288
aS'Methods and systems for controlling operation of a laser device '
p1289
aS'Network of Unmanned Vehicles '
p1290
aS'System and method for predicting behaviors of detected objects through environment representation '
p1291
aS'Method and system for controlling a vehicle during an autonomous control mode '
p1292
aS'Systems and methods for reliable relative navigation and autonomous following between unmanned aerial vehicle and a target object '
p1293
aS'Method and apparatus to localize an autonomous vehicle using convolution '
p1294
aS'Enabling multiple autonomous cargo deliveries in a single mission '
p1295
aS'Systems and methods for target tracking '
p1296
aS'Parking assist system with annotated map generation '
p1297
aS'Vertical take off and landing autonomous/semiautonomous/remote controlled aerial agricultural sensor platform '
p1298
aS'Apparatus and method for providing location and heading information of autonomous driving vehicle on road within housing complex '
p1299
aS'Use of motion data in the processing of automotive radar image processing '
p1300
aS'Method and apparatus for providing passenger embarkation points for points of interests '
p1301
aS'Lane change path planning algorithm for autonomous driving vehicle '
p1302
aS'Systems and methods for on-demand transportation '
p1303
aS'Collision avoidance control integrated with eps controller '
p1304
aS'Device and method for controlling a motor vehicle '
p1305
aS'Autonomous vehicle navigation system and method '
p1306
aS'Autonomous mobile robot for handling job assignments in a physical environment inhabited by stationary and non-stationary obstacles '
p1307
aS'Vehicle Control Using Modeled Swarming Behavior '
p1308
aS'Method and System for Autonomous Vehicles '
p1309
aS'Autonomous vehicle routing and navigation using passenger docking locations '
p1310
aS'Navigation based on radar-cued visual imaging '
p1311
aS'Modified autonomous vehicle settings '
p1312
aS'Controlling unmanned aerial vehicles as a flock to synchronize flight in aerial displays '
p1313
aS'Lane keeping system using rear camera '
p1314
aS'Velocity control for an unmanned aerial vehicle '
p1315
aS'Autonomous cargo delivery system '
p1316
aS'Transformable aerial vehicle '
p1317
aS'Assessing asynchronous authenticated data sources for use in driver risk management '
p1318
aS'Intelligent modular robotic apparatus and methods '
p1319
aS'Guidance apparatus of unmanned autonomous operating vehicle '
p1320
aS'Forestry Management System '
p1321
aS'Arrangement of area wire for unmanned autonomous operating vehicle and control apparatus of the same '
p1322
aS'Methods and systems for estimating vehicle speed '
p1323
aS'Methods and apparatuses for autonomous flight termination '
p1324
aS'Aerial farm robot system for crop dusting, planting, fertilizing and other field jobs '
p1325
aS'Using geometric features and history information to detect features such as car exhaust in point maps '
p1326
aS'Autonomous driving sensing system and method '
p1327
aS'Use of previous detections for lane marker detection '
p1328
aS'Modular rapid development system for building underwater robots and robotic vehicles '
p1329
aS'Systems and methods for uav battery power backup '
p1330
aS'Deployment of mobile automated vehicles '
p1331
aS'Autonomous vehicle comprising extracorporeal blood treatment machine '
p1332
aS'Human Augmentation of Robotic Work '
p1333
aS'Unified motion planning algorithm for autonomous driving vehicle in obstacle avoidance maneuver '
p1334
aS'Flight control for flight-restricted regions '
p1335
aS'Efficient Localization of Transmitters Within Complex Electromagnetic Environments '
p1336
aS'Autonomous resupply system and method '
p1337
aS'Vehicle trailer connect system '
p1338
aS'Method and appratus for causing an adjustment in parking position for vehicles '
p1339
aS'Autonomous driving merge management system '
p1340
aS'Transitioning between operational modes of an autonomous vehicle '
p1341
aS'Autonomous vehicle with reconfigurable seats '
p1342
aS'Driving mode alerts from self-driving vehicles '
p1343
aS'Multi-stage airbag in vehicle with reconfigurable interior '
p1344
aS'Autonomous coordination of agents '
p1345
aS'Work vehicle robotic platform '
p1346
aS'Forest Sensor Deployment and Monitoring System '
p1347
aS'Reverse iteration of planning data for system control '
p1348
aS'Optically assisted landing of autonomous unmanned aircraft '
p1349
aS'Autonomous control damper '
p1350
aS'Neuro-cognitive driver state processing '
p1351
aS'Method and apparatus for providing vehicle synchronization to facilitate a crossing '
p1352
aS'Methods and systems for decomposing fleet planning optimizations via spatial partitions '
p1353
aS'Camera calibration using structure from motion techniques '
p1354
aS'Ground and air vehicle electromagnetic signature detection and localization '
p1355
aS'Detecting lane markings '
p1356
ag1123
aS'Autonomous Unmanned Aerial Vehicle Decision-Making '
p1357
aS'Automated control of interactions between self-driving vehicles and pedestrians '
p1358
aS'Steering Wheel Light Bar '
p1359
aS'Request apparatus for delivery of medical support implement by UAV '
p1360
aS'Driver behavior from probe data for augmenting a data model '
p1361
aS'Method for Autonomous Parking of a Motor Vehicle, Driver Assistance Device for Performing the Method and Motor Vehicle with the Driver Assistance Device '
p1362
ag1227
aS'Drone systems for pre-trip inspection and assisted backing '
p1363
aS'Methods for operation of autonomous vehicles in special control zones '
p1364
aS'Using lighting and other streetside devices to indicate parking space availability and navigation information '
p1365
aS'Depth sensing method and system for autonomous vehicles '
p1366
aS'Apparatus and methods for training robots utilizing gaze-based saliency maps '
p1367
aS'Drive-Control Systems for Vehicles Such as Personal-Transportation Vehicles '
p1368
aS'System for optimizing the charging of electric vehicles using networked distributed energy storage systems '
p1369
aS'Vehicle operator monitoring and operations adjustments '
p1370
aS'Methods and Apparatus for Array Based Lidar Systems with Reduced Interference '
p1371
aS'Distributed airborne wireless networks '
p1372
aS'System, apparatus and method for long endurance vertical takeoff and landing vehicle '
p1373
aS'Automated system and method for modeling the behavior of vehicles and other agents '
p1374
aS'Assessment and management of emotional state of a vehicle operator '
p1375
aS'Luminaire with ambient sensing and autonomous control capabilities '
p1376
aS'Solid object detection system using laser and radar sensor fusion '
p1377
aS'Unmanned aerial vehicle landing interface '
p1378
aS'Countermeasures for threats to an uncrewed autonomous vehicle '
p1379
aS'Interactive automated driving system '
p1380
aS'Hybrid Power Systems for Vehicle with Hybrid Flight Modes '
p1381
aS'Robust and autonomous docking and recharging of quadrotors '
p1382
aS'Unmanned Aerial Systems Traffic Management '
p1383
aS'All weather autonomously driven vehicles '
p1384
aS'Connected vehicles adaptive security signing and verification methodology and node filtering '
p1385
aS'Image capture with privacy protection '
p1386
aS'Team-Oriented Human-Vehicle Interface For Adaptive Cruise Control System And Methods For Using Same '
p1387
aS'Unmanned device interaction methods and systems '
p1388
aS'Managing vehicles on a road network '
p1389
aS'Daylight Opening Surround '
p1390
aS'Counter-unmanned aerial vehicle system and method '
p1391
aS'Braking control system for vehicle '
p1392
aS'Method and apparatus for providing access to autonomous vehicles based on user context '
p1393
aS'Suspension Control System To Facilitate Wheel Motions During Parking '
p1394
aS'Object detection based on known structures of an environment of an autonomous vehicle '
p1395
aS'Unmanned vehicle (uv) control system '
p1396
aS'In-vehicle authorization for autonomous vehicles '
p1397
aS'Autonomous vehicle with reconfigurable interior '
p1398
aS'Vehicle personal assistant '
p1399
aS'Transport facility for autonomous navigation and method for determining damage to a motor vehicle '
p1400
aS'Controlling use of a single multi-vehicle parking space and a restricted location within the single multi-vehicle parking space using multiple cameras '
p1401
aS'Launching unmanned aerial copter from mid-air '
p1402
aS'Systems and Methods for Managing a Vehicle Sharing Facility '
p1403
aS'Water Vehicles '
p1404
aS'Real-time Occupancy Mapping System for Autonomous Vehicles '
p1405
aS'System and method for remote control of unmanned vehicles '
p1406
aS'Autonomous transport navigation to a shipping location using elements of a wireles node network '
p1407
aS'Autonomous systems, methods, and apparatus for ag based operations '
p1408
aS'Systems and methods for causing a vehicle response based on traffic light detection '
p1409
aS'Indoor and Outdoor Aerial Vehicles for Painting and Related Applications '
p1410
aS'System and method for managing unmanned aerial vehicles '
p1411
aS'Apparatus and methods for controlling attention of a robot '
p1412
aS'Position Estimation and Vehicle Control in Autonomous Multi-Vehicle Convoys '
p1413
aS'Systems, methods, and computer readable media for utilizing a plurality of unmanned aerial vehicles to conduct performance testing in a wireless communications network '
p1414
aS'Associating parking areas with destinations '
p1415
aS'On-board vehicle path prediction using processed sensor information '
p1416
aS'Near-flight testing maneuvers for autonomous aircraft '
p1417
aS'Apparatus and method for estimating and using a predicted vehicle speed in an indirect vision driving task '
p1418
aS'Method and system for determining a position of a vehicle '
p1419
aS'Water Area Management System '
p1420
aS'Apparatus and method for continuously establishing a boundary for autonomous driving availability and an automotive vehicle comprising such an apparatus '
p1421
aS'Non-enforcement autonomous parking management system and methods '
p1422
aS'Light detection and ranging device with oscillating mirror driven by magnetically interactive coil '
p1423
aS'Mobile autonomous surveillance '
p1424
aS"Method to gain driver's attention for autonomous vehicle "
p1425
aS'Autonomous vehicle detection of and response to yield scenarios '
p1426
aS'Light steering device with an array of oscillating reflective slats '
p1427
aS'Transitioning from autonomous vehicle control to driver control to responding to driver control '
p1428
aS'Vehicle device '
p1429
aS'Real-time road flare detection using templates and appropriate color spaces '
p1430
aS'System and Method for Control of Autonomous Marine Vessels '
p1431
aS'Methods and systems for pedestrian avoidance '
p1432
aS'Vehicle, vehicle system and method for increasing safety and/or comfort during autonomous driving '
p1433
aS'Method for controlling an autonomous vehicle system and motor vehicle '
p1434
aS'Vehicle trajectory optimization for autonomous vehicles '
p1435
aS'Systems and methods for vertical takeoff and/or landing '
p1436
aS'Image and video compression for remote vehicle assistance '
p1437
aS'System and method for tracking guiding lines by an autonomous vehicle '
p1438
aS'Roadway projection system '
p1439
aS'Autonomous Driving Vehicle and Autonomous Driving System '
p1440
aS'Systems and methods for braking a vehicle based on a detected object '
p1441
aS'Limitations on the use of an autonomous vehicle '
p1442
aS'Multi-level navigation monitoring and control '
p1443
aS'System for automatic takeoff and landing by interception of small uavs '
p1444
aS'Methods and systems for detection of reflective markers at long range '
p1445
aS'Unmanned aerial vehicle (uav) for collecting audio data '
p1446
aS'Interpretation of ambiguous vehicle instructions '
p1447
aS'Apparatus and method for recognizing driving environment for autonomous vehicle '
p1448
aS'Methods and systems for electronic payment for parking using autonomous position sensing '
p1449
aS'Uav flight display '
p1450
aS'Unmanned aerial vehicles '
p1451
aS'Methods and systems for determining a state of an unmanned aerial vehicle '
p1452
aS'Systems and methods for deploying autonomous underwater vehicles from a ship '
p1453
aS'Method and system for optimizing planting operations '
p1454
ag1171
aS'Autonomous data machines and systems '
p1455
ag1194
ag1359
aS'Locality adapted computerized assisted or autonomous driving of vehicles '
p1456
aS'Apparatus for guiding an autonomous vehicle towards a docking station '
p1457
aS'Virtual camera interface and other user interaction paradigms for a flying digital assistant '
p1458
aS'Spiking network apparatus and method with bimodal spike-timing dependent plasticity '
p1459
aS'Mixed autonomous and manual control of autonomous vehicles '
p1460
aS'System, method, and apparatus for settlement for participation in an electric power grid '
p1461
aS'Overtake assessment arrangement and system and autonomous vehicle with an overtake assessment arrangement '
p1462
aS'Variably controlled ground vehicle '
p1463
aS'Spiking neuron network sensory processing apparatus and methods '
p1464
aS'Automated hitching assist system '
p1465
aS'Providing Advertisements to Autonomous Vehicles '
p1466
aS'Advanced parking management system '
p1467
aS'Self-explaining autonomous vehicle '
p1468
aS'Marine seismic surveys using clusters of autonomous underwater vehicles '
p1469
aS'Accident response using autonomous vehicle monitoring '
p1470
aS'Apparatus and methods for robotic operation using video imagery '
p1471
aS'Individual driving preference adapted computerized assist or autonomous driving of vehicles '
p1472
aS'Method to control a vehicle path during autonomous braking '
p1473
aS'Contrast enhancement spiking neuron network sensory processing apparatus and methods '
p1474
aS'Driving mode changing method and apparatus of autonomous navigation vehicle '
p1475
aS'System, method, and apparatus for electric power grid and network management of grid elements '
p1476
aS'Light-based communications utilizing a gossip network in a vehicle/roadway environment '
p1477
aS'Control interface for a semi-autonomous vehicle '
p1478
aS'Autonomous vehicle detection of and response to emergency vehicles '
p1479
aS'Risk mitigation for autonomous vehicles relative to oncoming objects '
p1480
aS'Autonomous vehicle '
p1481
aS'Navigation of on-road vehicle based on vertical elements '
p1482
aS'Method and apparatus for changing an autonomously travelling motor vehicle to a safe state '
p1483
aS'Modular autonomous farm vehicle '
p1484
aS'Autonomous gardening vehicle with camera '
p1485
aS'Method for coordinating the operation of motor vehicles that drive in fully automated mode '
p1486
ag1433
aS'Accurate curvature estimation algorithm for path planning of autonomous driving vehicle '
p1487
aS'Internal safety systems for robotic vehicles '
p1488
aS'Remote assistance for an autonomous vehicle in low confidence situations '
p1489
aS'Vehicle controlling system and method '
p1490
aS'Semantics based safe landing area detection for an unmanned vehicle '
p1491
ag1194
aS'Method of controlling steering of a ground vehicle '
p1492
aS'Transitioning from autonomous vehicle control to driver control '
p1493
aS'Methods to operate autonomous vehicles to pilot vehicles in groups or convoys '
p1494
aS'Forward-facing multi-imaging system for navigating a vehicle '
p1495
aS'Vehicle sensor diagnosis system and method and a vehicle comprising such a system '
p1496
aS'Automated Parking Payment '
p1497
aS'Vehicle system, a vehicle and a method for autonomous road irregularity avoidance '
p1498
aS'Directing vehicle into feasible region for autonomous and semi-autonomous parking '
p1499
aS'Distributed communication of independent autonomous vehicles to provide redundancy and performance '
p1500
aS'System, method, and data packets for messaging for electric power grid elements over a secure internet protocol network '
p1501
aS'Systems and methods for air vehicles '
p1502
aS'Robotic vehicle active safety systems and methods '
p1503
aS'Unmanned autonomous traveling service apparatus and method based on driving information database '
p1504
aS'Optimized Parking System '
p1505
aS'Unmanned aerial vehicle management '
p1506
aS'Control device for an autonomous land vehicle '
p1507
aS'Agricultural autonomous vehicle platform with articulated base '
p1508
aS'Carrying autonomous vehicle system and methods '
p1509
aS'Flapping wing aerial vehicles '
p1510
aS'Dual airbags in vehicle with reconfigurable interior '
p1511
aS'Detailed map format for autonomous driving '
p1512
aS'System to automatically measure perception sensor latency in an autonomous vehicle '
p1513
aS'Rapid deployment air and water vehicle '
p1514
aS'Orchestrating autonomous movements of parked vehicles to optimize parking efficiency '
p1515
aS'Vehicle control system and method '
p1516
aS'Autonomous vehicle speed calibration '
p1517
aS'Autonomous vehicle with automatic window shade '
p1518
aS'Lane assignments for autonomous vehicles '
p1519
aS'Apparatus and methods for encoding of sensory data using artificial spiking neurons '
p1520
aS'Autonomous vehicle with independent auxiliary control units '
p1521
aS'Autonomous vehicle operated with guide assistance of human driven vehicles '
p1522
aS'Autonomous vehicle with improved visual detection ability '
p1523
aS'Folding vehicle '
p1524
aS'Unique signaling for autonomous vehicles to preserve user privacy '
p1525
aS'Self-calibrating sensors and actuators for unmanned vehicles '
p1526
aS'Semi-autonomous mode control '
p1527
aS'System and method for controlling unmanned vehicles '
p1528
aS'Vehicle navigation route search system, method, and program '
p1529
aS'Teleoperation system and method for trajectory modification of autonomous vehicles '
p1530
aS'Method and system for autonomous tracking of a following vehicle in the lane of a leading vehicle '
p1531
aS'Time To Avoid Collision For Active Steering Safety Systems '
p1532
aS'Traction control system for 4wd/awd vehicles equipped with onboard camera '
p1533
aS'Modular Payload Boxes and Autonomous Water Vehicle Configured to Accept Same '
p1534
aS'Identifying cost-effective parking for an autonomous vehicle '
p1535
aS'Autonomous vehicle lane routing and navigation '
p1536
aS'Bus detection for an autonomous vehicle '
p1537
aS'Methods for delivery to multiple locations using autonomous vehicles '
p1538
aS'Autonomous driving vehicle '
p1539
aS'Methods and underwater bases for using autonomous underwater vehicle for marine seismic surveys '
p1540
aS'Vehicle traffic control system '
p1541
aS'Determining Pickup and Destination Locations for Autonomous Vehicles '
p1542
aS'Fall back trajectory systems for autonomous vehicles '
p1543
aS'System for switching control of an autonomous vehicle '
p1544
aS'Providing remote assistance to an autonomous vehicle '
p1545
aS'Methods and Apparatus for Unmanned Aerial Vehicle Autonomous Aviation '
p1546
aS'Performing Services on Autonomous Vehicles '
p1547
aS'Remote vehicle monitoring '
p1548
aS'Image and map-based detection of vehicles at intersections '
p1549
aS'Autonomous underwater vehicle control system and method '
p1550
aS'Autonomous vehicle refueling locator '
p1551
aS'Apparatus and method for sharing vehicle information '
p1552
aS'Wireless, motion and position-sensing, integrating radiation sensor for occupational and environmental dosimetry '
p1553
aS'System for accommodating a pedestrian during autonomous vehicle operation '
p1554
aS'Closed-loop optimization of a wireless network using an autonomous vehicle '
p1555
aS'System and method for human operator intervention in autonomous vehicle operations '
p1556
aS'Delegating control of a vehicle '
p1557
aS'Autonomous delivery transportation network '
p1558
aS'Methods and systems for correcting an estimated heading using a map '
p1559
aS'Driver assistance system for a motor vehicle '
p1560
aS'Model checking for autonomous vehicles '
p1561
aS'Autonomous delivery platform '
p1562
aS'Autonomous vehicle and its failure determination method '
p1563
aS'Trailer backup assist system with adaptive steering angle limits '
p1564
aS'Autonomous vehicle environment detection system '
p1565
aS'Administering A Recall By An Autonomous Vehicle '
p1566
aS'Adaptive algorithms for interrogating the viewable scene of an automotive radar '
p1567
ag1342
aS'Method for autonomous controlling of a remote controlled aerial vehicle and corresponding system '
p1568
aS'Driving control apparatus for vehicle '
p1569
aS'Situation-based transfer of vehicle sensor data during remote operation of autonomous vehicles '
p1570
aS'Risk mitigation for autonomous vehicles relative to turning objects '
p1571
aS'Methods and systems for controlling steering systems of vehicles '
p1572
aS'Regional driving trend modification using autonomous vehicles '
p1573
aS'System, Controller and Method for Preventing Vehicle Rollaway '
p1574
aS'Device and method for self-automated parking lot for autonomous vehicles based on vehicular networking '
p1575
aS'Vehicle traveling control apparatus '
p1576
aS'Direction of arrival (DOA) estimation using multiple offset receive channels '
p1577
aS'Vehicle trajectory planning for autonomous vehicles '
p1578
aS'Method and device for autonomous braking of a vehicle following collision '
p1579
aS'Point-and-Click Control of Unmanned, Autonomous Vehicle Using Omni-Directional Visors '
p1580
aS'Systems, Vehicles And Methods For Controlling An Application Of A Plurality Of Trailer Brakes '
p1581
ag1342
aS'Monitoring autonomous vehicle braking '
p1582
aS'Vehicle behavior control apparatus '
p1583
aS'Method and Control Unit for Communication Between an Autonomous Vehicle and a Road User '
p1584
aS'Hybrid utility vehicle with selectable drivetrain '
p1585
aS'Autonomous vehicle operation in view-obstructed environments '
p1586
aS'Method and system of performing geophysical surveys with autonomous underwater vehicles '
p1587
aS'Method for determining a maximum speed limit for a reversing vehicle combination '
p1588
aS'Synchronously updated vehicle transportation network information for autonomous vehicle routing and navigation '
p1589
aS'Control arrangement arranged to control an autonomous vehicle, autonomous drive arrangement, vehicle and method '
p1590
ag1543
aS'Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle '
p1591
aS'Incident light sensor on autonomous vehicle '
p1592
aS'Calibration for autonomous vehicle operation '
p1593
aS'Software application to request and control an autonomous vehicle service '
p1594
aS'Independent steering, power torque control and transfer in autonomous vehicles '
p1595
aS'Probabilistic autonomous vehicle routing and navigation '
p1596
aS'Deployment and retrieval of seismic autonomous underwater vehicles '
p1597
aS'Autonomous vehicle action planning using behavior prediction '
p1598
aS'System and Method for Semi-Autonomous Driving of Vehicles '
p1599
aS'Automatic park and reminder system and method of use '
p1600
aS'Steering system and method for autonomous vehicles '
p1601
aS'Steering-based scrub braking '
p1602
aS'Driving assist device '
p1603
aS'Using other vehicle trajectories to aid autonomous vehicles driving through partially known areas '
p1604
aS'Autonomous winter solar panel '
p1605
aS'Traffic signal response for autonomous vehicles '
p1606
aS'Modifying autonomous vehicle driving by recognizing vehicle characteristics '
p1607
aS'Autonomous vehicle operation in obstructed occupant view and sensor detection environments '
p1608
aS'Detecting and responding to parking behaviors in autonomous vehicles '
p1609
aS'Autonomous vehicle lateral control for path tracking and stability '
p1610
aS'Method for operating an autonomous vehicle on a courier route '
p1611
aS'Assessment of human driving performance using autonomous vehicles '
p1612
aS'Autonomous vehicle theft prevention '
p1613
aS'Device and method for the autonomous control of motor vehicles '
p1614
aS'Autonomous vehicle control system '
p1615
aS'Sensor calibration for autonomous vehicles '
p1616
aS'Autonomous vehicle operation within a center turn lane '
p1617
aS'System and method for acoustic signature health monitoring of unmanned autonomous vehicles (UAVS) '
p1618
aS'Pre-purchase mechanism for autonomous vehicles '
p1619
aS'Lane changing for autonomous vehicles '
p1620
aS'Lighting control system and method for autonomous vehicles '
p1621
aS'Autonomous vehicle operation relative to unexpected dynamic objects '
p1622
aS'Subject tracking system for autonomous vehicles '
p1623
aS'Charging system for autonomous vehicles '
p1624
aS'Autonomous vehicle services '
p1625
aS'System and method of controlling autonomous vehicles '
p1626
aS'State-based operation for autonomous vehicles '
p1627
aS'Unmanned ground/aerial vehicle system having autonomous ground vehicle that remotely controls one or more aerial vehicles '
p1628
aS'Controlling autonomous vehicles in connection with transport services '
p1629
aS'Traffic aware lane determination for human driver and autonomous vehicle driving system '
p1630
aS'Automatic slot parking strategy '
p1631
aS'Autonomous vehicle window clearing '
p1632
aS'System and Method for Controlling Autonomous Vehicles '
p1633
aS'Assessing driver readiness for transition between operational modes of an autonomous vehicle '
p1634
aS'Park assist with tire radius consideration '
p1635
aS'Simulation system and methods for autonomous vehicles '
p1636
aS'Autonomous vehicle operation at blind intersections '
p1637
aS'Automated driving assistance using altitude data '
p1638
aS'Collision mitigated braking for autonomous vehicles '
p1639
aS'Autopark Steering Wheel Snap Reduction '
p1640
aS'Method for assisting the reversal of an articulated vehicle '
p1641
aS"PRE-ALERT OF LCC's STEERING TORQUE LIMIT EXCEED "
p1642
aS'Using multiple exposures to improve image processing for autonomous vehicles '
p1643
aS'Positioning autonomous vehicles based on field of view '
p1644
aS'Systems, devices and methods delivering energy using an uncrewed autonomous vehicle '
p1645
aS'Modifying the behavior of an autonomous vehicle using context based parameter switching '
p1646
aS'Target monitoring system with lens cleaning device '
p1647
aS'Accident monitoring using remotely operated or autonomous aerial vehicles '
p1648
aS'Size adjustment of forward objects for autonomous vehicles '
p1649
aS'Driving support device and driving support system '
p1650
aS'Door actuator adjustment for autonomous vehicles '
p1651
aS'Autonomous vehicle detection of and response to traffic officer presence '
p1652
aS'Fallback requests for autonomous vehicles '
p1653
aS'Backend system for route planning of autonomous vehicles '
p1654
aS'Redundant electrical power for autonomous vehicles '
p1655
aS'Method of controlling a differential lock '
p1656
aS'System and method for autonomous vehicle driving behavior modification '
p1657
aS'Altering autonomous or semi-autonomous vehicle operation based on route traversal values '
p1658
aS'Autonomous self-leveling vehicle '
p1659
aS'External indicators and notifications for vehicles with autonomous capabilities '
p1660
aS'Transitioning from autonomous vehicle control to operator vehicle control '
p1661
aS'Method for maintaining active control of an autonomous vehicle '
p1662
aS'Autonomous vehicle entertainment system '
p1663
aS'Autonomous vehicle operation based on interactive model predictive control '
p1664
aS'Autonomous Vehicle and Control Method Thereof '
p1665
aS'Multiple environment unmanned vehicle '
p1666
aS'Apparatus and method employing autonomous vehicles to reduce risk '
p1667
aS'System and method for energy optimization in autonomous vehicle operation '
p1668
aS'Interactive autonomous vehicle command controller '
p1669
aS'Autonomous vehicle dynamic climate control '
p1670
aS'Software application and logic to modify configuration of an autonomous vehicle '
p1671
aS'Autonomous vehicle detection of and response to intersection priority '
p1672
aS'Methods and devices for safe operation of undersize autonomous vehicles on public roads '
p1673
aS'Method and system for stowing steering column in an autonomous vehicle '
p1674
aS'Autonomous driving vehicle and infrastructure for supporting autonomous driving thereof '
p1675
aS'Removable manual controls for an autonomous vehicle '
p1676
aS'Autonomous vehicle operator performance tracking '
p1677
aS'Autonomous vehicle towing system and method '
p1678
aS'System and Method for Controlling Semi-Autonomous Vehicles '
p1679
aS'Method for controlling the path of an autonomous vehicle having steered wheels '
p1680
aS'System of autonomous vehicles '
p1681
aS'Elevated perception system for automated vehicles '
p1682
aS'Navigation system for vehicles '
p1683
aS'Autonomous vehicle emergency operating mode '
p1684
aS'Method for operating an autonomous driving safety or driver assistance system of a motor vehicle '
p1685
aS'Autonomous vehicle safety systems and methods '
p1686
aS'Generating and transmitting parking instructions for autonomous and non-autonomous vehicles '
p1687
aS'Method for parking a vehicle by using a parking assistant system '
p1688
aS'Vehicle traction map for autonomous vehicles '
p1689
aS'Autonomous vehicle control transitioning '
p1690
aS'Control modes for a trailer backup assist system '
p1691
aS'System and method for remotely assisting autonomous vehicle operation '
p1692
aS'System and method for controlling autonomous or semi-autonomous vehicle '
p1693
aS'Active lighting control for communicating a state of an autonomous vehicle to entities in a surrounding environment '
p1694
aS'Towable road motor vehicle '
p1695
aS'Object detection for an autonomous vehicle '
p1696
aS'Utility vehicle '
p1697
aS'Method and apparatus for operating a cushioning system for a motor vehicle '
p1698
aS'Methods and systems for steering-based oscillatory vehicle braking '
p1699
aS'Autonomous driving vehicle, autonomous driving management apparatus, and method of controlling the same '
p1700
aS'Autonomous vehicle fleet service and system '
p1701
aS'Temporal data associations for operating autonomous vehicles '
p1702
aS'Autonomous vehicle-based package pickup and transfer '
p1703
aS'Systems and Methods for Autonomous Vehicle Navigation '
p1704
aS'Method and apparatus for providing an operational configuration for an autonomous vehicle '
p1705
aS'Autonomous vehicle driving assist system, method, and program '
p1706
aS'Control system for selective autonomous vehicle control '
p1707
aS'Autonomous vehicle applique '
p1708
aS'Detector for optically detecting at least one object '
p1709
aS'Improvements in vehicle steering '
p1710
aS'Vehicle drag reduction device '
p1711
aS'Sensor-based object-detection optimization for autonomous vehicles '
p1712
aS'Minimizing incorrect sensor data associations for autonomous vehicles '
p1713
aS'Marker aided autonomous vehicle localization '
p1714
aS'Dispatch system for autonomous vehicles '
p1715
aS'Apparatus and method for generating global path for an autonomous vehicle '
p1716
aS'Management of autonomous vehicle lanes '
p1717
aS'Remote control and concierge service for an autonomous transit vehicle fleet '
p1718
aS'Autonomous vehicle virtual reality navigation system '
p1719
aS'Method and system for controlling a vehicle to a moving point '
p1720
aS'Autonomous vehicle with interactions with wearable devices '
p1721
aS'Managing autonomous vehicles '
p1722
aS'Method, control device and system for determining a tread depth of a tread of a tire '
p1723
aS'Battery Management Systems for Autonomous Vehicles '
p1724
aS'System and method for driver preferences for autonomous vehicles '
p1725
aS'System and method for controlling driving of autonomous vehicle '
p1726
aS'Operation of vehicle controls to effect autonomous passing, road exit and exit search operations '
p1727
aS'Method and apparatus for operator supervision and direction of highly autonomous vehicles '
p1728
aS'All-wheel-drive system interaction with fuel savings operation of a motor vehicle '
p1729
aS'Arranging passenger pickups for autonomous vehicles '
p1730
aS'Sensory stimulation system for an autonomous vehicle '
p1731
aS'Pickup and drop off zones for autonomous vehicles '
p1732
aS'Autonomous ready vehicle '
p1733
aS'Coordination of dispatching and maintaining fleet of autonomous vehicles '
p1734
aS'Real Time Risk Assessment and Operational Changes with Semi-Autonomous Vehicles '
p1735
aS'Sidepod stereo camera system for an autonomous vehicle '
p1736
aS'Trailer for autonomous vehicle '
p1737
aS'Autonomous vehicle operation at multi-stop intersections '
p1738
aS'Device and method for safety stoppage of an autonomous road vehicle '
p1739
aS'Monitoring autonomous vehicle steering '
p1740
aS'Control system for autonomous-capable vehicles '
p1741
aS'Method for autonomous vehicle parking '
p1742
aS'Steering system for autonomous vehicle '
p1743
aS'Autonomous vehicle operated with safety augmentation '
p1744
aS'Apparatus and method for autonomous control and balance of a vehicle and for imparting roll and yaw moments on a vehicle for test purposes '
p1745
aS'Autonomous vehicle driving system and method '
p1746
aS'Autonomous vehicle interaction with external environment '
p1747
aS'Systems and methods for managing restricted areas for unmanned autonomous vehicles '
p1748
aS'Obstacle Evaluation Technique '
p1749
aS'Path planning apparatus and method for autonomous vehicle '
p1750
aS'Utilizing accelerometer data to configure an autonomous vehicle for a user '
p1751
aS'Optimizing timing for configuring an autonomous vehicle '
p1752
aS'Vehicle control system and method for self-control driving thereof '
p1753
aS'Autonomous vehicle with adaptive side view mirrors '
p1754
aS'Maneuvering drive with smart central unit '
p1755
aS'Driving profiles for autonomous vehicles '
p1756
aS'Opportunistic unmanned autonomous vehicle energy harvesting '
p1757
aS'Customized Packaging for Unmanned Autonomous Vehicle Item Delivery '
p1758
aS'Computer-implemented method and system for dynamically positioning a vehicle relative to another vehicle in motion for on-the-fly offloading operations '
p1759
aS'Autonomous vehicle simulation system '
p1760
aS'Apparatus and method for generating traveling path of autonomous vehicle '
p1761
aS'Systems and methods for autonomous vehicle ride release confirmation '
p1762
aS'Method and system for improving ride quality in an autonomous vehicle '
p1763
aS'Adaptive autonomous vehicle planner logic '
p1764
aS'Laser diode firing system '
p1765
aS'Vehicle control system for autonomously guiding a vehicle '
p1766
ag1167
aS'Method for operating a driver assistance system of a motor vehicle with a combined longitudinal and transverse guidance function '
p1767
aS'Intention signaling for an autonomous vehicle '
p1768
aS'Vehicle operation assistance information management for autonomous vehicle control transfer '
p1769
aS'Vehicle operation assistance information management for autonomous vehicle control operation '
p1770
aS'Lane tracking system with active rear-steer '
p1771
aS'Method for warning back side of vehicle provided with rear bumper multi carrier '
p1772
aS'Enhanced Road Characterization for Adaptive Mode Drive '
p1773
aS'Autonomous vehicle and method of estimating self position of autonomous vehicle '
p1774
aS'Vehicle steering arrangement, autonomous vehicle steering arrangement, a vehicle, and a method of steering a vehicle '
p1775
aS'Autonomous Car Decision Override '
p1776
aS'Classifying objects detected by 3D sensors for autonomous vehicle operation '
p1777
aS'Tuning microbial populations with programmable nucleases '
p1778
aS'Autonomous vehicle parking and transition to manual control '
p1779
aS'Autonomous vehicle charging station connection '
p1780
aS'Driving support system '
p1781
aS'Autonomous Vehicle Platform and Safety Architecture '
p1782
ag1615
aS'Sliding mode trajectory voting strategy module and driving control system and method thereof '
p1783
aS'Automated driving safety system '
p1784
aS'Seat system for autonomous vehicles '
p1785
aS'Travel control apparatus for vehicle '
p1786
aS'Autonomous vehicle unauthorized passenger or object detection '
p1787
aS'Transportation network utilizing autonomous vehicles for transporting items '
p1788
aS'Self-Recognition of Autonomous Vehicles in Mirrored or Reflective Surfaces '
p1789
aS'Autonomous vehicle with modular control interface '
p1790
aS'Driving support system for vehicle '
p1791
aS'Method and device for generating test cases for autonomous vehicles '
p1792
aS'In-vehicle device, autonomous vehicle, autonomous driving assistance system, autonomous driving monitoring device, road management device, and autonomous driving information gathering device '
p1793
aS'Mitigation of input device failure and mode management '
p1794
ag1780
aS'Method And System Of Location Estimation And Navigation Of Autonomous Vehicles '
p1795
aS'Rear wiper system '
p1796
aS'Steering control in an aircraft equipped with a wheel drive system '
p1797
aS'Autonomous vehicle with improved simultaneous localization and mapping function '
p1798
aS'Autonomous vehicle media control '
p1799
aS'Topographical integration for trailer backup assist system '
p1800
aS'Real-time image-based vehicle detection based on a multi-stage classification '
p1801
aS'System and method for selectively displaying images in an autonomous vehicle '
p1802
aS'Spatial recognition in an autonomous vehicle group '
p1803
aS'Active adaptive haptic multi-function knob '
p1804
aS'Verifying a target object with reverse-parallax analysis '
p1805
aS'Hitch angle warning system and method '
p1806
aS'Sensory stimulation for an autonomous vehicle '
p1807
aS'Trailer sway warning system and method '
p1808
aS'A method for propelling a vehicle '
p1809
aS'System For Avoiding Collisions Between Autonomous Vehicles Conducting Agricultural Operations '
p1810
aS'System and method for presenting media contents in autonomous vehicles '
p1811
ag1167
aS'Method and apparatus for testing software for autonomous vehicles '
p1812
aS'Distributed collaborative operations processor systems and methods '
p1813
aS'Dynamic Virtual Object Generation for Testing Autonomous Vehicles in Simulated Driving Scenarios '
p1814
aS'Multi-mode trailer backup assist interface knob '
p1815
aS'Parking assist system '
p1816
aS'Turbine engine starting system '
p1817
aS'Vehicle steering device and vehicle steering control method '
p1818
aS'System and method for configuring autonomous vehicle responses based on a driver profile '
p1819
aS'Distribution decision trees '
p1820
aS'Method of path planning for evasive steering maneuver '
p1821
ag1167
aS'Secure start system for an autonomous vehicle '
p1822
ag1822
aS'Steering control apparatus having function of determining intention of driver and method of operating the same '
p1823
aS'System and method for scheduling a video conference in an autonomous vehicle '
p1824
aS'Control of adjustable ride height suspension '
p1825
aS'Vehicle mode adjusting system '
p1826
aS'Formatting sensor data for use in autonomous vehicle communications platform '
p1827
aS'Moveable internal shock-absorbing energy dissipation padding in an autonomous vehicle '
p1828
aS'System For Conducting An Agricultural Operation Using An Autonomous Vehicle '
p1829
aS'Gps activated park mode for adjustable suspension systems '
p1830
aS'Regeneration system for a vehicle '
p1831
aS'Positive location system for a locomotive consist '
p1832
aS'Attachable laterally-stable range extender for an electric vehicle '
p1833
aS'Parking feature multi-function tilt knob '
p1834
aS'Driving assistance control apparatus for vehicle '
p1835
aS'Vehicle active suspension system and method of control '
p1836
aS'System and methods to support autonomous vehicles via environmental perception and sensor calibration and verification '
p1837
aS'Method and system for providing a driver behavior adapted evasive maneuver '
p1838
aS'Methods for sample presentation using autonomous vehicles '
p1839
aS'Sensor failure mitigation system and mode management '
p1840
aS'Position and direction determination using multiple single-channel encoders '
p1841
aS'Speed limiting comfort enhancement '
p1842
aS'Classifier hierarchies for traffic light and traffic indicator detection '
p1843
aS'Transportation system of combined vehicles multi-coupled at highway speeds for electrical energy transfer and sharing '
p1844
aS'Illuminated vehicle control management pushbutton knob '
p1845
aS'Vehicle and operating method '
p1846
aS'Trailer backup assist system with active trailer braking for curvature control '
p1847
aS'Vehicle and method of using a spare tire '
p1848
aS'Vehicle lane control using differential torque '
p1849
aS'Radar target detection system for autonomous vehicles with ultra-low phase noise frequency synthesizer '
p1850
ag1167
aS'Trailer length and hitch angle bias estimation '
p1851
aS'Adaptive alert system for autonomous vehicle '
p1852
aS'System and method of using air suspension to improve vehicle unloading '
p1853
aS'Personal safety and privacy features for passengers of an autonomous vehicle based transportation system '
p1854
aS'Fault-Tolerant High-Performance Computer System for Autonomous Vehicle Maneuvering '
p1855
aS'Walk-away vehicle shutdown '
p1856
aS'Trailer backup assist remote knob state management '
p1857
aS'Air quality estimation methods and systems '
p1858
aS'Vehicle lifting and parallel parking aid '
p1859
aS'Controlling weight allocation between truck axles '
p1860
ag1786
aS'Method and device for assisting a driver of a vehicle during a lane change '
p1861
aS'Speed control for motor vehicles '
p1862
ag1786
aS'Secondary steering system unit, secondary steering system, vehicle and a method for secondary steering '
p1863
aS'Method and device for moving a vehicle into a target position '
p1864
aS'Systems and methods for correcting steering wheel angle errors '
p1865
aS'Method for loading a vehicle '
p1866
aS'Method and apparatus for rail-to-road shipping '
p1867
aS'Trailer length estimation method using trailer yaw rate signal '
p1868
aS'Driver monitoring '
p1869
aS'Autonomous vehicle cameras used for near real-time imaging '
p1870
aS'Autonomous vehicle scheduling system for pickup and drop-off of passengers '
p1871
aS'Vision-based indicator signal detection using spatiotemporal filtering '
p1872
aS'Low gravity all-surface vehicle '
p1873
aS'Handwheel obstruction detection and inertia compensation '
p1874
ag1576
aS'Tire windup compensation '
p1875
aS'Wheel assembly adjustment for vehicle events '
p1876
aS'Vehicle trailer parking brake '
p1877
aS'Systems and methods for vehicle dynamics assignment '
p1878
aS'Method for the at least semi-autonomous manoeuvring of a motor vehicle, driver assistance system and motor vehicle '
p1879
aS'Apparatus and method for controlling driving mode of vehicle '
p1880
aS'Automatic level control '
p1881
aS'Method for operating a driver assistance system to perform an autonomous parking maneuver '
p1882
ag1786
aS'Steering-wheel control '
p1883
aS'Orientation of the extent of a vehicle in the direction of the roadway in a parked end position with a parking assistance system for transverse parking '
p1884
aS'Use of laser scanner for autonomous truck operation '
p1885
aS'Split-block construction of waveguide channels for radar frontend '
p1886
aS'Control system for an autonomous vehicle and a method for generating a control signal and autonomous vehicle equipped with such control system '
p1887
ag1786
aS'Vehicle brake-control-system, vehicle comprising a brake-control-system and a method for controlling a vehicle brake system '
p1888
aS'Vehicle trailer communication '
p1889
aS'Remotely operated vehicular pushing apparatus '
p1890
aS'Navigation-linked vehicle de-icer or debris-remover control '
p1891
aS'Automobile-trailer hitch that eliminates jack-knifing '
p1892
aS'Torque control for vehicles with independent front and rear propulsion systems '
p1893
aS'Motor vehicle, in particular taxi '
p1894
aS'Wheel for preventing jackknifing and uneven tire wear in vehicles '
p1895
aS'Deciding on the direction of travel in the event of a resumption of movement in an automated parking process by means of a parking assistance system '
p1896
aS'Fender well fairing '
p1897
ag1576
aS'Determining the stationary state of detected vehicles '
p1898
aS'System for coordinating agricultural vehicle control for loading a truck '
p1899
aS'Predictive control of a motor vehicle '
p1900
aS'Semi truck on a rail flat car holding device '
p1901
aS'Washer nozzle integrated wiper blade '
p1902
aS'Camera system and vehicle '
p1903
aS'Apparatus and method for controlling autonomous vehicle platooning '
p1904
aS'Determination of deviation of vehicle range or fuel economy '
p1905
ag1697
aS'Rear window washer system '
p1906
aS'Method for determining the axle load of a vehicle '
p1907
aS'Self-steering bogie for a road vehicle '
p1908
aS'Humanized Steering Model For Automated Vehicles '
p1909
aS'Method for detecting vehicle collision '
p1910
aS'Road trailer with orientable secondary wheelset '
p1911
aS'Adaptive Algorithms for Interrogating the Viewable Scene of an Automotive Radar '
p1912
aS'Method and device for determining a lane-adaptation parameter for a lane-keeping system of a vehicle, as well as method and device for lane guidance of a vehicle '
p1913
aS'Front-rear torque split control for an all-wheel-drive vehicle with independent power-sources '
p1914
aS'Collision avoidance control integrated with electric power steering controller and rear steer '
p1915
aS'Dead reckoning system for vehicles '
p1916
aS'Driver assist arrangement '
p1917
aS'Power steering system, vehicle equipped with same, and control method thereof '
p1918
aS'Prevention safety device in course change of small-sized vehicle '
p1919
aS'Non-track-bound vehicle '
p1920
aS'Power prioritization in a vehicle using multiple power-sources '
p1921
aS'Steering input apparatus for vehicle and vehicle '
p1922
aS'Vision-based detection and classification of traffic lights '
p1923
aS'Remote start control for vehicles '
p1924
aS'Method and device for adapting a steering wheel angle of a steering wheel and a wheel steering angle of a wheel steering system in a motor vehicle '
p1925
aS'Enhanced vehicle lateral control (lane following/lane keeping/lane changing control) for trailering vehicles '
p1926
ag1516
aS'Wheel slip or spin notification '
p1927
aS'Hands Free Vehicle Charging System '
p1928
aS'Vehicle and method for controlling the same '
p1929
aS'Static obstacle detection '
p1930
aS'Method for chassis control and chassis control system '
p1931
aS'Rear vehicle body reinforcing structure '
p1932
aS'Automatic turn signal activation during a lane change maneuver '
p1933
aS'Image Switching Device For Vehicle '
p1934
aS'Method and system for lane detection and validation '
p1935
aS'Method for reducing reverse vehicle stopping distance using brake pre-charge '
p1936
aS'Roadway-Crossing-Anomaly Detection System and Method '
p1937
aS'Method and system for indicating a potential lane shift of a vehicle '
p1938
aS'Method of assisting machines at worksite '
p1939
aS'Automatic control method for the insertion and the extraction of a vehicle into and from a receiving station, and control device implementing a method of this kind '
p1940
aS'Vehicle race track driving assistance '
p1941
aS'Robotic cargo system '
p1942
aS'System and method for controlling a vehicle '
p1943
aS'Trailer backup assist system with hitch angle offset estimation '
p1944
aS'Vehicle including an aerodynamic system configured to selectively vary an aerodynamic force acting on the vehicle '
p1945
aS'Method for modifying steering of an automated vehicle for improved passenger comfort '
p1946
aS'Vehicle acceleration and deceleration control device '
p1947
aS'System and method for providing a corrected lane following path through a curve for trailering vehicles '
p1948
aS'Expert mode for vehicles '
p1949
aS'Map-based vehicle ride height control '
p1950
aS'Driving support control apparatus for vehicle '
p1951
aS'A Vehicle Control System '
p1952
aS'Control unit for vehicle and control method for vehicle '
p1953
ag1576
aS'Information collection system, on-vehicle device and server '
p1954
aS'Vehicle door control apparatus and vehicle '
p1955
aS'Providing wireless internet access using autonomous vehicles '
p1956
aS'Vehicle parking assist system '
p1957
aS'Integrated fuel station '
p1958
aS'Trailer backup assist system with hitch assist '
p1959
aS'Complex parent-subsidiary mobile carrier '
p1960
aS'Method for Producing a Model of the Surroundings of a Vehicle '
p1961
aS'Communication device for a motor vehicle, motor vehicle, and communication method '
p1962
aS'Dropcase suspension assembly for a motorized vehicle '
p1963
aS'Remote interrogation and override for automated driving system '
p1964
aS'Method of, and Apparatus for, Controlling the Speed of a Vehicle '
p1965
aS'Driving mode switching system and method for automobile '
p1966
aS'Vehicle yaw motion control method and apparatus using suspension '
p1967
aS'Vehicle event reconstruction system '
p1968
aS'Method for assisting a driver of a motor vehicle when parking, driver assistance system, and motor vehicle '
p1969
aS'Reconfigurable automated guided vehicle system '
p1970
aS'Retractable trailer apparatus '
p1971
aS'Hill parking aid '
p1972
aS'Vehicle system, vehicle comprising a vehicle system and method for allowing transition from an autonomous driving mode '
p1973
aS'Collision avoidance based on front wheel off tracking during reverse operation '
p1974
aS'Arrangement structure for vicinity information detection sensor '
p1975
aS'Anti slip device for automobile wheels with wheel disc arranged at the inner side plane of the wheel '
p1976
aS'Stabilization based path planning '
p1977
aS'Work vehicle and control method for work vehicle '
p1978
aS'Vehicle Control Device and Vehicle Control Method '
p1979
aS'Method and control unit for determining an angle between longitudinal axes of a vehicle combination '
p1980
aS'Surrounding risk displaying apparatus '
p1981
aS'Vehicle Safety System '
p1982
aS'Vehicle travel control device '
p1983
ag1842
aS'Dynamic autonomous system performance prediction methodology '
p1984
aS'Obstacle avoidance system with active suspensions '
p1985
aS'Vehicle, vehicle drive assembly and vehicle steering assembly '
p1986
aS'Bias and misalignment compensation for 6-dof imu using gnss/ins data '
p1987
aS'Automated differential lock '
p1988
aS'Method of utilizing a system for monitoring the pressure and/or the temperature of the tires of a vehicle and device allowing implementation '
p1989
aS'Method for operating a driver assistance system for automatically guiding a motor vehicle, and paired motor vehicle '
p1990
aS'Hitch angle detection for trailer backup assist system using multiple imaging devices '
p1991
aS'Deceleration determination of a vehicle '
p1992
aS'Vehicle curvature determination '
p1993
ag1957
aS'Method for Assisting a Driver of a Single-Track Motor Vehicle in Order to Drive Through a Bend Safely '
p1994
aS'Method and device for ascertaining or evaluating a setpoint trajectory of a motor vehicle '
p1995
aS'Method for operating a motor vehicle, control device, and computer program product '
p1996
aS'Vehicle movement control device, non-transitory computer readable medium, and vehicle '
p1997
aS'Power steering system for automobiles '
p1998
aS'Device and method for detecting wetness on a roadway '
p1999
aS'Building access and layout mapping for an autonomous vehicle based transportation system '
p2000
aS'Google Inc.'
p2001
ag2001
ag2001
ag2001
ag2001
ag2001
ag2001
ag2001
aS'Levant Power Corporation'
p2002
ag2001
aS'Ford Global Technologies, Llc'
p2003
ag2003
ag2001
ag2001
aS'John Solomon Klinger'
p2004
ag2001
ag2001
aS'Madhusoodhan Ramanujam'
p2005
ag2001
aS'Electronics And Telecommunications Research Institute'
p2006
ag2003
ag2001
ag2001
aS'Magna Electronics Inc.'
p2007
ag2001
ag2001
ag2003
aS'Steven Sounyoung Yu, Sounil Yu'
p2008
aS'GM Global Technology Operations LLC'
p2009
ag2001
ag2001
aS'Singularity University'
p2010
ag2001
aS'Philip Nemec, Brian Cullinane, Manuel Christian Clement, Robertus Christianus Elisabeth Mariet'
p2011
ag2001
ag2001
ag2005
ag2001
ag2001
aS'Volkswagen Ag'
p2012
ag2003
ag2009
ag2001
ag2001
ag2001
aS'Here Global B.V.'
p2013
ag2003
ag2001
ag2001
aS'International Business Machines Corporation'
p2014
ag2001
ag2001
ag2003
aS'Elwha Llc'
p2015
ag2001
ag2003
ag2001
ag2001
ag2001
ag2001
ag2003
ag2013
aS'Applied Minds, Llc'
p2016
ag2001
aS'Automotive Research & Testing Center'
p2017
aS'Working Drones, Inc.'
p2018
aS'Florida A&M University'
p2019
ag2001
aS'Anthony Patron, Youenn Colin, Blaise Bertrand, Vinh Pho, Raj Abhyanker'
p2020
aS'The Hong Kong University Of Science And Technology'
p2021
aS'The Travelers Indemnity Company'
p2022
aS'Volvo Car Corporation'
p2023
aS'Dematic Corp.'
p2024
ag2015
aS'Ford Global Technologies'
p2025
aS'Robert Bosch Gmbh'
p2026
ag2003
aS'The Boeing Company'
p2027
ag2009
aS'Helico Aerospace Industries Sia'
p2028
aS'Allstate Insurance Company'
p2029
ag2001
ag2001
ag2027
ag2001
ag2001
ag2001
ag2001
ag2009
ag2001
aS'Audi Ag, Volkswagen Ag'
p2030
ag2003
ag2025
aS'Renault S.A.S.'
p2031
ag2001
ag2001
ag2003
aS'Carnegie Mellon University'
p2032
ag2001
ag2001
aS'Hti, Ip, L.L.C.'
p2033
aS'Delphi Technologies, Inc.'
p2034
aS'Amazon Technologies, Inc.'
p2035
ag2001
aS'SZ DJI Technology Co., Ltd'
p2036
ag2001
aS'Ford Global Technologeis, Llc'
p2037
ag2009
ag2013
ag2001
aS'Mobileye Vision Technologies Ltd.'
p2038
aS'Carnegie Mellon University, GM Global Technology Operations LLC'
p2039
aS'Benjamin Malay'
p2040
ag2001
ag2001
ag2001
aS'Arafat M.A. ANSARI'
p2041
ag2001
aS'Aurora Flight Sciences Corporation'
p2042
aS'Toyota Motor Engineering & Manufacturing North America, Inc.'
p2043
ag2001
ag2001
ag2001
aS'Thomas Danaher Harvey'
p2044
aS'Hyundai Motor Company'
p2045
aS'Honeywell International Inc.'
p2046
ag2036
aS'Alain Anthony Mangiat, Unnikrishna Sreedharan Pillai, Jonathan Sheldon Kupferstein'
p2047
ag2017
ag2003
aS'Balu Subramanya'
p2048
aS'Brain Corporation'
p2049
aS'Tribal Rides, Inc.'
p2050
aS'SZ DJI Technology Co., Ltd.'
p2051
ag2035
ag2001
ag2001
ag2003
ag2001
aS'Denso Corporation'
p2052
ag2001
ag2027
aS'Toyota Motor Eng. & Mftg. North America'
p2053
aS'Pc-Tel, Inc.'
p2054
aS'Disney Enterprises, Inc.'
p2055
aS'Lenovo Enterprise Solutions (Singapore) Pte. Ltd.'
p2056
ag2001
aS'Proxy Technologies Inc.'
p2057
ag2029
ag2001
ag2006
aS'Uber Technologies, Inc.'
p2058
ag2003
aS'Qualcomm Incorporated'
p2059
aS'Honda Research Institute Europe Gmbh'
p2060
ag2001
ag2007
aS'Jaguar Land Rover Limited'
p2061
aS'Recreational Drone Event Systems, Llc'
p2062
ag2001
ag2043
ag2001
ag2009
aS'Rowbot Systems Llc'
p2063
aS'Honda Motor Co., Ltd.'
p2064
ag2001
aS'State Farm Mutual Automobile Insurance Company'
p2065
ag2009
ag2001
ag2015
ag2001
ag2001
ag2036
ag2001
ag2027
aS'Siemens Aktiengesellschaft'
p2066
ag2038
ag2064
aS'Shelton Gamini De Silva'
p2067
ag2001
aS'Continental Automotive Systems, Inc.'
p2068
ag2043
ag2001
ag2003
aS'Polaris Industries Inc.'
p2069
ag2003
aS'Feeney Wireless, LLC'
p2070
ag2003
ag2009
ag2064
ag2001
ag2001
ag2001
ag2003
ag2005
ag2001
ag2013
ag2003
ag2003
ag2001
ag2001
ag2064
aS'Oshkosh Corporation'
p2071
aS'Cybernet Systems Corporation'
p2072
ag2009
aS'Christopher Kenneth Wilson'
p2073
ag2001
ag2038
ag2001
ag2009
aS'Yukihiko ONO, Kenjiro Yamamoto, Ryoko Ichinose, Akira Oshima'
p2074
ag2045
aS'Harbrick LLC'
p2075
ag2013
aS'Cgg Services Sa'
p2076
aS'Intelligent Technologies International, Inc.'
p2077
aS'Myine Electronics, Inc.'
p2078
ag2009
ag2007
ag2001
ag2001
aS'Richard Schulman, Ronald Van Houten'
p2079
ag2001
ag2001
ag2023
aS'Southern Electrical Equipment Company, Inc.'
p2080
ag2042
ag2001
aS'Audi Ag'
p2081
ag2001
ag2036
aS'Verizon Patent And Licensing Inc.'
p2082
aS'Innova Electronics, Inc.'
p2083
aS'Hartford Fire Insurance Company'
p2084
ag2069
ag2001
ag2027
ag2001
ag2003
ag2001
ag2001
aS'Kevin Schlosser, Curt Eshbaugh, Joel Markham, Clifford T. Gunsallus, James W. Bacon'
p2085
ag2036
ag2007
aS'Chester Charles Malveaux'
p2086
ag2006
ag2001
ag2013
ag2009
aS'Raymond Cao'
p2087
ag2009
ag2081
ag2042
aS'Adept Technology, Inc.'
p2088
aS'Dennis M. Carleton'
p2089
aS'Joseph E. Kovarik, James J. Kovarik'
p2090
aS'Nissan North America, Inc.'
p2091
ag2038
ag2003
ag2055
ag2009
ag2036
ag2042
ag2036
aS'Maris, Ltd.'
p2092
ag2049
ag2064
ag2027
ag2064
ag2001
aS'Alliant Techsystems Inc.'
p2093
aS'Bee Robotics Corporation'
p2094
ag2001
ag2003
ag2001
aS'Eddie Hugh Williams'
p2095
ag2036
ag2035
aS'Fresenius Medical Care Holdings, Inc.'
p2096
aS'International Electronic Machines Corporation'
p2097
ag2032
ag2036
aS'Bastille Networks, Inc.'
p2098
aS'Lockheed Martin Corporation'
p2099
aS'Uusi, Llc'
p2100
ag2013
ag2009
aS'Toyota Motor Engineering & Manufacturing North America, Inc., Toyota Jidosha Kabushiki Kaisha'
p2101
ag2003
ag2014
ag2003
aS'Raytheon Company'
p2102
aS'Autonomous Solutions, Inc., Cnh Industrial America Llc'
p2103
ag2027
ag2001
ag2010
aS'Tenneco Automotive Operating Company Inc.'
p2104
ag2009
ag2013
ag2001
ag2001
ag2098
ag2001
ag2001
ag2027
ag2014
aS'Tk Holdings, Inc.'
p2105
ag2001
aS'Navteq B.V.'
p2106
aS'Daimler Ag'
p2107
ag2001
aS'Paccar Inc'
p2108
ag2044
aS'Silver Spring Networks, Inc.'
p2109
ag2060
ag2049
aS'Thomas A. Panzarella, John R. Spletzer'
p2110
aS'Stem, Inc'
p2111
ag2003
aS'Facet Technology Corp.'
p2112
aS'Sunlight Photonics Inc.'
p2113
ag2042
ag2001
aS'Anthony L. Chun, Glen J. Anderson, Albert Yosher'
p2114
aS'Express Imaging Systems, Llc'
p2115
ag2001
aS'Skycatch, Inc.'
p2116
ag2035
ag2043
ag2001
ag2055
aS'USA as Represented by the Administrator of the National Aeronautics & Space Administration (NASA)'
p2117
ag2072
aS'Faroog Ibrahim, Chenikkayala Nagadevendra, Varun Palathour Srirama'
p2118
aS'Mace Wolf'
p2119
ag2009
aS'Elwha LLC, a limited liability company of the State of Delaware'
p2120
ag2014
ag2061
ag2099
ag2007
ag2013
ag2003
ag2001
aS'Accenture Global Services Limited'
p2121
aS'Hill-Rom Services, Inc.'
p2122
ag2003
aS'Sri International'
p2123
ag2081
aS'Cloudparc, Inc.'
p2124
aS'Lily Robotics, Inc.'
p2125
aS'Addison Lee Limited'
p2126
aS'Liquid Robotics, Inc.'
p2127
ag2059
aS"Trevor O'Neill, Samuel Reeves, Joshua Koplin, Anthony Calabro, Nathan Bivans, Erik De Brun, Scott Poff, Richard Derman"
p2128
aS'Fedex Corporate Services, Inc.'
p2129
aS'Kinze Manufacturing, Inc.'
p2130
ag2038
ag2018
ag2051
ag2049
aS'Neya Systems, Llc'
p2131
aS'Ixia'
p2132
ag2091
aS'Toyota Motor Eng. & Man. North America (Tema)'
p2133
ag2059
aS'U.S. Army Research Laboratory Attn: Rdrl-Loc-I'
p2134
ag2023
ag2027
ag2023
aS'Siemens Corporation'
p2135
ag2001
aS'Harman International Industries, Inc.'
p2136
ag2043
ag2043
ag2001
ag2003
aS'Fujitsu Ten Limited'
p2137
ag2001
aS'Thomas Edwards, Eamon Carrig, Scott Nguyen, James Nugen, Walter Holemans'
p2138
ag2001
ag2023
ag2081
aS'Nissan North America, Inc'
p2139
ag2001
ag2001
aS'Unitronics Parking Solutions Ltd'
p2140
ag2136
aS'Hitachi, Ltd.'
p2141
ag2038
ag2014
ag2064
aS'Brandon Borko'
p2142
ag2001
ag2036
ag2064
ag2045
aS'Transparent Wireless Systems, Llc'
p2143
ag2036
aS'Dennis J. Dupray, Frederick W. LeBlanc'
p2144
ag2036
aS'Hadal, Inc.'
p2145
aS'Appareo Systems, Llc'
p2146
ag2041
aS'Knightscope, Inc.'
p2147
ag2052
aS'Tk Holding, Inc.'
p2148
aS'Intel Corporation'
p2149
aS'Dyson Technology Limited'
p2150
aS'Skydio, Inc.'
p2151
ag2049
ag2043
aS'Causam Holdings, LLC'
p2152
ag2023
ag2027
aS'Micah Richert'
p2153
ag2068
ag2005
ag2048
ag2043
ag2076
ag2065
ag2049
aS'Jennifer A. Healey, Alexandra C. Zafiroglu'
p2154
ag2009
ag2049
ag2045
ag2152
aS'Osram Sylvania Inc.'
p2155
aS'The Provost, Fellows, Foundation & Scholars, & The Other Members Of The Board, Of The College'
p2156
ag2043
ag2043
aS'Lg Electronics Inc.'
p2157
ag2043
ag2003
aS'Dawn Equipment Company'
p2158
aS'Hexagon Technology Center Gmbh'
p2159
ag2081
ag2023
ag2009
aS'Zoox, Inc.'
p2160
ag2001
aS'The University Of Michigan, Nissan North America, Inc.'
p2161
aS'Sikorsky Aircraft Corporation'
p2162
ag2052
aS'The U.S.A. As Represented by the Administrator of the National Aeronautics and Space Adminstration, GM Global Technology Operations LLC'
p2163
ag2003
ag2044
ag2038
ag2023
ag2013
ag2023
ag2009
aS'Legalforce, Inc.'
p2164
aS'Causam Energy, Inc.'
p2165
aS'Israel Aerospace Industries Ltd.'
p2166
ag2160
ag2045
ag2013
aS'ImageKeeper LLC'
p2167
ag2003
aS'Matthew Camacho-Cook, John E. Bares, Kent Cavender-Bares'
p2168
aS'Robo-team Ltd.'
p2169
aS'Daedalus Flight Systems, LLC, University Of Maryland, College Park'
p2170
ag2003
ag2043
ag2001
ag2027
ag2149
ag2091
ag2038
ag2003
ag2035
ag2049
ag2058
ag2058
aS'Adasworks Kft.'
p2171
aS'Ford Global Technologies, Llc, Theodore & Associates, Llc'
p2172
ag2001
aS'Clearpath Robotics, Inc.'
p2173
ag2003
aS'Youval Nehmadi, Alon Konchitsky'
p2174
aS'Aisin Aw Co., Ltd.'
p2175
ag2160
aS'Continental Teves Ag & Co. Ohg'
p2176
aS'Denso International America, Inc., Denso Corporation'
p2177
aS'Magna Powertrain Of America, Inc.'
p2178
ag2127
ag2014
ag2091
ag2001
ag2044
ag2157
ag2076
aS'Hitachi Construction Machinery Co., Ltd.'
p2179
ag2001
ag2001
ag2058
ag2058
aS'Cape Productions Inc.'
p2180
ag2005
ag2003
ag2043
aS'The United States Of America As Represented By The Secretary Of The Navy'
p2181
ag2043
ag2006
aS'Landauer, Inc.'
p2182
ag2068
aS'Cisco Technology, Inc.'
p2183
aS'Zipline International Inc.'
p2184
ag2014
ag2035
ag2001
ag2026
ag2001
ag2001
aS'Toyota Jidosha Kabushiki Kaisha'
p2185
ag2003
aS'James E. Niles'
p2186
ag2056
ag2001
ag2025
aS'Airbus Defence and Space GmbH'
p2187
aS'Fuji Jukogyo Kabushiki Kaisha'
p2188
ag2043
ag2043
ag2009
ag2014
aS'Bendix Commercial Vehicle Systems Llc'
p2189
aS'Universidade Do Porto, Instituto De Telecomunica\xc3\xa7\xc3\xb5es, Geolink, Lda, Carnegie Mellon University'
p2190
ag2188
aS'Adam Brown'
p2191
ag2091
ag2003
aS'Alberto Daniel Lacaze, Karl Nicholas Murphy'
p2192
ag2043
ag2003
ag2003
ag2052
aS'Bayerische Motoren Werke Aktiengesellschaft'
p2193
aS'American SportWorks LLC'
p2194
ag2043
aS'Pgs Geophysical As'
p2195
aS'Volvo Truck Corporation'
p2196
ag2091
ag2023
aS'Waymo Llc'
p2197
ag2001
ag2035
ag2160
ag2160
ag2160
ag2091
aS'Seabed Geosolutions B.V.'
p2198
ag2043
aS'Mitsubishi Electric Research Laboratories, Inc.'
p2199
ag2003
ag2034
ag2001
aS'Toyota Jidosha Kabushiki Kaisha, The University Of Tokyo, National University Corporation Tokyo University Of Agriculture And Technology'
p2200
ag2001
aS'Jeffrey Scott Adler, Harold Russell Baird'
p2201
ag2197
ag2012
ag2043
ag2197
ag2009
ag2003
ag2043
ag2003
aS'Fts Computertechnik Gmbh'
p2202
ag2091
ag2043
ag2043
ag2027
aS'Shay C. Colson, David A. Divine'
p2203
ag2043
ag2173
ag2043
aS'Jeffrey Clyne Garland'
p2204
ag2009
ag2001
aS'Easy Aerial Inc.'
p2205
aS'Faraday&Future Inc.'
p2206
aS'Southwest Research Institute'
p2207
ag2058
aS'Sivalogeswaran Ratnasingam'
p2208
ag2031
ag2003
ag2199
ag2043
ag2003
ag2160
ag2043
ag2026
ag2197
ag2003
ag2196
ag2009
ag2197
aS'Lenovo Enterprise Solutions (Singapore) Pte Ltd.'
p2209
ag2035
ag2197
ag2003
aS'Scope Technologies Holdings Limited'
p2210
ag2043
ag2052
ag2009
ag2043
ag2001
ag2058
ag2003
aS'Arvinmeritor Technology, Llc'
p2211
aS'Cruise Automation, Inc.'
p2212
ag2029
aS'Itrack Llc'
p2213
ag2043
ag2059
ag2058
ag2003
ag2003
ag2045
aS'Sandia Corporation'
p2214
aS'The United States Of America As Represented By The Secretary Of The Air Force'
p2215
ag2003
ag2160
ag2003
ag2160
ag2043
ag2044
ag2003
ag2006
ag2197
aS'Smartdrive Systems, Inc.'
p2216
aS'Avishtech, Llc'
p2217
ag2199
ag2031
aS'Lely Patent N.V.'
p2218
ag2043
aS'Vicinity Software Limited'
p2219
ag2003
aS'Wabco Gmbh'
p2220
ag2149
ag2029
aS'Stephen Chen'
p2221
ag2058
ag2003
ag2003
ag2212
ag2199
ag2160
aS"Commissariat \xc3\xa0 l'\xc3\xa9nergie atomique et aux \xc3\xa9nergies alternatives, Metacar Transport Systems"
p2222
ag2058
ag2069
ag2012
ag2001
aS'Hyundai Mobis Co., Ltd.'
p2223
ag2160
ag2009
ag2014
aS'Ants Technology (Hk) Limited.'
p2224
ag2013
ag2175
ag2007
aS'Micro Systems, Inc.'
p2225
aS'Basf Se'
p2226
ag2061
ag2108
ag2160
ag2043
ag2091
aS'National Taipei University Of Technology'
p2227
ag2045
ag2003
aS'The Florida International University Board Of Trustees'
p2228
ag2043
ag2103
aS'Bragi GmbH'
p2229
aS'Robert Lawson Vaughn, Timothy J. Gresham, Corey KUKIS, John Charles Weast'
p2230
aS'Continental Automotive Gmbh'
p2231
ag2059
ag2043
ag2045
ag2043
ag2215
ag2003
ag2197
ag2058
ag2001
aS'Polaris Industries, Inc.'
p2232
ag2160
ag2029
ag2058
aS'Silicis Technologies, Inc.'
p2233
ag2043
ag2023
ag2003
ag2058
ag2212
aS'Steering Solutions Ip Holding Corporation'
p2234
ag2058
aS'Mts Systems Corporation'
p2235
ag2006
ag2043
ag2059
ag2001
ag2045
ag2058
ag2058
ag2045
ag2003
aS'Truma Geraetetechnik Gmbh & Co. Kg'
p2236
aS'Inrix Inc.'
p2237
ag2059
ag2059
aS'Jaybridge Robotics, Inc.'
p2238
aS'Northrop Grumman Systems Corporation'
p2239
ag2045
ag2009
ag2043
ag2160
ag2001
aS'Continental Teves Ag & Co. Ohg, Conti Temic Microelectronic Gmbh'
p2240
ag2185
aS'AudiAG'
p2241
ag2058
ag2091
ag2091
ag2009
ag2045
ag2003
aS'Panasonic Intellectual Property Management Co., Ltd.'
p2242
ag2023
aS'Hemanki Doshi'
p2243
ag2043
aS'Massachusetts Institute Of Technology'
p2244
ag2003
ag2206
ag2188
aS'Polysync Technologies, Inc.'
p2245
ag2239
ag2017
ag2043
ag2023
ag2188
ag2003
ag2035
ag2003
ag2003
ag2188
ag2003
aS'Mitsubishi Electric Corporation'
p2246
ag2003
ag2206
ag2013
aS'John S. Kargilis'
p2247
aS'Isaiah W. Cox'
p2248
ag2060
ag2003
ag2003
ag2001
ag2043
ag2162
ag2003
ag2001
ag2003
ag2058
ag2003
aS'Volvo Truck Corporaiton'
p2249
aS'Cnh Industrial America Llc'
p2250
aS'Baidu Usa Llc'
p2251
ag2185
ag2003
ag2027
ag2185
ag2003
aS'Toyota Jidosha Kabushiki Kaisha, Aisin Seiki Kabushiki Kaisha'
p2252
aS'Paccar Inc.'
p2253
ag2246
ag2061
ag2001
ag2009
ag2185
ag2058
ag2058
ag2006
ag2023
ag2009
ag2206
ag2058
aS'Active Knowledge Ltd.'
p2254
ag2250
aS'Continental Automotive System, Inc.'
p2255
ag2194
aS'Electro-Motive Diesel, Inc.'
p2256
aS'Donald P. Clark'
p2257
ag2003
ag2185
ag2003
aS'Koninklijke Philips N.V.'
p2258
ag2023
ag2044
ag2003
ag2001
ag2003
ag2001
aS'Dershuen Allen Tang, James Arthur Knopp'
p2259
ag2003
aS'Daniel Theobald'
p2260
ag2003
ag2003
ag2009
aS'Yekutiel Josefsberg, Tal Lavian'
p2261
ag2185
ag2003
ag2043
ag2068
ag2009
ag2202
ag2003
ag2003
ag2009
aS'Innovative Inventions, LLC'
p2262
aS'International Truck Intellectual Property Company, Llc'
p2263
ag2188
ag2026
ag2003
ag2188
ag2023
ag2107
ag2003
ag2026
aS'Sea-Train Express - Llc'
p2264
ag2003
ag2009
ag2082
ag2014
ag2001
aS'Paha Designs, Llc'
p2265
ag2003
aS'Subaru Corporation'
p2266
ag2003
ag2009
ag2009
ag2003
aS'Valeo Schalter Und Sensoren Gmbh'
p2267
aS'Hyundai Motor Company, Kia Motors Corporation'
p2268
aS'Knorr-Bremse Systems For Commercial Vehicles Limited'
p2269
ag2003
ag2188
ag2003
ag2193
ag2108
ag2001
ag2060
ag2188
ag2023
ag2009
aS'Lawrence Clifford Williams'
p2270
ag2043
aS'Jacob Sidney Rand'
p2271
ag2009
aS'Hebei D-Dynamic New Energy Car Stock Corporation Ltd'
p2272
aS'Edward Earl Bonds'
p2273
ag2193
ag2108
ag2188
ag2001
ag2250
ag2026
aS'Stanley W. Bird'
p2274
aS'Hyundai Motor Company, Kcw Corporation'
p2275
ag2009
ag2006
ag2009
aS'Mtd Products Inc'
p2276
aS'Chrysler Group Llc'
p2277
ag2220
aS'Geoffrey Paul Sandford'
p2278
ag2034
ag2045
aS'Jean-Baptiste Segard'
p2279
ag2001
ag2026
ag2009
ag2009
ag2015
ag2023
aS'Isuzu Motors Limited'
p2280
aS'Suzuki Motor Corporation'
p2281
ag2066
ag2009
ag2157
ag2197
ag2009
ag2012
ag2009
ag2061
ag2015
ag2003
ag2045
ag2001
ag2081
ag2045
ag2009
ag2052
ag2064
ag2068
ag2003
ag2023
aS'Caterpillar Inc.'
p2282
aS"Commissariat A L'energie Atomique Et Aux Energies Alternatives"
p2283
ag2043
aS'Stratom, Inc.'
p2284
aS'Cnh Industrial America Llc, Autonomous Solutions, Inc.'
p2285
ag2003
ag2009
ag2034
aS'Mazda Motor Corporation'
p2286
ag2009
ag2009
ag2263
ag2185
aS'Autoliv Development Ab'
p2287
ag2188
ag2188
ag2185
ag2157
aS'Wal-Mart Stores, Inc.'
p2288
ag2003
aS'David L. Pichan'
p2289
ag2003
aS'Chen-Hsin Lin'
p2290
ag2193
ag2231
aS'Altoz, Inc'
p2291
ag2009
aS'Haldex Brake Products Limited'
p2292
aS'Hon Hai Precision Industry Co., Ltd.'
p2293
ag2045
ag2015
ag2267
ag2009
aS'Ronald D. Harris'
p2294
ag2003
ag2023
ag2068
ag2185
aS'Petr Gross'
p2295
ag2282
aS'Komatsu Ltd.'
p2296
aS'Hitachi Automotive Systems, Ltd.'
p2297
aS'Zf Friedrichshafen Ag'
p2298
ag2266
aS'Trw Limited'
p2299
ag2188
ag2003
aS'Drs Sustainment Systems, Inc.'
p2300
ag2003
aS'Michael Goren, Jeremy E. Goren'
p2301
ag2009
ag2263
aS'Ldl Technology'
p2302
ag2081
ag2003
ag2003
ag2003
aS'Ford Global Techologies, Llc'
p2303
ag2193
ag2026
ag2026
ag2185
aS'Microelectronica Maser, S.L.'
p2304
aS'Dr. Ing. H.C. F. Porsche Aktiengesellschaft'
p2305
ag2009
aS'David I. Ferguson, Dmitri A. Dolgov'
p2306
aS'Nathaniel Fairfield, Joshua Seth Herbach, Vadim Furman'
p2307
aS'Dmitri A. Dolgov, Christopher Paul Urmson'
p2308
aS'Brian Cullinane, Philip Nemec, Manuel Christian Clement, Robertus Christianus Elisabeth Mariet, Lilli Ing-Marie JONSSON'
p2309
aS'David Tse-Zhou Lu, Calvin Karl Johnson, Renaud-Roland Hubert'
p2310
aS'Jiajun Zhu, David I. Ferguson, Dmitri A. Dolgov'
p2311
aS'Donald Jason Burnette, Andrew Hughes Chatham, Matthew Paul McNaughton'
p2312
aS'Dmitri Dolgov, Andrew Schultz, Daniel Trawick Egnor, Christopher Urmson'
p2313
aS'Zackary Martin Anderson, Marco Giovanardi'
p2314
aS'Michael Steven Montemerlo, Hyman Jack Murveit, Christopher Paul Urmson, Dmitri A. Dolgov, Philip Nemec'
p2315
aS'Manoharprasad K. Rao, Mark A. Cuddihy, Jialiang Le'
p2316
aS'Wilford Trent Yopp'
p2317
aS'Dmitri Dolgov, Dave Ferguson'
p2318
aS'Dave Ferguson, Jiajun Zhu, Manuel Christian Clement'
p2319
aS'John Solomon Klinger'
p2320
aS'Joshua Seth Herbach, Nathaniel Fairfield, Peter Colijn'
p2321
aS'Joshua Seth Herbach, Nathaniel Fairfield'
p2322
aS'Madhusoodhan Ramanujam'
p2323
aS'David I. Ferguson, Jiajun Zhu'
p2324
aS'Kyoung-Hwan AN, Kyung-Bok SUNG, Dong-Yong Kwak'
p2325
aS'Thomas Edward Pilutti, Matt Y. Rupp, Roger Arnold Trombley, Andrew Waldis, Wilford Trent Yopp'
p2326
aS'Christopher Paul Urmson, Ian James Mahon, Dmitri A. Dolgov, Jiajun Zhu'
p2327
aS'David I. Ferguson'
p2328
aS'Nathaniel S. Johnson, Christopher L. Van Dan Elzen, Christoph Klas'
p2329
aS'Dmitri Dolgov, Christopher Urmson'
p2330
aS'Eric Peeters, Eric Teller, William Graham Patrick'
p2331
aS'Christopher Attard, Shane Elwart, Jeff Allen Greenberg, Rajit Johri, John P. Joyce, Devinder Singh Kochhar, Douglas Scott Rhode, John Shutko, Louis Tijerna, Eric Hongtei Tseng, Wilford Trent Yopp'
p2332
aS'Steven Sounyoung Yu, Sounil Yu'
p2333
aS'Upali Priyantha Mudalige, Michael Losh'
p2334
ag2331
ag2331
aS'Andreas Raptopoulos, Darlene Damm, Paola Santana, Martin Ling, Ido Baruchin'
p2335
aS'Pierre-Yves Droz, Jiajun Zhu'
p2336
aS'Philip Nemec, Brian Cullinane, Manuel Christian Clement, Robertus Christianus Elisabeth Mariet'
p2337
aS'Eric Peeters, Eric Teller, William Graham Patrick, Sergey Brin'
p2338
aS'Nathaniel Fairfield, Joshua Seth Herbach, Andrew Hughes Chatham, Michael Steven Montemerlo'
p2339
ag2323
ag2306
aS'Jiajun Zhu, Dmitri Dolgov, Dave Ferguson'
p2340
aS'William Brian LATHROP, Erik Glaser, Nathaniel Coser, Bryan GRANT, James TOGGWEILER'
p2341
aS'Christopher Attard, Shane Elwart, Jeff Allen Greenberg, Rajit Johri, John P. Joyce, Devinder Singh Kochhar, Douglas Scott Rhode, John Shutko, Hongtei Eric Tseng'
p2342
aS'Omer Tsimhoni, Asaf Degani, Charles A. Green, Jeremy A. Salinger, David M. Zande'
p2343
aS'Jiajun Zhu, Dmitri A. Dolgov, David I. Ferguson'
p2344
ag2328
ag2331
aS'Leon Oliver Stenneth'
p2345
aS'Matt Y. Rupp, Gerald H. Engelman, Alex Maurice Miller, Timothy D. Zwicky, Levasseur Tellis, Richard Lee Stephenson'
p2346
aS'Henrik Kretzschmar, Jiajun Zhu'
p2347
aS'Peter Lombrozo, Eric Teller, Bradley Templeton'
p2348
aS'James R. Kozloski, Timothy M. Lynar, Cristian VECCHIOLA'
p2349
aS'Robertus Christianus Elisabeth Mariet, Manuel Christian Clement, Philip Nemec, Brian Cullinane'
p2350
ag2306
aS'Dorian Jack Spero, Thomas Edward Pilutti, Matthew Y. Rupp, Peter Gyumyeong Joh'
p2351
aS'Roderick A. Hyde, Jordin T. Kare, David B. Tuckerman'
p2352
aS'David I. Ferguson, Donald Jason Burnette'
p2353
aS'Christos Kyrtsos, Thomas Edward Pilutti, Erick Michael Lavoie'
p2354
aS'David Ian Franklin Ferguson, Abhijit Ogale, Matthew Wang'
p2355
ag2328
aS'Dave Ferguson, Nathaniel Fairfield, Bradley Templeton'
p2356
ag2306
aS'Christopher Attard, Shane Elwart, Jeff Allen Greenberg, Rajit Johri, John P. Joyce, Devinder Singh Kochhar, Thomas Edward Pilutti, Douglas Scott Rhode, Matt Y. Rupp, John Shutko, Roger Arnold Trombley, Louis Tijerina, Hongtei Eric Tseng, Andrew Waldis'
p2357
aS'Vladimir Boroditsky, Leon Oliver Stenneth, James Adeyemi Fowe, Gavril Adrian Giurgiu'
p2358
aS'W. Daniel Hillis, Kjerstin I. WILLIAMS, Thomas A. Tombrello, James W. SARRETT, Luke W. Khanlian, Adrian L. KAEHLER, Russel Howe'
p2359
ag2340
aS'Yi-Feng Su, Ming-hung Li'
p2360
aS'Robert L. Dahlstrom'
p2361
aS'Sihle K. Wilson, Ronald E. Benson'
p2362
aS'Eric Teller, Peter Lombrozo'
p2363
aS'Anthony Patron, Youenn Colin, Blaise Bertrand, Vinh Pho, Raj Abhyanker'
p2364
aS'Vincent Kin Nang Lau'
p2365
aS'Beth S. Tirone, Donna L. Glenn, Eileen P. Casey, Dean M. Collins'
p2366
aS'Staffan Davidsson, Sicheng Chen'
p2367
aS'Michael S. Khodl, David M. Berghorn, Todd S. Hunter'
p2368
ag2352
aS'Doug Scott Rhode, Darrel Alan Recker, Erick Michael Lavoie'
p2369
aS'Zhongnan Shen, Fuliang Weng, Benno Albrecht'
p2370
aS'Douglas R. Martin, Kenneth J. Miller'
p2371
aS'Enrique Juan Casado Maga\xc3\xb1a, David Esteban-Campillo, David Scarlatti Jim\xc3\xa9nez, Ivan Maza, Fernando Caballero'
p2372
aS'Jin-woo Lee'
p2373
aS'Ilja Nevdahs, Janis Spogis, Nils Trapans, Edgars Rozentals, Agris Kipurs'
p2374
aS'Mark V. Slusar'
p2375
aS'Nathaniel Fairfield, Josh Seth Herbach, Vadim Furman'
p2376
aS'Joshua John Bialkowski, John Roberts, Abraham Bachrach'
p2377
aS'Ruben Fuentes, Jorge J. Gomez Sanz, Roberto Molina, Carlos Montes, Juan Pavon, David Scarlatti'
p2378
aS'William Graham Patrick, James Ryan Burgess, Andrew Conrad'
p2379
aS'Peter Craig Lombrozo'
p2380
aS'Nicholas Kenneth Hobbs, Liang-yu (Tom) Chi'
p2381
aS'David Ian Ferguson, Dirk Haehnel, Nathaniel Fairfield'
p2382
aS'James N. Nickolaou, Joel Pazhayampallil, Michael P. Turski'
p2383
aS'Christopher Ludwick, Clifford Ivar Nass, David I. Ferguson'
p2384
aS'William Brian LATHROP, James Leigh TOGGWEILER, Erik Robert GLASER, Nathaniel Robert COSER, Bryan GRANT'
p2385
aS'Gregor Allexi, Claudia Kunze, Torsten Wey, Mike John Mould, Stefan Kappes, Mithat Ceylan'
p2386
aS'Roger Arnold Trombley, Thomas Edward Pilutti, Erick Michael Lavoie, Christopher Nave, John Shutko, Rich Lanoue, Bradley G. Hochrein, Nate Rolfes'
p2387
aS'Nicoleta Minoiu-Enache'
p2388
aS'David I. Ferguson, Dmitri Dolgov'
p2389
aS'James Ryan Burgess, Joanna Cohen'
p2390
aS'Li Xu, Eric Hongtei Tseng, Thomas Edward Pilutti, Steven Yellin Schondorf, Davor David Hrovat, John P. Joyce'
p2391
aS'Ozan Tonguz, Wantanee Viriyasitavat'
p2392
aS'David Ian Ferguson, Dirk Haehnel'
p2393
aS'Nathaniel Fairfield, David Ian Ferguson, Abhijit Ogale, Matthew Wang, Yangli Hector Yee'
p2394
aS'Robert S. Siegel, Stephen Christopher Welch, James Ronald Barfield, JR.'
p2395
aS'Lawrence Dean Hazelton, Craig A. Baldwin, Robert James Myers, James M. Chan, Patrick Mitchell Griffin'
p2396
aS'Jonathan Cohn'
p2397
ag2324
aS'Mingyu Wang'
p2398
aS'Mathias Samuel Fleck'
p2399
ag2317
aS'Wende Zhang, James N. Nickolaou, Ryan M. Frakes'
p2400
ag2345
aS'Nicholas Kenneth Hobbs, Lawrence Burns, Brian Cullinane'
p2401
aS'Anna Clarke, Gali Nir, Eyal Bagon'
p2402
aS'Upali Priyantha Mudalige, Ragunathan Rajkumar, Seyed Reza Azimi, Gaurav Bhatia'
p2403
aS'Benjamin Malay'
p2404
aS'Joshua Seth Herbach, Nathaniel Fairfield, Dmitri Dolgov, Peter Colijn, Andrew Chatham'
p2405
ag2340
ag2306
aS'Arafat M.A. ANSARI'
p2406
aS'David I. Ferguson, Nathaniel Fairfield, Anthony Levandowski'
p2407
aS'James Peverill, Adam Woodworth, Benjamin Freudberg, Dan Cottrell, Terrence Mckenna'
p2408
aS'Bunyo Okumura, Danil V. Prokhorov'
p2409
aS'Samuel William Lenius, Pierre-Yves Droz'
p2410
ag2328
aS'Daniel Lynn Larner, Alex Khaykin, Thomas Daniel, Felix Jose Alvarez Rivera'
p2411
aS'Thomas Danaher Harvey'
p2412
aS'Byung Yong YOU, Young Chul Oh'
p2413
aS'Emray R. Goossen, Katherine Goossen, Scott H. Lafler'
p2414
aS'Ang Liu, Weiyu Mo, Yonggen Ling'
p2415
aS'Alain Anthony Mangiat, Unnikrishna Sreedharan Pillai, Jonathan Sheldon Kupferstein'
p2416
aS'Ming-Kuan Ko'
p2417
aS'Gerald H. Engelman, Alex Maurice Miller, Thomas Edward Pilutti, Matt Y. Rupp, Richard Lee Stephenson, Levasseur Tellis, Roger Arnold Trombley, Andrew Waldis, Timothy D. Zwicky'
p2418
aS'Balu Subramanya'
p2419
aS'Philip Meier, Heathcliff Hatcher, Marius Buibas'
p2420
aS'Kurt R. Laetz'
p2421
aS'Mingxi Wang'
p2422
aS'Gur Kimchi, Daniel Buchmueller, Scott A. Green, Brian C. Beckman, Scott Isaacs, Amir Navot, Fabian Hensel, Avi Bar-Zeev, Severan Sylvain Jean-Michel Rault'
p2423
aS'Leila Takayama, Matthew Ball, Joanna Cohen, Roger William Graves, Mathias Samuel Fleck, Andrew Lambert, James Ryan Burgess, Paul Richard Komarek, Trevor SHANNON'
p2424
aS'Brian Cullinane'
p2425
aS'Erick Michael Lavoie, Darrel Alan Recker, Kirt L. Eschtruth, Bradley G. Hochrein, William James Bouse'
p2426
aS'David I. Ferguson, Wan-Yen Lo'
p2427
aS'Takahito Nakano, Junpei Tatsukawa'
p2428
aS'David I. Ferguson, Nathaniel Fairfield'
p2429
aS'Michael J. Duffy, Scott H. Bouwer, John J. Mattero'
p2430
aS'Avdhut S. JOSHI, Michael R. James, Michael E. Samples'
p2431
aS'Brandon Johnson, James Zik, Atsushi Satoh, Buchanan Blake, Martin H. Singer'
p2432
aS'Paul A. Beardsley, Scott Frazier Watson, Javier Alonso-Mora'
p2433
aS'Gary D. Cudak, Christopher J. Hardee, Adam Roberts, Adrian X. Rodriguez'
p2434
aS'Russell Smith, Jamal Izadian'
p2435
aS'John Solomon Klinger, Robert F. Davis'
p2436
ag2375
aS'David Ian Ferguson, Dirk Haehnel, Ian Mahon'
p2437
aS'Kyoung-Hwan AN, Woo-Yong Han'
p2438
aS'William Ross, John Bares, David LaRose, Matthew Sweeney'
p2439
aS'Frederic Stefan, Uwe Gussen, Christoph Arndt, Rainer Busch'
p2440
aS'Arjun Prakash, Marcelo CERIBELLI'
p2441
aS'Jan FRITSCH, Martin Butz, Andreas ALIN'
p2442
aS'David Ian Ferguson, Turgay Senlet'
p2443
aS'Axel Nix, Joern Ihlenburg, Nazar F. Bally, Duane W. Gebauer'
p2444
aS'Harpreet Singh, Andrew Bradley'
p2445
aS'Steven D. Herz, Alfred N. Kovalik'
p2446
ag2340
aS'John Michael McNew, Vladimeros Vladimerou'
p2447
aS'Keith Allen Bonawitz, Dan Piponi'
p2448
aS'Nikolai K. Moshchuk, Shih-Ken Chen, Chad T. Zagorski, Aamrapali Chatterjee'
p2449
aS'Kent Cavender-Bares, Charles C. Bares'
p2450
aS'Makoto Yamamura, Toshiaki Kawakami'
p2451
ag2324
aS'Jerry Brett Suiter'
p2452
aS'Sushanta Das, Mounita Saha'
p2453
aS'Manuel Christian Clement, Robertus Christianus Elisabeth Mariet'
p2454
aS'William D. Duncan, Roderick A. Hyde, Jordin T. Kare, Stephen L. Malaska, Nathan P. Myhrvold, Robert C. Petroski, Thomas Allan Weaver, Lowell L. Wood, JR.'
p2455
aS'Andrew Hughes Chatham'
p2456
aS'Jiajun Zhu, Dmitri A. Dolgov, Christopher Paul Urmson'
p2457
aS'Ang Liu, Xiao Hu, Guyue ZHOU, Xuyang Pan'
p2458
aS'Christopher Paul Urmson, Michael Steven Montemerlo, Jiajun Zhu'
p2459
aS'Donald F. Wilkins'
p2460
aS'Livio Dalloro, Sanjeev Srivastava, Lucia Mirabella'
p2461
aS'Anna Clarke, Eyal Bagon, Igor Tubis'
p2462
aS'Arthur Alaniz, Joseph Whinnery, Robert Wesley Murrish, Michael Eamonn Gleeson-May'
p2463
aS'Shelton Gamini De Silva'
p2464
aS'David I. Ferguson, Donald Jason Burnette, Jiajun Zhu'
p2465
aS'Brandon Herzog, David Leslie Agnew, Andre Payant'
p2466
aS'Yasuo Uehara'
p2467
aS'David I. Ferguson, Bradley Templeton'
p2468
aS'Christopher Attard, Shane Elwart, Jeff Allen Greenberg, Rajit Johri, John P. Joyce, Devinder Singh Kochhar, Thomas Edward Pilutti, Douglas Scott Rhode, Matt Y. Rupp, John Shutko, Roger Arnold Trombley, Hongtei Eric Tseng, Andrew Waldis'
p2469
aS'Jeffrey D. Bennett, Amber P. Malone'
p2470
aS'Aaron L. Mills'
p2471
aS'Robert E. Ralston, Justin D. Bloom'
p2472
aS'Mark Allan Lippman'
p2473
aS'Fred W. Huntzicker, Paul R. Williams'
p2474
aS'Kei Oshida, Sue Bai, Shigenobu Saigusa, Yoichi Sugimoto, Samir Al-Stouhi'
p2475
ag2324
aS'Dave Ferguson, Abhijit Ogale'
p2476
aS'David I. Ferguson, David Silver'
p2477
aS'Erick Michael Lavoie'
p2478
ag2323
aS'Bradley Templeton, Eli Brandt'
p2479
aS'Leon Stenneth, Leo Modica'
p2480
aS'Christopher Attard, Shane Elwart, Jeff Allen Greenberg, Rajit Johri, Devinder Singh Kochhar, Doug Scott Rhode, John Shutko, Hongtei Eric Tseng'
p2481
aS'Gerald H. Engelman, Alex Maurice Miller, Richard Lee Stephenson, Levasseur Tellis, Timothy D. Zwicky'
p2482
aS'David Ian Franklin Ferguson, David Harrison Silver, St\xc3\xa9phane Ross, Nathaniel Fairfield, Ioan-Alexandru Sucan'
p2483
aS'Dmitri Dolgov'
p2484
aS'Kin C. Fung, Timothy J. Dick'
p2485
aS'Noah Zych'
p2486
aS'Charles J. Jacobus, Glenn J. Beach, Steve Rowe'
p2487
aS'Jin-woo Lee, Bakhtiar Brian Litkouhi'
p2488
aS'Christopher Kenneth Wilson'
p2489
aS'Bradley Templeton, Pierre-Yves Droz, Jiajun Zhu'
p2490
aS'Hila AHARONY, Maria DYSHEL, Amir Harel, Meital RABANI, Shaked SHAMAH, Kobi HORN'
p2491
aS'David Ian Ferguson, Dmitri Dolgov'
p2492
ag2334
aS'Yukihiko ONO, Kenjiro Yamamoto, Ryoko Ichinose, Akira Oshima'
p2493
ag2413
aS'Joshua John Hartung, Jonathan Lamb, David Paul Miller, Robert Dean Hambrick'
p2494
aS'Leon Oliver Stenneth, Vladimir Boroditsky'
p2495
aS'Thierry BRIZARD, David MAILLOTTE'
p2496
aS'David S. Breed, Ryan Breed'
p2497
aS'Joey Ray Grover, Scott Smereka, Joel J. Fischer'
p2498
aS'Jin-woo Lee, Youssef A. Ghoneim'
p2499
aS'Krishna Koravadi'
p2500
ag2322
aS'Philip Nemec, Anne Aula, David Tse-Zhou Lu, Brian Cullinane, Calvin Karl Johnson, Albert Shane, Christopher Ludwick, YooJung Ahn'
p2501
aS'Richard Schulman, Ronald Van Houten'
p2502
aS'Michael Steven Montemerlo, John Tisdale, Vadim Furman'
p2503
ag2308
aS'Mikael Thor, Stefan Solyom, Mattias Erik Brannstrom'
p2504
aS'Andrew S. Panto, Barry Wyeth Thomas, Barry Craig Thomas'
p2505
aS'Fabrice Kunzi, Donald Rogers, Terrence Mckenna'
p2506
aS'Dmitri A. Dolgov, Philip Nemec, Anne Aula'
p2507
aS'Michael Reichel, Mohamed Essayed Bouzouraa'
p2508
aS'Jiajun Zhu, Dmitri A. Dolgov, Nathaniel Fairfield'
p2509
aS'Ming Gong, Jin Dai, Hao Cui, Xiaodong Wang, Han Huang, Jun Wu, Wei Fan, Ning Ma, Xinhua Rong, Xingsen Lin'
p2510
aS'Sneha Akula'
p2511
aS'Ieon Chen'
p2512
aS'Steven J. Fernandes, Paul Brendan Olson, Pankaj Prakash'
p2513
aS'Adam J. Schlangen, Jason K. Raska'
p2514
aS'Pierre-Yves Droz, Chris Urmson'
p2515
aS'Enrique Juan Magana Casado, David Scarlatti, David Esteban-Campillo, Ivan Maza, Fernando Caballero'
p2516
aS'Jiajun Zhu, David I. Ferguson'
p2517
aS'Stefan Wolter, Florian Golm'
p2518
aS'Damien Bruno Jourdan'
p2519
aS'Michael Steven Montemerlo, Sebastian Thrun'
p2520
aS'Kevin Schlosser, Curt Eshbaugh, Joel Markham, Clifford T. Gunsallus, James W. Bacon'
p2521
aS'Bo Zang'
p2522
aS'Achim Gieseke, Frank Goseberg, Michael Biemer, Ruediger Boegel, Goerg Pflug'
p2523
aS'Chester Charles Malveaux'
p2524
aS'Seung-Jun Han, Kyung-Bok SUNG, Kyoung-Wook Min, Jeong-Dan Choi'
p2525
aS'Adam Brown'
p2526
aS'Jerome Beaurepaire, Marko Tapio Tuukkanen'
p2527
ag2373
aS'Raymond Cao'
p2528
aS'Nikolai K. Moshchuk, Shih-Ken Chen, Chad T. Zagorski'
p2529
aS'Martin Danzl, Sabine W\xc3\xbcst, Torsten Gollewski, Georg Kienzl, Franz-Michael Hagemann, Karl-Heinz Siedersberger, Thomas Miehling, Peter Kunsch'
p2530
aS'James Paduano, Terrence Mckenna'
p2531
aS'Matthew LaFary, Matthew Vestal, George V. Paul'
p2532
aS'Dennis M. Carleton'
p2533
aS'Joseph E. Kovarik, James J. Kovarik'
p2534
aS'Naoki Kojo, Siddharth Kumar Thakur, Nicolas Meuleau, Daisuke Saito, Nikhil Lele'
p2535
aS'Kevin Rosenblum, Erez Dagan'
p2536
aS'Christopher Attard, Shane Elwart, Jeff Allen Greenberg, Rajit Johri, Devinder Singh Kochhar, Douglas Scott Rhode, John Shutko, Eric Hongtei Tseng'
p2537
aS'James Alexander Stark, Clifford Wong, Robert Scott Trowbridge'
p2538
ag2488
aS'Xiao Hu, Ang Liu, Guyue ZHOU, Xuyang Pan'
p2539
aS'James D. Paduano, John B. Wissler, Michael D. Piedmonte, David A. Mindell'
p2540
aS'Tao Wang, Tao Zhao, Hao Du, Mingxi Wang'
p2541
aS'Christopher J. Carver, Kevin Wolsey'
p2542
aS'Marius Buibas'
p2543
aS'Makoto Yamamura, Toshiaki Kawakami, Atsushi Moroi, Kenta Kawanishi'
p2544
aS'John Lyle Vian, George Michael Roe, Josha Przbylko'
p2545
aS'Makoto Yamamura, Toshiaki Kawakami, Nobuyuki Habuka'
p2546
aS'Jonathan Baldwin Dowdall, Jiajun Zhu'
p2547
aS'George B. Papadopoulos, Derek R. DeVries, Steven W. Thomas, Timothy J. Van Dixhorn, Charles L. Weigel, Charles L. Dedon'
p2548
aS'Harm Burema, Anatoly Filin'
p2549
aS'Aleksey S. Boyko, Jiajun Zhu'
p2550
aS'Dale Scott Crombez, Thomas Edward Pilutti, Matt Y. Rupp, Roger Arnold Trombley, Andrew Waldis, Peter Francis Worrel, Wilford Trent Yopp'
p2551
ag2443
aS'Eddie Hugh Williams'
p2552
aS'Mingxi Wang, Hualiang Qiu, Mingyu Wang'
p2553
aS'William Spencer Worley, III, Eric Mathew Clayton'
p2554
aS'Matthew Doyle, Lee TANENBAUM, John TONG'
p2555
aS'Zahid F. Mian'
p2556
aS'Jin-woo Lee, Upali Priyantha Mudalige, Tianyu Gu, John M. Dolan'
p2557
aS'Mingyu Wang, Tao Wang, Jianyu Song'
p2558
aS'Robert John BAXLEY, Justin Trent Altman'
p2559
aS'Carl Herman, Dennis Rude, Thomas Spura, Shirley D. Kupst'
p2560
aS'David W. Shank, Josh Goulet, John Washeleski'
p2561
aS'Jerome Beaurepaire, Ari A. AARNIO'
p2562
aS'Bakhtiar Brian Litkouhi, Junqing Wei, John M. Dolan'
p2563
aS'Michael R. James, Katsuhiro Sakai, Toshiki Kindo, Danil V. Prokhorov, Masahiro Harada'
p2564
aS'Mark A. Cuddihy, Manoharprasad K. Rao, Jialiang Le'
p2565
aS'Michael S. Gordon, James R. Kozloski, Ashish Kundu, Peter K. Malkin, Clifford A. Pickover'
p2566
aS'Manoharprasad K. Rao, Jialiang Le'
p2567
aS'Geoffrey D. Ashton'
p2568
aS'Robert D. Ashby, Brad A. Baillio, Matthew D. Berkemeier, John Droter, Jeffrey L. Ferrin, Mark D. Hayes, Joshua Henrie, Michael G. Hornberger, Daniel J. Morwood, John A. M. Petersen, Thomas M. PETROFF, Eric A. Poulson, Colton J. Schenk, Devin M. Stewart, J. Brian Stewart, Melvin W. Torrie, Mitchel R. Torrie, Bret T. Turpin, Geoffrey L. Viola'
p2569
aS'John Lyle Vian, Charles B. Spinelli, Brian J. Tillotson, George Michael Roe, Joshua Przybylko'
p2570
aS'Keith Allen Bonawitz'
p2571
aS'Zachary Fleischman, Chris Sullivan'
p2572
aS'David R. Blankenship, Scott S. DUNAWAY, Karl C. Kazmirski, Mayur RATHAN'
p2573
aS'Michael D. Howard, Rajan Bhattacharyya, Michael J. Daily'
p2574
aS'Jerome Beaurepaire, Philippe Beaurepaire, Marko Tapio Tuukkanen'
p2575
ag2571
aS'Abhijit Ogale'
p2576
aS'Robert John BAXLEY, Christopher Jay Rouland'
p2577
aS'Donald Jason Burnette, David I. Ferguson'
p2578
ag2363
aS'James Statelar McGrew, John Lyle Vian'
p2579
ag2566
aS"Jason Carl Lisseman, Valerie Dawn Gardner, Dwayne Van'tZelfde, Erick Paul Staszak, Norbert Hubert Mueller, David William Andrews"
p2580
aS'William Graham Patrick'
p2581
aS'Ole Henry Dorum, Jane MacFarlane'
p2582
aS'Christophe Bonnet, Andreas Hiller, Gerhard Kuenzel, Martin Moser, Heiko Schiemenz'
p2583
ag2459
aS'Wesley Mays'
p2584
ag2412
aS'Dalton Theebaraj Victor, James Alexander Howarth, George Flammer'
p2585
aS'Nils EINECKE, Julian Eggert'
p2586
aS'Dimitry Fisher'
p2587
aS'Thomas A. Panzarella, John R. Spletzer'
p2588
aS'Ben KEARNS, Henry Holbrook HYDE, III, Jon BURLINSON, Drew STEVENS'
p2589
aS'Fling Tseng, Hsin-Hsiang Yang, Kwaku O. Prakah-Asante'
p2590
aS'Jamie E. Retterath, Robert A. Laumeyer'
p2591
aS'Sergey V. Frolov, Michael Cyrus, Allan J. Bruce, John Peter Moussouris'
p2592
aS'James Donald Paduano, Paul Nils Dahlstrand, John Brooke Wissler'
p2593
ag2311
aS'Anthony L. Chun, Glen J. Anderson, Albert Yosher'
p2594
aS'William G. Reed'
p2595
aS'Jiajun Zhu'
p2596
aS'Christian Sanz, Samuel Giles Miller, Jonathan Shyaun Noorani, Behrooze Sirang'
p2597
aS'Varadarajan Gopalakrishnan, Jesper Mikael Johansson, James Domit Mackraz, Jon Arron McClintock, Brandon William Porter, Andrew Jay Roths'
p2598
ag2467
aS'John Roberts, Abe Bachrach, James Ryan Burgess'
p2599
aS'Paul A. Beardsley, Michael Eriksson, Javier Alonso-Mora, Joern Rehder'
p2600
aS'Parimal Kopardekar'
p2601
aS'Charles J. Jacobus, Douglas Haanpaa'
p2602
aS'Faroog Ibrahim, Chenikkayala Nagadevendra, Varun Palathour Srirama'
p2603
aS'Mace Wolf'
p2604
aS'Claudia V. Goldman-Shenhar, Asaf Degani, Omer Tsimhoni, Christopher T. Thibodeau'
p2605
aS'Royce A. Levien, Richard T. Lord, Robert W. Lord, Mark A. Malamud, John D. Rinaldo, Jr., Lowell L. Wood, JR.'
p2606
aS'Sasha P. Caskey, Dimitri Kanevsky, James R. Kozloski, Tara N. Sainath'
p2607
aS'Mark Collins, Hugo NIGHTINGALE, Arafat Bhatti'
p2608
aS'James C. Kilian, Brede J. Wegener, Eric Wharton, David R. Gavelek'
p2609
aS'Nathaniel S. Johnson, William J. Chundrlik, Jr., Paul A. VanOphem, Christopher L. Van Dan Elzen'
p2610
aS'Marko Tapio Tuukkanen'
p2611
aS'Eric H. Tseng, Davor Hrovat, Jianbo Lu, Mitch McConnell, Matthias Dehmel, Michael Seemann, Fredrick V. Owens'
p2612
aS'David I. Ferguson, Abhijit Ogale'
p2613
aS'Pramila Mullan, Walid Negm, Edy S. Liongosari, Paul BARSAMIAN, Brian Richards, Sang-Ik Kim, Michael MUI, Robert FENNEY'
p2614
aS'Mika KATARA, Jiang Cheng, Alexander Maltsev, Bernhard Raaf, Michael R. Tierney'
p2615
aS'Mark A. Cuddihy, Christopher Attard, Jeff Allen Greenberg, Rajit Johri, Devinder Singh Kochhar, Jialiang Le, Manoharprasad K. Rao, Matthew Y. Rupp, John Shutko, Roger Arnold Trombley, Hongtei Eric Tseng, Andrew Waldis'
p2616
aS'Michael J. Wolverton, William S. Mark, Harry Bratt, Douglas A. Bercow'
p2617
aS'Michael Reichel, Andreas Siegel'
p2618
aS'Steven David Nerayoff, Thompson S. Wong'
p2619
aS'Henry W. Bradlow, Antoine Balaresque'
p2620
aS'Larry Scicluna, Yuriy BERNATSKIY'
p2621
aS'Roger G. Hine, Derek L. Hine'
p2622
aS'Lalan Jee Mishra, Richard Dominic Wietfeldt, Joseph Czompo'
p2623
aS"Trevor O'Neill, Samuel Reeves, Joshua Koplin, Anthony Calabro, Nathan Bivans, Erik De Brun, Scott Poff, Richard Derman"
p2624
aS'Ole-Petter Skaaksrud'
p2625
aS'Robert Blackwell, Rhett Schildroth, Michael J. Myers, Merlan J. Rolffs, Derrick Becker'
p2626
aS'Itai Ben Shalom'
p2627
ag2361
aS'Mingxi Wang, Xiangyu CHEN'
p2628
aS'Philip Meier'
p2629
aS'Mark Daniel Ollis'
p2630
aS'Avinash Ramanath'
p2631
aS'Daisuke Saito, Naoki Kojo, Siddharth Kumar Thakur, Nikhil Lele'
p2632
aS'Michael Robert James'
p2633
aS'Michael-David Nakayoshi Canoy, Kiet Tuan Chau, Stephen Alton Sprigg'
p2634
aS'Christopher C. Smyth'
p2635
aS'Erik STENBORG, Joakim SORSTEDT'
p2636
aS'Joshua Przybylko, John Lyle Vian'
p2637
aS'Stefan Solyom, Ake BLOM, Marcus Nils Gunnar ROTHOFF'
p2638
aS'Juan Aparicio, Math\xc3\xa4us Dejori, Justinian Rosca'
p2639
aS'Gaetan Pennecot, Pierre-Yves Droz, Zachary Morriss, William McCann'
p2640
aS'Jeffrey L. Hutchings'
p2641
aS'Derek S. Caveney'
p2642
aS'Bunyo Okumura'
p2643
aS'Drew Ulrich, Pierre-Yves Droz, Samuel Lenius'
p2644
ag2317
aS'Masashi TSUYUNASHI, Toshitaka Yamato'
p2645
aS'Wan-Yen Lo, David Ian Franklin Ferguson, Abhijit Ogale'
p2646
aS'Thomas Edwards, Eamon Carrig, Scott Nguyen, James Nugen, Walter Holemans'
p2647
aS'Jonathan Baldwin Dowdall'
p2648
aS'Stefan Solyom, Erik Coelingh, Mattias Erik Brannstrom'
p2649
aS'Michael Reichel, Karl-Heinz Siedersberger'
p2650
aS'Nicolas Meuleau'
p2651
aS'Eric Peeters, William Graham Patrick'
p2652
aS'Vadim Furman, Andrew Hughes Chatham, Abhijit Ogale, Dmitri Dolgov'
p2653
aS'Haim Shani'
p2654
aS'Stefan Marti, Davide Di Censo, Ajay Juneja'
p2655
aS'Kenichirou Kurata, Hiroto Morizane, Shigeru Matsuo'
p2656
aS'Erez Dagan'
p2657
aS'Gary D. Cudak, Christopher J. Hardee, Adrian X. Rodriguez'
p2658
aS'Victor Ng-Thow-Hing, Cuong Tran, Karlin Bark'
p2659
aS'Brandon Borko'
p2660
aS'Jonathan Baldwin Dowdall, Jiajun Zhu, Pierre-Yves Droz, Luke Wachter, Dorel Ionut Iordache'
p2661
aS'Xingwang Xu, Zisheng Cao, Hualiang Qiu, Mingyu Wang, Xiaozheng Tang'
p2662
aS'Victor Ng-Thow-Hing, Karlin Bark, Cuong Tran'
p2663
aS'Byung Yong YOU, Myung Seon Heo, Young Chul Oh'
p2664
aS'Nils Rydbeck, Santanu Dutta'
p2665
aS'Heli Zhong, Zhiyuan Zhang, Xiaojun Li'
p2666
aS'Dennis J. Dupray, Frederick W. LeBlanc'
p2667
aS'Guyue ZHOU, Shuo Yang, Ang Liu'
p2668
aS'Richard J. Rikoski, Robert S. Damus'
p2669
aS'Barry D. Batcheller, Joseph A. Heilman, David C. Batcheller, Robert V. Weinmann, Jeffrey L. Johnson, Paul D. Johnson, Paul A. Nystuen'
p2670
ag2406
aS'Arne Stoschek, William Santana Li, Stacy Dean Stephens, Mercedes Soria-Li, Aaron J. Lehnhardt, Dominic A. Villa, Phillip Wong'
p2671
ag2428
ag2580
aS'Jennifer A. Healey, Alexandra C. Zafiroglu'
p2672
aS'Michael David Aldred, Simon EDWARDS-PARTON'
p2673
aS'Abraham Bachrach, Adam Bry, Matthew Donahoe'
p2674
aS'Micah Richert, Filip Piekniewski, Eugene Izhikevich, Sach Sokol'
p2675
aS'Danil V. Prokhorov'
p2676
aS'Joseph W. Forbes, Jr.'
p2677
aS'Peter Harda, Erik Israelsson'
p2678
aS'Richard Donovan Jones, David A. Whelan, Lynne WENBERG'
p2679
aS'Micah Richert'
p2680
aS'Brandon Herzog, Hao Sun, Joyce Chen, Ibro Muharemovic'
p2681
ag2323
ag2419
aS'James Peter Foley'
p2682
aS'Thierry BRIZARD'
p2683
aS'Blake Konrardy, Scott T. Christensen, Gregory Hayward, Scott Farris'
p2684
aS'Marius Buibas, Micah Richert'
p2685
ag2672
aS'Chad T. Zagorski'
p2686
ag2680
aS'Young Chul Oh, Myung Seon Heo, Byung Yong YOU'
p2687
ag2677
aS'Jeremy Spaulding, Karlin Jessen, Mervyn Anthony'
p2688
aS'Conor McGinn, Mark Culleton'
p2689
aS'Michael J. Delp'
p2690
aS'Danil V. Prokhorov, Vladimeros Vladimerou'
p2691
aS'Sangha Park'
p2692
aS'Danil V. Prokhorov, Yasuo Uehara'
p2693
aS'Joseph Andreas Urhahne'
p2694
aS'Joseph D. Bassett, Rodney J. Arthur'
p2695
aS'Bo Pettersson'
p2696
ag2618
ag2649
ag2373
aS'Timothy David Kentley, Rachad Youssef Gamara, Sagar Behere'
p2697
aS'Nathaniel Fairfield, Joshua Seth Herbach'
p2698
aS'Jiechao Liu, Timothy Gordon, Ronald Heft'
p2699
aS'Hongcheng Wang, Ziyou Xiong, Jason C. Derenick, Christopher Stathis, Igor Cherepinsky'
p2700
aS'Junpei Tatsukawa'
p2701
aS'Andrew D. Dawson, William J. Bluethmann, Chunhao J. Lee, Robert L. Vitale, Raymond Guo, Venkata Prasad Atluri'
p2702
ag2317
ag2412
aS'Amnon Shashua, Gaby Hayon, Yossi Hadad, Efim Belman, Eyal Bagon'
p2703
aS'Erik Coelingh, Stefan Solyom, Mattias Erik Brannstrom'
p2704
aS'Leon Stenneth, Gavril Giurgiu'
p2705
aS'Erik Israelsson'
p2706
aS'Nikolai K. Moshchuk, Bakhtiar Brian Litkouhi, Shih-Ken Chen'
p2707
aS'Dongxia Liu, Hairong Lei, Raj Abhyanker'
p2708
ag2677
aS'Ohad RIX'
p2709
aS'Timothy David Kentley, Jesse Sol Levinson, Amanda Blair Lind'
p2710
aS'Byung Yong YOU'
p2711
aS'Jerome Beaurepaire'
p2712
aS'Jerry Speasl, Mike Patterson, Mark Roberts'
p2713
aS'Stefan Wolter'
p2714
aS'Matthew Camacho-Cook, John E. Bares, Kent Cavender-Bares'
p2715
aS'Daniel Cantor, Yehonatan Asher, Mor Rotbart, Mark Vaynberg, Yosi Wolf, Elad Levy'
p2716
aS'Paul D. SAMUEL, Imraan FARUQUE, James Sean Humbert'
p2717
ag2567
ag2690
ag2517
aS'Nathan Hiller'
p2718
aS'Alexandra C. Zafiroglu, Jennifer A. Healey, Juan I. Correa, Maria Paula Saba Dos Reis, Alejandro Abreu, Victoria S. Fang, Dalila Szostak, Sarah E. Fox'
p2719
aS'Yoshiro Takamatsu'
p2720
aS'Daniel Braunstein, Yoram Gdalyahu, Sergey RUBINSKY'
p2721
aS'Mark A. Cuddihy, Thomas Edward Pilutti, Manoharprasad K. Rao, Andrew Waldis, Roger Arnold Trombley, Matthew Y. Rupp, Wilford Trent Yopp'
p2722
aS'James Christopher Curlander, Ryan Scott Russell, Allan Scott Bathurst, Udit Madan, Jules Cook Graybill, Jonathan Blair Norwood, Wesley Scott Lauka, Pragyana K. Mishra, Darren Ernest Canavor'
p2723
aS'Dimitry Fisher, Botond Szatmary, Eugene Izhikevich'
p2724
aS'Nicholas Letwin, Sean Kelly'
p2725
ag2439
aS'Gergely Debreczeni'
p2726
aS'Chris P. Theodore, Keith Albert Nagara, Tyler Gregory Rusnak'
p2727
aS'Brian Kemler, Dan FREDINBURG'
p2728
aS'Ryan Christopher GARIEPY, Kareem Shehata, Prasenjit Mukherjee, Anthony Tod, Teyvonia THOMAS, Yan Ma'
p2729
aS'Thomas Edward Pilutti, Matthew Y. Rupp, Roger Arnold Trombley, Andrew Waldis'
p2730
aS'Youval Nehmadi, Alon Konchitsky'
p2731
aS'Masataka Fukumoto'
p2732
aS'Jesse Sol Levinson, Timothy David Kentley, Gabriel Thurston Sibley, Rachad Youssef Gamara, Ashutosh Gajanan Rege, Gary Linscott'
p2733
aS'Wilfried Mehr, Ulrich St\xc3\xa4hlin, Stefan L\xc3\xbcke'
p2734
aS'John Yester, Hans RIPARIP, Bo Sun, Hiroshi Hattori, Katsuhiko AKAMATSU'
p2735
aS'Bradley R. Larkin, Johannes Quehenberger'
p2736
aS'Timothy James Ong, Daniel Peter Moroni'
p2737
ag2658
ag2651
aS'David Ian Franklin Ferguson, Wan-Yen Lo'
p2738
ag2412
aS'Yonggwon KIM, Jieseop SIM'
p2739
aS'Antoine LELAURIN, Thierry BRIZARD'
p2740
aS'Tomoyuki Hamada, Kazuhiro Sugawara, Katsuaki Tanaka, Masaki Kanai'
p2741
aS'Peter Colijn, Joshua Seth Herbach, Matthew Paul McNaughton'
p2742
aS'Andrew Barton-Sweeney, Daniel Trawick Egnor, Nathaniel Fairfield'
p2743
aS'Nicholas Letwin, Morgan Jones'
p2744
ag2439
aS'Jason Soll, Thomas Finsterbusch, Louis Gresham, Mark Murphy, Gabriel Charalambides, Alexander Loo'
p2745
ag2323
ag2371
ag2643
aS'James A. Del Savio, Richard P. Berube, Stuart K. Beazley, Ryan K. Miller, Peter Licis, Alberico Menozzi'
p2746
ag2690
aS'Jung Sook Kim, Ju Wan Kim, Jeong Dan Choi'
p2747
aS'Daniel J. Valentino, James R. Thistlethwaite, Iii, R. Craig Yoder'
p2748
aS'David Leslie Agnew, Graham Lanier Fletcher'
p2749
aS'Baljit Singh, OM Prakash Suthar'
p2750
aS'Andrew Chambers, Keenan Wyrobek, Keller Rinaudo, Ryan Oksenhorn, William Hetzler'
p2751
aS'Alaa Abou Mahmoud, Sangeeta Gautam, David W. Joutras, Vinod A. Valecha'
p2752
aS'Christopher Charles Martenis'
p2753
aS'John Tisdale, Russell Smith, Nathaniel Fairfield'
p2754
aS'Robert Kornhaas'
p2755
aS'David I. Ferguson, Dmitri A. Dolgov, Christopher Urmson'
p2756
aS'Jussi Myllymaki'
p2757
aS'Tetsuya Taira, Yutaka Takaoka'
p2758
aS'Joseph M. Raad, Donald Jacob Mattern'
p2759
aS'James E. Niles'
p2760
ag2658
ag2526
aS'Mark A. Cuddihy, Manoharprasad K. Rao'
p2761
aS'Christian Thiele, Winfried Lohmiller, Lars Schoepfer, Hugo HEUSINGER, Werner Kleih'
p2762
aS'Hajime Oyama, Masato Mizoguchi, Yasushi TAKASO, Koji Matsuno, Shiro Ezoe, Satoru Akiyama, Eiichi Shiraishi, Takayuki Nagase, Harunobu Horiguchi'
p2763
ag2676
ag2691
aS'Kenneth L. Oblizajek, Stephen R. Pastor, David M. Caldwell, John D. Sopoci'
p2764
ag2434
aS'Charles E. Eberling, Ronald S. Plantan'
p2765
aS"Michel Celestino PAIVA FERREIRA, Lu\xc3\xads Manuel MARTINS DAMAS, Hugo Marcelo FERNANDES DA CONCEI\xc3\x87\xc3\x83O, Pedro MIRANDA DE ANDRADE DE ALBUQUERQUE D'OREY, Peter Steenkiste, Pedro Emanuel RODRIGUES GOMES, Ricardo Jorge Fernandes"
p2766
aS'Yasushi TAKASO'
p2767
ag2526
aS'Liam Pedersen'
p2768
aS'Hassen Hammoud, Jianbo Lu, Gilberto Burgio, Todd N. Clark, Otto Hofmann, Mohsen Lakehal-ayat, Shweta M. Farmer, Jason Shomsky, Roland Schaefer'
p2769
aS'Alberto Daniel Lacaze, Karl Nicholas Murphy'
p2770
aS'Stephen L. Robertson'
p2771
ag2761
ag2317
aS'Kazuyoshi Isaji, Naohiko Tsuru, Shou Morikawa'
p2772
aS'Emar Vegt, Lenja SOROKIN'
p2773
aS'Philip Joseph Jenkins, JR.'
p2774
aS'Katsuhiro Sakai, Danil V. Prokhorov, Bunyo Okumura, Naoki Nagasaka, Masahiro Harada, Nobuhide Kamata'
p2775
aS'Stig Rune Lennart Tenghamn'
p2776
aS'Carl-Johan HOEL, Kristoffer Tagesson'
p2777
aS'Nicolas Meuleau, Vikram Krishnamurthy'
p2778
aS'Peter Harda'
p2779
ag2743
aS'David Ian Franklin Ferguson, David Harrison Silver'
p2780
aS'Stephen Thomas Safarik'
p2781
aS'Bertrand Robert Douillard, Jesse Sol Levinson, Gabriel Thurston Sibley'
p2782
aS'Timothy David Kentley, Rachad Youssef Gamara, Gary Linscott'
p2783
aS'Timothy David Kentley'
p2784
ag2651
aS'Arne Henning Rokkan, Geir VALSVIK, Bjarne ISFELDT, Jean-Baptiste Danre'
p2785
aS'Bunyo Okumura, Michael R. James, Katsuhiro Sakai, Tomoki Nishi'
p2786
aS'Stefano Di Cairano, Spyridon Zafeiropoulos'
p2787
aS'Shane Elwart, Sudipto Aich'
p2788
aS'Matthew J. Lewis, Michael H. Laur'
p2789
aS'Peter Lombrozo'
p2790
aS'Hideo Inoue, Shintaro Inoue, Masahiro Mio, Shingo SAKAIDA, Tsukasa Shimizu, Masayuki Okuwa, Minoru Kamata, Takuma Ito, Pongsathorn Raksincharoensak, Masao Nagai'
p2791
ag2328
aS'Jeffrey Scott Adler, Harold Russell Baird'
p2792
aS'Jens-Steffen Ralf Gutmann, Andreas WENDEL, Nathaniel Fairfield, Dmitri A. Dolgov, Donald Jason Burnette'
p2793
aS'Hiroshi Horii'
p2794
ag2676
aS'David Harrison Silver, David Ian Franklin Ferguson'
p2795
aS'Pinaki Gupta'
p2796
aS'Frederic Stefan'
p2797
aS'Michael R. James'
p2798
aS'Douglas Raymond Martin, Mark Anthony ROCKWELL'
p2799
aS'Hermann Kopetz'
p2800
ag2720
ag2676
aS'Heishiro Toyoda'
p2801
aS'Thomas O. Smailus'
p2802
aS'Shay C. Colson, David A. Divine'
p2803
aS'Naoki Nagasaka, Danil V. Prokhorov'
p2804
aS'Simon DREXLER, Matthew Allen Rendall, Ryan Christopher GARIEPY, Mike Hanuschik, Paul Mohr'
p2805
ag2676
aS'Jeffrey Clyne Garland'
p2806
aS'Kyle Vogt, Divya Thakur'
p2807
aS'Christopher Paul Urmson, Peter Colijn, Dmitri A. Dolgov, Nathaniel Fairfield, Salil Pandit, Nirmal Patel, Ryan Powell, Min Li CHAN'
p2808
aS'Ivan STAMATOVSKI, Mohammad HEFNY'
p2809
aS'Bibhrajit HALDER, Chongyu Wang, Kenneth X. XIE'
p2810
aS'Ryan D. Lamm, Christopher I. MENTZER, Kristopher C. KOZAK, Marc C. ALBAN, Jason C. Gassaway, Richard D. Garcia'
p2811
aS'Matthew Sweeney, Emily Bartel, Jean-Sebastien Valois'
p2812
aS'Sivalogeswaran Ratnasingam'
p2813
aS'Helene Vorobieva, Nuciketa MINOIU ENACHE, Sebastien GLASER'
p2814
aS'Wilford Trent Yopp, Mark Allan Lippman'
p2815
aS'Karl Berntorp, Oktay Arslan'
p2816
aS'Emery Charles Gulash'
p2817
aS'Erick Michael Lavoie, Kerem Bayar, Michael Edward Brewer'
p2818
aS'Jesse Sol Levinson, Gabe Thurston Sibley, Ashutosh Gajanan Rege'
p2819
ag2676
aS'Pablo Luis Guarnizo Martinez'
p2820
aS'Nathaniel Fairfield'
p2821
aS'Erick Michael Lavoie, Nathaniel Abram Rolfes'
p2822
aS'Leo Laine'
p2823
ag2373
aS'David I. Ferguson, Abhijit S. Ogale'
p2824
aS'Gary D. Cudak, David G. Dean, Christopher J. Hardee, William E. Lohmeyer, Jr., Bryan M. Reese, J. Mark Weber'
p2825
aS'Jon Arron McClintock, Daniel Buchmueller, Varadarajan Gopalakrishnan, Fabian Hensel, Jesper Mikael Johansson, Brandon William Porter, Andrew Jay Roths'
p2826
aS'Jiajun Zhu, Christopher Urmson, David I. Ferguson, Nathaniel Fairfield, Dmitri Dolgov'
p2827
ag2478
aS'Samuel Lavie, Gil Emanuel Fuchs, Clayton Richard Morlock'
p2828
aS'Xue Mei, Naoki Nagasaka, Bunyo Okumura'
p2829
aS'Takahisa Yamashiro'
p2830
aS'Ian Rust'
p2831
aS'Michael J. Delp, Derek S. Caveney'
p2832
aS'Joshua Seth Herbach, Philip Nemec, Nathaniel Fairfield'
p2833
aS'William Ross, Michael Aitken'
p2834
aS'Dale Scott Crombez, Jerome Charles Ivan, James Robert McBride, Wayne Williams, Paul Joseph Szuszman, Roger Arnold Trombley, Peter Worrel, Hai Yu'
p2835
aS'Simon Dean'
p2836
aS'Gautier Minster, Sohrab Haghighat, Kevin Chu, Kyle Vogt'
p2837
ag2375
aS'Edzko Smid'
p2838
aS'Benjamin M. Geller'
p2839
aS'Stephen Alton Sprigg'
p2840
aS'Anthony Levandowski, Don Burnette'
p2841
ag2565
aS'Dimitar Petrov Filev, Jianbo Lu, Davor D. Hrovat'
p2842
aS'Won Jin JO, Hyoung Geun Kwon, Tae Won Lim, Changjae Lee, Seokyoul YANG'
p2843
aS'Clinton G. Hobbart, William D. Morse, Robert James Bickerstaff'
p2844
aS'Gennady Staskevich, Erik P. Blasch, Brian Abbe'
p2845
aS'Christopher Attard, Dale Scott Crombez, Jerome Charles Ivan, John P. Joyce, James Robert McBride, Wayne Williams, Paul Joseph Szuszman, Peter Worrel, Hai Yu, John Shutko, Jeff Allen Greenberg, Rajit Johri, Devinder Singh Kochhar, Hongtei Eric Tseng, Douglas Scott Rhode'
p2846
aS'Timothy David Kentley, Rachad Youssef Gamara'
p2847
aS'Aed M. Dudar'
p2848
ag2847
ag2643
ag2412
aS'Erik William Soderlind'
p2849
aS'Dong Yong Kwak'
p2850
aS'Christopher John Stoffel, Brian Douglas Cullinane, Nathaniel Fairfield, Alex Khaykin, Brian Torcellini'
p2851
aS'Jason Palmer, Mark Freitas, Daniel A. Deninger, David Forney, Slaven Sljivar, Alekh Vaidya, Jeffrey Griswold'
p2852
aS'Tarun Amla, Jyoti Amla, Keshav Amla'
p2853
aS'Stefano Di Cairano, Xiaodong Lan'
p2854
ag2388
aS'Jan Martinus Van Kuilenburg, Karel Van den Berg'
p2855
ag2676
aS'Con William Costello'
p2856
aS'Fling Finn Tseng, Imad Hassan Makki, Aed M. Dudar'
p2857
aS'Oliver Wulf'
p2858
aS'Igor Ljubuncic, Raphael Sack, Tomer RIDER, Shahar Taite'
p2859
aS'Howard Hayes, Regina Madigan, Surender Kumar, Mark Slusar'
p2860
aS'Stephen Chen'
p2861
aS'Peter Rander, David McAllister Bradley, Matthew Wood'
p2862
aS'Kenneth James Miller, William Paul Perkins, David B. Kelley'
p2863
aS'Erick Michael Lavoie, Douglas Scott Rhode'
p2864
aS'Ian Rust, Kyle Vogt, Solomon Bier, Drew Allyn Gross'
p2865
aS'Karl Berntorp, Stefano Di Cairano'
p2866
aS'Timothy David Kentley-Klay, Rachad Youssef Gamara'
p2867
aS'Valery CERVANTES, Jerome Laborde'
p2868
aS'Carlos Vallespi-Gonzalez'
p2869
aS'Adam J. Schlangen, Jason K. Raska, Carlos A. Villafan, Richard R. Maki, Shane A. Novotny, Jonathan Mark Hetland'
p2870
aS'Denis Stoof, Eckhard Babbel, Ulrich Sonnak, Matthias Kl\xc3\xb6pping'
p2871
ag2380
aS'Joo Yeob LEE'
p2872
aS'Timothy David Kentley, Jesse Sol Levinson, Rachad Youssef Gamara, Gabriel Thurston Sibley'
p2873
aS'Gautier Minster'
p2874
aS'Guillaume Hoareau, Johannes J. Liebenberg, John G. Musial, Todd R. Whitman'
p2875
aS'Ilya Blayvas, Ron Fridental, Shengwei Da'
p2876
aS'Marko Tuukkanen'
p2877
aS'Yoshito Kondo, Yuji Sato, Ken Ishikawa'
p2878
aS'Benjamin May, Joern Ihlenburg'
p2879
aS'Michael Owens, Thomas K. Ferguson'
p2880
aS'Ingmar Bruder, Simone Christina Spiller, Erwin Thiel, Stephan IRLE, Robert Send, Henrike Wonneberger'
p2881
aS'Simon Owen, Karl Richards, Andrew Maskell'
p2882
aS'Jeffrey P. Smith'
p2883
aS'Jesse Sol Levinson, Timothy David Kentley, Bertrand Robert Douillard'
p2884
ag2829
aS'Naoki Kojo, Mauro Della Penna'
p2885
aS'Shih-Chia HUANG, Ming-Kai Jiau, Sheng-Kai Chou'
p2886
ag2687
aS'Hassene Jammoussi, Pankaj Kumar, Imad Hassan Makki'
p2887
aS'Oliver Ullrich, Naphtali Rishe'
p2888
aS'Kristofer D. KUSANO, Yi Li, Hideki Hada, Miles J. JOHNSON'
p2889
aS'Michael G. Hornberger'
p2890
aS'Peter Vincent Boesen'
p2891
aS'Robert Lawson Vaughn, Timothy J. Gresham, Corey KUKIS, John Charles Weast'
p2892
aS'Matthias Kretschmann'
p2893
aS'William Henry Von Novak, Linda Stacey Irish'
p2894
aS'Yi Li'
p2895
aS'Won Jin JO, Hyoung Geun Kwon, Tae Won Lim, Yoonho Jang, Byungyong You'
p2896
ag2690
aS'Jeffrey Eggers, Mark Draper, Robert Shaw, Joshua Hamell, Heath Ruff'
p2897
aS'William N. Mansur, Mark D. Malone, Tuan A. Be, Ahmed Awadi'
p2898
aS'Nathaniel Fairfield, Joshua Seth Herbach, Christopher Kennedy Ludwick, Matthew Paul McNaughton, Renaud-Roland Hubert, Jennifer Arden, Min Li CHAN'
p2899
aS'Matthew Sweeney, Emily Bartel'
p2900
aS'Jennifer Arden, Brian Douglas Cullinane, Min Li CHAN, Renaud-Roland Hubert'
p2901
aS'Amber P. Malone, David J. Koenig, Kevin P. Blair, Patrick D. Weldon, Cole A. Sytsma'
p2902
ag2847
aS'Timothy W. Gibson, Surender Kumar, Regina Madigan'
p2903
aS'Eric Meyhofer, David Rice'
p2904
aS'Michael J. Stigler, Nicholas James Setar'
p2905
aS'Heishiro Toyoda, Joshua Domeyer'
p2906
aS'Jonas Nilsson, Erik Coelingh, Trent Victor'
p2907
ag2317
aS'Nicholas Letwin, Morgan Jones, Michael Sergi-Curfman'
p2908
aS'Gautier Minster, Peter Gao, Wei Mou'
p2909
aS'Richard K. Riefe, John F. Schulz'
p2910
aS'Justin Ho, Noah Zych'
p2911
aS'Craig Robert Shankwitz, Arthur Richard Baker, III'
p2912
aS'Kyoung Hwan An, Woo Yong HAN'
p2913
aS'Michael R. James, Danil V. Prokhorov'
p2914
aS'Rajarshi Gupta, Michael Franco Taveira'
p2915
ag2547
aS'Su Jung Yoo, Dong Hwi Lee, Hoi Won Kim'
p2916
aS'Richard Donnelly'
p2917
aS'Peter Rander'
p2918
aS'Kyun Sang Park'
p2919
aS'Jialiang Le, Thomas Edward Pilutti, Manoharprasad K. Rao, Matthew Y. Rupp, Roger Arnold Trombley, Andrew Waldis'
p2920
aS'Steve Aemisegger, Daniel GUMPP, Jochen Mueller, Tobias Schmid, Klaus MUESSLER, Ana Maria FERNANDEZ, Joerg Mueller, Oliver SCHAURER, Mario MOEHRING, Mathias VENSCHOTT, Stefan Thiel, Kamil ZAWADSKI'
p2921
aS'Christopher L. Scofield, Scott Sedlik'
p2922
aS'Marcelo CERIBELLI, Benjamin Lund, Lael Pearce'
p2923
aS'Benjamin Lund, Michael Franco Taveira, Lael Pearce, Marcelo CERIBELLI'
p2924
aS'William P. Baumann'
p2925
aS'Jerome H. Wei, Walter Wang, Arthur Gevorkian'
p2926
aS'Dong Hwi Lee, Keon Yup Chu, Hoi Won Kim, Su Jung Yoo'
p2927
aS'Jim K. Rainbolt, Nathaniel H. WILLIAMS, Dwayne A. Crocker, Janet S. Goings, Mary E. DeCaluwe'
p2928
ag2676
aS'Jesse Sol Levinson, Timothy David Kentley, Gabriel Thurston Sibley'
p2929
ag2410
aS'Gunter Anton Fendt, Ulrich St\xc3\xa4hlin, Bernhard Schmid, Marc Menzel'
p2930
aS'Seiji Kuwahara, Kazumi Hoshiya, Norimi Asahara, Yoshio Ito, Takahito Endo, Tadashi FUJIYOSHI'
p2931
aS'Wolfgang Mielich, Manfred Holzmann, Regina Meier'
p2932
aS'William Payne Ross, Chenggang Liu'
p2933
aS'Heather Konet, Roy Goudy, Andrew Christensen'
p2934
ag2934
aS'Jin-woo Lee, Nikolai K. Moshchuk, Shih-Ken Chen, Bakhtiar Brian Litkouhi'
p2935
aS'Woo Young Choi, Hyun Gyung KIM, Dong Eun Cha, Seung Mok Lee, Phil Jung Jeong'
p2936
aS'Jianbo Lu, Steven Joseph Szwabowski, Kwaku O. Prakah-Asante, Fling Tseng, Perry Robinson MacNeille, Xiaoming Wang'
p2937
aS'Ryosuke Murai, Tatsuo Sakai'
p2938
aS'Diomidis KATZOURAKIS, Caspar HANSELAAR, Mathias LIDBERG'
p2939
aS'Hemanki Doshi'
p2940
ag2690
aS'Timothy Kuan-Ta Lu, Robert James Citorik, Mark Kyle Mimee'
p2941
aS'John P. Joyce, Samer Abbas, Scott J. Lauffer'
p2942
aS'Boaz Jie Chai, Anil Paryani, Eahab Nagi El Naga, William Alan Beverley'
p2943
aS'Hajime Oyama'
p2944
aS'Joshua John Hartung, Peter Brink, Jonathan Lamb, David Paul Miller'
p2945
aS'Walter Wang, Jerome H. Wei, Bradley Feest, Benjamin Najar-Robles, Michael Z. Lim'
p2946
aS'Tong-Wen WANG, Wei-Feng HSU, Po-Kai TSENG'
p2947
aS'Nobuhide Kamata'
p2948
aS'Ichiro Sugioka, Douglas Frasher, Stefan Norberg'
p2949
ag2944
aS'Johannes Huennekens, Samuel Ellis, Greg Foletta'
p2950
aS'Avi Bar-Zeev, Brian C. Beckman, Daniel Buchmueller, Steven Gregory Dunn, Gur Kimchi'
p2951
aS'Brielle Reiff, Madeline Jane Schrier, Nithika Sivashankar'
p2952
aS'John P. Joyce, Scott J. Lauffer, Andrew Brown, Steven R. El Aile, Samer Abbas, Darrel Alan Recker'
p2953
aS'Shiro Ezoe'
p2954
aS'Frederic Stefan, Alain Marie Roger Chevalier, Michael Marbaix, Evangelos BITSANIS'
p2955
aS'Yoshiaki Tsuda'
p2956
ag2478
aS'Anil Paryani, Boaz Jie Chai, Evan Roger Fischer'
p2957
aS'Jingwei Xu, Bruce Bernhardt, Arnold Sheynman'
p2958
aS'John S. Kargilis'
p2959
aS'Isaiah W. Cox'
p2960
aS'Mathias FRANZIUS, Nils EINECKE'
p2961
aS'Thomas Edward Pilutti, Matthew Y. Rupp, Roger Arnold Trombley, Andrew T. Waldis'
p2962
aS'Erick Michael Lavoie, Roger Arnold Trombley, Hai Yu'
p2963
ag2576
aS'Norman C. Kerr'
p2964
aS'Eric Humenay'
p2965
ag2478
aS'Bradley Templeton, Nathaniel Fairfield, Dave Ferguson'
p2966
ag2478
aS'Richard Donnelly, David McAllister Bradley, Matthew Sweeney, Emily Bartel'
p2967
ag2478
aS'Lisa Ehrlich, Bertrand MOLIMARD, Johan BRINGHED, Anders HEIWALL'
p2968
aS'Aam Rusciolelli, Tyson Dollinger, John Posselius, Christopher A. Foster, Brian Ray'
p2969
aS'Liyun Li, Shaoshan Liu, Shuang Wu, James Peng'
p2970
aS'Tadashi FUJIYOSHI, Kazumi Hoshiya, Yoshio Ito, Norimi Asahara, Seiji Kuwahara, Takahito Endo, Kazuya Arakawa'
p2971
aS'Frederic Stefan, Alain Marie Roger Chevalier, Evangelos BITSANIS, Michael Marbaix'
p2972
aS'Emad W. Saad, John L. Vian'
p2973
aS'BaekGyu Kim, Shinichi Shiraishi, Jonathan Shum'
p2974
ag2478
aS'Tomohisa Yamashita, Masaya Kato, Hiroyuki Tachibana, Takashi Kuwayama, Hironobu Ishijima, Keisuke Oyama'
p2975
aS'William C. Kahn, Steve J. Polansky, Christopher G. Wehrwein'
p2976
aS'Yasuyoshi Hori, Yukiyasu Akemi, Masaya Endo, Hideyuki Tanaka, Takayuki Tanaka, Takahiro URABE, Kouhei Mori'
p2977
aS'Matt Jones, Peter Bontrager, Sebastian Paszkowicz, Paul Wheller'
p2978
aS'David Ian Franklin Ferguson, Abhijit Ogale'
p2979
ag2373
ag2971
aS'Christopher Valasek, Charles Miller'
p2980
ag2980
aS'Myung-Wook PARK, Yong-Bon Koo, Sang-Woo Lee, Woo-Yong Han'
p2981
aS'Ichiro Sugioka, Matthew Lawler, Kari KAUPPI, Aric DROMI, Nick SAKELLARIOU'
p2982
aS'Brian D. Christoff, John K. Dagg, Robert G. Izak, Christian E. Thomas'
p2983
aS'Matt K. LUBBERS, Matt John SAMPSON, Kenneth K. XIE'
p2984
aS'Mark Sibenac, Daniel Strother, Daniel Tascione, Morgan Jones, Jordan Brindza'
p2985
aS'Gil Thieberger, Ari M. Frank'
p2986
aS'Adam Rusciolelli, Tyson Dollinger, John Posselius, Christopher A. Foster, Brian Ray'
p2987
aS'Christian Schallmeier'
p2988
ag2774
aS'Steve D. Lundquist, Tom Otsubo'
p2989
aS'Donald P. Clark'
p2990
ag2478
aS'Shintaro Inoue, Hideo Inoue, Pongsathorn Raksincharoensak'
p2991
aS'Davorin David Hrovat, Li Xu, Eric Hongtei Tseng'
p2992
aS'Dave Alberto Tavares Cavalcanti, Marcin Krzysztof Szczodrak, Talmai Brand\xc3\xa3o De Oliveira, Yong Yang'
p2993
aS'Mats Jonasson, Derong YANG, Jonatan SILVLIN'
p2994
ag2412
ag2478
aS'Pete Lombrozo'
p2995
aS'Michael Hafner, Erick Michael Lavoie'
p2996
aS'David Ian Franklin Ferguson, Andreas WENDEL'
p2997
aS'Dershuen Allen Tang, James Arthur Knopp'
p2998
aS'Erick Michael Lavoie, Bradley G. Hochrein'
p2999
aS'Daniel Theobald'
p3000
ag2478
ag2478
aS'Sami Ahmed, Matthew M. Karaba, Paul R. Williams'
p3001
aS'Yekutiel Josefsberg, Tal Lavian'
p3002
ag2931
aS'Joseph M. Raad, Christos Kyrtsos, Tyler Daavettila, Donald Jacob Mattern, Erick Michael Lavoie'
p3003
aS'Mikiya Ishihara, Yi Li, Kazutoshi Ebe'
p3004
aS'Trevor B. McLennan, Kent R. Young'
p3005
aS'Claudia V. Goldman-Shenhar, Gila Kamhi'
p3006
aS'Stefan Poledna, Georg NIEDRIST, Eric Schmidt, Martin Hoefler'
p3007
aS'Shane Elwart, Walter Joseph Talamonti'
p3008
aS'Erick Michael Lavoie, Roger Arnold Trombley'
p3009
aS'Rulthe Ranjita Rajendrakumar Kulthe'
p3010
aS'Don A. Mistrot, Richard P. Duffield'
p3011
aS'Grzegorz Siuchta, James Jerome Korson'
p3012
aS'Koji Matsuno, Harunobu Horiguchi'
p3013
aS'Chengxuan Fu'
p3014
aS'Erick Michael Lavoie, Donald Jacob Mattern, Joseph M. Raad'
p3015
ag2944
aS'Mats Jonasson, Mikael Thor'
p3016
ag2583
aS'Miguel BAHENA, Attila BENAK, Andrew Brown, Sergio CONDONESU, Darrel Alan Recker, Lodewijk Wijffels'
p3017
aS'Stefan Nordbruch'
p3018
aS'David Kun'
p3019
aS'Li Xu, Hongtei Eric Tseng, Thomas Edward Pilutti'
p3020
aS'Eric L. Raphael, Bakhtiar B. Litkouhi, Jeremy A. Salinger'
p3021
aS'Sean Doyle, James Ronald Barfield, JR., Alex D. Berkobin, Thomas Steven Taylor, Bryant Elliott, Eric Berkobin, Hamsa Ibrahim, Sneha Akula, Dwight Hartman'
p3022
aS'Donald L. Bryson, Eric Kline, Sarbajit K. Rakshit'
p3023
aS'Abhijit Ogale, David Ian Franklin Ferguson'
p3024
aS'Benjamin Meager'
p3025
aS'Erick Michael Lavoie, Darrel Alan Recker, Michael Richard Johnson'
p3026
aS'Koji Matsuno, Masato Mizoguchi'
p3027
ag2478
aS'Jason J. Nolte, Kathryn E. Koski, Sachin K. Pindolia'
p3028
aS'Grant L. Meade, Norman J. Weigert, Vyacheslav Berezin'
p3029
aS'Jianbo Lu, Davor David Hrovat, Eric Hongtei Tseng, Li Xu'
p3030
aS'Jean-Francois Bariant, Nicole Wagemann'
p3031
aS'Byeong Wook Jeon'
p3032
aS'Matthew Fry'
p3033
ag2440
aS'Koji Matsuno, Satoru Akiyama, Takayuki Nagase, Eiichi Shiraishi, Shiro Ezoe, Hajime Oyama, Yasushi TAKASO, Masato Mizoguchi, Harunobu Horiguchi'
p3034
aS'Joseph Park, Oliver Nehls, Jan Bremkens, Lodewijk Wijffels, Sergio Codonesu'
p3035
aS'Alois Freistadt, Izden Sarihan'
p3036
aS'William C. Kahn, A. Brent Hankins'
p3037
ag2526
ag2961
aS'Harunobu Horiguchi'
p3038
aS'Mattias Erik Brannstrom, Jonas Nilsson, Mohammad Ali'
p3039
aS'Grant L. Meade, Vyacheslav Berezin, Charles A. Green'
p3040
aS'Lawrence Clifford Williams'
p3041
aS'Christopher L. Kowalk'
p3042
aS'Jacob Sidney Rand'
p3043
aS'Xiaofeng MAO, Thomas A. Klingler, Eric E. Krueger'
p3044
aS'Herwig Fischer'
p3045
aS'Edward Earl Bonds'
p3046
aS'Thomas BURTSCHE, Thomas Velten, Rainer Schillinger, Thomas Goldmann'
p3047
ag2883
aS'Junya SEKI'
p3048
ag2795
aS'Christopher A. Foster, Adam R. Rusciolelli, Tyson J. Dollinger, John Posselius, Brian R. Ray, Todd S. AZNAVORIAN'
p3049
aS'Stefan Kueperkoch, Jeannine Schwarzkopf'
p3050
aS'Stanley W. Bird'
p3051
aS'Hyun Sub KIM, Bock Cheol Lee, Nak Kyoung Kong, Young Sub Oh, Jin Hee Lee, Jin Wan Park, Ji Yong JEONG, Je Seong LEE, Jae Hyuck AN'
p3052
aS'Robert A. Dziurda, Joel P. Ruschman, Frank W. Meinert, Caroline Chung'
p3053
aS'Sangwoo Lee, Myungwook PARK, Wooyong HAN'
p3054
aS'Richard B. Weinberg, Todd P. Lindemann, Rachel A. White'
p3055
aS'Jimmy N. Eavenson, Sr., Adam Woodrum, Jonathan Prybor'
p3056
ag2959
aS'Daniel Czaja, Axel Stender, Thomas Treichel, Markus Wolf'
p3057
aS'Geoffrey Paul Sandford'
p3058
aS'Ludong Sun, Michael H. Laur, Jonathan L. Wieskamp, Miao Yan'
p3059
aS'Ji Hyun Yoon'
p3060
aS'Jean-Baptiste Segard'
p3061
ag2526
aS'Christian Renner'
p3062
ag3044
ag2529
aS'Tom Driscoll, Joseph R. Guerci, Russell J. Hannigan, Roderick A. Hyde, Muriel Y. Ishikawa, Jordin T. Kare, Nathan P. Myhrvold, David R. Smith, Clarence T. Tegreene, Yaroslav A. Urzhumov, Charles Whitmer, Lowell L. Wood, JR., Victoria Y. H. Wood'
p3063
aS'Tony Gustafsson, Mats Jonasson'
p3064
aS'Nobuyuki Iwao'
p3065
aS'Takashi Shimizu, Koji Kurata'
p3066
aS'Frank Gerstenberg, Goeran Keil, Michael Lehmann'
p3067
aS'Brendan M. Conlon, Shawn H. Swales, Michael C. Muir, Aniket P. Kothari, Michael V. WOON'
p3068
aS'Hyungseok OH, WonSeok Yoo, Jeongsu Kim'
p3069
aS'Andreas WENDEL, David Ian Franklin Ferguson'
p3070
aS'Paul A. Bauerle'
p3071
aS'Michael D\xc3\xbcring, Kai Franke, Daniel T\xc3\xb6pfer, Omar El MIKATI'
p3072
aS'Jin-woo Lee, Bakhtiar B. Litkouhi'
p3073
aS'Ian Hughes, Baptiste Bureau'
p3074
ag3063
aS'Bo Wu, Brittany Connolly, Christopher W. Bell, Raymond C. Siciak'
p3075
aS'Youn Seok Choi, Jee Yoon Suh'
p3076
aS'David Harrison Silver, Jonathan Baldwin Dowdall, David Ian Franklin Ferguson'
p3077
aS'Karl-Heinz Siedersberger'
p3078
aS'Sung Hoon Cho, Yong Dok An'
p3079
aS'Chad T. Zagorski, Nikolai K. Moshchuk'
p3080
aS'Kunitomo Aoki, Norio NINOMIYA'
p3081
aS'Jumpei Ichinokawa'
p3082
ag2749
aS'Harpreetsingh Banvait, Scott Vincent Myers, Ashley Elizabeth Micks, Sneha Kadetotad'
p3083
aS'Claus Allan Christensen, Christian Hedegaard, Thomas Bove'
p3084
aS'James D. Humphrey'
p3085
aS'Eric LUCET, Alain Micaelli, Fran\xc3\xa7ois-Xavier Russotto'
p3086
aS'Robert C. MacArthur'
p3087
aS'Dan Ambrosio, Jonathan Harrach-Salazar, Mark Gordon, Mark ROSENBLUM, Martin Sotola, Ryan Delgizzi, Peter James'
p3088
aS'Nathan Eric Bunderson, John Arthur Mitsuru Petersen, Brian Robert Ray'
p3089
aS'Erick Michael Lavoie, Donald Jacob Mattern, Joseph M. Raad, Tyler Daavettila, Robert Bell'
p3090
aS'Constandi J. Shami'
p3091
aS'Michael I. Chia, Walter K. Kosiak, Matthew R. Smith'
p3092
aS'Takashi Sugano, Shimpei Kusumoto'
p3093
ag3073
ag2831
aS'Anthony J. Cook, Darren William Gosbee'
p3094
aS'Shintaro Inoue, Hideo Inoue, Yutaka Hirano, Pongsathorn Raksincharoensak'
p3095
aS'Alessandro Zin, Long Ying'
p3096
aS'Yutaka Sato'
p3097
aS'Shinichi Igarashi, Hajime Oyama'
p3098
aS'Motomi Iyoda, Kenichi Ohue, Takashi Kojima'
p3099
aS'Jonghoon Kim'
p3100
aS"Donald R. High, Michael D. Atchley, John J. O'Brien"
p3101
aS'John Bales, Michael Hafner, Kevin Smith, Erick Michael Lavoie'
p3102
aS'David L. Pichan'
p3103
ag2478
aS'Chen-Hsin Lin'
p3104
aS'Martin Buchner, Tobias Strobel, Klaus Dollinger'
p3105
aS'Martin Schuermeier'
p3106
aS'Dennis Brazier, Mark Reese'
p3107
aS'Charles A. Green'
p3108
aS'Franck Bordes, Dudley Harrison'
p3109
aS'Yu-Tan Lien'
p3110
aS'Ki Mo SOHN'
p3111
aS'Tom Driscoll, Joseph R. Guerci, Russell J. Hannigan, Roderick A. Hyde, Muriel Y. Ishikawa, Jordin T. Kare, Nathan P. Myhrvold, David R. Smith, Clarence T. Tegreene, Yaroslav A. Urzhumov, Charles Whitmer, Lowell L. Wood, JR., Victoria Y.H. Wood'
p3112
aS'Malte Joos, Martin Hoerer'
p3113
aS"John P Spicer, Ningjian Huang, Greg Vanderheyden, James O'Dell"
p3114
aS'Ronald D. Harris'
p3115
aS'Li Xu, Eric Hongtei Tseng'
p3116
aS'Mathias Westlund, Jonas Nilsson'
p3117
aS'Graham Lanier Fletcher, Jeremy J McClain, David Leslie Agnew, Ibro Muharemovic, Brandon Herzog, Joyce Chen'
p3118
aS'Masanobu Ohmi, Seiji Yamamoto, Yoshiaki Matsumura, Kosuke Sakakibara, Kazuki SUGIE, Misato KINOSHITA'
p3119
aS'Ladislav KARN\xc3\x8dK'
p3120
aS'James D. Humphrey, Andrew J. Vitale, Joshua Struble, Bryan Everett'
p3121
aS'Ryuuen Kou, Akiharu Nishijima, Shinya Kondou'
p3122
aS'Tomonori Kawakami, Yuto Imanishi, Takeo Shibata'
p3123
aS'Alexander Banerjee'
p3124
aS'Hirotaka Saito, Junya SEKI, Kazufumi Suzuki'
p3125
aS'Florin-Cristian Matei'
p3126
ag2944
aS'Erick Michael Lavoie, Joseph M. Raad, Donald Jacob Mattern'
p3127
aS'Travis Dierks, Matthew Wootton'
p3128
aS'Davor David Hrovat, Hongtei Eric Tseng, Jianbo Lu, Li Xu'
p3129
aS'Michael Goren, Jeremy E. Goren'
p3130
aS'Rouhollah Jafari, Shuqing Zeng'
p3131
aS'James Jerome Korson, Grzegorz Siuchta'
p3132
aS'Thierry Moreau'
p3133
aS'Michael Reichel, Christian R\xc3\xb6sener'
p3134
aS'Zheng Hu, Erick Michael Lavoie'
p3135
aS'Scott J. Lauffer, John P. Joyce, Tobias John Pallett, Andrew Brown, Shane Elwart, Wayne Williams'
p3136
aS'Andrew Brown, Scott J. Lauffer, John P. Joyce, Steven R. El Aile, Tobias John Pallett, Shane Elwart, Wayne Williams'
p3137
aS'John Bales, Michael Hafner'
p3138
aS'Josef Seidl'
p3139
aS'Andreas Erban'
p3140
aS'Alexander Mueller, Thomas Kropf'
p3141
aS'Yukito Ohmura'
p3142
aS'Francisco FERRER-DALMAU NIETO, Francisco Javier VICANDI UNANUE, Carlos Javier IRIONDO ARRIZABALAGA, Jesus Maria Iriondo Arrizabalaga'
p3143
aS'Stefan Eberhardt'
p3144
aS'Jason E. Diehl, Jim K. Rainbolt, Mary E. DeCaluwe, Janet S. Goings'
p3145
aS'https://patents.google.com/patent/US8457827B1/en'
p3146
aS'https://patents.google.com/patent/US20150248131A1/en'
p3147
aS'https://patents.google.com/patent/US20140214255A1/en'
p3148
aS'https://patents.google.com/patent/US8818608B2/en'
p3149
aS'https://patents.google.com/patent/US9194168B1/en'
p3150
aS'https://patents.google.com/patent/US8700251B1/en'
p3151
aS'https://patents.google.com/patent/US8527199B1/en'
p3152
aS'https://patents.google.com/patent/US20140303827A1/en'
p3153
aS'https://patents.google.com/patent/US20140297116A1/en'
p3154
aS'https://patents.google.com/patent/US8718861B1/en'
p3155
aS'https://patents.google.com/patent/US8874301B1/en'
p3156
aS'https://patents.google.com/patent/US20150066284A1/en'
p3157
aS'https://patents.google.com/patent/US20140330479A1/en'
p3158
aS'https://patents.google.com/patent/US8880270B1/en'
p3159
aS'https://patents.google.com/patent/US20130238170A1/en'
p3160
aS'https://patents.google.com/patent/US8849494B1/en'
p3161
aS'https://patents.google.com/patent/US8996224B1/en'
p3162
aS'https://patents.google.com/patent/US20150339928A1/en'
p3163
aS'https://patents.google.com/patent/US20130245877A1/en'
p3164
aS'https://patents.google.com/patent/US20130211656A1/en'
p3165
aS'https://patents.google.com/patent/US20150149019A1/en'
p3166
aS'https://patents.google.com/patent/US8954252B1/en'
p3167
aS'https://patents.google.com/patent/US20140088855A1/en'
p3168
aS'https://patents.google.com/patent/US20150166062A1/en'
p3169
aS'https://patents.google.com/patent/US8473144B1/en'
p3170
aS'https://patents.google.com/patent/US8909391B1/en'
p3171
aS'https://patents.google.com/patent/US20150149017A1/en'
p3172
aS'https://patents.google.com/patent/US20150006005A1/en'
p3173
aS'https://patents.google.com/patent/US20140207325A1/en'
p3174
aS'https://patents.google.com/patent/US8930044B1/en'
p3175
aS'https://patents.google.com/patent/US9051043B1/en'
p3176
aS'https://patents.google.com/patent/US20140032034A1/en'
p3177
aS'https://patents.google.com/patent/US20140236414A1/en'
p3178
aS'https://patents.google.com/patent/US20140156182A1/en'
p3179
aS'https://patents.google.com/patent/US8948935B1/en'
p3180
aS'https://patents.google.com/patent/US20150254986A1/en'
p3181
aS'https://patents.google.com/patent/US20150346727A1/en'
p3182
aS'https://patents.google.com/patent/US8880272B1/en'
p3183
aS'https://patents.google.com/patent/US20140336935A1/en'
p3184
aS'https://patents.google.com/patent/US20140148988A1/en'
p3185
aS'https://patents.google.com/patent/US20150178998A1/en'
p3186
aS'https://patents.google.com/patent/US20140222277A1/en'
p3187
aS'https://patents.google.com/patent/US20130197736A1/en'
p3188
aS'https://patents.google.com/patent/US8825259B1/en'
p3189
aS'https://patents.google.com/patent/US8983682B1/en'
p3190
aS'https://patents.google.com/patent/US20150346718A1/en'
p3191
aS'https://patents.google.com/patent/US9079587B1/en'
p3192
aS'https://patents.google.com/patent/US9014905B1/en'
p3193
aS'https://patents.google.com/patent/US8793046B2/en'
p3194
aS'https://patents.google.com/patent/US20140195214A1/en'
p3195
aS'https://patents.google.com/patent/US8676431B1/en'
p3196
aS'https://patents.google.com/patent/US8521352B1/en'
p3197
aS'https://patents.google.com/patent/US20130184926A1/en'
p3198
aS'https://patents.google.com/patent/US20130304514A1/en'
p3199
aS'https://patents.google.com/patent/US20140309833A1/en'
p3200
aS'https://patents.google.com/patent/US9315212B1/en'
p3201
aS'https://patents.google.com/patent/US8977007B1/en'
p3202
aS'https://patents.google.com/patent/US20140129073A1/en'
p3203
aS'https://patents.google.com/patent/US8712624B1/en'
p3204
aS'https://patents.google.com/patent/US8949016B1/en'
p3205
aS'https://patents.google.com/patent/US20150149088A1/en'
p3206
aS'https://patents.google.com/patent/US20160026182A1/en'
p3207
aS'https://patents.google.com/patent/US20150336502A1/en'
p3208
aS'https://patents.google.com/patent/US20140333468A1/en'
p3209
aS'https://patents.google.com/patent/US20150177007A1/en'
p3210
aS'https://patents.google.com/patent/US20150344136A1/en'
p3211
aS'https://patents.google.com/patent/US20130231824A1/en'
p3212
aS'https://patents.google.com/patent/US8781669B1/en'
p3213
aS'https://patents.google.com/patent/US20150202770A1/en'
p3214
aS'https://patents.google.com/patent/US20150312774A1/en'
p3215
aS'https://patents.google.com/patent/US20150170287A1/en'
p3216
aS'https://patents.google.com/patent/US20150070160A1/en'
p3217
aS'https://patents.google.com/patent/US20150073589A1/en'
p3218
aS'https://patents.google.com/patent/US8595037B1/en'
p3219
aS'https://patents.google.com/patent/US20150057903A1/en'
p3220
aS'https://patents.google.com/patent/US20140121883A1/en'
p3221
aS'https://patents.google.com/patent/US20150106010A1/en'
p3222
aS'https://patents.google.com/patent/US20140319272A1/en'
p3223
aS'https://patents.google.com/patent/US9229453B1/en'
p3224
aS'https://patents.google.com/patent/US20160018822A1/en'
p3225
aS'https://patents.google.com/patent/US9390451B1/en'
p3226
aS'https://patents.google.com/patent/US9201421B1/en'
p3227
aS'https://patents.google.com/patent/US9422139B1/en'
p3228
aS'https://patents.google.com/patent/US20140142785A1/en'
p3229
aS'https://patents.google.com/patent/US20160244165A1/en'
p3230
aS'https://patents.google.com/patent/US8909428B1/en'
p3231
aS'https://patents.google.com/patent/US20130261871A1/en'
p3232
aS'https://patents.google.com/patent/US20140067187A1/en'
p3233
aS'https://patents.google.com/patent/US8798841B1/en'
p3234
aS'https://patents.google.com/patent/US20150268665A1/en'
p3235
aS'https://patents.google.com/patent/US20140277896A1/en'
p3236
aS'https://patents.google.com/patent/US20140121930A1/en'
p3237
aS'https://patents.google.com/patent/US20150066296A1/en'
p3238
aS'https://patents.google.com/patent/US20150134178A1/en'
p3239
aS'https://patents.google.com/patent/US8504233B1/en'
p3240
aS'https://patents.google.com/patent/US9302770B2/en'
p3241
aS'https://patents.google.com/patent/US9340228B2/en'
p3242
aS'https://patents.google.com/patent/US20140278029A1/en'
p3243
aS'https://patents.google.com/patent/US9056395B1/en'
p3244
aS'https://patents.google.com/patent/US20140063232A1/en'
p3245
aS'https://patents.google.com/patent/US20150370251A1/en'
p3246
aS'https://patents.google.com/patent/US20160231746A1/en'
p3247
aS'https://patents.google.com/patent/US9260244B1/en'
p3248
aS'https://patents.google.com/patent/US8825265B1/en'
p3249
aS'https://patents.google.com/patent/US9056676B1/en'
p3250
aS'https://patents.google.com/patent/US20150148988A1/en'
p3251
aS'https://patents.google.com/patent/US20150066282A1/en'
p3252
aS'https://patents.google.com/patent/US20150115571A1/en'
p3253
aS'https://patents.google.com/patent/US9189897B1/en'
p3254
aS'https://patents.google.com/patent/US9188985B1/en'
p3255
aS'https://patents.google.com/patent/US20150151725A1/en'
p3256
aS'https://patents.google.com/patent/US20130304279A1/en'
p3257
aS'https://patents.google.com/patent/US20140297067A1/en'
p3258
aS'https://patents.google.com/patent/US9008890B1/en'
p3259
aS'https://patents.google.com/patent/US20140307247A1/en'
p3260
aS'https://patents.google.com/patent/US8831813B1/en'
p3261
aS'https://patents.google.com/patent/US20160358477A1/en'
p3262
aS'https://patents.google.com/patent/US20130253754A1/en'
p3263
aS'https://patents.google.com/patent/US20160137311A1/en'
p3264
aS'https://patents.google.com/patent/US20160139594A1/en'
p3265
aS'https://patents.google.com/patent/US20150091374A1/en'
p3266
aS'https://patents.google.com/patent/US8838321B1/en'
p3267
aS'https://patents.google.com/patent/US20150336524A1/en'
p3268
aS'https://patents.google.com/patent/US20150149022A1/en'
p3269
aS'https://patents.google.com/patent/US20140088814A1/en'
p3270
aS'https://patents.google.com/patent/US20140018979A1/en'
p3271
aS'https://patents.google.com/patent/US20160070265A1/en'
p3272
aS'https://patents.google.com/patent/US20130289858A1/en'
p3273
aS'https://patents.google.com/patent/US20150166059A1/en'
p3274
aS'https://patents.google.com/patent/US20150166069A1/en'
p3275
aS'https://patents.google.com/patent/US20140210646A1/en'
p3276
aS'https://patents.google.com/patent/US20150350614A1/en'
p3277
aS'https://patents.google.com/patent/US20160209220A1/en'
p3278
aS'https://patents.google.com/patent/US9346560B2/en'
p3279
aS'https://patents.google.com/patent/US20150120094A1/en'
p3280
aS'https://patents.google.com/patent/US9321531B1/en'
p3281
aS'https://patents.google.com/patent/US8571743B1/en'
p3282
aS'https://patents.google.com/patent/US20160280267A1/en'
p3283
aS'https://patents.google.com/patent/US20140379247A1/en'
p3284
aS'https://patents.google.com/patent/US20130190985A1/en'
p3285
aS'https://patents.google.com/patent/US8761991B1/en'
p3286
aS'https://patents.google.com/patent/US20140374532A1/en'
p3287
aS'https://patents.google.com/patent/US20140032012A1/en'
p3288
aS'https://patents.google.com/patent/US20150304869A1/en'
p3289
aS'https://patents.google.com/patent/US20150284010A1/en'
p3290
aS'https://patents.google.com/patent/US20150309512A1/en'
p3291
aS'https://patents.google.com/patent/US9395727B1/en'
p3292
aS'https://patents.google.com/patent/US20140081505A1/en'
p3293
aS'https://patents.google.com/patent/US9355423B1/en'
p3294
aS'https://patents.google.com/patent/US8996228B1/en'
p3295
aS'https://patents.google.com/patent/US20140244096A1/en'
p3296
aS'https://patents.google.com/patent/US20160334797A1/en'
p3297
aS'https://patents.google.com/patent/US20140207535A1/en'
p3298
aS'https://patents.google.com/patent/US20160196756A1/en'
p3299
aS'https://patents.google.com/patent/US20130179382A1/en'
p3300
aS'https://patents.google.com/patent/US9081385B1/en'
p3301
aS'https://patents.google.com/patent/US20130314503A1/en'
p3302
aS'https://patents.google.com/patent/US20160153778A1/en'
p3303
aS'https://patents.google.com/patent/US20150346722A1/en'
p3304
aS'https://patents.google.com/patent/US8983705B2/en'
p3305
aS'https://patents.google.com/patent/US20160068103A1/en'
p3306
aS'https://patents.google.com/patent/US8781727B1/en'
p3307
aS'https://patents.google.com/patent/US20140032049A1/en'
p3308
aS'https://patents.google.com/patent/US20130325242A1/en'
p3309
aS'https://patents.google.com/patent/US20130211646A1/en'
p3310
aS'https://patents.google.com/patent/US9274525B1/en'
p3311
aS'https://patents.google.com/patent/US20150242953A1/en'
p3312
aS'https://patents.google.com/patent/US20130297195A1/en'
p3313
aS'https://patents.google.com/patent/US8768539B1/en'
p3314
aS'https://patents.google.com/patent/US20150102154A1/en'
p3315
aS'https://patents.google.com/patent/US8880273B1/en'
p3316
aS'https://patents.google.com/patent/US9221396B1/en'
p3317
aS'https://patents.google.com/patent/US20160068267A1/en'
p3318
aS'https://patents.google.com/patent/US20140081507A1/en'
p3319
aS'https://patents.google.com/patent/US20150088373A1/en'
p3320
aS'https://patents.google.com/patent/US20160247106A1/en'
p3321
aS'https://patents.google.com/patent/US20150210274A1/en'
p3322
aS'https://patents.google.com/patent/US20150100179A1/en'
p3323
aS'https://patents.google.com/patent/US20160214717A1/en'
p3324
aS'https://patents.google.com/patent/US9043069B1/en'
p3325
aS'https://patents.google.com/patent/US20160059889A1/en'
p3326
aS'https://patents.google.com/patent/US8855847B2/en'
p3327
aS'https://patents.google.com/patent/US9158980B1/en'
p3328
aS'https://patents.google.com/patent/US20150149018A1/en'
p3329
aS'https://patents.google.com/patent/US20140288763A1/en'
p3330
aS'https://patents.google.com/patent/US20140032093A1/en'
p3331
aS'https://patents.google.com/patent/US20150179062A1/en'
p3332
aS'https://patents.google.com/patent/US20150203107A1/en'
p3333
aS'https://patents.google.com/patent/US20150149265A1/en'
p3334
aS'https://patents.google.com/patent/US20160071418A1/en'
p3335
aS'https://patents.google.com/patent/US8676427B1/en'
p3336
aS'https://patents.google.com/patent/US9164511B1/en'
p3337
aS'https://patents.google.com/patent/US9062979B1/en'
p3338
aS'https://patents.google.com/patent/US20140303847A1/en'
p3339
aS'https://patents.google.com/patent/US20150338852A1/en'
p3340
aS'https://patents.google.com/patent/US8855904B1/en'
p3341
aS'https://patents.google.com/patent/US20150344038A1/en'
p3342
aS'https://patents.google.com/patent/US20150175070A1/en'
p3343
aS'https://patents.google.com/patent/US20150235557A1/en'
p3344
aS'https://patents.google.com/patent/US9248834B1/en'
p3345
aS'https://patents.google.com/patent/US9120485B1/en'
p3346
aS'https://patents.google.com/patent/US20160001781A1/en'
p3347
aS'https://patents.google.com/patent/US20140257621A1/en'
p3348
aS'https://patents.google.com/patent/US20140277691A1/en'
p3349
aS'https://patents.google.com/patent/US20130253767A1/en'
p3350
aS'https://patents.google.com/patent/US20150266455A1/en'
p3351
aS'https://patents.google.com/patent/US9383753B1/en'
p3352
aS'https://patents.google.com/patent/US20160046290A1/en'
p3353
aS'https://patents.google.com/patent/US8948954B1/en'
p3354
aS'https://patents.google.com/patent/US20150057891A1/en'
p3355
aS'https://patents.google.com/patent/US20150057871A1/en'
p3356
aS'https://patents.google.com/patent/US20150142244A1/en'
p3357
aS'https://patents.google.com/patent/US20150331422A1/en'
p3358
aS'https://patents.google.com/patent/US20150314780A1/en'
p3359
aS'https://patents.google.com/patent/US20140301161A1/en'
p3360
aS'https://patents.google.com/patent/US20150127239A1/en'
p3361
aS'https://patents.google.com/patent/US20160116293A1/en'
p3362
aS'https://patents.google.com/patent/US20150158524A1/en'
p3363
aS'https://patents.google.com/patent/US20150158499A1/en'
p3364
aS'https://patents.google.com/patent/US9523984B1/en'
p3365
aS'https://patents.google.com/patent/US9436182B2/en'
p3366
aS'https://patents.google.com/patent/US20140257661A1/en'
p3367
aS'https://patents.google.com/patent/US9081383B1/en'
p3368
aS'https://patents.google.com/patent/US8874267B1/en'
p3369
aS'https://patents.google.com/patent/US20150198951A1/en'
p3370
aS'https://patents.google.com/patent/US9162753B1/en'
p3371
aS'https://patents.google.com/patent/US20160125746A1/en'
p3372
aS'https://patents.google.com/patent/US8818681B1/en'
p3373
aS'https://patents.google.com/patent/US20140046506A1/en'
p3374
aS'https://patents.google.com/patent/US9014903B1/en'
p3375
aS'https://patents.google.com/patent/US9412278B1/en'
p3376
aS'https://patents.google.com/patent/US20160303969A1/en'
p3377
aS'https://patents.google.com/patent/US8855621B2/en'
p3378
aS'https://patents.google.com/patent/US20150187019A1/en'
p3379
aS'https://patents.google.com/patent/US20140124279A1/en'
p3380
aS'https://patents.google.com/patent/US9121703B1/en'
p3381
aS'https://patents.google.com/patent/US20140074339A1/en'
p3382
aS'https://patents.google.com/patent/US9381916B1/en'
p3383
aS'https://patents.google.com/patent/US20140300479A1/en'
p3384
aS'https://patents.google.com/patent/US20160304198A1/en'
p3385
aS'https://patents.google.com/patent/US8612135B1/en'
p3386
aS'https://patents.google.com/patent/US20130240673A1/en'
p3387
aS'https://patents.google.com/patent/US9164506B1/en'
p3388
aS'https://patents.google.com/patent/US20150344028A1/en'
p3389
aS'https://patents.google.com/patent/US20140263822A1/en'
p3390
aS'https://patents.google.com/patent/US20150142248A1/en'
p3391
aS'https://patents.google.com/patent/US9423498B1/en'
p3392
aS'https://patents.google.com/patent/US20150219464A1/en'
p3393
aS'https://patents.google.com/patent/US20150353085A1/en'
p3394
aS'https://patents.google.com/patent/US20160364823A1/en'
p3395
aS'https://patents.google.com/patent/US20150158528A1/en'
p3396
aS'https://patents.google.com/patent/US20160200317A1/en'
p3397
aS'https://patents.google.com/patent/US20150260526A1/en'
p3398
aS'https://patents.google.com/patent/US20140350725A1/en'
p3399
aS'https://patents.google.com/patent/US20140129075A1/en'
p3400
aS'https://patents.google.com/patent/US20160132705A1/en'
p3401
aS'https://patents.google.com/patent/US20160209845A1/en'
p3402
aS'https://patents.google.com/patent/US20150234045A1/en'
p3403
aS'https://patents.google.com/patent/US20150149023A1/en'
p3404
aS'https://patents.google.com/patent/US20140249693A1/en'
p3405
aS'https://patents.google.com/patent/US8494716B1/en'
p3406
aS'https://patents.google.com/patent/US20160070264A1/en'
p3407
aS'https://patents.google.com/patent/US20150323932A1/en'
p3408
aS'https://patents.google.com/patent/US20140263823A1/en'
p3409
aS'https://patents.google.com/patent/US20150294422A1/en'
p3410
aS'https://patents.google.com/patent/US20140019392A1/en'
p3411
aS'https://patents.google.com/patent/US8983693B2/en'
p3412
aS'https://patents.google.com/patent/US20140081479A1/en'
p3413
aS'https://patents.google.com/patent/US20130211647A1/en'
p3414
aS'https://patents.google.com/patent/US9086481B1/en'
p3415
aS'https://patents.google.com/patent/US20140067164A1/en'
p3416
aS'https://patents.google.com/patent/US20140303814A1/en'
p3417
aS'https://patents.google.com/patent/US8818609B1/en'
p3418
aS'https://patents.google.com/patent/US20150241878A1/en'
p3419
aS'https://patents.google.com/patent/US9063548B1/en'
p3420
aS'https://patents.google.com/patent/US20150136012A1/en'
p3421
aS'https://patents.google.com/patent/US20160039300A1/en'
p3422
aS'https://patents.google.com/patent/US8825226B1/en'
p3423
aS'https://patents.google.com/patent/US20140277894A1/en'
p3424
aS'https://patents.google.com/patent/US20140163730A1/en'
p3425
aS'https://patents.google.com/patent/US20150353082A1/en'
p3426
aS'https://patents.google.com/patent/US20150254988A1/en'
p3427
aS'https://patents.google.com/patent/US20160127931A1/en'
p3428
aS'https://patents.google.com/patent/US20130332008A1/en'
p3429
aS'https://patents.google.com/patent/US20140012465A1/en'
p3430
aS'https://patents.google.com/patent/US20150039173A1/en'
p3431
aS'https://patents.google.com/patent/US8788134B1/en'
p3432
aS'https://patents.google.com/patent/US20160355192A1/en'
p3433
aS'https://patents.google.com/patent/US9096150B2/en'
p3434
aS'https://patents.google.com/patent/US9513632B1/en'
p3435
aS'https://patents.google.com/patent/US9108584B2/en'
p3436
aS'https://patents.google.com/patent/US8494689B1/en'
p3437
aS'https://patents.google.com/patent/US20150045992A1/en'
p3438
aS'https://patents.google.com/patent/US20140077969A1/en'
p3439
aS'https://patents.google.com/patent/US9201426B1/en'
p3440
aS'https://patents.google.com/patent/US20160122038A1/en'
p3441
aS'https://patents.google.com/patent/US20140239602A1/en'
p3442
aS'https://patents.google.com/patent/US20130325202A1/en'
p3443
aS'https://patents.google.com/patent/US20150228195A1/en'
p3444
aS'https://patents.google.com/patent/US8874356B1/en'
p3445
aS'https://patents.google.com/patent/US9201424B1/en'
p3446
aS'https://patents.google.com/patent/US20150350914A1/en'
p3447
aS'https://patents.google.com/patent/US20130253753A1/en'
p3448
aS'https://patents.google.com/patent/US9176500B1/en'
p3449
aS'https://patents.google.com/patent/US20160357192A1/en'
p3450
aS'https://patents.google.com/patent/US9483948B1/en'
p3451
aS'https://patents.google.com/patent/US20140111325A1/en'
p3452
aS'https://patents.google.com/patent/US9307383B1/en'
p3453
aS'https://patents.google.com/patent/US20140244125A1/en'
p3454
aS'https://patents.google.com/patent/US20150088360A1/en'
p3455
aS'https://patents.google.com/patent/US20140081573A1/en'
p3456
aS'https://patents.google.com/patent/US20160129999A1/en'
p3457
aS'https://patents.google.com/patent/US20150370255A1/en'
p3458
aS'https://patents.google.com/patent/US20140320318A1/en'
p3459
aS'https://patents.google.com/patent/US20140225990A1/en'
p3460
aS'https://patents.google.com/patent/US20150339589A1/en'
p3461
aS'https://patents.google.com/patent/US20140018994A1/en'
p3462
aS'https://patents.google.com/patent/US20140088781A1/en'
p3463
aS'https://patents.google.com/patent/US20150246673A1/en'
p3464
aS'https://patents.google.com/patent/US20150131080A1/en'
p3465
aS'https://patents.google.com/patent/US9083425B1/en'
p3466
aS'https://patents.google.com/patent/US20130206921A1/en'
p3467
aS'https://patents.google.com/patent/US9495874B1/en'
p3468
aS'https://patents.google.com/patent/US20140218187A1/en'
p3469
aS'https://patents.google.com/patent/US20140139116A1/en'
p3470
aS'https://patents.google.com/patent/US9097800B1/en'
p3471
aS'https://patents.google.com/patent/US20160001883A1/en'
p3472
aS'https://patents.google.com/patent/US9524648B1/en'
p3473
aS'https://patents.google.com/patent/US20150025731A1/en'
p3474
aS'https://patents.google.com/patent/US20160221683A1/en'
p3475
aS'https://patents.google.com/patent/US20160039541A1/en'
p3476
aS'https://patents.google.com/patent/US20160275801A1/en'
p3477
aS'https://patents.google.com/patent/US20150253775A1/en'
p3478
aS'https://patents.google.com/patent/US20160036558A1/en'
p3479
aS'https://patents.google.com/patent/US20140140575A1/en'
p3480
aS'https://patents.google.com/patent/US20130219294A1/en'
p3481
aS'https://patents.google.com/patent/US20140022051A1/en'
p3482
aS'https://patents.google.com/patent/US8914225B2/en'
p3483
aS'https://patents.google.com/patent/US20160016506A1/en'
p3484
aS'https://patents.google.com/patent/US9085362B1/en'
p3485
aS'https://patents.google.com/patent/US20140156157A1/en'
p3486
aS'https://patents.google.com/patent/US20160125735A1/en'
p3487
aS'https://patents.google.com/patent/US20140195114A1/en'
p3488
aS'https://patents.google.com/patent/US8855849B1/en'
p3489
aS'https://patents.google.com/patent/US20150234387A1/en'
p3490
aS'https://patents.google.com/patent/US20160301698A1/en'
p3491
aS'https://patents.google.com/patent/US20150142246A1/en'
p3492
aS'https://patents.google.com/patent/US20140136187A1/en'
p3493
aS'https://patents.google.com/patent/US20140052323A1/en'
p3494
aS'https://patents.google.com/patent/US8830322B2/en'
p3495
aS'https://patents.google.com/patent/US20160179096A1/en'
p3496
aS'https://patents.google.com/patent/US20160247095A1/en'
p3497
aS'https://patents.google.com/patent/US20140263851A1/en'
p3498
aS'https://patents.google.com/patent/US20160260328A1/en'
p3499
aS'https://patents.google.com/patent/US20150032293A1/en'
p3500
aS'https://patents.google.com/patent/US20150153175A1/en'
p3501
aS'https://patents.google.com/patent/US20150101519A1/en'
p3502
aS'https://patents.google.com/patent/US20160318490A1/en'
p3503
aS'https://patents.google.com/patent/US20150274294A1/en'
p3504
aS'https://patents.google.com/patent/US20160144734A1/en'
p3505
aS'https://patents.google.com/patent/US9186793B1/en'
p3506
aS'https://patents.google.com/patent/US20140309836A1/en'
p3507
aS'https://patents.google.com/patent/US20160150427A1/en'
p3508
aS'https://patents.google.com/patent/US9151628B1/en'
p3509
aS'https://patents.google.com/patent/US20130238181A1/en'
p3510
aS'https://patents.google.com/patent/US9501061B2/en'
p3511
aS'https://patents.google.com/patent/US20140253722A1/en'
p3512
aS'https://patents.google.com/patent/US20150260530A1/en'
p3513
aS'https://patents.google.com/patent/US20140111332A1/en'
p3514
aS'https://patents.google.com/patent/US20150253772A1/en'
p3515
aS'https://patents.google.com/patent/US20130191189A1/en'
p3516
aS'https://patents.google.com/patent/US9063549B1/en'
p3517
aS'https://patents.google.com/patent/US20130342333A1/en'
p3518
aS'https://patents.google.com/patent/US20160146618A1/en'
p3519
aS'https://patents.google.com/patent/US20160161270A1/en'
p3520
aS'https://patents.google.com/patent/US9128190B1/en'
p3521
aS'https://patents.google.com/patent/US20150088358A1/en'
p3522
aS'https://patents.google.com/patent/US20150274178A1/en'
p3523
aS'https://patents.google.com/patent/US9286520B1/en'
p3524
aS'https://patents.google.com/patent/US20160147223A1/en'
p3525
aS'https://patents.google.com/patent/US9336436B1/en'
p3526
aS'https://patents.google.com/patent/US20150266489A1/en'
p3527
aS'https://patents.google.com/patent/US20150217763A1/en'
p3528
aS'https://patents.google.com/patent/US9405293B2/en'
p3529
aS'https://patents.google.com/patent/US9085354B1/en'
p3530
aS'https://patents.google.com/patent/US9384402B1/en'
p3531
aS'https://patents.google.com/patent/US20150286218A1/en'
p3532
aS'https://patents.google.com/patent/US20150203023A1/en'
p3533
aS'https://patents.google.com/patent/US20160282874A1/en'
p3534
aS'https://patents.google.com/patent/US20150336547A1/en'
p3535
aS'https://patents.google.com/patent/US20150233719A1/en'
p3536
aS'https://patents.google.com/patent/US20160003636A1/en'
p3537
aS'https://patents.google.com/patent/US20150266575A1/en'
p3538
aS'https://patents.google.com/patent/US9080866B1/en'
p3539
aS'https://patents.google.com/patent/US20160063987A1/en'
p3540
aS'https://patents.google.com/patent/US20140365228A1/en'
p3541
aS'https://patents.google.com/patent/US20160061612A1/en'
p3542
aS'https://patents.google.com/patent/US9123034B2/en'
p3543
aS'https://patents.google.com/patent/US20160117853A1/en'
p3544
aS'https://patents.google.com/patent/US20170069214A1/en'
p3545
aS'https://patents.google.com/patent/US20160076892A1/en'
p3546
aS'https://patents.google.com/patent/US20140345511A1/en'
p3547
aS'https://patents.google.com/patent/US20140379228A1/en'
p3548
aS'https://patents.google.com/patent/US20160357262A1/en'
p3549
aS'https://patents.google.com/patent/US20150205298A1/en'
p3550
aS'https://patents.google.com/patent/US20130190982A1/en'
p3551
aS'https://patents.google.com/patent/US20140111324A1/en'
p3552
aS'https://patents.google.com/patent/US9134731B2/en'
p3553
aS'https://patents.google.com/patent/US20160091899A1/en'
p3554
aS'https://patents.google.com/patent/US20160327950A1/en'
p3555
aS'https://patents.google.com/patent/US20140229411A1/en'
p3556
aS'https://patents.google.com/patent/US20160252903A1/en'
p3557
aS'https://patents.google.com/patent/US8583520B1/en'
p3558
aS'https://patents.google.com/patent/US20150353094A1/en'
p3559
aS'https://patents.google.com/patent/US20150346724A1/en'
p3560
aS'https://patents.google.com/patent/US20140016858A1/en'
p3561
aS'https://patents.google.com/patent/US20160304122A1/en'
p3562
aS'https://patents.google.com/patent/US20150348112A1/en'
p3563
aS'https://patents.google.com/patent/US20140218527A1/en'
p3564
aS'https://patents.google.com/patent/US9428183B2/en'
p3565
aS'https://patents.google.com/patent/US20140177387A1/en'
p3566
aS'https://patents.google.com/patent/US9646428B1/en'
p3567
aS'https://patents.google.com/patent/US20150339826A1/en'
p3568
aS'https://patents.google.com/patent/US20150158486A1/en'
p3569
aS'https://patents.google.com/patent/US20150251664A1/en'
p3570
aS'https://patents.google.com/patent/US20140193066A1/en'
p3571
aS'https://patents.google.com/patent/US8812186B2/en'
p3572
aS'https://patents.google.com/patent/US8588991B1/en'
p3573
aS'https://patents.google.com/patent/US20150023668A1/en'
p3574
aS'https://patents.google.com/patent/US20140132082A1/en'
p3575
aS'https://patents.google.com/patent/US9278689B1/en'
p3576
aS'https://patents.google.com/patent/US20160176397A1/en'
p3577
aS'https://patents.google.com/patent/US20170038775A1/en'
p3578
aS'https://patents.google.com/patent/US20140172290A1/en'
p3579
aS'https://patents.google.com/patent/US20140365062A1/en'
p3580
aS'https://patents.google.com/patent/US20150237791A1/en'
p3581
aS'https://patents.google.com/patent/US20150163993A1/en'
p3582
aS'https://patents.google.com/patent/US20150286219A1/en'
p3583
aS'https://patents.google.com/patent/US20150266488A1/en'
p3584
aS'https://patents.google.com/patent/US20160018229A1/en'
p3585
aS'https://patents.google.com/patent/US9517767B1/en'
p3586
aS'https://patents.google.com/patent/US9465388B1/en'
p3587
aS'https://patents.google.com/patent/US20140249718A1/en'
p3588
aS'https://patents.google.com/patent/US20150170526A1/en'
p3589
aS'https://patents.google.com/patent/US20130190983A1/en'
p3590
aS'https://patents.google.com/patent/US20150134202A1/en'
p3591
aS'https://patents.google.com/patent/US20150088357A1/en'
p3592
aS'https://patents.google.com/patent/US9384666B1/en'
p3593
aS'https://patents.google.com/patent/US20150103159A1/en'
p3594
aS'https://patents.google.com/patent/US20150266490A1/en'
p3595
aS'https://patents.google.com/patent/US20150149263A1/en'
p3596
aS'https://patents.google.com/patent/US20150012165A1/en'
p3597
aS'https://patents.google.com/patent/US20140052336A1/en'
p3598
aS'https://patents.google.com/patent/US9451020B2/en'
p3599
aS'https://patents.google.com/patent/US20140277788A1/en'
p3600
aS'https://patents.google.com/patent/US20130168497A1/en'
p3601
aS'https://patents.google.com/patent/US9630619B1/en'
p3602
aS'https://patents.google.com/patent/US8989943B2/en'
p3603
aS'https://patents.google.com/patent/US20160189435A1/en'
p3604
aS'https://patents.google.com/patent/US20160364989A1/en'
p3605
aS'https://patents.google.com/patent/US20150012167A1/en'
p3606
aS'https://patents.google.com/patent/US20150051779A1/en'
p3607
aS'https://patents.google.com/patent/US20130338825A1/en'
p3608
aS'https://patents.google.com/patent/US20150307191A1/en'
p3609
aS'https://patents.google.com/patent/US20150142247A1/en'
p3610
aS'https://patents.google.com/patent/US20150316386A1/en'
p3611
aS'https://patents.google.com/patent/US8838322B1/en'
p3612
aS'https://patents.google.com/patent/US9010678B1/en'
p3613
aS'https://patents.google.com/patent/US9449512B2/en'
p3614
aS'https://patents.google.com/patent/US20150293534A1/en'
p3615
aS'https://patents.google.com/patent/US20170008521A1/en'
p3616
aS'https://patents.google.com/patent/US20150261219A1/en'
p3617
aS'https://patents.google.com/patent/US9547986B1/en'
p3618
aS'https://patents.google.com/patent/US9047568B1/en'
p3619
aS'https://patents.google.com/patent/US20170090476A1/en'
p3620
aS'https://patents.google.com/patent/US9494439B1/en'
p3621
aS'https://patents.google.com/patent/US9535423B1/en'
p3622
aS'https://patents.google.com/patent/US9033089B2/en'
p3623
aS'https://patents.google.com/patent/US9494938B1/en'
p3624
aS'https://patents.google.com/patent/US20160129917A1/en'
p3625
aS'https://patents.google.com/patent/US20150246672A1/en'
p3626
aS'https://patents.google.com/patent/US20160116912A1/en'
p3627
aS'https://patents.google.com/patent/US20170010613A1/en'
p3628
aS'https://patents.google.com/patent/US9507346B1/en'
p3629
aS'https://patents.google.com/patent/US9189961B2/en'
p3630
aS'https://patents.google.com/patent/US20150251656A1/en'
p3631
aS'https://patents.google.com/patent/US20150019094A1/en'
p3632
aS'https://patents.google.com/patent/US20140283726A1/en'
p3633
aS'https://patents.google.com/patent/US20150241241A1/en'
p3634
aS'https://patents.google.com/patent/US20150345966A1/en'
p3635
aS'https://patents.google.com/patent/US9373045B1/en'
p3636
aS'https://patents.google.com/patent/US20150379468A1/en'
p3637
aS'https://patents.google.com/patent/US20170057542A1/en'
p3638
aS'https://patents.google.com/patent/US20140321236A1/en'
p3639
aS'https://patents.google.com/patent/US20150221222A1/en'
p3640
aS'https://patents.google.com/patent/US20160370194A1/en'
p3641
aS'https://patents.google.com/patent/US9551992B1/en'
p3642
aS'https://patents.google.com/patent/US9616896B1/en'
p3643
aS'https://patents.google.com/patent/US20160334230A1/en'
p3644
aS'https://patents.google.com/patent/US20160054737A1/en'
p3645
aS'https://patents.google.com/patent/US20150348335A1/en'
p3646
aS'https://patents.google.com/patent/US20150105933A1/en'
p3647
aS'https://patents.google.com/patent/US20150110344A1/en'
p3648
aS'https://patents.google.com/patent/US8880275B1/en'
p3649
aS'https://patents.google.com/patent/US9400500B2/en'
p3650
aS'https://patents.google.com/patent/US20150241880A1/en'
p3651
aS'https://patents.google.com/patent/US20130320212A1/en'
p3652
aS'https://patents.google.com/patent/US20150210279A1/en'
p3653
aS'https://patents.google.com/patent/US9363690B1/en'
p3654
aS'https://patents.google.com/patent/US9488979B1/en'
p3655
aS'https://patents.google.com/patent/US20150321641A1/en'
p3656
aS'https://patents.google.com/patent/US9552564B1/en'
p3657
aS'https://patents.google.com/patent/US9043072B1/en'
p3658
aS'https://patents.google.com/patent/US20150081188A1/en'
p3659
aS'https://patents.google.com/patent/US9315178B1/en'
p3660
aS'https://patents.google.com/patent/US9256852B1/en'
p3661
aS'https://patents.google.com/patent/US20150234384A1/en'
p3662
aS'https://patents.google.com/patent/US9522699B2/en'
p3663
aS'https://patents.google.com/patent/US20160116913A1/en'
p3664
aS'https://patents.google.com/patent/US20150235480A1/en'
p3665
aS'https://patents.google.com/patent/US9261590B1/en'
p3666
aS'https://patents.google.com/patent/US9199553B2/en'
p3667
aS'https://patents.google.com/patent/US20160232795A1/en'
p3668
aS'https://patents.google.com/patent/US20160090100A1/en'
p3669
aS'https://patents.google.com/patent/US20160358475A1/en'
p3670
aS'https://patents.google.com/patent/US20160176398A1/en'
p3671
aS'https://patents.google.com/patent/US20140207336A1/en'
p3672
aS'https://patents.google.com/patent/US9349284B2/en'
p3673
aS'https://patents.google.com/patent/US20140149011A1/en'
p3674
aS'https://patents.google.com/patent/US20170212511A1/en'
p3675
aS'https://patents.google.com/patent/US20160362113A1/en'
p3676
aS'https://patents.google.com/patent/US8994581B1/en'
p3677
aS'https://patents.google.com/patent/US9244462B2/en'
p3678
aS'https://patents.google.com/patent/US8903620B2/en'
p3679
aS'https://patents.google.com/patent/US20160259330A1/en'
p3680
aS'https://patents.google.com/patent/US20140350812A1/en'
p3681
aS'https://patents.google.com/patent/US20150137564A1/en'
p3682
aS'https://patents.google.com/patent/US20150100190A1/en'
p3683
aS'https://patents.google.com/patent/US9043088B2/en'
p3684
aS'https://patents.google.com/patent/US20160362045A1/en'
p3685
aS'https://patents.google.com/patent/US20130267377A1/en'
p3686
aS'https://patents.google.com/patent/US20160221500A1/en'
p3687
aS'https://patents.google.com/patent/US20140160885A1/en'
p3688
aS'https://patents.google.com/patent/US20150298738A1/en'
p3689
aS'https://patents.google.com/patent/US20150345971A1/en'
p3690
aS'https://patents.google.com/patent/US20160129908A1/en'
p3691
aS'https://patents.google.com/patent/US20170199523A1/en'
p3692
aS'https://patents.google.com/patent/US9224053B1/en'
p3693
aS'https://patents.google.com/patent/US9454154B1/en'
p3694
aS'https://patents.google.com/patent/US20170124781A1/en'
p3695
aS'https://patents.google.com/patent/US20170132934A1/en'
p3696
aS'https://patents.google.com/patent/US20170120753A1/en'
p3697
aS'https://patents.google.com/patent/US20150345967A1/en'
p3698
aS'https://patents.google.com/patent/US20160121983A1/en'
p3699
aS'https://patents.google.com/patent/US9511767B1/en'
p3700
aS'https://patents.google.com/patent/US20150259007A1/en'
p3701
aS'https://patents.google.com/patent/US20160068158A1/en'
p3702
aS'https://patents.google.com/patent/US9499202B2/en'
p3703
aS'https://patents.google.com/patent/US9043071B1/en'
p3704
aS'https://patents.google.com/patent/US20150336587A1/en'
p3705
aS'https://patents.google.com/patent/US9355562B1/en'
p3706
aS'https://patents.google.com/patent/US20140041713A1/en'
p3707
aS'https://patents.google.com/patent/US9707960B2/en'
p3708
aS'https://patents.google.com/patent/US20160068156A1/en'
p3709
aS'https://patents.google.com/patent/US20160221573A1/en'
p3710
aS'https://patents.google.com/patent/US9682707B1/en'
p3711
aS'https://patents.google.com/patent/US9796421B1/en'
p3712
aS'https://patents.google.com/patent/US20160273922A1/en'
p3713
aS'https://patents.google.com/patent/US20170166222A1/en'
p3714
aS'https://patents.google.com/patent/US20160362084A1/en'
p3715
aS'https://patents.google.com/patent/US20160033965A1/en'
p3716
aS'https://patents.google.com/patent/US20170036678A1/en'
p3717
aS'https://patents.google.com/patent/US20160161602A1/en'
p3718
aS'https://patents.google.com/patent/US20170057496A1/en'
p3719
aS'https://patents.google.com/patent/US8775013B1/en'
p3720
aS'https://patents.google.com/patent/US20150356665A1/en'
p3721
aS'https://patents.google.com/patent/US9475491B1/en'
p3722
aS'https://patents.google.com/patent/US9663025B2/en'
p3723
aS'https://patents.google.com/patent/US20170043768A1/en'
p3724
aS'https://patents.google.com/patent/US20170097645A1/en'
p3725
aS'https://patents.google.com/patent/US20170315557A1/en'
p3726
aS'https://patents.google.com/patent/US20170193627A1/en'
p3727
aS'https://patents.google.com/patent/US20170146995A1/en'
p3728
aS'https://patents.google.com/patent/US20170297576A1/en'
p3729
aS'https://patents.google.com/patent/US9625904B2/en'
p3730
aS'https://patents.google.com/patent/US20170147959A1/en'
p3731
aS'https://patents.google.com/patent/US9672734B1/en'
p3732
aS'https://patents.google.com/patent/US20150307089A1/en'
p3733
aS'https://patents.google.com/patent/US20150088374A1/en'
p3734
aS'https://patents.google.com/patent/US20170168485A1/en'
p3735
aS'https://patents.google.com/patent/US20170110022A1/en'
p3736
aS'https://patents.google.com/patent/US20160257303A1/en'
p3737
aS'https://patents.google.com/patent/US20170132334A1/en'
p3738
aS'https://patents.google.com/patent/US20160179093A1/en'
p3739
aS'https://patents.google.com/patent/US20140136043A1/en'
p3740
aS'https://patents.google.com/patent/US20170158175A1/en'
p3741
aS'https://patents.google.com/patent/US20160075369A1/en'
p3742
aS'https://patents.google.com/patent/US20160114831A1/en'
p3743
aS'https://patents.google.com/patent/US20160288831A1/en'
p3744
aS'https://patents.google.com/patent/US9654738B1/en'
p3745
aS'https://patents.google.com/patent/US20150309510A1/en'
p3746
aS'https://patents.google.com/patent/US9778653B1/en'
p3747
aS'https://patents.google.com/patent/US9720412B1/en'
p3748
aS'https://patents.google.com/patent/US20160210757A1/en'
p3749
aS'https://patents.google.com/patent/US20160236638A1/en'
p3750
aS'https://patents.google.com/patent/US9616886B2/en'
p3751
aS'https://patents.google.com/patent/US20140131977A1/en'
p3752
aS'https://patents.google.com/patent/US20170241184A1/en'
p3753
aS'https://patents.google.com/patent/US20160144867A1/en'
p3754
aS'https://patents.google.com/patent/US9368026B1/en'
p3755
aS'https://patents.google.com/patent/US9557183B1/en'
p3756
aS'https://patents.google.com/patent/US9457684B2/en'
p3757
aS'https://patents.google.com/patent/US9162569B2/en'
p3758
aS'https://patents.google.com/patent/US20170267256A1/en'
p3759
aS'https://patents.google.com/patent/US9587952B1/en'
p3760
aS'https://patents.google.com/patent/US20150168953A1/en'
p3761
aS'https://patents.google.com/patent/US9809158B2/en'
p3762
aS'https://patents.google.com/patent/US9684306B2/en'
p3763
aS'https://patents.google.com/patent/US9582003B1/en'
p3764
aS'https://patents.google.com/patent/US20150094897A1/en'
p3765
aS'https://patents.google.com/patent/US20170253241A1/en'
p3766
aS'https://patents.google.com/patent/US20160328976A1/en'
p3767
aS'https://patents.google.com/patent/US20150266576A1/en'
p3768
aS'https://patents.google.com/patent/US9481459B2/en'
p3769
aS'https://patents.google.com/patent/US20150274169A1/en'
p3770
aS'https://patents.google.com/patent/US20170123422A1/en'
p3771
aS'https://patents.google.com/patent/US9682609B1/en'
p3772
aS'https://patents.google.com/patent/US20170126810A1/en'
p3773
aS'https://patents.google.com/patent/US9528838B2/en'
p3774
aS'https://patents.google.com/patent/US9493158B2/en'
p3775
aS'https://patents.google.com/patent/US20160121918A1/en'
p3776
aS'https://patents.google.com/patent/US20150187216A1/en'
p3777
aS'https://patents.google.com/patent/US9802638B1/en'
p3778
aS'https://patents.google.com/patent/US9663118B1/en'
p3779
aS'https://patents.google.com/patent/US20170168503A1/en'
p3780
aS'https://patents.google.com/patent/US20160375901A1/en'
p3781
aS'https://patents.google.com/patent/US9535422B2/en'
p3782
aS'https://patents.google.com/patent/US20150073638A1/en'
p3783
aS'https://patents.google.com/patent/US20150329111A1/en'
p3784
aS'https://patents.google.com/patent/US20150046076A1/en'
p3785
aS'https://patents.google.com/patent/US20170192429A1/en'
p3786
aS'https://patents.google.com/patent/US20170129487A1/en'
p3787
aS'https://patents.google.com/patent/US20160378112A1/en'
p3788
aS'https://patents.google.com/patent/US9811085B1/en'
p3789
aS'https://patents.google.com/patent/US20140057237A1/en'
p3790
aS'https://patents.google.com/patent/US20170167881A1/en'
p3791
aS'https://patents.google.com/patent/US20170247040A1/en'
p3792
aS'https://patents.google.com/patent/US20150367886A1/en'
p3793
aS'https://patents.google.com/patent/US20170192423A1/en'
p3794
aS'https://patents.google.com/patent/US9568915B1/en'
p3795
aS'https://patents.google.com/patent/US9804599B2/en'
p3796
aS'https://patents.google.com/patent/US20160016619A1/en'
p3797
aS'https://patents.google.com/patent/US9672446B1/en'
p3798
aS'https://patents.google.com/patent/US20150343900A1/en'
p3799
aS'https://patents.google.com/patent/US20150073658A1/en'
p3800
aS'https://patents.google.com/patent/US9260092B1/en'
p3801
aS'https://patents.google.com/patent/US9400187B2/en'
p3802
aS'https://patents.google.com/patent/US9606539B1/en'
p3803
aS'https://patents.google.com/patent/US20170242442A1/en'
p3804
aS'https://patents.google.com/patent/US9796529B1/en'
p3805
aS'https://patents.google.com/patent/US20170090478A1/en'
p3806
aS'https://patents.google.com/patent/US20160159368A1/en'
p3807
aS'https://patents.google.com/patent/US20160347327A1/en'
p3808
aS'https://patents.google.com/patent/US20170277182A1/en'
p3809
aS'https://patents.google.com/patent/US20170261988A1/en'
p3810
aS'https://patents.google.com/patent/US20140291480A1/en'
p3811
aS'https://patents.google.com/patent/US20160046287A1/en'
p3812
aS'https://patents.google.com/patent/US9139241B1/en'
p3813
aS'https://patents.google.com/patent/US9720415B2/en'
p3814
aS'https://patents.google.com/patent/US20170031015A1/en'
p3815
aS'https://patents.google.com/patent/US20160178382A1/en'
p3816
aS'https://patents.google.com/patent/US9772197B2/en'
p3817
aS'https://patents.google.com/patent/US20160025505A1/en'
p3818
aS'https://patents.google.com/patent/US20170197626A1/en'
p3819
aS'https://patents.google.com/patent/US20170308082A1/en'
p3820
aS'https://patents.google.com/patent/US20170276494A1/en'
p3821
aS'https://patents.google.com/patent/US20160059881A1/en'
p3822
aS'https://patents.google.com/patent/US20170151959A1/en'
p3823
aS'https://patents.google.com/patent/US20170174221A1/en'
p3824
aS'https://patents.google.com/patent/US20150239298A1/en'
p3825
aS'https://patents.google.com/patent/US20170072812A1/en'
p3826
aS'https://patents.google.com/patent/US20170297586A1/en'
p3827
aS'https://patents.google.com/patent/US20170080933A1/en'
p3828
aS'https://patents.google.com/patent/US20170248957A1/en'
p3829
aS'https://patents.google.com/patent/US9529357B1/en'
p3830
aS'https://patents.google.com/patent/US20150266467A1/en'
p3831
aS'https://patents.google.com/patent/US20170277191A1/en'
p3832
aS'https://patents.google.com/patent/US9789880B2/en'
p3833
aS'https://patents.google.com/patent/US9613386B1/en'
p3834
aS'https://patents.google.com/patent/US20160167653A1/en'
p3835
aS'https://patents.google.com/patent/US20170123421A1/en'
p3836
aS'https://patents.google.com/patent/US20170234689A1/en'
p3837
aS'https://patents.google.com/patent/US20170259753A1/en'
p3838
aS'https://patents.google.com/patent/US20160200235A1/en'
p3839
aS'https://patents.google.com/patent/US20170057514A1/en'
p3840
aS'https://patents.google.com/patent/US20170297569A1/en'
p3841
aS'https://patents.google.com/patent/US20150100191A1/en'
p3842
aS'https://patents.google.com/patent/US20170057520A1/en'
p3843
aS'https://patents.google.com/patent/US20170267233A1/en'
p3844
aS'https://patents.google.com/patent/US20170293306A1/en'
p3845
aS'https://patents.google.com/patent/US20170090480A1/en'
p3846
aS'https://patents.google.com/patent/US9310808B2/en'
p3847
aS'https://patents.google.com/patent/US20170221366A1/en'
p3848
aS'https://patents.google.com/patent/US20160167648A1/en'
p3849
aS'https://patents.google.com/patent/US9626874B1/en'
p3850
aS'https://patents.google.com/patent/US20130332061A1/en'
p3851
aS'https://patents.google.com/patent/US20170320500A1/en'
p3852
aS'https://patents.google.com/patent/US20170284819A1/en'
p3853
aS'https://patents.google.com/patent/US20170285642A1/en'
p3854
aS'https://patents.google.com/patent/US20150298694A1/en'
p3855
aS'https://patents.google.com/patent/US20150253536A1/en'
p3856
aS'https://patents.google.com/patent/US20140114521A1/en'
p3857
aS'https://patents.google.com/patent/US20170068245A1/en'
p3858
aS'https://patents.google.com/patent/US9679490B2/en'
p3859
aS'https://patents.google.com/patent/US20170300855A1/en'
p3860
aS'https://patents.google.com/patent/US20150094944A1/en'
p3861
aS'https://patents.google.com/patent/US20160314224A1/en'
p3862
aS'https://patents.google.com/patent/US20170301239A1/en'
p3863
aS'https://patents.google.com/patent/US20170213164A1/en'
p3864
aS'https://patents.google.com/patent/US20170203766A1/en'
p3865
aS'https://patents.google.com/patent/US20170123429A1/en'
p3866
aS'https://patents.google.com/patent/US9368936B1/en'
p3867
aS'https://patents.google.com/patent/US20170072967A1/en'
p3868
aS'https://patents.google.com/patent/US20160349755A1/en'
p3869
aS'https://patents.google.com/patent/US20140244131A1/en'
p3870
aS'https://patents.google.com/patent/US20170240096A1/en'
p3871
aS'https://patents.google.com/patent/US20160375767A1/en'
p3872
aS'https://patents.google.com/patent/US20160375768A1/en'
p3873
aS'https://patents.google.com/patent/US8903607B2/en'
p3874
aS'https://patents.google.com/patent/US20160046230A1/en'
p3875
aS'https://patents.google.com/patent/US20160229252A1/en'
p3876
aS'https://patents.google.com/patent/US9274526B2/en'
p3877
aS'https://patents.google.com/patent/US20170158227A1/en'
p3878
aS'https://patents.google.com/patent/US20170297588A1/en'
p3879
aS'https://patents.google.com/patent/US9576185B1/en'
p3880
aS'https://patents.google.com/patent/US20150064138A1/en'
p3881
aS'https://patents.google.com/patent/US20170297565A1/en'
p3882
aS'https://patents.google.com/patent/US20170225581A1/en'
p3883
aS'https://patents.google.com/patent/US20150183426A1/en'
p3884
aS'https://patents.google.com/patent/US20170139411A1/en'
p3885
aS'https://patents.google.com/patent/US20170097640A1/en'
p3886
aS'https://patents.google.com/patent/US20150166061A1/en'
p3887
aS'https://patents.google.com/patent/US9141109B1/en'
p3888
aS'https://patents.google.com/patent/US20170101032A1/en'
p3889
aS'https://patents.google.com/patent/US20160259335A1/en'
p3890
aS'https://patents.google.com/patent/US20170080900A1/en'
p3891
aS'https://patents.google.com/patent/US9786187B1/en'
p3892
aS'https://patents.google.com/patent/US20170103270A1/en'
p3893
aS'https://patents.google.com/patent/US20170227960A1/en'
p3894
aS'https://patents.google.com/patent/US20160288785A1/en'
p3895
aS'https://patents.google.com/patent/US20170132117A1/en'
p3896
aS'https://patents.google.com/patent/US20170225567A1/en'
p3897
aS'https://patents.google.com/patent/US20160159348A1/en'
p3898
aS'https://patents.google.com/patent/US20170225578A1/en'
p3899
aS'https://patents.google.com/patent/US20170074964A1/en'
p3900
aS'https://patents.google.com/patent/US20130185888A1/en'
p3901
aS'https://patents.google.com/patent/US20150129713A1/en'
p3902
aS'https://patents.google.com/patent/US20170108867A1/en'
p3903
aS'https://patents.google.com/patent/US20150105960A1/en'
p3904
aS'https://patents.google.com/patent/US20160257341A1/en'
p3905
aS'https://patents.google.com/patent/US9349055B1/en'
p3906
aS'https://patents.google.com/patent/US20170315771A1/en'
p3907
aS'https://patents.google.com/patent/US9606535B2/en'
p3908
aS'https://patents.google.com/patent/US20170101130A1/en'
p3909
aS'https://patents.google.com/patent/US9393961B1/en'
p3910
aS'https://patents.google.com/patent/US20160023526A1/en'
p3911
aS'https://patents.google.com/patent/US20170253252A1/en'
p3912
aS'https://patents.google.com/patent/US20160023525A1/en'
p3913
aS'https://patents.google.com/patent/US20160001763A1/en'
p3914
aS'https://patents.google.com/patent/US20170316692A1/en'
p3915
aS'https://patents.google.com/patent/US20170309072A1/en'
p3916
aS'https://patents.google.com/patent/US20160304124A1/en'
p3917
aS'https://patents.google.com/patent/US20170132118A1/en'
p3918
aS'https://patents.google.com/patent/US20160155339A1/en'
p3919
aS'https://patents.google.com/patent/US20170286570A1/en'
p3920
aS'https://patents.google.com/patent/US20170029024A1/en'
p3921
aS'https://patents.google.com/patent/US20160075375A1/en'
p3922
aS'https://patents.google.com/patent/US20140245727A1/en'
p3923
aS'https://patents.google.com/patent/US20160288830A1/en'
p3924
aS'https://patents.google.com/patent/US20170285639A1/en'
p3925
aS'https://patents.google.com/patent/US9187088B1/en'
p3926
aS'https://patents.google.com/patent/US9227632B1/en'
p3927
aS'https://patents.google.com/patent/US20160298758A1/en'
p3928
aS'https://patents.google.com/patent/US20170269940A1/en'
p3929
aS'https://patents.google.com/patent/US20170272943A1/en'
p3930
aS'https://patents.google.com/patent/US20150120142A1/en'
p3931
aS'https://patents.google.com/patent/US20160205146A1/en'
p3932
aS'https://patents.google.com/patent/US9643466B1/en'
p3933
aS'https://patents.google.com/patent/US20170080948A1/en'
p3934
aS'https://patents.google.com/patent/US9785150B2/en'
p3935
aS'https://patents.google.com/patent/US20170113641A1/en'
p3936
aS'https://patents.google.com/patent/US20170311534A1/en'
p3937
aS'https://patents.google.com/patent/US20140379214A1/en'
p3938
aS'https://patents.google.com/patent/US20130313035A1/en'
p3939
aS'https://patents.google.com/patent/US9354034B2/en'
p3940
aS'https://patents.google.com/patent/US9643669B1/en'
p3941
aS'https://patents.google.com/patent/US20170080974A1/en'
p3942
aS'https://patents.google.com/patent/US20170088174A1/en'
p3943
aS'https://patents.google.com/patent/US9669677B2/en'
p3944
aS'https://patents.google.com/patent/US20170023945A1/en'
p3945
aS'https://patents.google.com/patent/US20160339910A1/en'
p3946
aS'https://patents.google.com/patent/US20170154371A1/en'
p3947
aS'https://patents.google.com/patent/US9533683B2/en'
p3948
aS'https://patents.google.com/patent/US8965691B1/en'
p3949
aS'https://patents.google.com/patent/US9676377B2/en'
p3950
aS'https://patents.google.com/patent/US9442487B1/en'
p3951
aS'https://patents.google.com/patent/US9527394B1/en'
p3952
aS'https://patents.google.com/patent/US20170113722A1/en'
p3953
aS'https://patents.google.com/patent/US9393857B1/en'
p3954
aS'https://patents.google.com/patent/US9540043B2/en'
p3955
aS'https://patents.google.com/patent/US9500565B2/en'
p3956
aS'https://patents.google.com/patent/US9227659B2/en'
p3957
aS'https://patents.google.com/patent/US20170302282A1/en'
p3958
aS'https://patents.google.com/patent/US20160347314A1/en'
p3959
aS'https://patents.google.com/patent/US20170240204A1/en'
p3960
aS'https://patents.google.com/patent/US20170291544A1/en'
p3961
aS'https://patents.google.com/patent/US20150137463A1/en'
p3962
aS'https://patents.google.com/patent/US20170316533A1/en'
p3963
aS'https://patents.google.com/patent/US20170270014A1/en'
p3964
aS'https://patents.google.com/patent/US20150226146A1/en'
p3965
aS'https://patents.google.com/patent/US20170297620A1/en'
p3966
aS'https://patents.google.com/patent/US20170225537A1/en'
p3967
aS'https://patents.google.com/patent/US20150217732A1/en'
p3968
aS'https://patents.google.com/patent/US20160257355A1/en'
p3969
aS'https://patents.google.com/patent/US9586620B2/en'
p3970
aS'https://patents.google.com/patent/US20160180714A1/en'
p3971
aS'https://patents.google.com/patent/US20170106865A1/en'
p3972
aS'https://patents.google.com/patent/US20160280262A1/en'
p3973
aS'https://patents.google.com/patent/US20160325721A1/en'
p3974
aS'https://patents.google.com/patent/US20170225679A1/en'
p3975
aS'https://patents.google.com/patent/US20140200770A1/en'
p3976
aS'https://patents.google.com/patent/US20170300063A1/en'
p3977
aS'https://patents.google.com/patent/US9623880B1/en'
p3978
aS'https://patents.google.com/patent/US20160362135A1/en'
p3979
aS'https://patents.google.com/patent/US20170088165A1/en'
p3980
aS'https://patents.google.com/patent/US20160214533A1/en'
p3981
aS'https://patents.google.com/patent/US20170219362A1/en'
p3982
aS'https://patents.google.com/patent/US9305223B1/en'
p3983
aS'https://patents.google.com/patent/US20170158270A1/en'
p3984
aS'https://patents.google.com/patent/US20160280258A1/en'
p3985
aS'https://patents.google.com/patent/US9789905B2/en'
p3986
aS'https://patents.google.com/patent/US9434415B2/en'
p3987
aS'https://patents.google.com/patent/US9694777B2/en'
p3988
aS'https://patents.google.com/patent/US20170282870A1/en'
p3989
aS'https://patents.google.com/patent/US20170129298A1/en'
p3990
aS'https://patents.google.com/patent/US20170227967A1/en'
p3991
aS'https://patents.google.com/patent/US9550497B2/en'
p3992
aS'https://patents.google.com/patent/US20140081522A1/en'
p3993
aS'https://patents.google.com/patent/US20160207528A1/en'
p3994
aS'https://patents.google.com/patent/US20160132055A1/en'
p3995
aS'https://patents.google.com/patent/US9731761B1/en'
p3996
aS'https://patents.google.com/patent/US9783231B2/en'
p3997
aS'https://patents.google.com/patent/US20160368336A1/en'
p3998
aS'https://patents.google.com/patent/US9178258B1/en'
p3999
aS'https://patents.google.com/patent/US20160195877A1/en'
p4000
aS'https://patents.google.com/patent/US20170259817A1/en'
p4001
aS'https://patents.google.com/patent/US20170101080A1/en'
p4002
aS'https://patents.google.com/patent/US20170287320A1/en'
p4003
aS'https://patents.google.com/patent/US9522624B1/en'
p4004
aS'https://patents.google.com/patent/US9475466B2/en'
p4005
aS'https://patents.google.com/patent/US9415646B1/en'
p4006
aS'https://patents.google.com/patent/US9662974B2/en'
p4007
aS'https://patents.google.com/patent/US9422012B2/en'
p4008
aS'https://patents.google.com/patent/US20170144646A1/en'
p4009
aS'https://patents.google.com/patent/US9630617B2/en'
p4010
aS'https://patents.google.com/patent/US9238490B1/en'
p4011
aS'https://patents.google.com/patent/US20170235306A1/en'
p4012
aS'https://patents.google.com/patent/US9558659B1/en'
p4013
aS'https://patents.google.com/patent/US9529364B2/en'
p4014
aS'https://patents.google.com/patent/US20160187884A1/en'
p4015
aS'https://patents.google.com/patent/US9371077B1/en'
p4016
aS'https://patents.google.com/patent/US9707937B2/en'
p4017
aS'https://patents.google.com/patent/US9409529B2/en'
p4018
aS'https://patents.google.com/patent/US9224300B2/en'
p4019
aS'https://patents.google.com/patent/US9707909B2/en'
p4020
aS'https://patents.google.com/patent/US20160347364A1/en'
p4021
aS'https://patents.google.com/patent/US8984706B2/en'
p4022
aS'https://patents.google.com/patent/US9469303B2/en'
p4023
aS'https://patents.google.com/patent/US20150291213A1/en'
p4024
aS'https://patents.google.com/patent/US20170096164A1/en'
p4025
aS'https://patents.google.com/patent/US20160375932A1/en'
p4026
aS'https://patents.google.com/patent/US9334003B2/en'
p4027
aS'https://patents.google.com/patent/US20160131753A1/en'
p4028
aS'https://patents.google.com/patent/US9463798B2/en'
p4029
aS'https://patents.google.com/patent/US20160121883A1/en'
p4030
aS'https://patents.google.com/patent/US9573623B2/en'
p4031
aS'https://patents.google.com/patent/US9677897B2/en'
p4032
aS'https://patents.google.com/patent/US9643604B2/en'
p4033
aS'https://patents.google.com/patent/US9333985B2/en'
p4034
aS'https://patents.google.com/patent/US20170206789A1/en'
p4035
aS'https://patents.google.com/patent/US9381818B2/en'
p4036
aS'https://patents.google.com/patent/US9669820B1/en'
p4037
aS'https://patents.google.com/patent/US20170166237A1/en'
p4038
aS'https://patents.google.com/patent/US9779314B1/en'
p4039
aS'https://patents.google.com/patent/US9546635B2/en'
p4040
aS'https://patents.google.com/patent/US20170174257A1/en'
p4041
aS'https://patents.google.com/patent/US20170247054A1/en'
p4042
aS'https://patents.google.com/patent/US20170101030A1/en'
p4043
aS'https://patents.google.com/patent/US9412028B2/en'
p4044
aS'https://patents.google.com/patent/US20160101701A1/en'
p4045
aS'https://patents.google.com/patent/US20170174210A1/en'
p4046
aS'https://patents.google.com/patent/US9335766B1/en'
p4047
aS'https://patents.google.com/patent/US20150158487A1/en'
p4048
aS'https://patents.google.com/patent/US9242674B2/en'
p4049
aS'https://patents.google.com/patent/US9573515B2/en'
p4050
aS'https://patents.google.com/patent/US20160142685A1/en'
p4051
aS'https://patents.google.com/patent/US20170166205A1/en'
p4052
aS'https://patents.google.com/patent/US9327699B2/en'
p4053
aS'https://patents.google.com/patent/US20170217276A1/en'
p4054
aS'https://patents.google.com/patent/US20170096139A1/en'
p4055
aS'https://patents.google.com/patent/US20160107620A1/en'
p4056
aS'https://patents.google.com/patent/US20170003686A1/en'
p4057
aS'https://patents.google.com/patent/US9475494B1/en'
p4058
aS'https://patents.google.com/patent/US20160332554A1/en'
p4059
aS'https://patents.google.com/patent/US20170297621A1/en'
p4060
aS'https://patents.google.com/patent/US20170106796A1/en'
p4061
aS'https://patents.google.com/patent/US20170158262A1/en'
p4062
aS'https://patents.google.com/patent/US20170240171A1/en'
p4063
aS'https://patents.google.com/patent/US20170021812A1/en'
p4064
aS'https://patents.google.com/patent/US20170247032A1/en'
p4065
aS'https://patents.google.com/patent/US20170192426A1/en'
p4066
aS'https://patents.google.com/patent/US20170113745A1/en'
p4067
aS'https://patents.google.com/patent/US20160297439A1/en'
p4068
aS'https://patents.google.com/patent/US20170015311A1/en'
p4069
aS'https://patents.google.com/patent/US20170210414A1/en'
p4070
aS'https://patents.google.com/patent/US20170197620A1/en'
p4071
aS'https://patents.google.com/patent/US20160364921A1/en'
p4072
aS'https://patents.google.com/patent/US20170268280A1/en'
p4073
aS'https://patents.google.com/patent/US20170302362A1/en'
p4074
aS'https://patents.google.com/patent/US20170101089A1/en'
p4075
aS'https://patents.google.com/patent/US20160194194A1/en'
p4076
aS'https://patents.google.com/patent/US20170158007A1/en'
p4077
aS'https://patents.google.com/patent/US20160274581A1/en'
p4078
aS'https://patents.google.com/patent/US20170101097A1/en'
p4079
aS'https://patents.google.com/patent/US20160293009A1/en'
p4080
aS'https://patents.google.com/patent/US20160031319A1/en'
p4081
aS'https://patents.google.com/patent/US20170305423A1/en'
p4082
aS'https://patents.google.com/patent/US20140316666A1/en'
p4083
aS'https://patents.google.com/patent/US20170151950A1/en'
p4084
aS'https://patents.google.com/patent/US20170197485A1/en'
p4085
aS'https://patents.google.com/patent/US20170004367A1/en'
p4086
aS'https://patents.google.com/patent/US20170158240A1/en'
p4087
aS'https://patents.google.com/patent/US20170308084A1/en'
p4088
aS'https://patents.google.com/patent/US20160114844A1/en'
p4089
aS'https://patents.google.com/patent/US20170129536A1/en'
p4090
aS'https://patents.google.com/patent/US20160325757A1/en'
p4091
aS'https://patents.google.com/patent/US20160297432A1/en'
p4092
aS'https://patents.google.com/patent/US20170299769A1/en'
p4093
aS'https://patents.google.com/patent/US20160272001A1/en'
p4094
aS'https://patents.google.com/patent/US20170084171A1/en'
p4095
aS'https://patents.google.com/patent/US20170210386A1/en'
p4096
aS'https://patents.google.com/patent/US20170226947A1/en'
p4097
aS'https://patents.google.com/patent/US20160018220A1/en'
p4098
aS'https://patents.google.com/patent/US20170287186A1/en'
p4099
aS'https://patents.google.com/patent/US20170101102A1/en'
p4100
aS'https://patents.google.com/patent/US20170267237A1/en'
p4101
aS'https://patents.google.com/patent/US20170106869A1/en'
p4102
aS'https://patents.google.com/patent/US20140058581A1/en'
p4103
aS'https://patents.google.com/patent/US20170087951A1/en'
p4104
aS'https://patents.google.com/patent/US20170066323A1/en'
p4105
aS'https://patents.google.com/patent/US20170234988A1/en'
p4106
aS'https://patents.google.com/patent/US20160272177A1/en'
p4107
aS'https://patents.google.com/patent/US20160236523A1/en'
p4108
aS'https://patents.google.com/patent/US20170102707A1/en'
p4109
aS'https://patents.google.com/patent/US20170174130A1/en'
p4110
aS'https://patents.google.com/patent/US20170160745A1/en'
p4111
aS'https://patents.google.com/patent/US20170158225A1/en'
p4112
aS'https://patents.google.com/patent/US20170028970A1/en'
p4113
aS'https://patents.google.com/patent/US20170247042A1/en'
p4114
aS'https://patents.google.com/patent/US20160375907A1/en'
p4115
aS'https://patents.google.com/patent/US20160264147A1/en'
p4116
aS'https://patents.google.com/patent/US20160264087A1/en'
p4117
aS'https://patents.google.com/patent/US20150232119A1/en'
p4118
aS'https://patents.google.com/patent/US20150339922A1/en'
p4119
aS'https://patents.google.com/patent/US20170213403A1/en'
p4120
aVAbstract\u000aA vehicle configured to operate in an autonomous mode could determine a current state of the vehicle and the current state of the environment of the vehicle. The environment of the vehicle includes at least one other vehicle. A predicted behavior of the at least one other vehicle could be determined based on the current state of the vehicle and the current state of the environment of the vehicle. A confidence level could also be determined based on the predicted behavior, the current state of the vehicle, and the current state of the environment of the vehicle. In some embodiments, the confidence level may be related to the likelihood of the at least one other vehicle to perform the predicted behavior. The vehicle in the autonomous mode could be controlled based on the predicted behavior, the confidence level, and the current state of the vehicle and its environment.
p4121
aVAbstract\u000aExample systems and methods enable an autonomous vehicle to request assistance from a remote operator in certain predetermined situations. One example method includes determining a representation of an environment of an autonomous vehicle based on sensor data of the environment. Based on the representation, the method may also include identifying a situation from a predetermined set of situations for which the autonomous vehicle will request remote assistance. The method may further include sending a request for assistance to a remote assistor, the request including the representation of the environment and the identified situation. The method may additionally include receiving a response from the remote assistor indicating an autonomous operation. The method may also include causing the autonomous vehicle to perform the autonomous operation.
p4122
aVAbstract\u000aAspects of the present disclosure relate generally to modeling a vehicle's view of its environment. This view need not include what objects or features the vehicle is actually seeing, but rather those areas that the vehicle is able to observe using its sensors if the sensors were completely un-occluded. For example, for each of a plurality of sensors of the object detection component, a computer may an individual 3D model of that sensor's field of view. Weather information is received and used to adjust one or more of the models. After this adjusting, the models may be aggregated into a comprehensive 3D model. The comprehensive model may be combined with detailed map information indicating the probability of detecting objects at different locations. A model of the vehicle's environment may be computed based on the combined comprehensive 3D model and detailed map information and may be used to maneuver the vehicle.
p4123
aVAbstract\u000aAspects of the present disclosure relate switching between autonomous and manual driving modes. In order to do so, the vehicle's computer may conduct a series of environmental, system, and driver checks to identify certain conditions. The computer may correct some of these conditions and also provide a driver with a checklist of tasks for completion. Once the tasks have been completed and the conditions are changed, the computer may allow the driver to switch from the manual to the autonomous driving mode. The computer may also make a determination, under certain conditions, that it would be detrimental to the driver's safety or comfort to make a switch from the autonomous driving mode to the manual driving mode.
p4124
aVAbstract\u000aIn one aspect, a vehicle's computing device may receive information identifying a client computing device, a pickup location, and an encryption key. When the vehicle is within a given distance of the pickup location, the computing device uses the encryption key to authenticate the client computing device. When the client computing device is authenticated, the computing device may estimate a first distance between the client computing device and the vehicle based on a strength of a signal received from the client computing device. The computing device may then automatically determine when to unlock the vehicle by selecting between a first distance value and a second distance value. The first value is selected when the first distance is greater than a threshold value, and the second value is selected when the first distance is less than the threshold value. The computing device may unlock the vehicle based on the determination.
p4125
aVAbstract\u000aAspects of the disclosure relate generally to detecting discrete actions by traveling vehicles. The features described improve the safety, use, driver experience, and performance of autonomously controlled vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, an autonomous vehicle is capable of detecting and tracking nearby vehicles and is able to determine when these nearby vehicles have performed actions of interest by comparing their tracked movements with map data.
p4126
aVAbstract\u000aDisclosed herein are methods and apparatus for generating accurate maps for autonomous vehicles. A map is stored at a computing device associated with a vehicle. The vehicle can be operated in a partially-autonomous mode, where the computing device can generate driving directions for manual execution along a route based on the map. The computing device can be configured to receive and store information related to features and a quality of driving along the route. The map can be updated and quality control statistics can be determined based on the stored information. The updated map can be promoted based on the quality control statistics. In response to promoting the updated map, the computing device can store the promoted map and enable the vehicle to operate in the autonomous-operation mode using the promoted map.
p4127
aVAbstract\u000aMethods and systems for adaptive methods for transitioning control to the driver are described. A computing device controlling a vehicle autonomously may be configured to receive a request for a transition of the vehicle from autonomous mode to manual mode through an indication by the driver. The computing device may determine the state of the vehicle based on parameters related to the autonomous operation of the vehicle. Based on the state of the vehicle and the indication, the computing device may determine instructions corresponding to the transition of control, which may include a strategy for the transition and duration of time corresponding to the transition of control. The computing device may provide the instructions to perform the transition of control of the vehicle from autonomous mode to manual mode.
p4128
aVAbstract\u000aA self-driving vehicle with an integrated fully-active suspension system. The fully-active suspension utilizes data from one or more sensors used for autonomous driving (e.g. vision, LIDAR, GPS) in order to anticipate road conditions in advance. The system builds a topographical map of the road surface. Suspension and road data is delivered back to the vehicle in order to change autonomous driving behavior including route planning. Energy storage is regulated based on a planned route. Forward and lateral acceleration feel is mitigated through active pitch and tilt compensation. The fully-active suspension pushes and pulls the suspension in three or more operational quadrants in order to deliver superior ride comfort, handling, and/safety of the vehicle.
p4129
aVAbstract\u000aAspects of the disclosure relate generally to determining whether an autonomous vehicle should be driven in an autonomous or semiautonomous mode (where steering, acceleration, and braking are controlled by the vehicle's computer). For example, a computer may maneuver a vehicle in an autonomous or a semiautonomous mode. The computer may continuously receive data from one or more sensors. This data may be processed to identify objects and the characteristics of the objects. The detected objects and their respective characteristics may be compared to a traffic pattern model and detailed map information. If the characteristics of the objects deviate from the traffic pattern model or detailed map information by more than some acceptable deviation threshold value, the computer may generate an alert to inform the driver of the need to take control of the vehicle or the computer may maneuver the vehicle in order to avoid any problems.
p4130
aVAbstract\u000aA transportation vehicle with an autonomous driving control has a set-up mode, an active drive mode, a safe shutdown mode, and an emergency response mode. The active drive mode autonomously navigates along a driving route specified in the set-up mode. A driver sensing system senses a driver presence in the driver seat and a driver's physiological state. Active drive mode is not entered from set-up mode unless the driver is present in the driver seat and the physiological state matches a normal condition. While in active driving mode, an elapsed time period is measured whenever the driver presence is not detected. If the time period increases above a first threshold then a notice is given to the driver that the active drive mode may be interrupted. If the time period increases above a second threshold then the active drive mode is terminated and the safe shutdown mode is initiated. A sensed physiological state is compared to a predetermined emergency condition and if a match is found then the autonomous driving control terminates the active drive mode and the emergency response mode is initiated.
p4131
aVAbstract\u000aA condition of an operator of a vehicle is detected. It is determined that the condition is an impaired condition. At least one autonomous operation is performed based on the impaired condition.
p4132
aVAbstract\u000aMethods and systems for predictive reasoning for controlling speed of a vehicle are described. A computing device may be configured to identify a first and second vehicle travelling ahead of an autonomous vehicle and in a same lane as the autonomous vehicle. The computing device may also be configured to determine a first buffer distance behind the first vehicle at which the autonomous vehicle will substantially reach a speed of the first vehicle and a second buffer distance behind the second vehicle at which the first vehicle will substantially reach a speed of the second vehicle. The computing device may further be configured to determine a distance at which to adjust a speed of the autonomous vehicle based on the first and second buffer distances and the speed of the autonomous vehicle, and then provide instructions to adjust the speed of the autonomous vehicle based on the distance.
p4133
aVAbstract\u000aMethods and apparatus are disclosed related to autonomous vehicle applications for selecting destinations. A control system of an autonomous vehicle can determine a status of the autonomous vehicle. The control system can determine a possible destination of the autonomous vehicle. The control system can generate and provide a hint related to the possible destination based on the status of the autonomous vehicle. The control system can receive input related to the hint. Based on the input, the control system can determine whether to navigate the autonomous vehicle to the possible destination. After determining to navigate the autonomous vehicle to the possible destination, the control system can direct the autonomous vehicle to travel to the possible destination.
p4134
aVAbstract\u000aA method for coordinating the paths of multiple autonomous vehicles and a vehicle configured to coordinate its path with the path(s) of other vehicles so as to enhance cooperation between the vehicles. The method also enables the vehicles to perform their respective missions more efficiently. The method is applicable to any system in which multiple autonomous vehicles may need to coordinate their paths with each other.
p4135
aVAbstract\u000aAn autonomous vehicle may determine to seek assistance navigating using a first trajectory. The autonomous vehicle may be configured to receive and store data about a plurality of obstacles. A particular obstacle in the plurality of obstacles may partially or wholly obstruct the first trajectory. The autonomous vehicle may select a portion of the stored data that includes data representing the particular obstacle. The selected portion of the stored data may be provided to an assistance center. A second trajectory may be received from the assistance center, where the second trajectory is not obstructed by the particular obstacle.
p4136
aVAbstract\u000aAn autonomous vehicle may determine that a speed of the autonomous vehicle is less than or equal to a threshold speed, and that the autonomous vehicle has not detected a traffic control signal. The autonomous vehicle may identify a cause C for the speed to be less than or equal to the threshold speed. The autonomous vehicle may start a timer T that is based on the cause C. After the timer T expires, the autonomous vehicle may determine whether the cause C remains as a cause for the speed to be less than or equal to the threshold speed. After determining that the cause C remains the cause for the speed to be less than or equal to the threshold speed, the autonomous vehicle may send an assistance signal indicating a stuck condition.
p4137
aVAbstract\u000aTechnology is described for operating a fleet of autonomous vehicles. A request for a taxi service may be received from a mobile device. The request may include a current location of the mobile device. They request may indicate that the taxi service is to be performed at a current time. An autonomous vehicle may be selected from the fleet of autonomous vehicles to perform the taxi service based in part on an availability of the autonomous vehicle and a proximity between the autonomous vehicle and the current location of the mobile device. Instructions may be provided to the autonomous vehicle to perform the taxi service according to the request. The autonomous vehicle may be configured to provide commands to drive the autonomous vehicle to the current location of the mobile device in order to perform the taxi service.
p4138
aVAbstract\u000aMethods and devices for actively modifying a field of view of an autonomous vehicle in view of constraints are disclosed. In one embodiment, an example method is disclosed that includes causing a sensor in an autonomous vehicle to sense information about an environment in a first field of view, where a portion of the environment is obscured in the first field of view. The example method further includes determining a desired field of view in which the portion of the environment is not obscured and, based on the desired field of view and a set of constraints for the vehicle, determining a second field of view in which the portion of the environment is less obscured than in the first field of view. The example method further includes modifying a position of the vehicle, thereby causing the sensor to sense information in the second field of view.
p4139
aVAbstract\u000aDisclosed herein are an autonomous driving apparatus and method for a vehicle. The autonomous driving apparatus includes an autonomous driving context data processing unit, a simulator unit, a section determination unit, a path planning unit, and a context determination main control unit. The autonomous driving context data processing unit gathers autonomous driving context data. The simulator unit simulates autonomous driving based on the gathered autonomous driving context data. The section determination unit determines a reliable section or an unreliable section based on results of the simulation. The path planning unit searches for at least one global path to a set destination based on results of the determination, and searches the at least one global path for a local path along which the autonomous driving is possible. The context determination main control unit controls the autonomous driving of the vehicle along the local path.
p4140
aVAbstract\u000aA computer in a first vehicle is configured to receive data relating to a second vehicle. The computer may use the data to determine that the second vehicle is being operated at least partially autonomously. Further, the computer may cause the first vehicle to take an action to autonomously operate the first vehicle based at least in part on determining that the second vehicle is being operated at least partially autonomously.
p4141
aVAbstract\u000aAspects of the disclosure relate generally to notifying a pedestrian of the intent of a self-driving vehicle. For example, the vehicle may include sensors which detect an object such as a pedestrian attempting or about to cross the roadway in front of the vehicle. The vehicle's computer may then determine the correct way to respond to the pedestrian. For example, the computer may determine that the vehicle should stop or slow down, yield, or stop if it is safe to do so. The vehicle may then provide a notification to the pedestrian of what the vehicle is going to or is currently doing. For example, the vehicle may include a physical signaling device, an electronic sign or lights, a speaker for providing audible notifications, etc.
p4142
aVAbstract\u000aA method and apparatus are provided for determining whether a driving environment has changed relative to previously stored information about the driving environment. The apparatus may include an autonomous driving computer system configured to detect one or more vehicles in the driving environment, and determine corresponding trajectories for those detected vehicles. The autonomous driving computer system may then compare the determined trajectories to an expected trajectory of a hypothetical vehicle in the driving environment. Based on the comparison, the autonomous driving computer system may determine whether the driving environment has changed and/or a probability that the driving environment has changed, relative to the previously stored information about the driving environment.
p4143
aVAbstract\u000aA control system for a vehicle includes a camera disposed at a vehicle and having a field of view exterior of the vehicle. An image processor is operable to process image data captured by the camera to at least detect objects or other vehicles. The control system, responsive to determination of a traffic condition, is operable to control a steering system of the vehicle. Responsive at least in part to image processing of captured image data, the control system is operable to detect a lane splitting vehicle approaching or adjacent to the vehicle. With the vehicle traveling in an occupied traffic lane and responsive to detection of the lane splitting vehicle approaching the vehicle, the control system controls the steering system of the vehicle to move the vehicle in a direction away from a side region of the occupied lane at which the lane splitting vehicle is detected.
p4144
aVAbstract\u000aMethods and systems for controlling vehicle lateral lane positioning are described. A computing device may be configured to identify an object in a vicinity of a vehicle on a road. The computing device may be configured to estimate, based on characteristics of the vehicle and respective characteristics of the object, an interval of time during which the vehicle will be laterally adjacent to the object. Based on the characteristics of the vehicle, the computing device may be configured to estimate longitudinal positions of the vehicle on the road during the interval of time. Based on the respective characteristics of the object, the computing device may be configured to determine a lateral distance for the vehicle to maintain between the vehicle and the object during the interval of time at the longitudinal positions of the vehicle, and provide instructions to control the vehicle based on the lateral distance.
p4145
aVAbstract\u000aThe present disclosure relates to a deployment system for an unmanned aerial vehicle (UAV). In one aspect, an illustrative deployment system includes a communication system configured for receiving diagnostic data corresponding to an object held by a UAV, wherein the object has an expiration condition; and a logic module configured for (i) determining that the expiration condition has been satisfied based, at least in part, on the received diagnostic data, and (ii) responsive to determining that the expiration condition has been satisfied, initiating an action that includes sending to the UAV both (a) navigation data relating to a remedial facility, and (b) instructions to navigate to the remedial facility based, at least in part, on the navigation data.
p4146
aVAbstract\u000aA vehicle operator is identified. Based at least in part on the operator's identity, one or more parameters are determined specifying a mode for autonomously operating the vehicle. The vehicle is autonomously operated at least in part according to the one or more parameters.
p4147
aVAbstract\u000aAn autonomous unmanned road vehicle and how it can be used to make deliveries. The unmanned vehicle is capable of operating autonomously on paved roadways. The vehicle has a control system for autonomous driving and a perception system for detecting objects in its surroundings. The vehicle also has one or more cargo compartments for carrying the delivery items. The vehicle may have a flashing light beacon to increase the conspicuousness of the vehicle. In consideration that the vehicle does not carry passengers, the size and/or motor power of the vehicle may be reduced as compared to conventional passenger vehicles.
p4148
aVAbstract\u000aA system and method for providing lane changing maneuvers in an autonomously driven vehicle. The vehicle includes a navigation controller that provides a planned route for the vehicle to follow and a vehicle controller that receives route information from the navigation controller and provides steering, braking and throttle control for the vehicle to follow the route. Either the navigation controller or the vehicle controller may initiate a lane change maneuver to cause the vehicle to be steered from a travel lane to an adjacent lane. In response to the lane change requirement, the navigation controller provides a route segment to the vehicle controller and a lane-change zone so that the vehicle controller can steer the vehicle to the adjacent lane while in the lane-change zone.
p4149
aVAbstract\u000aEmbodiments described herein may relate to an unmanned aerial vehicle (UAV) navigating to a medical situation in order to provide medical support. An illustrative method involves a UAV (a) determining an approximate target location associated with a medical situation, (b) using a first navigation process to navigate the UAV to the approximate target location, where the first navigation process generates flight-control signals based on the approximate target location, (c) making a determination that the UAV is located at the approximate target location, and (d) in response to the determination that the UAV is located at the approximate target location, using a second navigation process to navigate the UAV to the medical situation, wherein the second navigation process generates flight-control signals based on real-time localization of the medical situation.
p4150
aVAbstract\u000aEmbodiments described herein may help to provide medical support via a fleet of unmanned aerial vehicles (UAVs). An illustrative medical-support system may include multiple UAVs, which are configured to provide medical support for a number of different medical situations. Further, the medical-support system may be configured to: (a) identify a remote medical situation, (b) determine a target location corresponding to the medical situation, (c) select a UAV from the fleet of UAVs, where the selection of the UAV is based on a determination that the selected UAV is configured for the identified medical situation, and (d) cause the selected UAV to travel to the target location to provide medical support.
p4151
aVAbstract\u000aEmbodiments described herein include a delivery system having unmanned aerial delivery vehicles and a logistics network for control and monitoring. In certain embodiments, a ground station provides a location for interfacing between the delivery vehicles, packages carried by the vehicles and users. In certain embodiments, the delivery vehicles autonomously navigate from one ground station to another. In certain embodiments, the ground stations provide navigational aids that help the delivery vehicles locate the position of the ground station with increased accuracy.
p4152
aVAbstract\u000aA computing device may be configured to receive sensor information indicative of respective characteristics of vehicles on a road of travel of a first vehicle. The computing device may be configured to identify, based on the respective characteristics, a second vehicle that exhibits an aggressive driving behavior manifested as an unsafe or unlawful driving action. Also, based on the respective characteristics, the computing device may be configured to determine a type of the second vehicle. The computing device may be configured to estimate a distance between the first vehicle and the second vehicle. The computing device may be configured to modify a control strategy of the first vehicle, based on the aggressive driving behavior of the second vehicle, the type of the second vehicle, and the distance between the first vehicle and the second vehicle; and control the first vehicle based on the modified control strategy.
p4153
aVAbstract\u000aAspects of the present disclosure relate generally to identifying and displaying traffic lanes that are available for autonomous driving. This information may be displayed to a driver of a vehicle having an autonomous driving mode, in order to inform the driver of where he or she can use the autonomous driving mode. In one example, the display may visually distinguishing between lanes that are available for auto-drive from those that are not. The display may also include an indicator of the position of a lane (autodrive or not) currently occupied by the vehicle. In addition, if that lane is an autodrive lane the display may include information indicating how much further the vehicle may continue in the autonomous driving mode in that particular lane. The display may also display information indicating the remaining autodrive distance in other lanes as well as the lane with the greatest remaining autodrive distance.
p4154
aVAbstract\u000aEmbodiments described herein may relate to an unmanned aerial vehicle (UAV) navigating to a medical situation in order to provide medical support. An illustrative method involves a UAV (a) housing a medical-support device, (b) determining a target location associated with at least one individual in need of medical assistance, (c) navigating the UAV from a remote location to the target location, (d) the computing system making a determination that the UAV is located at the target location, and (e) in response to the determination that the UAV is located at the target location, delivering by a delivery mechanism the medical-support device for providing medical assistance for the at least one individual in need of medical assistance.
p4155
aVAbstract\u000aExample systems and methods allow for reporting and sharing of information reports relating to driving conditions within a fleet of autonomous vehicles. One example method includes receiving information reports relating to driving conditions from a plurality of autonomous vehicles within a fleet of autonomous vehicles. The method may also include receiving sensor data from a plurality of autonomous vehicles within the fleet of autonomous vehicles. The method may further include validating some of the information reports based at least in part on the sensor data. The method may additionally include combining validated information reports into a driving information map. The method may also include periodically filtering the driving information map to remove outdated information reports. The method may further include providing portions of the driving information map to autonomous vehicles within the fleet of autonomous vehicles.
p4156
aVAbstract\u000aTechnology is described for parking autonomous vehicles. An autonomous vehicle may receive an instruction to park the autonomous vehicle. The instruction may be received when the autonomous vehicle is in a preselected location. The autonomous vehicle may select at least one parking area that potentially has available parking spaces to park the autonomous vehicle using, in part, a defined set of parking criteria. Commands may be provided to drive the autonomous vehicle to the parking area. The autonomous vehicle may be configured to select an available parking space within the parking area to park the autonomous vehicle. The autonomous vehicle may send a confirmation message after the autonomous vehicle is parked in the available parking space within the parking area. The confirmation message may include a parking location associated with the autonomous vehicle.
p4157
aVAbstract\u000aA method and apparatus is provided for controlling the operation of an autonomous vehicle. According to one aspect, the autonomous vehicle may track the trajectories of other vehicles on a road. Based on the other vehicle's trajectories, the autonomous vehicle may generate a representative trajectory. Afterwards, the autonomous vehicle may change at least one of its speed or direction based on the representative trajectory.
p4158
aVAbstract\u000aExample methods and systems for detecting weather conditions using vehicle onboard sensors are provided. An example method includes receiving laser data collected for an environment of a vehicle, and the laser data includes a plurality of laser data points. The method also includes associating, by a computing device, laser data points of the plurality of laser data points with one or more objects in the environment, and determining given laser data points of the plurality of laser data points that are unassociated with the one or more objects in the environment as being representative of an untracked object. The method also includes based on one or more untracked objects being determined, identifying by the computing device an indication of a weather condition of the environment.
p4159
aVAbstract\u000aA method for controlling a vehicle which includes obtaining, via at least one detecting device, behavior information of a driver in the vehicle, and transitioning control statuses of the vehicle according to the driver behavior information.
p4160
aVAbstract\u000aData is collected during operation of a vehicle. A determination is made that a confidence assessment of at least one of the data indicates at least one fault condition. A first autonomous operation affected by the fault condition is discontinued, where a second autonomous operation that is unaffected by the fault condition is continued.
p4161
aVAbstract\u000aMethods and control systems are provided for automatically controlling operation of a vehicle. In one embodiment, the control system includes an exterior sensor for sensing the environment outside the vehicle. A processor is in communication with the exterior sensor and configured to calculate a driving plan of the vehicle based at least partially on the sensed environment outside the vehicle. The processor is also configured to calculate a confidence level of the driving plan of the vehicle based at least partially on the sensed environment around the vehicle. The control system also includes a display in communication with the processor and configured to receive data from the processor and display a representation of at least one of the driving plan and the confidence level.
p4162
aVAbstract\u000aAspects of the disclosure relate generally to maneuvering autonomous vehicles. Specifically, the vehicle may determine the uncertainty in its perception system and use this uncertainty value to make decisions about how to maneuver the vehicle. For example, the perception system may include sensors, object type models, and object motion models, each associated with uncertainties. The sensors may be associated with uncertainties based on the sensor's range, speed, and /or shape of the sensor field. The object type models may be associated with uncertainties, for example, in whether a perceived object is of one type (such as a small car) or another type (such as a bicycle). The object motion models may also be associated with uncertainties, for example, not all objects will move exactly as they are predicted to move. These uncertainties may be used to maneuver the vehicle.
p4163
aVAbstract\u000aIn an example implementation, an autonomous vehicle is configured to detect closures and lane shifts in a lane of travel. The vehicle is configured to operate in an autonomous mode and determine a presence of an obstacle substantially positioned in a lane of travel of the vehicle using a sensor. The lane of travel has a first side, a second side, and a center, and the obstacle is substantially positioned on the first side. The autonomous vehicle includes a computer system. The computer system determines a lateral distance between the obstacle and the center, compares the lateral distance to a pre-determined threshold, and provides instructions to control the autonomous vehicle based on the comparison.
p4164
aVAbstract\u000aAn illustrative emergency-support system may include multiple unmanned aerial vehicles (UAVs), which are configured to provide emergency support for a number of different emergency situations. Further, the emergency-support system may be configured to: (a) identify a request for assistance in a remote emergency situation, (b) identify a remote device associated with the request for assistance, (c) determine a target location corresponding to the emergency situation, (d) control a UAV to travel to the target location to provide emergency support, and (e) enable an otherwise restricted capability of one or more of the remote device or the UAV after controlling the UAV to travel to the target location, wherein the capability is enabled to help provide emergency support in the remote emergency situation.
p4165
aVAbstract\u000aAn autonomous vehicle may be partially controlled or monitored by a remote endpoint assigned to the autonomous vehicle. The autonomous vehicle sends one or more assisted driving messages directly to the autonomous vehicle or through a server. The server may identify multiple potential remote driving endpoints and assign one or more of the potential remote driving endpoints to the autonomous vehicle. The one or more potential remote driving endpoints return a command to the autonomous vehicle directly or through the server.
p4166
aVAbstract\u000aA computer in a first vehicle is programmed to receive a first set of data from at least one sensor in the first vehicle and to receive a second set of data from at least one second vehicle. The second set of data is from at least one sensor in the at least one second vehicle. The computer is further programmed to use both the first set of data and the second set of data to identify at least one feature of a road being traversed by the first vehicle.
p4167
aVAbstract\u000aMethods and systems for detecting hand signals of a cyclist by an autonomous vehicle are described. An example method may involve a computing device receiving a plurality of data points corresponding to an environment of an autonomous vehicle. The computing device may then determine one or more subsets of data points from the plurality of data points indicative of at least a body region of a cyclist. Further, based on an output of a comparison of the one or more subsets with one or more predetermined sets of cycling signals, the computing device may determine an expected adjustment of one or more of a speed of the cyclist and a direction of movement of the cyclist. Still further, based on the expected adjustment, the computing device may provide instructions to adjust one or more of a speed of the autonomous vehicle and a direction of movement of the autonomous vehicle.
p4168
aVAbstract\u000aA vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.
p4169
aVAbstract\u000aAutomatic driver modeling is used to integrate human-controlled vehicles into an autonomous vehicle network. A driver of a human-controlled vehicle is identified based on behavior patterns of the driver measured by one or more sensors of an autonomous vehicle. A model of the driver is generated based on the behavior patterns of the driver measured by the one or more sensors of the autonomous vehicle. Previously stored behavior patterns of the driver are then retrieved from a database to augment the model of the driver. The model of the driver is then transmitted from the autonomous vehicle to nearby vehicles with autonomous interfaces.
p4170
aVAbstract\u000aA vehicle has a plurality of control apparatuses, a user input, a geographic position component, an object detection apparatus, memory, and a display. A processor is also included and is programmed to receive the destination information, identify a route, and determine the current geographic location of the vehicle. The processor is also programmed to identify an object and object type based on object information received from the object detection apparatus and to determine at least one warning characteristic of the identified object based on at least one of: the object type, a detected proximity of the detected object to the vehicle, the location of the detected object relative to predetermined peripheral areas of the vehicle, the current geographic location of the vehicle, and the route. The processor is also configured to select and display on the display an object warning image based on the at least one warning characteristic.
p4171
aVAbstract\u000aA vehicle can be controlled in a first autonomous mode of operation by at least navigating the vehicle based on map data. Sensor data can be obtained using one or more sensors of the vehicle. The sensor data can be indicative of an environment of the vehicle. An inadequacy in the map data can be detected by at least comparing the map data to the sensor data. In response to detecting the inadequacy in the map data, the vehicle can be controlled in a second autonomous mode of operation and a user can be prompted to switch to a manual mode of operation. The vehicle can be controlled in the second autonomous mode of operation by at least obtaining additional sensor data using the one or more sensors of the vehicle and navigating the vehicle based on the additional sensor data.
p4172
aVAbstract\u000aAn autonomous control system for a vehicle that controls the speed and steering system of the vehicle to operate in a lane-keeping mode or a lane-changing mode. Position sensors sense the location of surrounding vehicles. A lane determining system identifies a current lane where the vehicle is located. A source of oncoming lane course data provides information as to the course of the current lane. A controller provides instructions to the steering system and speed control system to maneuver the vehicle in either the lane-keeping mode or the lane-changing mode. The driver may override the control system by providing a manual input to the steering system or the speed control system.
p4173
aVAbstract\u000aA property of an insurance policy may be determined, at least in part, upon characteristics of a vehicle autonomous drive mode selection system. The characteristics may pertain to any capability, configuration, and/or operating state of the autonomous drive mode selection system (and/or vehicle). For example, a property of the insurance policy may be based upon whether the autonomous drive mode selection system is enabled or disabled. In some embodiments, the property of the insurance policy may be based upon which of one or more autonomous driving modes is selected via an autonomous drive mode selection system. The property of the insurance policy may be dynamic, and may be updated in response to changes to the autonomous drive mode selection system.
p4174
aVAbstract\u000aAspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.
p4175
aVAbstract\u000aA method of identifying a trailer with a vehicle includes a step of transmitting a unique identifier with a wireless transmitter attached to the trailer. The wireless transmitter may be housed as part of a sensor module with a sensor that senses a parameter of the trailer for operating a trailer backup assist system. The housing of the sensor module may be adapted to be removably attached to the trailer. The unique identifier emitted by the wireless transmitter is received with a wireless receiver on the vehicle. After the unique identifier is recognized by a controller on the vehicle, a parameter of the trailer may be accessed for autonomously guiding the trailer along a desired backing path.
p4176
aVAbstract\u000aMethods and systems for detecting a vehicle signal through image differencing and filtering are described. A computing device may be configured to receive a sequence of images of an identified vehicle in a vicinity of a given vehicle. The computing device may be configured to determine, based on a comparison of a first image of a pair of images of the sequence of images to a second image of the pair of images, a portion of image data exhibiting a change in color and a change in brightness between the first image and the second image of the pair of images. The computing device may be configured to determine that the portion indicates a light signal for the identified vehicle; and provide instructions to control the given vehicle based on the light signal of the identified vehicle.
p4177
aVAbstract\u000aMethods and devices for controlling a vehicle in an autonomous mode are disclosed. In one aspect, an example method is disclosed that includes obtaining, by a computer system, lane information that provides an estimated location of a lane of a road on which a vehicle is travelling, where the computer system is configured to control the vehicle in an autonomous mode. The example method further includes determining, by the computer system, that the lane information has become unavailable or unreliable and, in response to determining that the lane information has become unavailable or unreliable, the computer system analyzing trajectories of other vehicles to locate a potential merge point on the road and creating a new trajectory that follows the lane at the potential merge point.
p4178
aVAbstract\u000aDisclosed herein are methods and apparatus for controlling autonomous vehicles utilizing maps that include visibility information. A map is stored at a computing device associated with a vehicle. The vehicle is configured to operate in an autonomous mode that supports a plurality of driving behaviors. The map includes information about a plurality of roads, a plurality of features, and visibility information for at least a first feature in the plurality of features. The computing device queries the map for visibility information for the first feature at a first position. The computing device, in response to querying the map, receives the visibility information for the first feature at the first position. The computing device selects a driving behavior for the vehicle based on the visibility information. The computing device controls the vehicle in accordance with the selected driving behavior.
p4179
aVAbstract\u000aA autonomous driving computer system determines whether a driving environment has changed. One or more objects and/or object types in the driving environment may be identified as primary objects. The autonomous driving computer system may be configured to detect the primary objects and/or object types, and compare the detected objects and/or object types with the previous known location of the detected object and/or object types. The autonomous driving computer system may obtain several different metrics to facilitate the comparison. A confidence probability obtained from the comparison may indicate the degree of confidence that the autonomous driving computer system has in determining that the driving environment has actually changed.
p4180
aVAbstract\u000aA vehicle is operated at least partially autonomously. A predicted path of the vehicle is monitored to identify an object with which the vehicle is likely to collide. A graphical user interface (GUI) is provided that includes the predicted path, a proposed path for the vehicle to avoid a collision with an object, and the vehicle. A selection is made to follow one of the predicted path and the proposed path. The GUI is updated to include the selected one of the predicted path and the proposed path, along with a location of the vehicle on the selected one of the predicted path and the proposed path.
p4181
aVAbstract\u000aMethods for personalized driving of autonomously driven vehicles include: (a) downloading at least a portion of a driving profile to a vehicle, wherein the vehicle is configured for autonomous driving and wherein the driving profile is associated with a specific driver; and (b) executing one or a plurality of operating instructions prescribed by the driving profile, such that the vehicle is operable in a driving style imitative of the specific driver. Apparatuses for personalized driving of autonomously driven vehicles are described.
p4182
aVAbstract\u000aAt least one embodiment of this disclosure includes a method for an autonomous vehicle (e.g., a fully autonomous or semi-autonomous vehicle) to communicate with external observers. The method includes: receiving a task at the autonomous vehicle; collecting data that characterizes a surrounding environment of the autonomous vehicle from a sensor coupled to the autonomous vehicle; determining an intended course of action for the autonomous vehicle to undertake based on the task and the collected data; and conveying a human understandable output via an output device, the human understandable output expressly or implicitly indicating the intended course of action to an external observer.
p4183
aVAbstract\u000aMethods and systems for detecting weather conditions including sunlight using onboard vehicle sensors are described. In one example, a method is provided that includes receiving laser data collected for an environment of a vehicle. The method also includes associating laser data points with one or more objects in the environment, and determining given laser data points that are unassociated with the one or more objects in the environment as being representative of an untracked object at a given position with respect to the vehicle. The method also includes determining that the untracked object remains at a substantially same relative position with respect to the vehicle as the vehicle moves, and identifying by the computing device an indication that a weather condition of the environment of the vehicle is sunny.
p4184
aVAbstract\u000aAn autonomous driver assistance system is integrated with a vehicular control system to constantly detect ambient road environment of the vehicle, identify a vehicle ahead with same driving route to a destination, and follow the vehicle ahead by autonomous driving to the destination. Signals of direction indicators of the vehicle ahead can be recognized to determine a driving direction and driving state of the vehicle ahead beforehand, thereby reducing the chances of emergency brake and collision and increasing driving efficiency. Without expensive radar detection equipment, the present invention can be easily integrated with a vehicular control system to tackle the high installation cost and integration difficulty of conventional autonomous driver assistance apparatuses.
p4185
aVAbstract\u000aA system is disclosed including an aerial vehicle to perform a task to an object, while in an aerial mode that includes at least one of a hover mode or a slow movement mode during a predominant phase of the task being performed, the aerial vehicle has a command and control system, a removable mobile computing device that when attached to the aerial vehicle assists in control of the aerial vehicle and when detached assists in control of the aerial vehicle with user intervention through the mobile device, wherein assist in control is further performed through the command and control system and at least one attachment attachable to the aerial vehicle for facilitating the task performed to the object by the aerial vehicle while the aerial vehicle is in the aerial mode, the at least one attachment is controlled by the removable mobile computing device. Methods are also disclosed.
p4186
aVAbstract\u000aVarious examples are described for an artificial intelligence valet system. In one example, among others, a distributed information sharing system can obtain route information associated with a geographic area and provide the route information to a user vehicle in response to a request. In another example, an autonomous user vehicle can receive a request to autonomously proceed to a user defined location; obtain route information; and determine a route to the user defined location using the route information. In another example, a collision avoidance system can determine if an object is in a path of travel of a vehicle based at least in part upon sensory data and maneuver the vehicle based at least in part upon an object determination. In another example, an accident reporting system can determine an occurrence of a violation of a vehicle; obtain recordings of the environment surrounding the vehicle; and report the violation.
p4187
aVAbstract\u000aAn autonomous vehicle configured for active sensing may also be configured to weigh expected information gains from active-sensing actions against risk costs associated with the active-sensing actions. An example method involves: (a) receiving information from one or more sensors of an autonomous vehicle, wherein one or more control processes for an autonomous vehicle are based upon the information, (b) determining an information-improvement expectation that corresponds to an active-sensing action, (c) determining a risk-cost that corresponds to the active-sensing action; and (d) based on both (i) the information-improvement expectation for the active-sensing action and (ii) the risk-cost for the active-sensing action, determining whether the active-sensing action is advisable.
p4188
aVAbstract\u000aA method, device and system of sidewalk messaging of an autonomous robot are disclosed. In one embodiment, an autonomous robot includes a motherboard comprising a processor communicatively coupled with a memory, a sensory fusion circuitry to execute a command of a sensory fusion algorithm, and a communication circuitry to bi-directionally communicate an instruction between a central server and the autonomous robot. A sidewalk lighting circuitry executes a projection command of a sidewalk messaging algorithm. The sidewalk lighting circuitry autonomously projects a relevant projection of at least one of an operational status message, a directional message, and an advertisement message on a ground of a sidewalk area immediately in front of a present trajectory of the autonomous robot based on the projection command generated by applying the sidewalk messaging algorithm to instructions of at least one of the sensory fusion circuitry, the central server, and the communication circuitry.
p4189
aVAbstract\u000aA wireless coverage characterization platform uses an autonomous vehicle or robot, such as an unmanned aerial vehicle or other small robot, to autonomously collect key wireless coverage parameters for an indoor environment. One or more vehicles or robots are equipped with integrated simultaneous localization and mapping sensors as well as wireless signal measurement sensors. As a vehicle traverses the indoor environment, on-board processing components process the sensor measurement data to simultaneously build an indoor map of the environment and to learn the wireless coverage characteristics of the environment incrementally. The vehicle's navigation system guides the vehicle through the environment based on the sensor measurements and the learned indoor map until a complete map of the wireless signal strength at all locations throughout the environment is obtained. The system can identify areas of weak wireless coverage or interference sources and recommend access point device locations based on results of the survey.
p4190
aVAbstract\u000aSystems, apparatus, interfaces, methods, and articles of manufacture that provide for insurance claims handling, underwriting, and risk assessment applications utilizing autonomous vehicle data.
p4191
aVAbstract\u000aA method and arrangement are described for handover warning in a vehicle having autonomous driving capabilities and a vehicle controller configured to control unmanned autonomous travel. A processor may be configured to monitor if there is a need to transition from unmanned autonomous travel to manual control of the vehicle. A detecting arrangement may be configured to monitor a vehicle driver and evaluate the vehicle driver's readiness to assume the act of driving the vehicle. A warning arrangement may be configured to provide warning information when driver-handover is requested by the processor, which warning arrangement may be further configured to adapt warning information timing in respect to the evaluated vehicle driver's readiness to assume the act of driving the vehicle. A warning output system may be configured to output the time adapted warning information to a vehicle passenger compartment.
p4192
aVAbstract\u000aAn order-picking method includes autonomously routing a plurality of mobile robotic units in an order fulfillment facility and picking articles to or putting articles from the robotic units in the order fulfillment facility. A material-handling robotic unit that is adapted for use in an order fulfillment facility includes an autonomous mobile vehicle base and a plurality of article receptacles positioned on the base. A visual indicator associated with the receptacle facilitates picking articles to or putting articles from the robotic unit.
p4193
aVAbstract\u000aA property of an insurance policy may be determined, at least in part, upon characteristics of a vehicle autonomous drive mode selection system. The characteristics may pertain to any capability, configuration, and/or operating state of the autonomous drive mode selection system (and/or vehicle). For example, a property of the insurance policy may be based upon whether the autonomous drive mode selection system is enabled or disabled. In some embodiments, the property of the insurance policy may be based upon which of one or more autonomous driving modes is selected via an autonomous drive mode selection system. The property of the insurance policy may be dynamic, and may be updated in response to changes to the autonomous drive mode selection system.
p4194
aVAbstract\u000aA system and method of calculating a heading angle for a trailer that is being backed by a vehicle. A trailer backup assist control module, in communication with a hitch angle detecting apparatus, receives a hitch angle and determines displacement of left and right vehicle wheels using information supplied by vehicle wheel speed sensors while the vehicle is backing the trailer. A vehicle heading angle is determined using left and right wheel displacement information and a known vehicle track width. A trailer heading angle is then calculated using the vehicle heading angle and the hitch angle.
p4195
aVAbstract\u000aA method of providing parking assistance in a vehicle includes identifying with a controller in a vehicle a plurality of available parking spaces for the vehicle, generating with a video output device operatively connected to the controller an interface with a graphical depiction of the vehicle and the plurality of available parking spaces, receiving a first input gesture with a gesture input device to select one parking space from the plurality of available parking spaces, and operating the vehicle to park the vehicle in the one parking space using the controller configured with a parking assistance service in the vehicle.
p4196
aVAbstract\u000aAn aerial image is received. A portion of the aerial image is identified that represents an area of interest that includes a vehicle. The portion of the aerial image is analyzed to generate an identification of one or more objects in the area of interest related to a route of the vehicle.
p4197
aVAbstract\u000aAn autonomous battery replacement station for an unmanned aerial vehicle (UAV) is provided. The UAV includes a replaceable battery. The station includes (a) a landing platform configured to receive the UAV, (b) a storage location configured to store a replacement battery for the UAV, and (c) a means for swapping the replaceable battery on the UAV with a replacement battery from the storage location.
p4198
aVAbstract\u000aA system and method for providing path planning and generation in a semi-autonomous or autonomously driven vehicle that provides a steering correction for collision avoidance purposes. The method includes detecting a lane center of a roadway lane that the vehicle is traveling along and determining a lane centering path that directs the vehicle from its current position to the lane center. The method also includes detecting a moving object in front of the vehicle and determining if a collision between the vehicle and the object will occur if the vehicle travels along the lane centering path at the current vehicle speed. The method solves a fifth-order polynomial equation to define a collision avoidance path from the current vehicle position to a waypoint a safe distance from the object and a return path from the waypoint to the lane center that the vehicle is automatically steered along.
p4199
aVAbstract\u000aA method for an autonomous vehicle to follow a target is provided. The method may include obtaining a position and a velocity of a target and obtaining a position of an autonomous vehicle. The method may also include obtaining a path that encloses the position of the target and determining a path rate for the autonomous vehicle to move along the path based on the velocity of the target. The method may also include determining a path position along the path based on the position of the autonomous vehicle and determining a change in the position of the autonomous vehicle based on the path position, the path rate, and the velocity of the target. The method may also include adjusting a velocity and a direction of the autonomous vehicle to achieve the change in the position of the autonomous vehicle.
p4200
aVAbstract\u000aSystem and methods are disclosed for determining, through vehicle-to-vehicle communication, whether vehicles are involved in autonomous droning. Vehicle driving data and other information may be used to calculate a autonomous droning reward amount. In addition, vehicle involved in a drafting relationship in addition to, or apart from, an autonomous droning relationship may be financially rewarded. Moreover, aspects of the disclosure related to determining ruminative rewards and/or aspects of vehicle insurance procurement/underwriting.
p4201
aVAbstract\u000aDisclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.
p4202
aVAbstract\u000aAn unmanned aerial vehicle (UAV) including a winch system, wherein the winch system includes a winch line having a first end that is secured to the payload, and wherein the winch system is controllable to vary the rate of descent of the payload, an inertial measurement unit positioned on the payload or on the first end of the winch line, wherein the inertial measurement unit is configured to measure oscillations of the payload, and a control system configured to (a) receive data from the IMU, (b) determine oscillations of the payload based on the data received from the IMU, and (c) operate the winch system to vary the deployment rate of the winch line so to damp oscillations of the payload.
p4203
aVAbstract\u000aThe present invention provides a distributed agent-based computer infrastructure configured to manage a mission of an unmanned vehicle that includes generating a mission plan and executing the mission plan. The computer infrastructure comprises an operator interface component, an autonomous mission management component and a vehicle systems interface component. The autonomous mission management component comprises agents configured for receiving information from an operator, for generating a mission plan from the received information including a path to be traveled, and for monitoring execution of the mission plan.
p4204
aVAbstract\u000aEmbodiments described herein may help to provide medical support via a fleet of unmanned aerial vehicles (UAVs). An illustrative UAV may include a housing, a payload, a line-deployment mechanism coupled to the housing and a line, and a payload-release mechanism that couples the line to the payload, wherein the payload-release mechanism is configured to release the payload from the line. The UAV may further include a control system configured to determine that the UAV is located at or near a delivery location and responsively: operate the line-deployment mechanism according to a variable deployment-rate profile to lower the payload to or near to the ground, determine that the payload is touching or is within a threshold distance from the ground, and responsively operate the payload-release mechanism to release the payload from the line.
p4205
aVAbstract\u000aAspects of the disclosure relate generally to determining by what degree a driver is gripping a steering wheel. In one example, a computer may send an electrically assisted power steering system (EPS) motor an excitation command to move. The EPS motor may respond by moving a flexible coupling between the steering wheel and the EPS motor. This may cause a corresponding movement at the steering wheel. A torque sensor may generate pattern data by monitoring the flexible coupling during the movement. The EPS motor may generate system position data for the entire steering system, for example, from the tires to the steering wheel. The pattern data and the system position data may be compared by the computer to determine the degree of grip. In this regard, the computer may determine the degree of a driver's grip without the need for additional sensors.
p4206
aVAbstract\u000aMethods and apparatuses for gesture-based controls are disclosed. In one aspect, a method is disclosed that includes maintaining a correlation between a plurality of predetermined gestures, in combination with a plurality of predetermined regions of a vehicle, and a plurality of functions. The method further includes recording three-dimensional images of an interior portion of the vehicle and, based on the three-dimensional images, detecting a given gesture in a given region of the vehicle, where the given gesture corresponds to one of the plurality of predetermined gestures and the given region corresponds to one of the plurality of predetermined regions. The method still further includes selecting, based on the correlation, a function associated with the given gesture in combination with the given region and initiating the function in the vehicle.
p4207
aVAbstract\u000aMethods and systems for detection of a construction zone using information from a plurality of sources are described. In an example, a computing device, configured to control the vehicle, may be configured to receive information, from a plurality of sources, relating to detection of a construction zone on the road on which the vehicle is travelling. Also, the computing device may be configured to determine a likelihood of existence of the construction zone on the road, based on the information. Further the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle, based on the likelihood; and control the vehicle based on the modified control strategy.
p4208
aVAbstract\u000aA system and method designed to improve sensor visibility for a host vehicle operating in an autonomous driving mode when one or more forward-looking sensors are being occluded or obstructed. According to an exemplary embodiment, when a forward-looking object detection sensor is being obstructed by a target vehicle located closely ahead of the host vehicle, the method determines if lateral movement by the host vehicle within its own lane is appropriate to improve sensor visibility around the target vehicle. If lateral movement is deemed appropriate, the method generates lateral movement commands that dictate the direction and distance of the lateral movement by the host vehicle. This may enable the object detection sensors to at least partially see around the obstructing target vehicle and improve the preview distance of the sensors.
p4209
aVAbstract\u000aThe present disclosure relates to enabling an autonomous vehicle operating in a self-driving mode to communicate information about what the vehicle is about to do or is currently doing. For example, one or more processors may maneuver a vehicle in an autonomous or self-driving mode. While maneuvering the vehicle in the autonomous driving mode, a time when the vehicle will begin to accelerate may be determined. A first audible signal may be played through a speaker at a time t seconds before the time when the vehicle will begin to accelerate. While maneuvering the vehicle in the autonomous driving mode, a time when the vehicle will begin to decelerate may also be determined. A second audible signal, different from the first audible signal, may be played through the speaker at the time when the vehicle begins decelerating.
p4210
aVAbstract\u000aA steering wheel is configured as a dual-state input device configured to operate in two distinct states based on a current driving mode. In a manual driving mode, the input device is configured to control a limited set of vehicle functions and in an autonomous mode the input device is configured to control an expanded set of vehicle functions. The steering wheel includes a wheel rim movably mounted on a steering column and a hub disposed within a center of the wheel rim on the steering column, the main body portion comprising an interactive touch screen disposed on the main body portion. The wheel rim is configured to disengage from the hub and move along the steering column to a retracted position.
p4211
aVAbstract\u000aA method and apparatus for controlling a parking process of a vehicle. The method including setting an upper speed limit; using a speed-limiting device to limit the speed of the vehicle at a parking speed that is less than or equal to the upper speed limit speed; suppressing an accelerator pedal speed increase request that increases the vehicle speed over the upper speed limit; and performing the assisted parking operation while limiting the vehicle speed and terminating the suppression of the increase in speed when the accelerator pedal is depressed by more than a predetermined value. Wherein the predetermined value is selected as a function of a slope on which the vehicle is located. The invention also relates to a steering system for an assisted parking procedure of a vehicle and a vehicle with such a steering system.
p4212
aVAbstract\u000aA system and method for configuring a trailer backup assist system. The system and method communicates predetermined trailer parameters, which are embedded on a tag attached to the trailer, to a controller in the trailer backup assist system. A trailer backup assist system is configured using the predetermined trailer parameters and the configured trailer backup assist system is activated to operate using the trailer parameters.
p4213
aVAbstract\u000aA vehicle control system including human-control members generating signals for manual piloting of actuators of the vehicle, an automatic control module generating signals for automatic piloting of the actuators of the vehicle, and a switching module to select the manual-piloting signals in a manual mode of operation and the autonomous-piloting signals in an autonomous mode of operation. The automatic control module includes a block for automatic formulation of at least one calculated autonomous piloting signal and a security block to transmit to the switching module a calculated autonomous piloting signal in a case of normal autonomous operation and an emergency autonomous piloting signal in a case of abnormal autonomous operation.
p4214
aVAbstract\u000aMethods and devices for controlling a vehicle in an autonomous mode are disclosed. In one aspect, an example method is disclosed that includes obtaining, by a computer system, lane information that provides an estimated location of a lane of a road on which a vehicle is traveling, where the computer system is configured to control the vehicle in an autonomous mode. The example method further includes determining, by the computer system, that the lane information has become unavailable or unreliable and, in response to determining that the lane information has become unavailable or unreliable, the computer system using at least one sensor to monitor at least one neighboring vehicle and controlling the vehicle to maintain a distance between the vehicle and the at least one neighboring vehicle to be at least a predetermined minimum distance.
p4215
aVAbstract\u000aAn unmanned aerial vehicle (UAV) is disclosed that includes a retractable payload delivery system. The payload delivery system can lower a payload to the ground using a delivery device that secures the payload during descent and releases the payload upon reaching the ground. The delivery device can include a channel in which a payload mount attachment for a payload can be inserted. The payload mount attachment can include an aperture for receiving a retaining rod to secure the attachment, and thus the payload, to the delivery device. The retaining rod can assume either an engaged position, in which a portion of the retaining rod engages the payload mount attachment while the payload mount attachment is inserted in the channel, or a disengaged position, in which the retaining rod does not engage the payload mount attachment.
p4216
aVAbstract\u000aA trailer backup assist system for a vehicle reversing a trailer includes a sensor module adapted to attach to the trailer and generate a trailer yaw rate or a trailer speed. The trailer backup assist system also includes a vehicle sensor system that generates a vehicle yaw rate and a vehicle speed. Further, the trailer backup assist system includes a controller that estimates a hitch angle based on the trailer yaw rate or the trailer speed and the vehicle yaw rate and the vehicle speed in view of a kinematic relationship between the trailer and the vehicle.
p4217
aVAbstract\u000aMethods and software for managing vehicle priority proximate to a potential travel-priority conflict zone, such as a roadway intersection, where travel conflicts, such as crossing traffic, can arise. Coordination involves forming an ad-hoc network in a region containing the conflict zone using, for example, vehicle-to-vehicle communications and developing a dynamic traffic control plan based on information about vehicles approaching the conflict zone. Instructions based on the dynamic traffic control plan are communicated to devices aboard vehicles in the ad-hoc network, which display one or more virtual traffic signals to the operators of the vehicles and/or control the vehicles (for example, in autonomous vehicles) in accordance with the dynamic traffic control plan, which may account for a priority level associated with one or more of the vehicles.
p4218
aVAbstract\u000aMethods and systems for construction zone sign detection are described. A computing device may be configured to receive a 3D point cloud of a vicinity of a road on which a vehicle is travelling. The 3D point cloud may include points corresponding to light reflected from objects in the vicinity of the road. The computing device may be configured to determine a set of points representing an area at a given height from a surface of the road, and estimate a shape associated with the set of points. Further, the computing device may be configured to determine a likelihood that the set of points represents a construction zone sign, based on the estimated shape. Based on the likelihood, the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle; and control the vehicle based on the modified control strategy.
p4219
aVAbstract\u000aMethods and systems for detection of a construction zone sign are described. A computing device, configured to control the vehicle, may be configured to receive, from an image-capture device coupled to the computing device, images of a vicinity of the road on which the vehicle is travelling. Also, the computing device may be configured to determine image portions in the images that may depict sides of the road at a predetermined height range. Further, the computing device may be configured to detect a construction zone sign in the image portions, and determine a type of the construction zone sign. Accordingly, the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle; and control the vehicle based on the modified control strategy.
p4220
aVAbstract\u000aA system comprise a server configured to communicate vehicle information with a vehicle transceiver of a vehicle moving along a vehicle route and communicate drone information with a drone transceiver of a drone moving along a drone route. A computing device with a memory and a processor may be configured to communicatively connect with the server, process the vehicle information and the drone information, identify a plurality of pickup locations based in part on the vehicle information and drone information, select at least one of the plurality of pickup locations based in part on a priority score associated with a travel time to or wait time for each of the plurality of pickup locations, and update the drone route based in part on the selected pickup location.
p4221
aVAbstract\u000aSystems and methods for operating an automated vehicle such as an autonomous vehicle may include an autonomous guidance system, a method of automatically controlling and autonomous vehicle based on electronic messages from roadside infrastructure or other-vehicles, a method of automatically controlling an autonomous vehicle based on cellular telephone location information, pulsed LED vehicle-to-vehicle (V2V) communication system, a method and apparatus for controlling an autonomous vehicle, an autonomous vehicle with unobtrusive sensors, and adaptive cruise control integrated with a lane keeping assist system. The systems and methods may use information from radar, lidar, a camera or vision/image devices, ultrasonic sensors, and digital map data to determine a route or roadway position and provide for steering, braking, and acceleration control of a host vehicle.
p4222
aVAbstract\u000aA system for analyzing the network traffic health of an inventory management system that includes an autonomous vehicle and a plurality of access points. The autonomous vehicle interacts with access points in an inventory management system, and network traffic information related to network connectivity between the autonomous vehicle and the access points is obtained. The autonomous vehicle or the access points transmit(s) the network traffic information to a computer system that can generate a graphical user interface that represents the network traffic information for the inventory management system. The network traffic information can include a variety of information about the interactions between autonomous vehicles and access points, such as roam time of the autonomous vehicles between access points as the autonomous vehicles navigate within the inventory management system.
p4223
aVAbstract\u000aA method and apparatus is provided for controlling the operation of an autonomous vehicle. According to one aspect, the autonomous vehicle may track the trajectories of other vehicles on a road. Based on the other vehicle's trajectories, the autonomous vehicle may generate a pool of combined trajectories. Subsequently, the autonomous vehicle may select one of the combined trajectories as a representative trajectory. The representative trajectory may be used to change at least one of the speed or direction of the autonomous vehicle.
p4224
aVAbstract\u000aSystems and methods are provided for docking an unmanned aerial vehicle (UAV) with a vehicle. The UAV may be able to distinguish a companion vehicle from other vehicles in the area and vice versa. The UAV may take off and/or land on the vehicle. The UAV may be used to capture images and stream the images live to a display within the vehicle. The vehicle may control the UAV. The UAV may be in communication with the companion vehicle while in flight.
p4225
aVAbstract\u000aEmbodiments described herein may relate to systems and methods for navigating to an emergency situation. An alert device may be controlled to issue alerts to draw the attention of bystanders to associated supplies for a situation. An illustrative method involves (a) receiving, by a computing system, a transmission indicating a situation at a designated location; (b) the computing system determining an approximate target area associated with the designated location; (c) the computing system making a determination that an alert device is located within the approximate target area; and (d) in response to the determination that the alert device is located within the approximate target area, the computing system executing instructions to activate at least one alert on the alert device indicating the situation and the designated location of the situation.
p4226
aVAbstract\u000aA message is received from a vehicle via a network. A driver status is identified based on at least one of whether the message was received and content in the message. A driving instruction is determined based at least in part on the driver status. The driving instruction is transmitted via the network.
p4227
aVAbstract\u000aA system and method for providing visual assistance through a graphic overlay super-imposed on a back-up camera image for assisting a vehicle operator when backing up a vehicle to align a tow ball with a trailer tongue. The method includes providing camera modeling to correlate the camera image in vehicle coordinates to world coordinates, where the camera modeling provides the graphic overlay to include a tow line having a height in the camera image that is determined by an estimated height of the trailer tongue. The method also includes providing vehicle dynamic modeling for identifying the motion of the vehicle as it moves around a center of rotation. The method then predicts the path of the vehicle as it is being steered including calculating the center of rotation.
p4228
aVAbstract\u000aMethods for communicating a ranking characterizing a portion of a roadway include: (a) ranking at least one segment of a roadway based on an amount of deviation between a true driving behavior on the at least one segment of the roadway and an expected driving behavior predefined for the at least one segment of the roadway; and (b) communicating the ranking to a client. Apparatuses for communicating a ranking characterizing a portion of a roadway are described.
p4229
aVAbstract\u000aAspects of the disclosure relate generally to generating and providing route options for an autonomous vehicle. For example, a user may identify a destination, and in response the vehicle's computer may provide routing options to the user. The routing options may be based on typical navigating considerations such as the total travel time, travel distance, fuel economy, etc. Each routing option may include not only an estimated total time, but also information regarding whether and which portions of the route may be maneuvered under the control of the vehicle alone (fully autonomous), a combination of the vehicle and the driver (semiautonomous), or the driver alone. The time of the longest stretch of driving associated with the autonomous mode as well as map information indicating portions of the routes associated with the type of maneuvering control may also be provided.
p4230
aVAbstract\u000aSystems and methods use cameras to provide autonomous navigation features. In one implementation, a driver assist navigation system may include at least one image capture device configured to acquire a plurality of images of an area in a vicinity of the vehicle; a data interface; and at least one processing device. The at least one processing device may be configured to: receive the plurality of images via the data interface; identify, based on analysis of the plurality of images, a trigger for stopping the vehicle; and based on the identified trigger, cause the vehicle to stop according to a braking profile including a first segment associated with a first deceleration rate, a second segment which includes a second deceleration rate less than the first deceleration rate, and a third segment in which a level of braking is decreased as a target stopping location is approached, as determined based on the analysis of the plurality of images.
p4231
aVAbstract\u000aA system and method for efficiently and continuously allowing vehicles to travel through an intersection. The method includes broadcasting a synchronization signal to all vehicles that will be entering the intersection and broadcasting an intersection flow time to all of the vehicles that will be entering the intersection that identifies which travel lanes travel in what direction. The method also includes identifying an arrival synchronization pattern for all of the vehicles that will be entering the intersection and controlling a speed of the vehicles traveling through the intersection and a time for the vehicles entering the intersection so that vehicles traveling in perpendicular or cross directions to the intersection will simultaneously travel through the intersection without colliding with each other.
p4232
aVAbstract\u000aA vehicle control system may include a vehicle frame, a mount secured to the vehicle frame and configured for rigidly securing a smartphone therein such that motions experienced by the vehicle frame are correspondingly experienced by the smartphone, and system electronics arranged on the frame and in communication with the smartphone and vehicle controllers, the system electronics configured to receive signals from the smartphone and control directional devices of the vehicle based on the signals via the vehicle controllers. A system for preparing signals for transmission to the vehicle to control navigation may also be provided.
p4233
aVAbstract\u000aAn autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.
p4234
aVAbstract\u000aExample methods and systems for detecting weather conditions including wet surfaces using vehicle onboard sensors are provided. An example method includes receiving laser data collected for an environment of a vehicle. The method also includes determining laser data points that are associated with one or more objects in the environment, and based on laser data points being unassociated with the one or more objects in the environment, identifying an indication that a surface on which the vehicle travels is wet. The method may further include receiving radar data collected for the environment of the vehicle that is indicative of a presence of the one or more objects in the environment of the vehicle, and identifying the indication that the surface on which the vehicle travels is wet further based on laser data points being unassociated with the one or more objects in the environment indicated by the radar data.
p4235
aVAbstract\u000aAspects of the disclosure relate generally to speed control in an autonomous vehicle. For example, an autonomous vehicle may include a user interface which allows the driver to input speed preferences. These preferences may include the maximum speed above the speed limit the user would like the autonomous vehicle to drive when other vehicles are present and driving above or below certain speeds. The other vehicles may be in adjacent or the same lane the vehicle, and need not be in front of the vehicle.
p4236
aVAbstract\u000aA smart vehicle can be operated by generating a 3D model of a sensor's field of view; receiving information from neighboring vehicles to compensate for blindspots in the sensor's field of view and in a driver's field of view; receiving traffic information, weather information; adjusting one or more characteristics of the plurality of 3D models based on the received traffic and weather information and blindspot information; aggregating the plurality of 3D models to generate a comprehensive 3D model; and combining the comprehensive 3D model with detailed map information; and using the combined comprehensive 3D model with detailed map information to maneuver the vehicle.
p4237
aVAbstract\u000aMethods and devices for detecting traffic signals and their associated states are disclosed. In one embodiment, an example method includes a scanning a target area using one or more sensors of a vehicle to obtain target area information. The vehicle may be configured to operate in an autonomous mode, and the target area may be a type of area where traffic signals are typically located. The method may also include detecting a traffic signal in the target area information, determining a location of the traffic signal, and determining a state of the traffic signal. Also, a confidence in the traffic signal may be determined. For example, the location of the traffic signal may be compared to known locations of traffic signals. Based on the state of the traffic signal and the confidence in the traffic signal, the vehicle may be controlled in the autonomous mode.
p4238
aVAbstract\u000aAn aerial vehicle system for gathering data may comprise a Waypoint Location, wherein the Waypoint Location comprises an arresting cable; a Ground Control Station, wherein the Ground Control Station comprises a charging cable; and an aerial vehicle, wherein the aerial vehicle comprises an onboard battery, a capturing hook and a sensor payload for generating surveillance data. The aerial vehicle may be configured to autonomously travel between the Waypoint Location and the Ground Control Station. The aerial vehicle may be configured to couple with the arresting cable via the capturing hook. The aerial vehicle may be configured to electronically couple with the charging cable via the capturing hook to facilitate charging the aerial vehicle's onboard battery.
p4239
aVAbstract\u000aDisclosed herein are computer devices, systems, and methods for remotely operating an autonomous passenger vehicle. When an autonomous vehicle encounters an unexpected driving environment unsuitable for autonomous operation, such as road construction or an obstruction, vehicle sensors can capture data about the vehicle and the unexpected driving environment, including images, radar and lidar data, etc. The captured data can be sent to a remote operator. The remote operator can manually operate the vehicle remotely or issue commands to the autonomous vehicle to be executed by on various vehicle systems. The captured data sent to the remote operator can be optimized to conserve bandwidth, such as by sending a limited subset of the captured data.
p4240
aVAbstract\u000aA rotatable LIDAR device including contactless electrical couplings is disclosed. An example rotatable LIDAR device includes a vehicle electrical coupling including (i) a first conductive ring, (ii) a second conductive ring, and (iii) a first coil. The example rotatable LIDAR device further includes a LIDAR electrical coupling including (i) a third conductive ring, (ii) a fourth conductive ring, and (iii) a second coil. The example rotatable LIDAR device still further includes a rotatable LIDAR electrically coupled to the LIDAR electrical coupling. The first conductive ring and the third conductive ring form a first capacitor configured to transmit communications to the rotatable LIDAR, the second conductive ring and the fourth conductive ring form a second capacitor configured to transmit communications from the rotatable LIDAR, and the first coil and the second coil form a transformer configured to provide power to the rotatable LIDAR.
p4241
aVAbstract\u000aA method is provided that includes receiving user input identifying a travel destination for a first vehicle, determining, by a processor, a first route for the first vehicle to follow, and configuring the first vehicle to follow the first route. The method further includes obtaining a model for a second vehicle that shares a road with the first vehicle and comparing model to a pre-determined template for a vehicle that is known to be a special purpose vehicle in order to determine whether the first template and the second template match. The method further includes determining, by the processor, a second route that leads to the travel destination, when a match is found to exist, and switching the first vehicle from following the first route to following the second route.
p4242
aVAbstract\u000aA vehicle is provided that includes a frame and a mount to couple a first end of an apparatus to the frame. The apparatus comprises a central region that includes a first energy-absorbing material. A first side of the central region is included in the first end of the apparatus coupled to the frame. The apparatus comprises a side region that includes a second energy-absorbing material. The side region is positioned along a second side of the upper region. The side region is configured to be positioned above a wheel of the vehicle.
p4243
aVAbstract\u000aA method of moving autonomous or driverless vehicles being parked or accessed in a parking area is disclosed. The vehicles are parked in columns spaced too closely to allow drivers to enter or exit. The movements of the vehicles are coordinated by a central computer which computes a set of movements, transmits them to the vehicles, and commands and controls the execution. Multiple vehicles are moved sequentially or simultaneously to the computed locations for access, storage or exit. Sensors in the vehicles can transmit relative location information to the central computer to be used in the computations. Vehicles can be shuffled from column to column or from the front to the rear of a column to allow access. Temporary aisles can be formed for exit by vehicles or for access for loading or unloading.
p4244
aVAbstract\u000aDisclosed herein is a driving control exchanging method for an autonomous vehicle by which a driving control may be easily exchanged between a driver and an autonomous vehicle, acquisition of a driving control by a child or a person who cannot drive is prevented, and the relative laws can be complied, making it possible to safely and conveniently manage the autonomous vehicle.
p4245
aVAbstract\u000aDevices, systems, and techniques for generating a graphical user interface including a three-dimensional virtual containment space for flight of an unmanned aerial vehicle (UAV) are described. In some examples, the graphical user interface may be generated based on user input defining a virtual boundary for the flight of the UAV.
p4246
aVAbstract\u000aSystems and methods for controlling a movable object within an environment are provided. In one aspect, a method may comprise: determining, using at least one of a plurality of sensors carried by the movable object, an initial location of the movable object; generating a first signal to cause the movable object to navigate within the environment; receiving, using the at least one of the plurality of sensors, sensing data pertaining to the environment; generating, based on the sensing data, an environmental map representative of at least a portion of the environment; receiving an instruction to return to the initial location; and generating a second signal to cause the movable object to return to the initial location, based on the environmental map.
p4247
aVAbstract\u000aA method for controlling a swarm of autonomous vehicles to perform a multitude of tasks using either a one touch or a single gesture/action command. These commands may include sending the swarm on an escort mission, protecting a convoy, distributed surveillance, search and rescue, returning to a base, or general travel to a point as a swarm. A gesture to initiate a command may include a simple touch of a button, drawing a shape on the screen, a voice command, shaking the unit, or pressing a physical button on or attached to the mobile platform.
p4248
aVAbstract\u000aAn autonomous vehicle driving support system is mounted on a vehicle, is electrically connected to an electronic control unit (ECU) of the vehicle, and has a dangerous driving state determination device and a driving assistance device. The dangerous driving state determination device detects a driving condition of the driver and a collision possibility of the vehicle. The driving assistance device provides suitable driving assistance functions to control the vehicle through the ECU. Given the driving condition of the driver and the collision possibility, corresponding driving assistance function is provided to control the vehicle. Accordingly, the cost arising from an expensive detection system required for enhanced driving assistances to drivers and passengers can be reduced.
p4249
aVAbstract\u000aA vehicle includes at least one autonomous driving sensor configured to monitor at least one condition while the vehicle is operating in an autonomous mode. A processing device is configured to control at least one vehicle subsystem while the vehicle is operating in the autonomous mode. The processing device is configured to control the at least one vehicle subsystem according to a driver preference.
p4250
aVAbstract\u000aA parking management system that facilitates motorist guidance, payment, violation detection, and enforcement using highly accurate space occupancy detection, unique vehicle identification and guidance displays is described. The system enables reduced time to find parking, congestion mitigation, accurate violation detection, and easier enforcement, and increased payment and enforcement revenues to cities. A system facilitating intersection management is also described having applicability to road intersections and railway crossings.
p4251
aVAbstract\u000aIn some implementations, a camera may be disposed on an autonomous aerial platform. A user may operate a smart wearable device adapted to configured, and/or operate video data acquisition by the camera. The camera may be configured to produce a time stamp, and/or a video snippet based on receipt of an indication of interest from the user. The aerial platform may comprise a controller configured to navigate a target trajectory space. In some implementation, a data acquisition system may enable the user to obtain video footage of the user performing an action from the platform circling around the user.
p4252
aVAbstract\u000aA method and system for management and anticipatory deployment of autonomously controlled vehicles are disclosed. According to one embodiment, a method may include calculating the geographic locations and periods of time where self-driving vehicles might experience the greatest probability of being requested to provide transportation services to passengers or cargo, and then communicating the resulting locations and times to self-driving vehicles, causing the vehicles to deploy themselves to those certain locations at those certain times, all prior to and in anticipation of specific requests being initiated by users or entities for such transport.
p4253
aVAbstract\u000aSystems and methods are provided for swapping the battery on an unmanned aerial vehicle (UAV). The UAV may be able to identify and land on an energy provision station autonomously. The UAV may take off and/or land on the energy provision station. The UAV may communicate with the energy provision station. The energy provision station may store and charge batteries for use on a UAV.
p4254
aVAbstract\u000aThis disclosure describes an unmanned aerial vehicle (\u201cUAV\u201d) configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory.
p4255
aVAbstract\u000aAn unmanned aerial vehicle (UAV) is disclosed that includes a retractable payload delivery system. The payload delivery system can lower a payload to the ground using an assembly that secures the payload during descent and releases the payload upon reaching the ground. The assembly can also include a bystander communication module for generating cues for bystander perception. While the assembly securing the payload is being lowered from the UAV, the bystander communication module can generate an avoidance cue indicating that bystanders should avoid interference with the assembly. The assembly also includes sensors that generate data used, at least in part, to determine when the descending assembly is at or near the ground, at which point the assembly releases the payload. The bystander communication module can then cease the avoidance cue and the UAV can retract the assembly.
p4256
aVAbstract\u000aMethods and systems for control of vehicles based on auditory signals are described. In an example, a computing device may be configured to control a vehicle or may be in communication with the vehicle. The computing device may be configured to receive audio information relating to an audible crosswalk signal for an intersection. The computing device also may be configured to determine a likelihood associated with a presence of a pedestrian in a crosswalk at the intersection based on the audio information. The computing device further may be configured to determine a control strategy associated with a driving behavior of the vehicle from among multiple control strategies, based on the likelihood, and may be configured to provide instructions to control the vehicle based on the determined control strategy.
p4257
aVAbstract\u000aAn autonomous steering system for a vehicle includes a park assist steering module configured to generate a first steering angle command across a communication network of the vehicle. A backup assist steering module is also configured to generate a second steering angle command across the communication network of the vehicle. A steering angle controller is configured to receive the first and second steering angle commands and generate a third steering angle command for controlling a steered wheel of the vehicle based on acceptable steering column torque conditions for the respective steering module.
p4258
aVAbstract\u000aAn autonomous vehicle may be configured to use environmental information for image processing. The vehicle may be configured to operate in an autonomous mode in an environment and may be operating substantially in a lane of travel of the environment. The vehicle may include a sensor configured to receive image data indicative of the environment. The vehicle may also include a computer system configured to compare environmental information indicative of the lane of travel to the image data so as to determine a portion of the image data that corresponds to the lane of travel of the environment. Based on the portion of the image data that corresponds to the lane of travel of the environment and by disregarding a remaining portion of the image data, the vehicle may determine whether an object is present in the lane, and based on the determination, provide instructions to control the vehicle in the autonomous mode in the environment.
p4259
aVAbstract\u000aA lane departure control system is provided which works to control a lane departure of a vehicle. When the vehicle is expected to unintentionally leave a lane of a road, the system steers the vehicle toward the center of the lane at a first yaw rate. Afterwards, when the vehicle is determined to be traveling toward a virtual line extending parallel to the boundary line, the system directs the vehicle parallel to the virtual line at a second yaw rate. The system keeps an absolute value of the first yaw rate below a first upper limit and also keeps an absolute value of the second yaw rate below a second upper limit that is less than the first upper limit. This provides an improved comfortable ride to a driver of the vehicle when the vehicle is directed parallel to the virtual line.
p4260
aVAbstract\u000aMethods and devices for using uncertainty regarding observations of traffic intersections to modify behavior of a vehicle are disclosed. In one embodiment, an example method includes determining a state of a traffic intersection using information from one or more sensors of a vehicle. The vehicle may be configured to operate in an autonomous mode. The method may also include determining an uncertainty associated with the determined state of the traffic intersection. The method may further include controlling the vehicle in the autonomous mode based on the determined state of the traffic intersection and the determined uncertainty.
p4261
aVAbstract\u000aApparatus, systems, and methods provide for a modular vehicle system utilized for lifting and maneuvering payloads. According to aspects of the disclosure, any number of individual lift vehicles may be connected to create a unified lift vehicle. The individual lift vehicles may be placed adjacent to one another according to a determined lifting array formation and coupled together using connection mechanisms. The connection mechanisms rigidly and communicatively connect the individual lift vehicles to create the unified lift vehicle suitable for lifting and maneuvering a payload.
p4262
aVAbstract\u000aA vehicle system includes a first sensor and a second sensor, each having, respectively, different first and second modalities. A controller includes a processor configured to: receive a first sensor input from the first sensor and a second sensor input from the second sensor; detect, synchronously, first and second observations from, respectively, the first and second sensor inputs; project the detected first and second observations onto a graph network; associate the first and second observations with a target on the graph network, the target having a trajectory on the graph network; select either the first or the second observation as a best observation based on characteristics of the first and second sensors; and estimate a current position of the target by performing a prediction based on the best observation and a current timestamp.
p4263
aVAbstract\u000aA system, apparatus, and method for the measurement, collection, and analysis of radio signals are provided. A transport host device, including an unmanned aerial vehicle, can transport a scanning device into desired locations for autonomously collecting radio data for a wireless network, thereby enabling the rapid interrogation and optimization the wireless network, including in locations and spatial areas where previously known systems and methods have been impractical or impossible.
p4264
aVAbstract\u000aA method for providing shared control over movement of a vehicle within a space. The method includes receiving user input related to a velocity and a direction for the vehicle within the space. The method includes processing the user input to selectively adjust the velocity and the direction desired by the user based on a set of predefined constraints to generate a trajectory for the vehicle for an upcoming time period. The method includes operating drive mechanisms in the vehicle based on the trajectory to move the vehicle from a first position to a second position within the space during the upcoming time period. A grid map defining locations of obstacles in the space may be used to define the trajectory to avoid collisions, and a guidance trajectory may be used to further control movement to achieve a desired throughput and control vehicle movement within particular portions of the space.
p4265
aVAbstract\u000aA computer receives data detailing operation of a plurality of at least partially manually operated automobiles. The computer determines one or more trends in the operation of the plurality of at least partially manually operated automobiles, based at least in part on the data detailing the operation of the plurality of manually operated vehicles. The computer generates one or more operational rules, based, at least in part, on the one or more trends. The computer transmits the one or more operational rules to one or more at least semi-autonomous vehicles.
p4266
aVAbstract\u000aA radio detection and ranging (RADAR) system that emits radio signals from a transmit antenna and receives reflected signals with a receive array of antenna elements. The signals received at the receive array are conveyed through a plurality of waveguide couplers. The plurality of waveguide couplers receives signals from each antenna element at a plurality of antenna ports and outputs signals from a plurality of output ports. The waveguide couplers convey signals such that the output ports receive signals from associated sub-array sets of the antenna ports. The waveguide couplers have an overlapping arrangement such that a given sub-array set of antenna ports overlaps with a neighboring sub-array set of antenna ports by including at least half of the antenna ports in the neighboring sub-array set.
p4267
aVAbstract\u000aA non-transitory processor-readable medium storing code causes a processor at a first vehicle (e.g., a first autonomous vehicle) to generate a first planned path based on a current position of the first vehicle and a mission requirement assigned to the first vehicle. A first planned path associated with a second vehicle (e.g., a second autonomous vehicle), which is based on a current position of the second vehicle and a mission requirement assigned to the second vehicle, is received at the first vehicle. After the first planned path associated with the second vehicle is received, a second planned path is generated based on the first planned path associated with the second vehicle and at least one of the mission requirement assigned to the first vehicle or the first planned path of the first vehicle. The second planned path of the first vehicle is transmitted to the second vehicle.
p4268
aVAbstract\u000aSystem and methods are disclosed for determining, through vehicle-to-vehicle communication, whether vehicles are involved in autonomous droning. Vehicle driving data and other information may be used to calculate a autonomous droning reward amount. In addition, vehicle involved in a drafting relationship in addition to, or apart from, an autonomous droning relationship may be financially rewarded. Moreover, aspects of the disclosure related to determining ruminative rewards and/or aspects of vehicle insurance procurement/underwriting.
p4269
aVAbstract\u000aMethods and systems for construction zone object detection are described. A computing device may be configured to receive, from a LIDAR, a 3D point cloud of a road on which a vehicle is travelling. The 3D point cloud may comprise points corresponding to light reflected from objects on the road. Also, the computing device may be configured to determine sets of points in the 3D point cloud representing an area within a threshold distance from a surface of the road. Further, the computing device may be configured to identify construction zone objects in the sets of points. Further, the computing device may be configured to determine a likelihood of existence of a construction zone, based on the identification. Based on the likelihood, the computing device may be configured to modify a control strategy of the vehicle; and control the vehicle based on the modified control strategy.
p4270
aVAbstract\u000aThe present invention relates to an apparatus and method for performing cooperative autonomous driving between a vehicle and a driver. For this, a cooperative autonomous driving apparatus according to the present invention includes a driver state determination unit for determining a state of a driver and calculating the state of the driver as a risk index. An autonomous driving control unit classifies section characteristics of respective sections included in a path to a destination corresponding to the driver based on section data stored in a database (DB), and controls autonomous driving of a vehicle in which the driver is riding, based on a driving environment recognized for the path to the destination corresponding to the driver. A driving control determination unit determines driving modes of the respective sections included in the path based on the state of the driver and the section characteristics.
p4271
aVAbstract\u000aA transport arrangement system operates to receive a transport request from a user, and to make a selection of a vehicle type for the user based at least in part on a set of criteria associated with the transport request or user information. For example, the determination of whether an autonomous vehicle is to be provided can be based at least in part on the destination specified with the transport request.
p4272
aVAbstract\u000aA system and method for demand-activated remote monitoring and/or control of motor vehicles via a radio data communication link with a coordination unit. The coordination unit is configured for conveying requests for remote monitoring and/or remote control of a motor vehicle and offers for performing the remote control from control terminals located remotely from the coordination unit. After acceptance of an offer by the vehicle, the coordination unit provides a data communication link between the motor vehicle and the control terminal over which the remote control and/or monitoring is performed.
p4273
aVAbstract\u000aVarious embodiments include methods for piggybacking an unmanned aerial vehicle (UAV) on a vehicle (e.g., motor vehicles and trailers coupled to motor vehicles) to reach a destination. Various embodiments may include determining whether to dock on a vehicle. One or more candidate vehicles may be identified for docking. Travel profile characteristics of the one or more candidate vehicles may be identified. A first vehicle may be selected from the one or more candidate vehicles based on one or more travel profile characteristics that assist the UAV in reaching the UAV destination. The UAV may dock with the first vehicle. While docked to the first vehicle the UAV may charge an onboard battery via an electrical connection in a docking structure or by harvesting energy in the wind caused by movement of the vehicle by configuring the UAV rotors to charge the battery.
p4274
aVAbstract\u000aAn anticipatory monitoring and prediction system can include methods for generating effective, accurate predictions of other traffic objects in the vicinity of an ego-car. The invention proposes to combine approximate probability distributions (ADPs) of agent states with Attractor Functions (AFs) for generating distributed probabilistic representations of the potential future states of the observed traffic objects. AFs are selected based on both the current road context, in which the ego-car is situated, and the current states of all participating objects. The generated predictions can be used to filter incoming sensory information for better object state estimations, rate the nature of the behavior of other traffic objects by comparing generated predictions with actual perceived sensor information, or infer accident likelihoods by comparing the predicted state distributions of objects and the ego-car. Warning and information signals or control commands can be issued in a driving assistance system.
p4275
aVAbstract\u000aMethods and systems for lane boundary detection using images are described. A computing device may be configured to receive, from an image-capture device coupled to a vehicle, an image of a road of travel of the vehicle. The computing device may be configured to identify a pixel in the image based on an intensity of the pixel and a comparison of the intensity of the pixel to respective intensities of neighboring pixels. Based on the intensity of the pixel and the comparison, the computing device may be configured to determine a likelihood that the pixel belongs to a portion of the image depicting a lane marker on the road. Based at least on the likelihood, the computing device may be configured to and provide instructions to control the vehicle.
p4276
aVAbstract\u000aA vehicular vision system includes a forward facing camera module having a forward facing camera having forward field of view, and includes a rearward facing camera having a rearward field of view. The forward facing camera module includes an image processor, a decoder and an encoder. Image data captured by the rearward facing camera is fed to the decoder and an output of the decoder is fed to the image processor. The image processor is operable to process image data captured by the forward facing camera to at least detect objects in the forward field of view and is operable to process the decoder output to at least detect objects the rearward field of view. An image processor output is fed to the encoder and an encoder output is fed to a display that is viewable by a driver of the vehicle during a reversing maneuver of the vehicle.
p4277
aVAbstract\u000aA trailer parameter identification system (1) for identifying at least one geometrical parameter relating to a trailer (5) comprises at least one sensor (9, 10, 11, 7A, 7B) and a processor (33A, 33B). The at least one sensor (9, 10, 11, 7A, 7B) is configured to acquire data. The processor (33A, 33B) is configured to process said data to generate a value representative of a geometrical parameter of the trailer (5).
p4278
aVAbstract\u000aArchitecture for a multimodal, multiplatform switching, unmanned vehicle (UV) swarm system which can execute missions in diverse environments. The architecture includes onboard and ground processors to handle and integrate multiple sensor inputs generating a unique UV pilot experience for a remote drone pilot (RDP) via a virtual augmented reality cockpit (VARC). The RDP is monitored by an operational control system and an experienced control pilot. A ground processor handles real-time localization, forwarding of commands, generation and delivery of augmented content to users, along with safety features and overrides. The UVs onboard processors and autopilot execute the commands and provide a redundant source of safety features and override in the case of loss of signal. The UVs perform customizable missions, with adjustable rules for differing skill levels. RDPs experience real-time virtual piloting of the UV with augmented interactive and actionable visual and audio content delivered to them via VARC systems.
p4279
aVAbstract\u000aMethods and systems for detecting weather conditions including fog using vehicle onboard sensors are provided. An example method includes receiving laser data collected from scans of an environment of a vehicle, and associating, by a computing device, laser data points of with one or more objects in the environment. The method also includes comparing laser data points that are unassociated with the one or more objects in the environment with stored laser data points representative of a pattern due to fog, and based on the comparison, identifying by the computing device an indication that a weather condition of the environment of the vehicle includes fog.
p4280
aVAbstract\u000aA least restrictive allowable driving state of a semi-autonomous driving system is determined based on one or more threats and sensor performance. A current driving state and a future driving state are determined based on an attention state and a steering state of a driver. Warnings are provided to the driver in order to match the current driving state to the future driving state. Driver interaction and attention are enforced when the driver does not respond to the warnings.
p4281
aVAbstract\u000aMethods and systems for performing flocking while executing a fleet plan are provided. An example method includes receiving a sequence of coverage requirements for a region and an associated period of time, and determining a respective sequence of intended destinations for each of one or more vehicles of a fleet of vehicles to travel to over the period of time. Additionally, based on a determined sequence of intended destinations for a vehicle of the one or more vehicles and based on a desired spatial relationship between the vehicle and one or more neighboring vehicles for a given time period, a flocking-based direction of travel for the vehicle may be determined for the given time period.
p4282
aVAbstract\u000aA collision avoidance system for assisting a driver in avoiding a collision between a host vehicle and obstacle. A processor recursively calculates a time-to-collision with the obstacle and an optimal collision avoidance path for avoiding the collision. The optimum collision avoidance path is recursively generated based on a position and speed of the host vehicle relative to the obstacle and an updated calculated time-to-collision. A sensing device determines whether the driver of the vehicle has initiated a steering maneuver to avoid the obstacle. A steering assist mechanism maintains the host vehicle along the optimum collision avoidance path. The steering assist mechanism applies a steering assist torque for producing steering adjustments to assist in guiding the host vehicle along the optimum collision avoidance path to the target lane. The steering assist torque generated by the steering assist mechanism is recursively adjusted based on a recent updated optimum collision avoidance path.
p4283
aVAbstract\u000aAn autonomous vehicle platform system and method configured to perform various in-season management tasks, including selectively applying fertilizer, mapping growth zones and seeding cover crop within an agricultural field, while self-navigating between rows of planted crops and beneath the canopy of the planted crops on the uneven terrain of an agricultural field, allowing for an ideal in-season application of fertilizer to occur once the planted crop is well established and growing rapidly, in an effort to limit the loss of fertilizer.
p4284
aVAbstract\u000aIn an apparatus for controlling an unmanned autonomous operating vehicle having an electric motor supplied with power from a battery for operating lawn mower blades, and magnetic sensors for detecting intensity of a magnetic field of an area wire such that the vehicle is controlled to run about in an operating area defined by the area wire to mow lawn using the blades and to return to a charging device installed on the area wire so as to charge the battery, a distance from the area wire is detected based on the detected intensity of the magnetic field detected by the magnetic sensors, and a different one of returning trajectories defined along the area wire in advance with respect to distances from the area wire is selected, whenever the vehicle is to be returned.
p4285
aVAbstract\u000aMethods and systems are disclosed for determining sensor degradation by actively controlling an autonomous vehicle. Determining sensor degradation may include obtaining sensor readings from a sensor of an autonomous vehicle, and determining baseline state information from the obtained sensor readings. A movement characteristic of the autonomous vehicle, such as speed or position, may then be changed. The sensor may then obtain additional sensor readings, and second state information may be determined from these additional sensor readings. Expected state information may be determined from the baseline state information and the change in the movement characteristic of the autonomous vehicle. A comparison of the expected state information and the second state information may then be performed. Based on this comparison, a determination may be made as to whether the sensor has degraded.
p4286
aVAbstract\u000aSystems and methods for generating data representative of insurance coverage for autonomous vehicles are provided. In particular, systems and methods for generating data representative of insurance coverage for autonomous vehicles based on data representative of autonomous vehicle reliability are provided. The data representative of autonomous vehicle reliability may include data representative of the autonomous vehicle original equipment manufacturer test results, autonomous vehicle system manufacturer test results, autonomous vehicle system component manufacturer test results, insurance company autonomous vehicle, systems and/or component test results, and/or third party test results of the autonomous vehicle, systems and/or components.
p4287
aVAbstract\u000aAn autonomous vehicle positioning system for determining a position of a remote vehicle relative to a mobile host vehicle based on safety alert messages broadcast from the remote vehicle relating to an event in a road of travel. A host vehicle communication unit communicates with the remote vehicle for receiving the broadcast messages from the remote vehicle. A host vehicle control unit identifies reference points along the road of travel. Each reference point identifies a position of the host vehicle and associated signal reception properties, for example time-of-arrival, angle-of-arrival and received signal strength when the host vehicle receives the broadcast message. The control unit of the host vehicle selects a set of the reference points having identified positions and associated times, angles and signal strength. The control unit determines a position of the remote vehicle as a function of the time difference-of-arrival, angle-of-arrival or received signal strength between each selected reference point in the set.
p4288
aVAbstract\u000aOne aspect of the disclosure provides a control device that is located inside the passenger compartment of a vehicle. The control device may include a portable computing device configured to execute software that effectively enables passengers to use a touch screen (or another input device) to perform control actions for the vehicle that would otherwise take a flip of a switch, turning of a knob, or pressing of a pedal. For example, the portable computing device may be used to steer the vehicle or apply the brakes of the vehicle. The capabilities of the portable computing device are subject to location-specific permissions. The portable computing device, for example, may be allowed to steer the vehicle only when it is located in the area of the vehicle's driver seat.
p4289
aVAbstract\u000aA motor vehicle system includes a motor vehicle including an aircraft landing portion, and an actively propelled unmanned aircraft configured to be supported on the aircraft landing portion. The vehicle and aircraft are configured such that the vehicle can provide at least one of fuel and electrical energy to the aircraft while the aircraft is supported on the aircraft landing portion.
p4290
aVAbstract\u000aAspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.
p4291
aVAbstract\u000aMethods and systems are disclosed for cross-validating a second sensor with a first sensor. Cross-validating the second sensor may include obtaining sensor readings from the first sensor and comparing the sensor readings from the first sensor with sensor readings obtained from the second sensor. In particular, the comparison of the sensor readings may include comparing state information about a vehicle detected by the first sensor and the second sensor. In addition, comparing the sensor readings may include obtaining a first image from the first sensor, obtaining a second image from the second sensor, and then comparing various characteristics of the images. One characteristic that may be compared are object labels applied to the vehicle detected by the first and second sensor. The first and second sensors may be different types of sensors.
p4292
aVAbstract\u000aSystems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried by the unmanned aerial vehicle and configured to provide sensor data and one or more processors. The one or more processors can be individually or collectively configured to: determine, based on the sensor data, an environment type for the environment; select a flight mode from a plurality of different flight modes based on the environment type, wherein each of the plurality of different flight mode is associated with a different set of operating rules for the unmanned aerial vehicle; and cause the unmanned aerial vehicle to operate within the environment while conforming to the set of operating rules of the selected flight mode.
p4293
aVAbstract\u000aAspects of the disclosure relate generally to detecting road weather conditions. Vehicle sensors including a laser, precipitation sensors, and/or camera may be used to detect information such as the brightness of the road, variations in the brightness of the road, brightness of the world, current precipitation, as well as the detected height of the road. Information received from other sources such as networked based weather information (forecasts, radar, precipitation reports, etc.) may also be considered. The combination of the received and detected information may be used to estimate the probability of precipitation such as water, snow or ice in the roadway. This information may then be used to maneuver an autonomous vehicle (for steering, accelerating, or braking) or identify dangerous situations.
p4294
aVAbstract\u000aA system and method is provided that permits optical communication between vehicles or vehicles and transportation fixtures by modulating an optical source located on either a vehicle or a transportation fixture. The optical source is modulated to include information about the vehicle or fixture. The modulated optical signal is then transmitted from the optical source to an environment external the vehicle or fixture. The system may further include sensors for receiving input optical information signals from the external environment that contains information about external sources, such as other vehicles or fixtures. The system further includes a processor for controlling signal modulation and processing input optical information received from the vehicle sensors.
p4295
aVAbstract\u000aA computer-implemented method for managing a fleet of electric vehicles includes a fleet management computing system selecting an optimal vehicle fleet size and a plurality of discharging parking lot locations based on (i) historical electrical energy consumption for a geographic area and (ii) historical traffic flow though the geographic area during one or more time periods of interest. The fleet management computing system collects transportation demand data from a plurality of users comprising requests for transportation to locations within the geographic area and uses (i) the optimal vehicle fleet size, (ii) the plurality of discharging parking lot locations, and (iii) the transportation demand data to select routing information for each of a plurality of electric vehicles. Then, the fleet management computing system routes each respective autonomous vehicle according to its respective routing information.
p4296
aVAbstract\u000aSystems and methods use cameras to provide autonomous navigation features. In one implementation, a lane ending detection system is provided for a vehicle. One or more processing devices associated with the system receive at least one image via a data interface. The device(s) extract lane ending information from the road sign(s) included in the image data and determine, based on at least one indicator of position of the vehicle, a distance from the vehicle to one or more lane constraints associated with the current lane. The processing device(s) determine, based on the lane ending information and the vehicle position, whether a current lane in which the vehicle is traveling is ending. Further, the system may cause the vehicle to change lanes if the lane in which the vehicle is traveling is ending.
p4297
aVAbstract\u000aA computer-implemented method and system for in-vehicle dynamic virtual reality includes determining a spatial environment around a vehicle and one or more maneuver paths for the vehicle in the spatial environment. The method includes updating a virtual view based on the spatial environment and the maneuver paths. Updating the virtual view includes augmenting one or more components of a virtual world model to indicate the spatial environment and the maneuver paths. The virtual view is rendered to an output device. The method includes generating a vehicle maneuver request for the vehicle. The vehicle maneuver request includes at least a desired vehicle maneuver and the vehicle maneuver request is based at least in part on the spatial environment. The method includes controlling one or more vehicle systems of the vehicle based on the vehicle maneuver request.
p4298
aVAbstract\u000aThis invention relates to an Unmanned Aerial Vehicle hereinafter called \u201cMother UAV\u201d member (11) capable of carrying modules of Sub Unmanned Aerial Vehicle members (12) hereinafter called \u201cSub UAV\u201d member. More particularly, the method and system that is capable of communicating via satellite and remote control technology wherein ejecting said Sub UAV members (12) from the Mother UAV member (11) wherein Sub UAV members (12) autonomously fly in sequence in a coordinated manner with the Mother UAV member (11), and capable of engaging in multiple missions in high, medium, low altitude, and surface, also communication with under sea submarines (27). Further, comprises of a method and system that the Sub UAV members (12) are able to return back to the Mother UAV member (11) after the mission is completed and be firmly secured to the flatbed (14) of the Mother UAV member (11). The present invention is specifically designed for multifunctional and multipurpose applications where humans and other vehicles are unable to access, for civil, commercial and military purposes.
p4299
aVAbstract\u000aMethods and devices for estimating a heading of a target vehicle are disclosed. An example method may include determining a first point cloud representative of a location of a target vehicle at a first time period and a second point cloud representative of the location of the target vehicle at a second time period. Using a computing device, an initial comparison between the first point cloud and the second point cloud may be determined based on an estimate of a speed for the target vehicle and a time difference between the first time period and the second time period. Additionally, the initial comparison may be revised based on a minimization of a distance between points of the first point cloud and corresponding points of the second point cloud. An estimate of a heading of the target vehicle may then be determined based on the revised comparison.
p4300
aVAbstract\u000aA disclosed method of maneuvering a vehicle-trailer unit in reverse travel with a backing system includes, among other things, determining that the vehicle-trailer unit is backing up with an electronic control unit for the backing system. A current hitch angle is determined, which represents the relative angle between the vehicle and the trailer with the electronic control unit. A requested hitch angle rate of change versus distance traveled is calculated with the electronic control unit, wherein the requested hitch angle rate of change is based upon a input from a joystick control which provides a requested hitch angle rate of change signal value in proportion to the joystick position. A steering angle is calculated with the electronic control unit based upon the requested hitch angle rate of change, wherein the steering angle will allow movement of the vehicle-trailer unit in the reverse direction to obtain the requested hitch angle rate of change; and a request is sent to a steering system to provide the steering angle.
p4301
aVAbstract\u000aAn intelligent navigation system navigates a motor vehicle according to real-time road conditions and maneuverability conditions. The intelligent navigation system predicts and corrects potential route deviations before they actually occur. The intelligent navigation system interacts with the maneuverability of a motor vehicle, such that it can navigate the motor vehicle with very little to no human intervention. The intelligent navigation system may embody a method comprising the steps of receiving, from an input device, destination information related to a destination to be reached by the motor vehicle; receiving, from a positioning device, initial location information related to an initial location of the motor vehicle; determining, using a processor, a task for maneuvering the motor vehicle from the initial location to the destination; and instructing, using the processor, a vehicle maneuver controller to implement the task.
p4302
aVAbstract\u000aMethods and devices for using a relationship between activities of different traffic signals in a network to improve traffic signal state estimation are disclosed. An example method includes determining that a vehicle is approaching an upcoming traffic signal. The method may further include determining a state of one or more traffic signals other than the upcoming traffic signal. Additionally, the method may also include determining an estimate of a state of the upcoming traffic signal based on a relationship between the state of the one or more traffic signals other than the upcoming traffic signal and the state of the upcoming traffic signal.
p4303
aVAbstract\u000aA wearable computing device in a vehicle is identified by a vehicle in a computer. Collected data is received relating to autonomous operation of the vehicle. A message is sent to the wearable computing device based at least in part on the collected data.
p4304
aVAbstract\u000aA tracked ATV includes a frame, a track coupled to the frame, and a power source supported by the frame and drivingly coupled to the track. The tracked ATV further includes a steering and drive assembly, which has a first hydraulic pump coupled to the tracks for large radius turns. The steering and drive assembly also has a second hydraulic pump coupled to the tracks for small radius turns.
p4305
aVAbstract\u000aA collision detection system for a vehicle includes a sensor and a camera. The sensor measures a first data set of an object relative to the vehicle. The camera measures a second data set of the object relative to the vehicle and separately measures an image-based time-to-collision with the object based on scalable differences of captured images. A fusion module matches data from the sensor and the camera and estimates a collision threat based on the matched data. A plausibility module generates a signal if the measured image-based time-to-collision is less than a calculated steering-based time-to-collision and a braking-based time-to-collision with the object. A countermeasure module actuates a countermeasure device, such as an autonomous braking system, if the collision threat exceeds an actuation threshold and the signal from the plausibility module is received, thereby statistically reducing the rate of false actuations of the countermeasure device.
p4306
aVAbstract\u000aEmbodiments of the invention provide a dynamic routing intelligent vehicle enhancement system and method. Intelligent land buoys can be proximately disposed to roadways. Each of the intelligent land buoys can gather situational awareness information about the roadways and one or more vehicles traveling thereon. The intelligent land buoys can compress the situational awareness information. One or more remote computer servers can receive the compressed situational awareness information from the plurality of intelligent land buoys, decompress it, and process the decompressed situational awareness information. The one or more remote computer servers can generate vehicle operational intelligence information based at least on the decompressed situational awareness information, and can transmit the vehicle operational intelligence information to the plurality of intelligent land buoys and/or directly to one or more autonomous or semi-autonomous vehicles.
p4307
aVAbstract\u000aA presence of precipitation is determined. At least one attribute of the precipitation is identified. At least one autonomous control action for a vehicle is determined based at least in part on the precipitation.
p4308
aVAbstract\u000aSystems and methods for controlled parking of autonomous vehicles are provided. In one embodiment, a method includes sending a request from a vehicle to park within a parking area controlled by a parking control system using a bi-directional trust system employing a digital authentication certificate, receiving at the vehicle a parking space assignment from the parking control system indicating an assigned parking space within the parking area using the bi-directional trust system, and autonomously controlling the vehicle to drive the vehicle to the assigned parking space within the parking area.
p4309
aVAbstract\u000aEmbodiments, systems, and techniques for vehicle operation assistance are provided herein. Vehicle operation assistance may be provided by monitoring characteristics of an occupant of a vehicle and determining an emergency status for the occupant based on characteristics of the occupant, transmitting a request for help based on the emergency status indicating the occupant of the vehicle is experiencing an emergency, receiving a \u201cfollow me\u201d request from a potential leader vehicle, enabling follower mode such that vehicle is a follower vehicle and the potential leader vehicle is a leader vehicle, establishing a connection with the leader vehicle and receiving navigation instructions from the leader vehicle based on the vehicle being in follower mode, generating driving action commands based on navigation instructions, and executing respective driving action commands in an autonomous fashion based on the vehicle being in follower mode.
p4310
aVAbstract\u000aA method includes receiving, at a computing system, audio data from one or more microphones associated with a vehicle. In one example, the audio data originates from a source external to the vehicle and the vehicle is configured to operate in an autonomous mode. The method also includes processing the audio data to generate directional data related to a direction of the source of the audio data relative to the vehicle and processing the audio data to generate identification data related to an identity of the source of the audio data. Further, the method includes controlling the vehicle in the autonomous mode in response to the directional data and the identification data, using the computing system.
p4311
aVAbstract\u000aMethods and systems for the use of detected objects for image processing are described. A computing device autonomously controlling a vehicle may receive images of the environment surrounding the vehicle from an image-capture device coupled to the vehicle. In order to process the images, the computing device may receive information indicating characteristics of objects in the images from one or more sources coupled to the vehicle. Examples of sources may include RADAR, LIDAR, a map, sensors, a global positioning system (GPS), or other cameras. The computing device may use the information indicating characteristics of the objects to process received images, including determining the approximate locations of objects within the images. Further, while processing the image, the computing device may use information from sources to determine portions of the image to focus upon that may allow the computing device to determine a control strategy based on portions of the image.
p4312
aVAbstract\u000aAspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.
p4313
aVAbstract\u000aA trailer backup assist system, according to one embodiment, includes a steering input device for inputting a desired backing path of a trailer. The trailer backup assist system also includes a first sensor that senses a hitch angle between a vehicle and the trailer. Further, the trailer backup assist system includes a second sensor that senses a proximity of an object in a perimeter field of at least one of the vehicle and the trailer. A controller of the trailer backup assist system generates an available set of backing paths for the trailer based on the proximity of the object and the hitch angle. The available set of backing paths does not include backing paths that cross a space occupied by the object or that cause a jackknife condition between the vehicle and the trailer.
p4314
aVAbstract\u000aTechnology is described for sharing an autonomous vehicle. An autonomous vehicle may receive a request to perform a task. The autonomous vehicle may determine whether the task conflicts with previously scheduled tasks to be performed at the autonomous vehicle. The autonomous vehicle may add the task to a schedule of tasks to be performed at the autonomous vehicle when the task does not conflict with the previously scheduled tasks. The autonomous vehicle may provide commands to enable the autonomous vehicle to perform the task in accordance with the schedule.
p4315
aVAbstract\u000aMethods and devices for using position logs of vehicles to determine the presence and behavior of traffic controls are disclosed. An example method includes receiving movement data that is indicative of movement of a plurality of vehicles through an intersection. The movement data may be received by a computing device and may include, for each respective vehicle, data indicative of the respective vehicle's position as a function of time for multiple instances of time. The method may further include detecting a pattern in the movement data using the computing device. The detected pattern may be indicative of a probable traffic control for the intersection. According to the method, an indication of the probable traffic control for the intersection may be stored in a database.
p4316
aVAbstract\u000aDangerous driving events may be reported by detecting an occurrence of a dangerous event relating to the operation of a vehicle. A notification message of the dangerous event may be generated involving a time of occurrence of the dangerous event, a location of the dangerous event, and an event type of a plurality of event types for the dangerous event. The notification message may then be transmitted to communicate the occurrence dangerous driving event and information related to the dangerous driving event.
p4317
aVAbstract\u000aData may be collected relating to autonomous operation of a vehicle. A first confidence assessment concerning whether the vehicle should operate autonomously may then be generated, and it may be determined whether the first confidence assessment meets or exceeds a predetermined threshold. An alert may be provided via a user interface in the vehicle relating to ending autonomous operation of the vehicle if the first confidence assessment meets or exceeds the predetermined threshold.
p4318
aVAbstract\u000aA vehicle includes an autonomous driving sensor configured to detect a road condition and output at least one road condition signal representing the road condition, an autonomous mode controller configured to control the vehicle according to the at least one road condition signal, and a communication module configured to broadcast the road condition signal.
p4319
aVAbstract\u000aAspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.
p4320
aVAbstract\u000aA vehicle configured to operate in an autonomous mode is provided. The vehicle is configured to follow a baseline trajectory. Changes to the baseline trajectory are received by a computer system associated with the vehicle. The computer system creates a function representing the current trajectory of the vehicle, as well as one or more functions defining any desired trajectory criteria, and generates an optimization problem from the functions, which, when solved, provide a new trajectory for the vehicle to follow that moves efficiently and smoothly toward the changed baseline trajectory.
p4321
aVAbstract\u000aA method for controlling vehicle systems includes receiving monitoring information from one or more monitoring systems and determining a plurality of driver states based on the monitoring information from the one or more monitoring systems. The method includes determining a combined driver state based on the plurality of driver states and modifying control of one or more vehicle systems based on the combined driver state.
p4322
aVAbstract\u000aA terrain classification system for a vehicle includes a sensor positioned to scan a surrounding terrain, the sensor providing a sensor signal representative of returns from scanning the surrounding terrain. The terrain classification system also includes a processing circuit configured to receive the sensor signal, classify the surrounding terrain using the sensor signal, evaluate a library of acoustic data to determine an expected acoustic signature that corresponds to the classified surrounding terrain, and create an acoustic cost map with the expected acoustic signature.
p4323
aVAbstract\u000aA system for automated inventory management and material handling removes the requirement to operate fully automatically or all-manual using conventional vertical storage and retrieval (S&R) machines. Inventory requests to place palletized material into storage at a specified lot location or retrieve palletized material from a specified lot are resolved into missions for autonomous fork trucks, equivalent mobile platforms, or manual fork truck drivers (and their equipment) that are autonomously or manually executed to effect the request. Automated trucks plan their own movements to execute the mission over the warehouse aisles or roadways sharing this space with manually driven trucks. Automated units drive to planned speed limits, manage their loads (stability control), stop, go, and merge at intersections according human driving rules, use on-board sensors to identify static and dynamic obstacles, and human traffic, and either avoid them or stop until potential collision risk is removed.
p4324
aVAbstract\u000aA lane controller system installed on a vehicle may include components for self-diagnosing malfunctions on the vehicle. The system may include a desired path generator for generating a desired path that keeps the vehicle within a road lane; a steering controller for providing steering a steering correction to keep the vehicle within the road lane; a vehicle state estimator for estimating the state of the vehicle; a lane marking detector for detecting position of road lane markings; a path predictor for predicting a path actively followed by the vehicle; a virtual dynamics module for modeling the anticipated path of the vehicle following input of the steering controller; a comparer that compares the results of actual steering corrections applied with those predicted by the virtual dynamics module, and a diagnostic system that determines a root cause of malfunctions, based on the comparison by the comparer.
p4325
aVAbstract\u000aSystems and methods for building road models, driver models, and vehicle models and making predictions may use driving data received from a plurality of vehicles being driving along a path by a driver. The driving data including a minimum of vehicle location preferably supplemented by data related to the time of observations, vehicle dynamics, and various vehicle sensors. The received data may be categorized into a plurality of maneuvers and a plurality of variables that describe the maneuvers and the received driving data may be identified. A road model may then be built for the path based on the identified variables and maneuvers and the behaviors of a particular driver compared to the road model to assess their driving and intervene as appropriate.
p4326
aVAbstract\u000aA light detection and ranging device with dynamically adjustable angular resolution for use as a sensor providing environmental information for navigating an autonomous vehicle is disclosed. A first region of a scanning zone is scanned while emitting light pulses at a first pulse rate, and a second region of the scanning zone is scanned while emitting light pulses at a second pulse rate different from the first pulse rate. Information from the LIDAR device indicative of the time delays between the emission of the light pulses and the reception of the corresponding returning light pulses is received. A three dimensional point map is generated where the resolution of the point map in the first region is based on the first pulse rate and is based on the second pulse rate in the second region.
p4327
aVAbstract\u000aSystems and methods use cameras to provide autonomous and/or driver-assist navigation features. In some implementations, techniques for predicting the location of first roadway lane constraints are provided. The system may receive multiple images of a roadway in a vicinity of a vehicle, recognize a first roadway lane constraint, and, when lane prediction conditions are determined to be satisfied, predict a location of a second roadway lane constraint. In some implementations, techniques for detecting and responding to construction zones are provided. The system may receive multiple images of a roadway in a vicinity of a vehicle, recognize indicators of a construction zone in the images, determine that the vehicle is proximate to a construction zone, and output a signal indicating that the vehicle is proximate to a construction zone.
p4328
aVAbstract\u000aMethods and systems for modifying vehicle behavior based on confidence in lane estimation are described. In an example, a computing device may be configured to receive lane information relating to locations of lane boundaries and may be configured to estimate a lane boundary on a road on which the vehicle is traveling, based on the lane information. The computing device also may be configured to determine a level of confidence for the estimated lane boundary, modify a driving behavior for the vehicle based on the level of confidence, and also may be configured to control the vehicle based on the modified driving behavior.
p4329
aVAbstract\u000aA method for prioritizing potential threats identified by vehicle active safety systems. The method includes providing context information including map information, vehicle position information, traffic assessment information, road condition information, weather condition information, and vehicle state information. The method calculates a system context value for each active safety system using the context information. Each active safety system provides a system threat level value, a system braking value, a system steering value, and a system throttle value. The method calculates an overall threat level value using all of the system context values and all of the system threat level values. The method then provides a braking request value to vehicle brakes based on all of the system braking values, a throttle request value to a vehicle throttle based on all of the system throttle values, and a steering request value to vehicle steering based on all of the system steering values.
p4330
aVAbstract\u000aThe invention is intended to be able to generate map data even if a location not suited for identification of a matching position exists. A map data creation device creates map data, the map data being used for autonomous movement by a vehicle (1 a), a vehicle (1 b) and/or other vehicles (1), based on a relative position of the vehicle (1 b) which exists around the vehicle (1 a), relative to the vehicle (1 a), the relative position being measured by the vehicle (1 a), and object shape data of an object which exists around the vehicle (1 b), the object shape being measured by the vehicle (1 b). Moreover, the relative position of the vehicle (1 b) relative to the vehicle (1 a) is calculated based on the object shape data measured by the vehicle (1 a).
p4331
aVAbstract\u000aAn apparatus and method for managing failure in an autonomous navigation system are provided. The method includes collecting, by a controller, failure information in the autonomous navigation system and a monitoring a driver condition. The controller is configured to collect the failure information in the autonomous navigation system, and determine whether to switch control from the autonomous navigation vehicle to a manual driving mode based on the driver condition.
p4332
aVAbstract\u000aIn embodiments of an autonomous vehicle interface system, system nodes are each implemented as a distributed node for independent data processing of low-level sensor data and/or high-level system data. The high-level system data is abstracted from the low-level sensor data, providing invariance to system configuration in higher-level processing algorithms. The autonomous vehicle interface system includes at least one real-time bus for data communications of the low-level sensor data and the high-level system data between the system nodes. The system also includes an application programming interface (API) configured for access by the system nodes to the low-level sensor data and the high-level system data that is published on the real-time bus and accessible via the API.
p4333
aVAbstract\u000aAn autonomous vehicle may be operable in an autonomous mode and a manual mode. A confidence threshold is accessed from a database. The confidence threshold may be associated with a particular geographic area containing the autonomous vehicle. The confidence threshold may be constant for the geographic area accessible by the autonomous vehicle. A computing device calculates a vehicle confidence level based on at least one confidence factor and compares the confidence threshold to the vehicle confidence level. The computing device generates a driving mode command for a vehicle based on the comparison. In one example, the driving mode command transitions the autonomous vehicle to the autonomous mode, if applicable, when the vehicle confidence score exceeds the confidence threshold. In one example, the driving mode command transitions the autonomous vehicle to the manual mode, if applicable, when the vehicle confidence score does not exceed the confidence threshold.
p4334
aVAbstract\u000aA seismic survey system records seismic signals during a marine seismic survey. The system includes at least two underwater bases and plural autonomous underwater vehicles (AUVs) that carry appropriate seismic sensors. An AUV is housed by an underwater base and it is launched to a final destination from the underwater base. The AUV receives pinger signals from at least two underwater bases for correcting its trajectory toward the final destination.
p4335
aVAbstract\u000aVehicle-mounted device includes an inertial measurement unit (IMU) having at least one accelerometer or gyroscope, a GPS receiver, a camera positioned to obtain unobstructed images of an area exterior of the vehicle and a control system coupled to these components. The control system re-calibrates each accelerometer or gyroscope using signals obtained by the GPS receiver, and derives information about objects in the images obtained by the camera and location of the objects based on data from the IMU and GPS receiver. A communication system communicates the information derived by the control system to a location separate and apart from the vehicle. The control system includes a processor that provides a location of the camera and a direction in which the camera is imaging based on data from the IMU corrected based on data from the GPS receiver, for use in creating the map database.
p4336
aVAbstract\u000aA vehicle computer system in an autonomous vehicle includes a wireless transceiver configured to communicate with a remote device. The vehicle computer system also includes a processor in communication with the wireless transceiver. The processor is configured to receive instructions from the remote device to initiate an automatic valet-mode, receive data from the remote device indicative of a user's pick-up location, and send instructions to a vehicle module instructing the vehicle to drive to the user's pick-up location.
p4337
aVAbstract\u000aA system and method for converting a vehicle steering angle command to a vehicle steering torque command for a vehicle steering system in a vehicle. The method estimates a self-aligning torque that defines the torque that maintains a vehicle steering wheel at a neutral steering position or to a position that makes no slip angle at the road wheel, applies known total steering torque commands to the steering system at a plurality of sample time steps where the known steering torque commands include the self-aligning torque, and measures a vehicle steering angle at each time step. The method then models the steering system of the vehicle using the torque commands, the measured steering angles, a system delay and a plurality of unknown parameters.
p4338
aVAbstract\u000aA vehicle monitoring system includes a central processor operable to receive vehicle inputs from multiple vehicles. The vehicle inputs are indicative of driving conditions of the vehicles. The central processor is operable to receive, for each vehicle of the multiple vehicles, an environment input indicative of the environment at that vehicle. Responsive to the vehicle inputs and the environment inputs, the central processor determines if one or more of the multiple vehicles is at or approaching a hazardous condition. Responsive to a determination that one or more of the multiple vehicles is a threatened vehicle at a potentially hazardous condition, the central monitoring system at least one of (i) actuates an alert of the threatened vehicle to alert a driver of the threatened vehicle of the determined hazardous condition and (ii) controls a vehicle system of the threatened vehicle to mitigate the determined hazardous condition.
p4339
aVAbstract\u000aMethods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.
p4340
aVAbstract\u000aAspects of the present disclosure relate to a vehicle for maneuvering a passenger to a destination autonomously. The vehicle includes one or more computing devices and a set of user input buttons for communicating requests to stop the vehicle and to initiate a trip to the destination with the one or more computing devices. The set of user input buttons consisting essentially of a dual-purpose button and an emergency stopping button different from the dual-purpose button configured to stop the vehicle. The dual-purpose button has a first purpose for communicating a request to initiate the trip to the destination and a second purpose for communicating a request to pull the vehicle over and stop the vehicle. The vehicle has no steering wheel and no user inputs for the steering, acceleration, and deceleration of the vehicle other than the set of user input buttons.
p4341
aVAbstract\u000aA method of controlling the behavior of an occupant of a vehicle (20) includes sensing an auxiliary mode of the vehicle (20) and comparing a first vehicle operation mode to a predetermined threshold to determine a first incident. The method proceeds by actuating a resistive device (24) in response to the first incident to apply a resistance to an operational input by an occupant of the vehicle (20). The method is characterized by monitoring a precursory auxiliary mode event of the vehicle (20) subsequent to the first incident and prior to a presence of the auxiliary mode, and de-actuating the resistive device (24) in response to the precursory auxiliary mode event to remove the applied resistance.
p4342
aVAbstract\u000aSystems and methods are provided that may optimize basic models of an intersection in a roadway with high intensity image data of the intersection of the roadway. More specifically, parameters that define the basic model of the intersection in the roadway may be adjusted to more accurately define the intersection. For example, by comparing a shape of the intersection predicted by the basic model with extracted curbs and lane boundaries from elevation and intensity maps, the intersection parameters can be optimized to match real intersection-features in the environment. Once the optimal intersection parameters have been found, roadgraph features describing the intersection may be extracted.
p4343
aVAbstract\u000aAspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.
p4344
aVAbstract\u000aThe present disclosure relates to a vehicle adapted for autonomous driving, such as an autonomous vehicle, comprising an assisting object detecting system for detecting obstructing objects to the vehicle. The object detecting system is adapted to detect an object by comparing a reference value of a selected parameter with a measured value of the selected parameter. The present disclosure also relates to a method and a computer program product for use in the vehicle.
p4345
aVAbstract\u000aAn unmanned aerial vehicle and associated methods for inspecting infrastructure assets includes a multirotor, electrically driven helicopter apparatus and power supply; a flight computer; positioning and collision avoidance equipment; and at least one sensor such as a camera. The flight computer is programmed for automated travel to and inspection of selected waypoints, at which condition data is collected for further analysis. The method also includes protocols for segmenting the flight path to accomplish sequential inspection of a linear asset such as a power line using limited-range equipment.
p4346
aVAbstract\u000aAn obstacle-avoidance system for a vehicle, the obstacle-avoidance system may comprise: a communication device; a plurality of sensors, the plurality of sensors configured to detect collision threats within a predetermined distance of the vehicle; and a processor. The processor may communicatively couple to the communication device and the plurality of sensors and configured to receive navigation commands being communicated to a control system via said communication device. The processor may also receive, from at least one of said plurality of sensors, obstruction data reflecting the position of an obstruction. Using the obstruction data, the processor identifies a direction for avoiding said obstruction. In response, the processor may output, via said communication device, a command to said control system causing the vehicle to travel in said flight direction.
p4347
aVAbstract\u000aAn autonomous vehicle detects a tailgating vehicle and uses various response mechanisms. For example, a vehicle is identified as a tailgater based on whether its characteristics meet a variable threshold. For example, when the autonomous vehicle is traveling at slower speeds, the threshold is defined in distance. When the autonomous vehicle is traveling at faster speeds, the threshold is defined in time. The autonomous vehicle may respond to the tailgater by modifying its driving behavior. In one example, the autonomous vehicle adjusts a headway buffer (defined in time) from another vehicle in front of the autonomous vehicle. For example, if the tailgater is T seconds too close to the autonomous vehicle, the autonomous vehicle increases the headway buffer to the vehicle in front of it by some amount relative to T.
p4348
aVAbstract\u000aIn a method of autonomous driving a vehicle on a parking area, a movement of a vehicle is controlled by an external stationary control device which is located in or in vicinity of the parking area and capable of steering the vehicle autonomously to or from an assigned parking space. An impending or actual collision with another moving or parked vehicle is detected by at least one sensor of the vehicle; and data generated by the sensor is analyzed by an evaluation unit. In response to the situation at hand, the control device makes a behavioral decision, such as, e.g., triggering an alert signal or maneuvering the vehicle.
p4349
aVAbstract\u000aAn autonomous vehicle configured to determine the heading of an object-of-interest based on a point cloud. An example computer-implemented method involves: (a) receiving spatial-point data indicating a set of spatial points, each spatial point representing a point in three dimensions, where the set of spatial points corresponds to an object-of-interest; (b) determining, for each spatial point, an associated projected point, each projected point representing a point in two dimensions; (c) determining a set of line segments based on the determined projected points, where each respective line segment connects at least two determined projected points; (d) determining an orientation of at least one determined line segment from the set of line segments; and (e) determining a heading of the object-of-interest based on at least the determined orientation.
p4350
aVAbstract\u000aSystems and methods for UAV safety are provided. An authentication system may be used to confirm UAV and/or user identity and provide secured communications between users and UAVs. The UAVs may operate in accordance with a set of flight regulations. The set of flight regulations may be associated with a geo-fencing device in the vicinity of the UAV.
p4351
aVAbstract\u000aA system may include a user interface, a transmitter, a processor, and a memory having a program communicatively connected to the processor. The processor may be configured to receive a body sensor output associated with an occupant of a vehicle, receive a vehicle sensor output associated with the vehicle, compare the body and vehicle sensor outputs with a threshold, prompt for a confirmation associated with at least one of the body and vehicle sensor outputs, determine an issue type based on at least one of the body and vehicle sensor outputs, and send a notification including the issue type.
p4352
aVAbstract\u000aA cellphone controllable car intrusion system is provided. This system includes a vehicle OEM system, including an electronic control unit (ECU), a diagnostic port, a plurality of OEM cameras, a plurality of OEM sensors, an OEM satellite communication system, and an OEM local communication system. The diagnostic port, OEM cameras, OEM sensors, OEM satellite communication system, and the OEM local communication system being in electric communication with the ECU. A cellphone is provided having a local communication system disposed therein. The cellphone is in wireless communication with the ECU. The cellphone is adapted to configure the ECU to enable operation of the OEM cameras in response to receipt by the cellphone of an alert signal from the OEM sensors, indicating that an intrusion is in process. The alert signals are representative of detection of a monitor event by one or more of the OEM sensors.
p4353
aVAbstract\u000aA system configured to determine an insurance premium associated with an account that covers a vehicle including an autonomous feature and a driver comprising a computer memory that stores biographical information including information regarding the autonomous feature; a processor that receives information associated with telematics data associated with the vehicle, concerning use of the vehicle and the autonomous feature; the processor further configured to determine discrete segments of use by the vehicle, and to determine a driver signature associated with each of the discrete segments of use; the processor further configured to generate a driver risk assessment responsive to the one of the discrete segments of use; the processor further configured to calculate pricing information based on the risk assessment and the biographical information; and a transmitter configured to transmit the pricing information to a user device.
p4354
aVAbstract\u000aA utility vehicle with ergonomic, safety, and maintenance features is disclosed. A vehicle is also disclosed with improved cooling, suspension and drive systems. These features enhance the utility of the vehicle.
p4355
aVAbstract\u000aExample methods and systems for controlling operation of a laser device are provided. A method may include receiving an output of a proximity sensor that is positioned adjacent to a laser device, and determining based on the output of the proximity sensor that an object is within a threshold distance to the laser device. The method may also include based on the laser device emitting laser pulses, providing, by a computing device, instructions to discontinue the emission of laser pulses by the laser device based on the object being within the threshold distance. The method may further include based on the laser device being inactive, providing, by the computing device, instructions to prevent the emission of laser pulses by the laser device based on the object being within the threshold distance.
p4356
aVAbstract\u000aThe present invention provides a co-operative network of unmanned vehicles that participate in co-operative task allocation. Each unmanned vehicle comprises a computer system with an executive level configured to control motion of the unmanned vehicle and an automatic decision level configured to communicate with other unmanned vehicles, to receive task descriptions, to participate in task allocation, and to provide descriptions of tasks to be performed to the executive level for execution. Each unmanned vehicle submits a bid for each task it can perform, the bid reflecting an execution cost for the task. The bids are compared and the task effectively auctioned to the unmanned vehicle with a lowest execution cost. Each unmanned vehicle builds a task plan from its allocated tasks, decomposes the associated task descriptions into elementary task descriptions and forwards the elementary task descriptions in a format suitable for the executive level to execute.
p4357
aVAbstract\u000aAspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.
p4358
aVAbstract\u000aA method and control system for maintaining attentiveness of a driver of a vehicle during an autonomous control mode. A series of cognitively demanding tasks is presented to the driver via a man-machine interface during the autonomous control mode. Driver responses to the tasks are monitored, and an audible alert is provided to the driver if the response of the driver and/or a reaction time of the driver in making the response indicate an insufficient level of driver attentiveness.
p4359
aVAbstract\u000aA method for navigating an airborne device relative to a target comprises detecting, at an optical detector on the airborne device, an optical signal generated by one or more LEDs on the target. The method also comprises comparing, by a processor on the airborne device, the detected optical signal with a previously-detected optical signal. The method further comprises determining, by the processor based on the comparison, a change in location of at least one of the airborne device or the target. The method also comprises adjusting a position of the airborne device based on the determined change in location. The method also comprises predicting, by the processor, a movement of the target based on information indicative of at least one of a position, a rotation, an orientation, an acceleration, a velocity, or an altitude of the target, wherein the position of the airborne device is adjusted based on the predicted movement of the target. The method also comprises detecting an obstacle in a flight path associated with the airborne device and adjusting a position of the airborne device is further based, at least in part, on detected obstacle information.
p4360
aVAbstract\u000aAspects of the disclosure relate generally to an autonomous vehicle accessing portions of a map to localize itself within the map. More specifically, one or more convolution scores may be generated between a prior map and a current map. Convolution scores may be generated by applying a fast Fourier transform on both the prior and current maps, multiplying the results of the transforms, and taking the inverse fast Fourier transform of the product. Based on these convolution scores, an autonomous vehicle may determine the offset between the maps and localize itself relative to the prior map.
p4361
aVAbstract\u000aSome embodiments of the invention provide methods and apparatus enabling multiple unmanned cargo deliveries in a single mission. An assembly having multiple hooks may be coupled to an unmanned vehicle via a cable. Prior to a mission originating at a starting location, multiple cargo loads may each be loaded on to a respective pallet, wrapped in a cargo delivery net, and attached to one of the hooks. A ground controller may instruct the unmanned vehicle to deliver the cargo loads to separate locations. The unmanned delivery vehicle may navigate to a first delivery location, perform delivery of a first cargo load by causing the hook on the assembly to release the first load, autonomously exit the first location and navigate to a second delivery location without returning to the starting location, and perform delivery of a second cargo load by causing the hook on the assembly to release the second load.
p4362
aVAbstract\u000aThe present invention provides systems, methods, and devices related to target tracking by UAVs. The UAV may be configured to receive target information from a control terminal related to a target to be tracked by an imaging device coupled to the UAV. The target information may be used by the UAV to automatically track the target so as to maintain predetermined position and/or size of the target within one or more images captured by the imaging device. The control terminal may be configured to display images from the imaging device as well as allowing user input related to the target information.
p4363
aVAbstract\u000aA driver assistance system of a vehicle includes at least one vehicle environmental sensor having a field of sensing exterior of the vehicle. A sensor data processor is operable to process sensor data captured by the sensor. When the vehicle is operated, the sensor data processor receives captured sensor data that is representative of the vehicle surrounding scene. The sensor data processor fuses the sensor data with map data to generate an annotated master map of the scene captured by the sensor. A display device is operable to display information for viewing by a driver of the vehicle. The displayed information is derived at least in part from the annotated master map and is displayed for viewing by the driver of the vehicle who is executing a maneuver of the vehicle.
p4364
aVAbstract\u000aThe invention provides for a vertical takeoff and landing capable aerial vehicle with multiple rotors that is designed to carry agricultural sensors and telemetry allowing for real time control of agricultural equipment in accord with sensor data. The ability to carry a suite of agricultural sensors combined with multiple rotors will allow the craft to operate quickly in hovering and longitudinal flight over rows of farm fields and other vegetation and use an NDVI imager and other sensors to take data readings and real time imagery which will allow farmers and other personnel to determine vegetation type, need for chemical applications, plant fertilization, irrigation requirements, and other vegetation features including types of vegetation present. This will allow for precision agricultural, vegetation, and crop management and for farmers it will increase the efficiency of precision agriculture operations.
p4365
aVAbstract\u000aDisclosed herein is an apparatus and method for providing location and heading information of an autonomous driving vehicle on a road within a housing complex. The apparatus includes an image sensor installed on an autonomous driving vehicle and configured to detect images of surroundings depending on motion of the autonomous driving vehicle. A wireless communication unit is installed on the autonomous driving vehicle and is configured to receive a Geographic Information System (GIS) map of inside of a housing complex transmitted from an in-housing complex management device in a wireless manner. A location/heading recognition unit is installed on the autonomous driving vehicle, and is configured to recognize location and heading of the autonomous driving vehicle based on the image information received from the image sensor and the GIS map of the inside of the housing complex received via the wireless communication unit.
p4366
aVAbstract\u000aIn an example method, a vehicle configured to operate in an autonomous mode could have a radar system used to aid in vehicle guidance. The method could include a plurality of antennas configured to transmit and receive electromagnetic signals. The method may also include a one or more sensors configured to measure a movement of the vehicle. A portion of the method may be performed by a processor configured to: i) determine adjustments based on the movement of the vehicle; ii) calculate distance and direction information for received electromagnetic signals; and iii) recover distance and direction information for received electromagnetic signals with the adjustments applied. The processor may be further configured to adjust the movement of the autonomous vehicle based on the distance and direction information with adjustments applied.
p4367
aVAbstract\u000aAn approach is provided for determining a recommended passenger embarkation point to associate with a point of interest. An embarkation platform determines one or more candidate passenger embarkation points. The embarkation platform also processes contextual information associated with the one or more passenger embarkation points, the at least one passenger, the at least one vehicle, or a combination thereof to determine at least one recommended passenger embarkation point from among the one or more candidate passenger embarkation points. Information regarding the at least one recommended embarkation point is then caused to be presented.
p4368
aVAbstract\u000aA system and method for providing path planning and generation for automated lane centering and/or lane changing purposes for a vehicle traveling on a roadway, where the method employs roadway measurement values from a vision camera within an effective range of the camera and roadway measurement values from a map database beyond the range of the camera. The method uses the roadway measurement values from the camera to determine a desired path along a first segment of the roadway and identifies an end of the first segment based on how accurately the camera defines the roadway. The method then uses the roadway measurement values from the map database to determine the desired path along a second segment of the roadway that begins at the end of the first segment, where a transition from the first segment to the second segment is smooth.
p4369
aVAbstract\u000aSystems and methods are disclosed including a ride-sharing computer to receive a ride-sharing request from a rider, wherein the computer includes a route analysis module to collect travel data and appointments from a calendar from a first mobile device of a first user and from a second mobile device of a second user, and to determine a first travel pattern associated with the first user and a second travel pattern associated with the second user and a carpool matching module to determine a match between the first and second travel patterns, and to generate a carpool proposal directed at the first and second users, wherein one of the travel patterns is a common portion of the other travel pattern proximally the same time for spatially and temporally common on-demand carpooling; and a ride-sharing vehicle and having a mobile device coupled to the computer, wherein the mobile device picks up the first and second users based on the carpool proposal.
p4370
aVAbstract\u000aA system and method for generating an overlay torque command for an electric motor in an EPS system for use in a collision avoidance system. The method uses model predictive control that employs a six-dimensional vehicle motion model including a combination of a one-track linear bicycle model and a one-degree of freedom steering column model to model the vehicle steering. The method determines a steering control goal that defines a path tracking error between the current vehicle path and the desired vehicle path through a cost function that includes an optimal total steering torque command. The MPC determines the optimal total steering torque command to minimize the path error, and then uses driver input torque, EPS assist torque and the total column torque command to determine the torque overlay command.
p4371
aVAbstract\u000aA motor vehicle comprising at least one driver assistance system (2) to pre-calculate future driving situations of the motor vehicle (1) for a specified time interval by evaluating ego data related to the motor vehicle (1) and environmental data related to the motor vehicle environment, wherein the motor vehicle (1) is controllable by a driver in a first operating mode of the driver assistance system (2), wherein the driver assistance system (2) is designed, upon fulfillment of one switchover condition dependent at least upon future driving situations, to be temporarily switched over into a second operating mode in which the motor vehicle (1) is autonomously controlled by the driver assistance system (2) without the possibility of intervention by the driver, wherein driving is continued in the second operating mode.
p4372
aVAbstract\u000aAn autonomous vehicle is improved with a navigational system having both cameras and echolocation sensors, each including overlapping fields of view. The cameras and echolocation sensors may be part of an optical and echolocation system, respectively, that may work in conjunction with a global positioning system to determine a course for the autonomous vehicle to reach an objective while detecting and avoid obstacles along the course.
p4373
aVAbstract\u000aAn intelligent mobile robot having a robot base controller and an onboard navigation system that, in response to receiving a job assignment specifying a job location that is associated with one or more job operations, activates the onboard navigation system to automatically determine a path the mobile robot should use to drive to the job location, automatically determines that using an initially-selected path could cause the mobile robot to run into stationary or non-stationary obstacles, such as people or other mobile robots, in the physical environment, automatically determines a new path to avoid the stationary and non-stationary obstacles, and automatically drives the mobile robot to the job location using the new path, thereby avoiding contact or collisions with those obstacles. After the mobile robot arrives at the job location, it automatically performs said one or more job operations associated with that job location.
p4374
aVAbstract\u000aA system for controlling a group of vehicles as a whole in which each individual member of the group receives telemetry from other members of the group or from the group as a whole, and makes decisions regarding the setting and/or changing of local operating parameters based on the received telemetry.
p4375
aVAbstract\u000aA method and system for facilitating cost effective, reliable, system redundant, self-driving vehicles involves the employment of specialized lane marking components that permit unprecedented sensor feedback, and in particular, a system and method that enables accurate lane marking recognition despite adverse weather conditions, which presently pose problems experienced by self-driving systems that rely upon vision based camera systems.
p4376
aVAbstract\u000aA method and apparatus for autonomous vehicle routing and navigation using passenger docking locations are disclosed. Autonomous vehicle routing and navigation using passenger docking locations may include an autonomous vehicle identifying vehicle transportation network information representing a vehicle transportation network, the vehicle transportation network including a primary destination, wherein identifying the vehicle transportation network information includes identifying the vehicle transportation network information such that it includes docking location information representing a plurality of docking locations, wherein each docking location corresponds with a respective location in the vehicle transportation network. The autonomous vehicle may determine a target docking location for the primary destination based on the vehicle transportation network information, identify a route from an origin to the target docking location in the vehicle transportation network using the vehicle transportation network information, and travel from the origin to the target docking location using the route.
p4377
aVAbstract\u000aA navigation system for a vehicle may include at least one image capture device configured to acquire a plurality of images of an environment of a vehicle and a radar sensor to detect an object in the environment of the vehicle and to provide and output including range information indicative of at least one of a range or range rate between the vehicle and the object. The system may also include at least one processing device programmed to: receive the plurality of images from the at least one image capture device; receive the output from the radar sensor; determine, for each of a plurality of image segments in a first image, from among the plurality of images, and corresponding image segments in a second image, from among the plurality of images, an indicator of optical flow; use range information determined based on the output of the radar sensor together with the indicators of optical flow determined for each of the plurality of image segments in the first image and the corresponding image segments in the second image to calculate for each of a plurality of imaged regions at least one value indicative of a focus of expansion; identify a target object region, including at least a subset of the plurality of imaged regions that share a substantially similar focus of expansion; and cause a system response based on the identified target object region.
p4378
aVAbstract\u000aA vehicle includes at least one autonomous driving sensor configured to monitor at least one condition while operating in an autonomous mode. The vehicle further includes a processing device configured to identify at least one occupant, select a profile associated with the occupant, and autonomously operate at least one subsystem according to the selected profile and the at least condition monitored by the at least one autonomous driving sensor.
p4379
aVAbstract\u000aA system for flock-based control of a plurality of unmanned aerial vehicles (UAVs). The system includes UAVs each including a processor executing a local control module and memory accessible by the processor for use by the local control module. The system includes a ground station system with a processor executing a fleet manager module and with memory storing a different flight plan for each of the UAVs. The flight plans are stored on the UAVs, and, during flight operations, each of the local control modules independently controls the corresponding UAV to execute its flight plan without ongoing control from the fleet manager module. The fleet manager module is operable to initiate flight operations by concurrently triggering initiation of the flight plans by the multiple UAVs. Further, the local control modules monitor front and back and communication channels and, when a channel is lost, operate the UAV in a safe mode.
p4380
aVAbstract\u000aMethod for controlling a vehicle to maintain a desired position on a roadway includes monitoring roadway information behind the vehicle using a rearward detection device and monitoring vehicle sensor information. Frontward positional information is projected based on rearward positional information obtained from the monitored roadway information behind the vehicle. Forward roadway curvature is estimated based on the vehicle sensor information. Roadway information ahead of the vehicle is modeled based on the projected frontward positional information and the estimated forward roadway curvature to determine desired vehicle positional information. Future vehicle positional information is predicted with respect to the modeled roadway information based on the monitored vehicle sensor information and the estimated forward roadway curvature. The desired vehicle position information is compared to the predicted future vehicle positional information and a steering command is generated based on a deviation in the predicted future position information from the desired vehicle positional information.
p4381
aVAbstract\u000aSystems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried on the unmanned aerial vehicle and configured to receive sensor data of the environment and one or more processors. The one or more processors may be individually or collectively configured to: determine, based on the sensor data, an environmental complexity factor representative of an obstacle density for the environment; determine, based on the environmental complexity factor, one or more operating rules for the unmanned aerial vehicle; receive a signal indicating a desired movement of the unmanned aerial vehicle; and cause the unmanned aerial vehicle to move in accordance with the signal while complying with the one or more operating rules.
p4382
aVAbstract\u000aThe present invention is directed to a system and methods of providing platform-agnostic systems and methods capable of providing an integrated processor and sensor suite with supervisory control software and interfaces to perform small unit rapid response resupply and CASEVAC into hazardous and unpredictable environments.
p4383
aVAbstract\u000aSystems, devices, and methods for a transformable aerial vehicle are provided. In one aspect, a transformable aerial vehicle includes: a central body and at least two transformable frames assemblies respectively disposed on the central body, each of the at least two transformable frame assemblies having a proximal portion pivotally coupled to the central body and a distal portion; an actuation assembly mounted on the central body and configured to pivot the at least two frame assemblies to a plurality of different vertical angles relative to the central body; and a plurality of propulsion units mounted on the at least two transformable frame assemblies and operable to move the transformable aerial vehicle.
p4384
aVAbstract\u000aA computer-implemented method includes receiving from a telemetric apparatus carried by a first vehicle an identity of an operator of the first vehicle and kinematic data characterizing movement and first location of the first vehicle. At least one weather condition associated with the first location is received from a source of environmental data. At least one of terrain geometry of the first location, road speed limit at the first location, vehicle-to-infrastructure (V2I) data generated by an instrument proximate the first location, and vehicle-to-vehicle (V2V) data generated by an instrument proximate the first location is received from a source of location-specific data. The data received by the first communication device is stored in a database. Data from the database is provided to at least one entity.
p4385
aVAbstract\u000aApparatus and methods for an extensible robotic device with artificial intelligence and receptive to training controls. In one implementation, a modular robotic system that allows a user to fully select the architecture and capability set of their robotic device is disclosed. The user may add/remove modules as their respective functions are required/obviated. In addition, the artificial intelligence is based on a neuronal network (e.g., spiking neural network), and a behavioral control structure that allows a user to train a robotic device in manner conceptually similar to the mode in which one goes about training a domesticated animal such as a dog or cat (e.g., a positive/negative feedback training paradigm) is used. The trainable behavior control structure is based on the artificial neural network, which simulates the neural/synaptic activity of the brain of a living organism.
p4386
aVAbstract\u000aIn an apparatus for guiding an unmanned autonomous operating vehicle having an electric motor supplied with power from a battery (30) for operating a lawn mower blades, other electric motors for driving wheels, and two magnetic sensors attached at the front for detecting intensity of a magnetic field of an area wire and controlled to run about in an operating area defined by the area wire to perform operation and to return to a charging device installed on the area wire so as to charge the battery, the area wire is laid with an offset to right or left when viewed in a plane such that the vehicle is turned from a straight-running position to a direction of the offset and then is returned to the straight-running position when the vehicle runs to be connected to the charging device, thereby guiding the vehicle to the charging device.
p4387
aVAbstract\u000aA method and apparatus of managing a forest. A forestry management system comprises a forestry manager. The forestry manager is configured to receive information about a forest from a group of autonomous vehicles, analyze the information to generate a result about a state of the forest from the information, and coordinate operation of the group of autonomous vehicles using the result.
p4388
aVAbstract\u000aIn an arrangement of an area wire for an unmanned autonomous operating vehicle having an electric motor supplied with power from a battery for operating an operating machine, and magnetic sensors for detecting intensity of a magnetic field of the area wire and controlled to run about in an operating area defined by the area wire to perform an operation using the operating machine and to return to a charging device installed on the area wire so as to charge the battery, there are provided with a charging device detecting area set to be used for detecting a position of the charging device, and a turn-back portion formed by bending the area wire at an appropriate position toward the charging device detecting area and again bending the area wire to return in a same direction with a predetermined space, whereby the operating area is divided into a plurality of zones.
p4389
aVAbstract\u000aMethods and systems for estimating vehicle speed are disclosed. A light detecting and ranging (LIDAR) device obtains a set of spatial points indicative of locations of reflective surfaces in an environment of the LIDAR device. A plurality of target points that correspond to a target surface of a target vehicle is identified in the set of spatial points. The plurality of target points includes a first point indicative of a first location on the target surface obtained by the LIDAR device at a first time and a second point indicative of a second location on the target surface obtained by the LIDAR device at a second time. A speed of the target vehicle is estimated based on the first location, the first time, the second location, and the second time.
p4390
aVAbstract\u000aEmbodiments include a flight safety assembly onboard an aerial vehicle, which includes a first sensor configured to sense first information related to flight of the aerial vehicle and a second sensor configured to sense second information related to the flight of the aerial vehicle. A sensor input is adapted to receive third information related to the flight of the aerial vehicle. A processor is operably coupled to the first sensor, the second sensor, and the sensor input. The processor is configured to determine three independent instantaneous impact points for the aerial vehicle by independently analyzing each of the first information, the second information and the third information. The processor is also configured to generate three independent onboard flight termination indicators for each of the three independent instantaneous impact points that intersects with a region to be protected.
p4391
aVAbstract\u000aModern farming is currently being done by powerful ground equipment or aircraft that weigh several tons and treat uniformly tens of hectares per hour. Automated farming can use small, agile, lightweight, energy-efficient automated robotic equipment that flies to do the same job, even able to farm on a plant-by-plant basis, allowing for new ways of farming. Automated farming uses unmanned aerial vehicles (UAVs) that are equipped with detachable implements and reservoirs and that we call \u201caerial farm robots.\u201d Automated farming uses high-precision GPS and other precision positioning and vision technology to autonomously and precisely perform crop dusting, planting, fertilizing and other field related farming or husbandry tasks. The subsystems for the control, refill, recharge and communication subsystems of the aerial farm robots are part of the overall automated farming system, and can autonomously handle most of the husbandry tasks on a farm.
p4392
aVAbstract\u000aDisclosed herein are systems and methods for classifying regions of a scanning zone of a light detection and ranging (LIDAR) scan. One example includes a method for receiving information indicative of a light detection and ranging (LIDAR) scan of a vehicle. The method further involves generating a point map of the scanning zone. The method further involves generating a density profile of the point map that is indicative of density of one or more regions of the scanning zone characterized at one or more distances. The method further involves generating an elevation profile of the point map that is indicative of elevation of one or more reflected features in the scanning zone characterized at one or more distances. The method further involves classifying regions of the scanning zone based on the density profile and the elevation profile.
p4393
aVAbstract\u000aA computer in a vehicle is configured to operate the vehicle in at least one of an autonomous and a semi-autonomous mode. The computer is further configured to detect at least one condition of a roadway being traveled by the vehicle, the condition comprising at least one of a restricted lane, a restricted zone, a construction zone, and accident area, an incline, a hazardous road surface. The computer is further configured to determine at least one autonomous action based on the condition, the at least one autonomous action including at least one of altering a speed of the vehicle, controlling vehicle steering, controlling vehicle lighting, transitioning the vehicle to manual control, and controlling a distance of the vehicle from an object.
p4394
aVAbstract\u000aMethods and systems for use of previous detections to improve lane marker detection are described. A computing device may be configured to receive lane information generated at previous time periods, and relates to detection of a lane boundary on a road of travel of a vehicle. The computing device may be configured to estimate, based on the lane information, a projection of a respective lane boundary ahead of the vehicle on the road. The computing device may further be configured to determine, based on a speed of the vehicle and geometry of the road, a level of confidence for the projection of the respective lane boundary. The computing device may also be configured to provide instructions to control the vehicle based on the projection and the level of confidence.
p4395
aVAbstract\u000aA modular system for building underwater robotic vehicles (URVs), including a pressure vessel system, modular chassis elements, a propulsion system and compatible buoyancy modules. The pressure vessel system uses standardized, interchangeable modules to allow for ease of modification of the URV and accommodation of different internal and external components such as sensors and computer systems. The system also includes standard, reconfigurable connections of the pressure vessel to the modular chassis system. A standardized, modular propulsion system includes a magnetic clutch, and a magnetic sleeve used to power the URV on or off.
p4396
aVAbstract\u000aSystems and methods are provided for swapping the battery on an unmanned aerial vehicle (UAV) while providing continuous power to at least one system on the UAV. The UAV may be able to identify and land on an energy provision station autonomously. The UAV may take off and/or land on the energy provision station. The UAV may communicate with the energy provision station. The energy provision station may store and charge batteries for use on a UAV. The UAV and/or the energy provision station may have a backup energy source to provide continuous power to the UAV.
p4397
aVAbstract\u000aAn automated mobile vehicle configured to autonomously provide coverage for inoperable infrastructure components at various locations. A plurality of automated mobile vehicles may be deployed to provide emergency lighting, a wireless network, audio, video, etc., at an event area. The event area may be indoors and/or outdoors.
p4398
aVAbstract\u000aAn autonomous vehicle is provided that includes an autonomous vehicle control system, a dialysis machine, and an interface providing an electrical communication between the dialysis machine and the autonomous vehicle control system. The dialysis machine is configured to perform a dialysis treatment on a patient while the autonomous vehicle is under the control of the autonomous vehicle control system. A vehicle is also provided that includes a navigation system, a dialysis machine, and an interface between the navigation system and the dialysis machine. The vehicle can be a car, a train, a plane, or another vehicle.
p4399
aVAbstract\u000aA solution for performing a set of tasks using one or more robotic devices is provided. The robotic device can be configured to perform each task using one or more effector devices, one or more sensor devices, and a hybrid control architecture including a plurality of dynamically changeable levels of autonomy. The levels of autonomy can include: full autonomy of the robotic device, teleoperation of the robotic device by a human user, and at least one level of shared control between the computer system and the human user.
p4400
aVAbstract\u000aA method for automated lane centering and/or lane changing purposes for a vehicle traveling on a roadway that employs roadway points from a map database to determine a reference vehicle path and sensors on the vehicle for detecting static and moving objects to adjust the reference path. The method includes reducing the curvature of the reference path to generate a reduced curvature reference path that reduces the turning requirements of the vehicle and setting the speed of the vehicle from posted roadway speeds from the map database. The method also includes providing multiple candidate vehicle paths and vehicle speeds to avoid the static and moving objects in front of the vehicle.
p4401
aVAbstract\u000aSystems, methods, and devices are provided for providing flight response to flight-restricted regions. The location of an unmanned aerial vehicle (UAV) may be compared with a location of a flight-restricted region. If needed a flight-response measure may be taken by the UAV to prevent the UAV from flying in a no-fly zone. Different flight-response measures may be taken based on the distance between the UAV and the flight-restricted region and the rules of a jurisdiction within which the UAV falls.
p4402
aVAbstract\u000aSystems and methods can support determining a physical position of a radio transmitter. A physical model for electromagnetic signal propagation within the electromagnetic environment may be established. Radio frequency signal power levels associated with the radio transmitter may be received from one or more radio frequency sensors. Parameters associated with the physical model may be estimated for one or more test locations within the electromagnetic environment. An error metric between the received radio frequency signal power levels and the physical model may be computed for the one or more test locations. Bounds on the parameters associated with the physical model may be established to prune away physically impossible solutions. The parameters associated with the physical model may be optimized across the one or more test locations to establish a preferred location estimate for the radio transmitter.
p4403
aVAbstract\u000aSome embodiments relate to a system and method of automatically transporting cargo from a loading station to an unloading station using a vehicle. Loading and unloading of cargo may be accomplished automatically without the need for human operators of either the loading station, the unloading station, or the vehicle. The unloading and loading station each comprise guide rails and a plurality of directional signal sources used by the vehicle to control its current position so that it may retrieve and deliver a target load. The vehicle comprises at least one sensor for detecting modulated directional signals and a controller to control the current position of the vehicle based on the received signals.
p4404
aVAbstract\u000aA vehicle trailer connect system and automated parking system for use with a motor vehicle. Apparatus of the system has an input for obtaining information from a vehicle communication bus; an output for sending information to a vehicle communications bus; a control circuit for controlling the position and movement of a motor vehicle; an image gathering system to obtain visual or spatial data between a motor vehicle hitch and a hitch receiver attached to the trailer. A system controller guides vehicle steering as the vehicle is backed through a field of view of the image gathering system.
p4405
aVAbstract\u000aAn approach is provided for processing and/or facilitating a processing of sensor information associated with one or more parked vehicles to determine one or more parking conditions, wherein at least one subset of the one or more parked vehicles is configured with one or more automatic movement systems. The approach involves determining at least one adjustment to the one or more of the parked vehicles based, at least in part, on the one or more parking conditions. The approach further involves causing, at least in part, (a) a presentation of at least one notification regarding the one or more parking conditions, the at least one adjustment, or a combination thereof (b) an activation of the one or more automatic movement systems to perform the at least one adjustment; or (c) a combination thereof.
p4406
aVAbstract\u000aAn autonomous driving merge management system includes an autonomous driving control device and an intention decision management system. The management system includes a candidate strategy subsystem generating a plurality of candidate driving strategies, a merging vehicle behavior recognition subsystem predicting a merging intention of a merging vehicle; an intention-based interactive prediction subsystem predicting future merging scenarios between the host vehicle and merging vehicle as a function of inputs by the merging vehicle behavior recognition subsystem and inputs by the candidate strategy subsystem, and a cost function-based evaluation subsystem determining a cost for each future merging scenario generated by the intention-based interactive prediction subsystem. A processor selects a merge strategy of the host vehicle based on intention-based prediction results and cost function-based evaluation results. The autonomous driving control device applies the merge strategy to the host vehicle for allowing the merging vehicle to cooperatively merge with the host vehicle.
p4407
aVAbstract\u000aArrangements relating to the transitioning of a vehicle between operational modes are described. The vehicle can transition between a first operational mode and a second operational mode. The second operational mode has a greater degree of manual involvement than the first operational mode. For instance, the first operational mode can be an unmonitored autonomous operational mode, and the second operational mode can be a monitored autonomous operational mode or a manual operational mode. It can be determined whether an operational mode transition event has occurred while the vehicle is operating in the first operational mode. In response to determining that an operational mode transition event has occurred, a time buffer for continuing in the first operational mode before switching to the second operational mode can be determined. A transition alert can be presented within the vehicle. The transition alert can represent the determined time buffer.
p4408
aVAbstract\u000aA vehicle includes a passenger compartment and at least one seat located in the passenger compartment. The seat can be moved from a front-facing position to a rear-facing position for when the vehicle is operating in an autonomous mode. The vehicle may further include autonomous driving sensors and an autonomous controller that receives signals generated by the autonomous driving sensors and controls at least one vehicle subsystems according to the signals received.
p4409
aVAbstract\u000aA computer-implemented method, system, and/or computer program product alerts a proximate entity of a current real-time driving mode of a vehicle. One or more processors determine a current real-time driving mode of a vehicle. The current real-time driving mode is either an autonomous mode or a manual mode. The vehicle is in the autonomous mode when being driven and controlled by an on-board computer, and the vehicle is in the manual mode when being driven and controlled by a human driver. The processor(s) generate a driving mode indicator that identifies the current real-time driving mode of the vehicle. An indicator emitter then broadcasts the driving mode indicator from the vehicle to the proximate entity, such that the driving mode indicator indicates the current real-time driving mode of the vehicle.
p4410
aVAbstract\u000aA steering wheel is locatable between an operational position at a driver seat of a vehicle and a stowed position in the vehicle. A first airbag is coupled to the steering wheel, and a multi-stage airbag laterally overlaps the driver seat and a passenger seat of the vehicle next to the driver seat. A controller includes instructions for detecting a frontal collision, locating the steering wheel, deploying the first airbag at the driver seat and the multi-stage airbag at the passenger seat when the steering wheel is in the operational position, and deploying the multi-stage airbag at the driver and passenger seats when the steering wheel is in the stowed position.
p4411
aVAbstract\u000aA method of controlling movement of an agent operating within an autonomous system includes determining, using a processing device associated with the agent, a highest attraction point for the agent on a line of optimal transmission between a detected event within an area of surveillance by the autonomous system and a base station within the autonomous system, and calculating an attraction force for the agent, based on the line of optimal transmission and location of the detected event; determining proximity of the agent to one or more additional agents operating within the autonomous system, and calculating a repulsion force for the agent so as to maintain a minimum separating distance between the agent and the one or more additional agents; calculating a resultant force for the agent based on the attraction force and the repulsion force; and changing a direction of the agent based on the resultant force.
p4412
aVAbstract\u000aA robotic control system for a vehicle having a chassis and a drive system carrying the chassis. The robotic control system including a controller configured to control the drive system. The controller being further configured to at least one of auto-load the vehicle onto a trailer, preclude tipping of the vehicle, stabilize yaw of the vehicle, simulate Ackerman steering, balance the vehicle on two wheels, retrieve an other vehicle, transfer a payload from the vehicle to the other vehicle, coupling of at least one other vehicle to the vehicle, retrieval or movement of a container using either relative sensing or absolute position referencing, profile cutting of plants, and 3D print cement.
p4413
aVAbstract\u000aA method and apparatus for managing a location. Soil sensor units are deployed in the location in a forest from a group of aerial vehicles. Information is generated about a number of soil conditions in the location in the forest using the soil sensor units in the location. The information is transmitted from the soil sensor units to a remote location for analysis.
p4414
aVAbstract\u000aMethods and systems for reverse-iterating a backward planner determining trajectories for vehicles of a fleet of vehicles are provided. In one example an iterator configured for recursively determining the contingency tables at successive time steps in a computational iteration order from a target time to an initial time is caused to reverse-generate the contingency tables in an order from the initial time to the target time. Reverse-generation is caused by recursively: (i) subdividing a sequence of time steps by a factor of at least two into successively smaller sub-sequences, (ii) iterating in a computational iteration order over each recursively subdivided sub-sequence, and (iii) generating a contingency table closest in time to the initial time for the recursive iteration over each recursively subdivided sub-sequence.
p4415
aVAbstract\u000aSystems, methods, apparatuses, and landing platforms are provided for visual and/or ground-based landing of unmanned aerial vehicles. The unmanned aerial vehicles may be capable of autonomously landing. Autonomous landings may be achieved by the unmanned air vehicles with the use of an imager and one or more optical markers on a landing platform. The optical markers may be rectilinear, monochromatic patterns that may be detected by a computing system on the unmanned aerial vehicle. Furthermore, the unmanned aerial vehicle may be able to automatically land by detecting one or more optical markers and calculating a relative location and/or orientation from the landing platform.
p4416
aVAbstract\u000aA damper system for a vehicle comprises an electrically adjustable hydraulic shock absorber and a damper control module. The damper control module is disposed with and coupled to with the shock absorber. The damper control module determines a target damping state of the shock absorber based on data received from a plurality of sensors. Furthermore, the damper control module controls the shock absorber, such that the shock absorber operates at the target damping state.
p4417
aVAbstract\u000aA driver state module for interfacing with a vehicle, with a surroundings vicinity of the vehicle and with a driver of the vehicle, the driver state module comprising: (i) a frame memory for storing representations of behaviors with related context; (ii) an evaluation system for ranking the frames based on goals and rewards; (iii) a working memory comprising a foreground sub-memory and a background sub-memory, the working memory for holding and sorting frames into foreground and background frames, and (iv) a recognition processor for identifying salient features relevant to a frame in the foreground memory ranked highest by the evaluation system.
p4418
aVAbstract\u000aAn approach is provided for determining at least one intention to perform at least one crossing of at least one object within proximity of at least one first vehicle. The approach involves determining at least one second vehicle within proximity of the at least one crossing, the at least one first vehicle, or a combination thereof. The approach further involves causing, at least in part, a signaling among at least one first device associated with the at least one first vehicle and at least one second device associated with the at least one second vehicle, wherein the signaling causes, at least in part, a synchronization of at least one movement, at least one stop, the at least one intention to perform the at least one crossing, or a combination thereof among the at least one first vehicle, the at least one second vehicle, at least one cloud service, or a combination thereof in response to the at least one request.
p4419
aVAbstract\u000aExample methods and systems for decomposing fleet planning optimizations via spatial partitions are described. An example method includes receiving information indicating a sequence of coverage requirements for a region over a period of time. The region is characterized by a plurality of landmarks and the period of time is divided into a plurality of phases. An individual coverage requirement indicates a desired number of vehicles of a plurality of vehicles for respective landmarks at a given phase. The method also includes dividing the region into a plurality of sub-regions, and determining sub-region fleet plans for the plurality of sub-regions based on estimates of one or more vehicles entering respective sub-regions and estimates of one or more vehicles leaving respective sub-regions. The method also includes combining the sub-region fleet plans to produce a fleet plan responsive to the sequence of coverage requirements for the region.
p4420
aVAbstract\u000aExample methods and systems for camera calibration using structure from motion techniques are described herein. Within examples, an autonomous vehicle may receive images from a vehicle camera system and may determine an image-based pose based on the images. To determine an image-bases pose, an autonomous vehicle may perform various processes related to structure from motion, such as image matching and bundle adjustment. In addition, the vehicle may determine a sensor-based pose indicative of a position and orientation of the vehicle through using information provided by vehicle sensors. The vehicle may align the image-based pose with the sensor-based pose to determine any adjustments to the position or orientation that may calibrate the cameras. In an example, a computing device of the vehicle may align the different poses using transforms, rotations, and/or scaling.
p4421
aVAbstract\u000aSystems and methods can support identifying radio transmissions associated with autonomous or remote-controlled vehicles. Radio frequency signals may be received using one or more sensors, wherein the sensors comprise radio receivers. Radio frequency fingerprints may be identified within one or more of the radio frequency signals, wherein the radio frequency fingerprints comprise radio signal characteristics or radio hardware identifiers. A stored radio frequency fingerprint may be determined as matching the received radio frequency fingerprint. A motion characteristic may be computed. The received radio frequency fingerprint may be associated with an autonomous or remote-controlled vehicle based upon the stored radio frequency fingerprint or the motion characteristic. Information regarding the identified autonomous or remote-controlled vehicle may be presenting to one or more operator interfaces.
p4422
aVAbstract\u000aAspects of the disclosure relate generally to detecting lane markers. More specifically, laser scan data may be collected by moving a laser along a roadway. The laser scan data may include data points describing the intensity and location information of objects within range of the laser. Each beam of the laser may be associated with a respective subset of data points. For a single beam, the subset of data points may be further divided into sections. For each section, the average intensity and standard deviation may be used to determine a threshold intensity. A set of lane marker data points may be generated by comparing the intensity of each data point to the threshold intensity for the section in which the data point appears and based on the elevation of the data point. This set may be stored for later use or otherwise made available for further processing.
p4423
aVAbstract\u000aAn autonomous vehicle configured for active sensing may also be configured to weigh expected information gains from active-sensing actions against risk costs associated with the active-sensing actions. An example method involves: (a) receiving information from one or more sensors of an autonomous vehicle, (b) determining a risk-cost framework that indicates risk costs across a range of degrees to which an active-sensing action can be performed, wherein the active-sensing action comprises an action that is performable by the autonomous vehicle to potentially improve the information upon which at least one of the control processes for the autonomous vehicle is based, (c) determining an information-improvement expectation framework across the range of degrees to which the active-sensing action can be performed, and (d) applying the risk-cost framework and the information-improvement expectation framework to determine a degree to which the active-sensing action should be performed.
p4424
aVAbstract\u000aA method and apparatus for autonomously managing operation of an unmanned aerial vehicle. Sensor data is received by a computer system located onboard the unmanned aerial vehicle. The sensor data is processed by the computer system to generate information of interest related to at least one target, while the unmanned aerial vehicle is out of a communications range of a control station. A number of actions to be performed is identified by the computer system based on the information of interest related to the at least one target, while the unmanned aerial vehicle is out of the communications range of the control station.
p4425
aVAbstract\u000aAn SDV on-board computer on an SDV receives an SDV recognition signal from a pedestrian signal transceiver worn by a pedestrian. An SDV signal transceiver on the SDV transmits a pedestrian acknowledgement message to the signal transceiver worn by the pedestrian. The SDV on-board computer receives a pedestrian movement signal from a set of pedestrian sensors that monitor movement of the pedestrian. The SDV on-board computer receives an SDV movement signal from a set of SDV sensors on the SDV that track movement of the SDV. The SDV on-board computer, based on the SDV movement signal and the pedestrian movement signal, directs an SDV control processor on the SDV to modify the movement of the SDV in order to provide the pedestrian with time and space required to avoid the pedestrian being struck by the SDV, and notifies the pedestrian that this SDV movement modification will occur.
p4426
aVAbstract\u000aThe present invention is directed to a steering apparatus for a vehicle having a including a light element providing indication and warning light signals to the user of the vehicle. The light element can be associated with a PCB mounted to the steering wheel grip for controlling the operation of the light element. The PCB may be thermally coupled to a heat exchange component such that heat from the light element is transferred from the PCB to the steering wheel grip.
p4427
aVAbstract\u000aAn illustrative apparatus may include a UAV request apparatus having a housing with at least one interface configured to accept one or more inputs that are each indicative of a particular type of medical situation. A control system may be configured to receive, via the interface, a first input that corresponds to a first type of medical situation in which a defibrillator is configured to provide medical support; and send, via a first network interface to an access system for a network of UAVs, a medical support request including a unique electronic identifier for the apparatus and an indication of the first type of medical situation, such that a UAV delivers a defibrillator to a location associated with the unique electronic identifier.
p4428
aVAbstract\u000aIn one implementation, sets of probe data are collected by probe vehicles. The probe data describes the driving characteristics of the probe vehicles. The sets of probe data are sent to a server or a mobile device for analysis. A polycurve, including a piecewise function of map data, is modified based on the probe data. The polycurve may be a spline curve for an advanced driver assistance system. The modified polycurve may be used in the advanced driver assistance system for a vehicle traveling along the same path previously traversed by the probe vehicles. Based on the polycurve modified by the probe data, a driver assistance feature is provided to the vehicle.
p4429
aVAbstract\u000aAn autonomous parking procedure of a motor vehicle involves transferring a command to activate the autonomous parking procedure using a communication link between an operator situated outside the motor vehicle and the motor vehicle. Before beginning the autonomous parking procedure of the motor vehicle the target position and/or last driven trajectory of the motor vehicle is stored in a storage device. The motor vehicle then performs the parking procedure autonomously from the start position using the stored data after the first activation of the autonomous parking procedure.
p4430
aVAbstract\u000aAspects of the disclosure relate generally to detecting road weather conditions. Vehicle sensors including a laser, precipitation sensors, and/or camera may be used to detect information such as the brightness of the road, variations in the brightness of the road, brightness of the world, current precipitation, as well as the detected height of the road. Information received from other sources such as networked based weather information (forecasts, radar, precipitation reports, etc.) may also be considered. The combination of the received and detected information may be used to estimate the probability of precipitation such as water, snow or ice in the roadway. This information may then be used to maneuver an autonomous vehicle (for steering, accelerating, or braking) or identify dangerous situations.
p4431
aVAbstract\u000aEmbodiments relate to using a UAV for assisting drivers of large wheeled vehicles when backing up in reverse and for conducting pre-trip inspections of the wheeled vehicle prior to driving. The UAV can be a multirotor copter using simultaneous localization and mapping technology to maneuver autonomously. Alternatively, the driver of the wheeled vehicle may use remote control to maneuver the UAV.
p4432
aVAbstract\u000aA method of controlling autonomous or driverless vehicles in a specific control zone is disclosed. The vehicles enter the zone and come under the control of a zone authority that coordinates the movements of the vehicles until they leave the zone. The behavior of the vehicles is modified to insure that it matches a set of rules established by the zone authority. The zone may be an area such as a bridge, tunnel or construction zone where efficient, possibly single lane, travel requires tight coordination. Other possible zones include parking areas, indoor passages and areas with security concerns. The zone authority simultaneously controls multiple autonomous vehicles and possible additional driver operated vehicles. The messages establishing control or providing continuing administration of rules may be delivered by any type of communications link or may be associated with a device issued to vehicles entering the zone which is collected on exit.
p4433
aVAbstract\u000aA method for directing a vehicle to a parking space within an environment is disclosed. The method includes selecting a parking space from a collection of parking spaces within the environment, further selecting one or more lighting devices within the environment based at least on a location of the selected parking space, and sending a signal to the one or more lighting devices to generate a lighting pattern visible to a driver of the vehicle, where the lighting pattern directs the driver to navigate the vehicle toward the parking space. In addition, the vehicle may be navigated using radio navigation algorithms based on beacon signals broadcasted from streetside devices, such as lighting devices or parking meters.
p4434
aVAbstract\u000aIn one aspect, an image processing method for processing images is provided, comprising the steps of: obtaining, from an optical sensor, at least two images, determining an image warping function at least partially compensating the distortion, applying the determined image warping function to the image including the distortion, and calculating by a processing unit, and outputting, a depth and/or disparity image from the at least two images.
p4435
aVAbstract\u000aRobotic devices may be trained using saliency maps derived from gaze of a trainer. In navigation applications, the saliency map may correspond to portions of the environment being observed by a driving instructor during training using a gaze detector. During an operation, a driver assist robot may utilize the saliency map in order to assess attention of the driver, detect potential hazards, and issue alerts. Responsive to a detection of a mismatch between the driver current attention and the target attention derived from the saliency map, the robot may issue a warning, and/or prompt the driver of an upcoming hazard. A data processing apparatus may employ gaze based saliency maps in order to analyze, e.g., surveillance camera feeds for intruders, open doors, hazards, policy violations (e.g., open doors).
p4436
aVAbstract\u000aDrive-control systems for personal-transportation vehicles can function as active driving aids that enable autonomous and semi-autonomous cooperative navigation of electric-powered wheelchairs (EPWs) and other vehicles both indoors, and in dynamic, outdoor environments. The systems can help to compensate for the loss of cognitive, perceptive, or motor function in the driver by interpreting the driver's intent and seeing out into the environment on the driver's behalf. The systems can incorporate intelligent sensing and drive-control means that work in concert with the driver to aid in negotiating changing terrain, avoiding obstacles/collisions, maintaining a straight trajectory, etc. In addition, the systems can be configured to facilitate higher-level path planning, and execution of non-linear routes of travel in a safe and efficient manner.
p4437
aVAbstract\u000aEmbodiments of the present invention include control methods employed in multiphase distributed energy storage systems that are located behind utility meters typically located at, but not limited to, medium and large commercial and industrial locations. Some embodiments of the invention use networked multiphase distributed energy storage systems located at an electric load location or installed at interconnection points along the electric power distribution grid to provide a means for balancing the load created from an electric charging station, which are adapted to transfer power between one or more electric vehicles and the electric power grid.
p4438
aVAbstract\u000aA vehicle computer is configured to perform one or more operations of the vehicle without occupant input. Data is stored relating to a baseline occupant state. Data is collected relating to a current occupant state. A comparison is performed of the baseline occupant state to the current occupant state. A parameter is modified governing performance of the one or more operations according to the comparison.
p4439
aVAbstract\u000aAn array-based light detection and ranging (LiDAR) unit includes an array of emitter/detector sets configured to cover a field of view for the unit. Each emitter/detector set emits and receives light energy on a specific coincident axis unique for that emitter/detector set. A control system coupled to the array of emitter/detector sets controls initiation of light energy from each emitter and processes time of flight information for light energy received on the coincident axis by the corresponding detector for the emitter/detector set. The time of flight information provides imaging information corresponding to the field of view. Interference among light energy is reduced with respect to detectors in the LiDAR unit not corresponding to the specific coincident axis, and with respect to other LiDAR units and ambient sources of light energy. In one embodiment, multiple array-based LiDAR units are used as part of a control system for an autonomous vehicle.
p4440
aVAbstract\u000aEmbodiments of methods and apparatus for providing distributed airborne wireless communications are provided herein. In some embodiments, an airborne wireless communication node includes: an airborne fleet comprising a plurality of airborne platforms having flight control electronics configured to control flight of individual airborne platforms and coordinate a flight plan of the airborne fleet as a whole; and a distributed communication payload, wherein the communication payload is subdivided into constituent parts, wherein the parts are distributed and positioned on respective ones of the plurality of airborne platforms. In some embodiments, the distributed communication payload includes: air-to-user link equipment to provide communication links with end-users, the air-to-user link equipment further comprising an RF antenna; air-to-air link equipment to provide communications between individual airborne platforms; and payload control electronics to control the air-to-user and air-to-air link equipment and managing communication services.
p4441
aVAbstract\u000aA vertical take-off and landing (VTOL) aircraft according to an aspect of the present invention comprises a fuselage, an empennage having an all-moving horizontal stabilizer located at a tail end of the fuselage, a wing having the fuselage positioned approximately halfway between the distal ends of the wing, wherein the wing is configured to transform between a substantially straight wing configuration and a canted wing configuration using a canted hinge located on each side of the fuselage. The VTOL aircraft may further includes one or more retractable pogo supports, wherein a retractable pogo support is configured to deploy from each of the wing's distal ends.
p4442
aVAbstract\u000aA method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.
p4443
aVAbstract\u000aDevices, systems, and techniques are provided for assessment and management of an emotional state of a vehicle operator. Assessment of the emotional state of the vehicle can include accessing operational information indicative of performance of a vehicle, behavioral information indicative of behavior of an operator of the vehicle, and or wellness information indicative of a physical condition of the operator of the vehicle. In one aspect, these three types of information can be combined to generate a rich group set of data, metadata, and/or signaling that can be utilized or otherwise leveraged to generate a condition metric representative of the emotional state of the vehicle operator. Management of the emotional state can be customized to the specific context of the vehicle and/or the emotional state, and can be implemented proactively or reactively.
p4444
aVAbstract\u000aA number of luminaires can be communicably coupled and networked. Some or all of the luminaires may be equipped with a number of sensors including motion sensors. Upon detecting motion of an object in the vicinity of a luminaire, the luminaire can increase the luminous output of the lighting subsystem in the luminaire and communicate a targeted or broadcast output signal to some or all of the remaining luminaires in the network. The output signal may variously contain data indicative of one or more parameters related to motion of the object (direction of travel, velocity, etc.) or one or more parameters related to the increased luminous output of the luminaire. Responsive to the receipt of an output signal generated by another luminaire, the luminaire may autonomously adjust the luminous output of the lighting subsystems responsive to an event detected by the other luminaire.
p4445
aVAbstract\u000aA light detection and ranging device associated with an autonomous vehicle scans through a scanning zone while emitting light pulses and receives reflected signals corresponding to the light pulses. The reflected signals indicate a three-dimensional point map of the distribution of reflective points in the scanning zone. A radio detection and ranging device scans a region of the scanning zone corresponding to a reflective feature indicated by the three-dimensional point map. Solid objects are distinguished from non-solid reflective features on the basis of a reflected radio signal that corresponds to the reflective feature. Positions of features indicated by the reflected radio signals are projected to estimated positions during the scan with the light detection and ranging device according to relative motion of the radio-reflective features indicated by a frequency shift in the reflected radio signals.
p4446
aVAbstract\u000aThe present disclosure is directed toward systems and methods for autonomously landing an unmanned aerial vehicle (UAV). In particular, systems and methods described herein enable a UAV to land within and interface with a UAV ground station (UAVGS). In particular, one or more embodiments described herein include systems and methods that enable a UAV to conveniently interface with and land within a UAV ground station (UAVGS). For example, one or more embodiments include a UAV that includes a landing base and landing frame that interfaces with a landing housing of a UAVGS.
p4447
aVAbstract\u000aUncrewed autonomous vehicles (\u201cUAVs\u201d) may navigate from one location to another location. Described herein are systems, devices, and methods providing countermeasures for threats that may compromise the UAVs. A plurality of UAVs may establish a mesh network to distribute information to one another. A first UAV may receive external data from a second UAV using the mesh network. The external data may be used to confirm or cross-check data such as location, heading, altitude, and so forth. Disagreement between data generated by the first UAV with external data from the second UAV may result in the determination that the first UAV is compromised. Remedial actions may be taken, such as the first UAV may be directed to a safe location to land or park, may receive commands from another UAV, and so forth.
p4448
aVAbstract\u000aA system, device, and methods of interactive automated driving are disclosed. One example method includes receiving a current value from one or more sensors disposed on a vehicle and determining a current vehicle state based on the current value. The method also includes generating a target vehicle state based on the current vehicle state and including a range of target values and generating a desired vehicle state. The desired vehicle state includes a desired value based on one or more driver inputs received at one or more vehicle interfaces. If the desired value falls inside the range of target values, the method also includes sending a command to one or more vehicle systems to change the vehicle state from the target vehicle state to the desired vehicle state.
p4449
aVAbstract\u000aEmbodiments described herein may relate to methods and systems for supplying auxiliary power to an unmanned aerial vehicle (UAV) with different flight modes. In particular, the system may determine that a UAV is operating in a first flight mode. Responsively, the system may cause the UAV to draw power from a first power source at a first power level while operating in the first flight mode. Subsequently, the system may determine that the UAV switched from operating in the first flight mode to operating in a second flight mode. Responsively, the system may cause the UAV, while operating in the second flight mode, to continue drawing power from the first power source at the first power level and draw power from a second power source at a second power level, where the UAV consumes power at a higher rate during the second flight mode than during the first flight mode.
p4450
aVAbstract\u000aA method of docking and recharging using a base station and a station-mating frame on the multicopter. The base station includes an upward-facing camera that is used by a docking controller to detect the presence, position, and orientation of a frame, with infrared light-emitting diodes arranged in a predefined pattern. The controller of the base station acts to emit wireless signals to the multicopter to guide the multicopter with its station-mating frame to a predefined position above the base station. The controller transmits a wireless signal to the multicopter to reduce thrust, and the multicopter lowers itself onto a sloped receiving surface that may be arranged in a crown pattern to provide passive gravity-driven centering, which causes the station-mating frame to slide to a lowest vertical point of the receiving assembly. A locking mechanism engages to lock the frame in place and provide electrical contact for recharging.
p4451
aVAbstract\u000aThe present invention provides a traffic management system for managing unmanned aerial systems (UASs) operating at low-altitude. The system includes surveillance for locating and tracking UASs in uncontrolled airspace, for example, in airspace below 10,000 feet MSL. The system also includes flight rules for safe operation of UASs in uncontrolled airspace. The system further includes computers for processing said surveillance and for applying the flight rules to UASs. The traffic management system may be portable, persistent, or a hybrid thereof.
p4452
aVAbstract\u000aAutonomously driven vehicles operate in rain, snow and other adverse weather conditions. An on-board vehicle sensor has a beam with a diameter that is only intermittently blocked by rain, snow, dustor other obscurant particles. This allows an obstacle detection processor is to tell the difference between obstacles, terrain variations and obscurant particles, thereby enabling the vehicle driving control unit to disregard the presence of obscurant particles along the route taken by the vehicle. The sensor may form part of a LADAR or RADAR system or a video camera. The obstacle detection processor may receive time-spaced frames divided into cells or pixels, whereby groups of connected cells or pixels and/or cells or pixels that persist over longer periods of time are interpreted to be obstacles or terrain variations. The system may further including an input for receiving weather-specific configuration parameters to adjust the operation of the obstacle detection processor.
p4453
aVAbstract\u000aWe introduce a connected vehicles adaptive security signing and verification methodology. We also introduce an adaptive node filtering at receiver, using noise levels and received signal strength. This invention addresses two important pillars in connected vehicle technology and autonomous cars: The first one is related to the security 1609.2 format and its main two functions: signing and verification. The second one explains how the noise level and signal strength can be used to filter undesired connected nodes. In this presentation, we provide various examples and variations on these topics.
p4454
aVAbstract\u000aA method of providing obscurant data includes receiving image data including an image of a target and receiving a preference setting corresponding to the target. Obscurant data of at least a portion of the image data corresponding to the target are determined using the received preference setting. A method of providing surveillance image data includes capturing image data including an image of a target, querying a database to receive a preference setting corresponding to the target, determining the obscurant data of the portion of the image data, and selectively modifying the received image data according to the determined obscurant data to provide the surveillance image data.
p4455
aVAbstract\u000aA team-oriented adaptive cruise control system, for use in support of operations of a vehicle. The system includes instructions that cause a processor to perform operations including communicating, to a human user, via a vehicle-user interface, a request to participate regularly, actively, and collaboratively as a member of a collaborative adaptive-cruise-control (ACC) team, to include the system, in an ongoing team relationship of cooperation regarding operating the team-oriented ACC system over time. The operations further include providing, to the user, a commitment communication advising the user that the system will be dedicated to participating regularly, actively, and collaboratively as a team member. The operations also include receiving, from the user, an agreement communication to participate as a member of the collaborative ACC team. And the operations include forming, responsive to receiving the agreement communication, the collaborative ACC team including the user and team-oriented ACC system.
p4456
aVAbstract\u000aStructures and protocols are presented for configuring an unmanned aerial device to participate in the performance of tasks, for using data resulting from such a configuration or performance, or for facilitating other interactions with such devices.
p4457
aVAbstract\u000aA system and method for managing vehicles on a road network can include a processor that performs operations including accessing a matrix of vehicle parameters of a plurality of communicating vehicles on the road network and representing the plurality of communicating vehicles in a graph with a plurality of nodes corresponding to the plurality of communicating vehicles and edges corresponding to the vehicle parameters. The system and method can include partitioning, with a processing device, the graph to reduce disruptions to the road network below a threshold level to support safe and efficient traffic flow and assigning one or more exclusion zones within the road network to each partition of the graph by associating the vehicle parameters for each vehicle.
p4458
aVAbstract\u000aThe present invention relates to a daylight opening surround (3; 101) for a motor vehicle (1). The surround (3; 101) has a light transmitting element (15; 103) for transmitting light from a light source (19; 111). The present invention also relates to a light transmitting element (15; 103) for a surround (3; 101); a controller for a daylight opening surround (3; 101); and a motor vehicle (1).
p4459
aVAbstract\u000aA deployable net capture apparatus which is mounted on an unmanned aerial vehicle to enable the interception and entanglement of a threat unmanned aerial vehicle. The deployable net capture apparatus includes a deployable net having a cross-sectional area sized for intercepting and entangling the threat unmanned aerial vehicle, and a deployment mechanism capable of being mounted to the unmanned aerial vehicle. The deployment mechanism includes an inflatable frame or a rod for positioning the net in a deployed position.
p4460
aVAbstract\u000aA braking control system for a vehicle includes at least one sensor having a field of view exterior of the vehicle. A control, after actuation of the vehicle brake system, determines the speed of the vehicle and relative speed of the vehicle to another vehicle or object, and, responsive to the speed of the vehicle and the relative speed, the control controls the vehicle brake system. Responsive to a determination that at least one of (i) a collision has occurred, (ii) the vehicle speed is greater than a threshold amount and (iii) the relative speed is greater than a threshold amount, the system determines if the vehicle driver is impaired, and, responsive to a determination that the driver is impaired, the control controls braking of the subject vehicle, and responsive to a determination that the driver is not impaired, the control allows the driver to override the system.
p4461
aVAbstract\u000aAn approach is provided for granting access to an autonomous vehicle based on validation of a request, and configuring an autonomous vehicle to transport a user and/or items to at least one destination. The approach involves receiving a transport request for a transport of at least one user, at least one item, or a combination thereof to at least one destination. The approach also involves determining profile information associated with the at least one user, the at least one item, or a combination thereof, wherein the profile information specifies at least one role associated with the at least one user, the at least one item, or a combination thereof. The approach further involves causing, at least in part, a validation of the request based, at least in part, on a comparison of the at least one destination to one or more approved destinations associated with the at least one role. The approach also involves causing, at least in part, a granting of an access to one or more autonomous vehicles for the transport of the at least one user, the at least one item, or a combination thereof to the at least one destination based, at least in part, on the validation.
p4462
aVAbstract\u000aA method for controlling a vehicle includes the step of determining if a curb parking operation is feasible for the vehicle. If a curb parking operation is deemed infeasible, an operator of the vehicle is notified that curb parking is infeasible. If a curb parking operation is deemed feasible, actuatable elements of the vehicle are controlled to facilitate the curb parking operation.
p4463
aVAbstract\u000aAn autonomous vehicle may be configured to detect objects based on known structures of an environment. The vehicle may be configured to obtain image data from a sensor and be configured to operate in an autonomous mode. The image data may include data indicative of a known structure in the environment. The vehicle may include a computer system. The computer system may determine, based on a first portion of the image data, information indicative of an appearance of the known structure. The computer system may determine, based on a second portion of the image data, information indicative of an appearance of an unknown object in the environment. The computer system may also compare the information indicative of the appearance of the known structure with the information indicative of the appearance of the unknown object and provide instructions to control the vehicle in the autonomous mode based on the comparison.
p4464
aVAbstract\u000aUnmanned vehicle (UV) control may include receiving a UV work order and generating a mission request based on the UV work order. The mission request may identify an objective of a mission, assign a UV and a sensor to the mission from a fleet of UVs and sensors, and assign a first movement plan to the mission based on the identified objective of the mission. The assigned UV may be controlled according to the assigned first movement plan, and communication data may be received from the assigned sensor. The communication data may be analyzed to identify an event related to the mission. The identified event and the first movement plan may be analyzed to assign a second movement plan to the mission based on the analysis of the identified event and the first movement plan to meet the identified objective of the mission.
p4465
aVAbstract\u000aTechnologies for authorizing a passenger of an autonomous vehicle include determining a passenger authorization policy based on a request for a taxi service and determining whether a passenger is authorized for the taxi service based on the passenger authorization policy. The passenger authorization policy may include a set of rules for authorizing a passenger based on the request for the taxi service and/or a global authorization policy. For example, the passenger may be authorized based on the identity of the passenger, the number of passengers, the age of the passenger, an authentication token, and/or other methodologies. The passenger authorization policy may be generated by the autonomous vehicle in response to the request for a taxi service or received from a passenger authorization management server as part of the request for the taxi service.
p4466
aVAbstract\u000aA vehicle includes a steering wheel located in a passenger compartment. The steering wheel is configured to be moved from an operational position to a stowed position. In the event of a collision, a first airbag is configured to deploy when the steering wheel is in the operational position and a second airbag is configured to deploy when the steering wheel is in the stowed position.
p4467
aVAbstract\u000aA vehicle personal assistant to engage a user in a conversational dialog about vehicle-related topics, such as those commonly found in a vehicle owner's manual, includes modules to interpret spoken natural language input, search a vehicle knowledge base and/or other data sources for pertinent information, and respond to the user's input in a conversational fashion. The dialog may be initiated by the user or more proactively by the vehicle personal assistant based on events that may be currently happening in relation to the vehicle. The vehicle personal assistant may use real-time inputs obtained from the vehicle and/or non-verbal inputs from the user to enhance its understanding of the dialog and assist the user in a variety of ways.
p4468
aVAbstract\u000aDamage caused by accidents that occur during autonomous driving of a motor vehicle should be reliably detected. For this purpose, a transport facility with a driving area which can be autonomously driven by a motor vehicle, has a detection device for detecting a first state of the motor vehicle in an entrance area outside the driving area and for detecting a second state in an exit area located within the driving area. In addition, transport facility has an evaluation device for determining a possible difference between the second state and the first state relating to damage of the motor vehicle.
p4469
aVAbstract\u000aA method of tracking the use of at least one destination location, the method including identifying a vehicle by use of identification images captured by an identification camera, such as by processing of images of license plates, determining characteristics of the vehicle visible in the identification images, and determining usage of a destination location, such as a parking spot, based on a camera monitoring the destination location capturing images of the vehicle having characteristics corresponding to those determined for the identification images.
p4470
aVAbstract\u000aAn unmanned aerial vehicle (UAV) copter for consumer photography or videography can be launched by a user throwing the UAV copter into mid-air. The UAV copter can detect that the UAV copter has been thrown upward while propeller drivers of the UAV copter are inert. In response to detecting that the UAV copter has been thrown upward, the UAV copter can compute power adjustments for propeller drivers of the UAV copter to have the UAV copter reach a predetermined elevation above an operator device. The UAV copter can then supply power to the propeller drivers in accordance with the computed power adjustments.
p4471
aVAbstract\u000aA method and apparatus for managing a networked vehicle resource sharing facility, the method and system provide for:\u000a(a) detecting a plurality of inputs corresponding to vehicle booking requests, wherein each of the plurality of vehicle booking requests contains data identifying a drop-off location and a pick-up location that is distinct from the pick-up location of each of the other customers;\u000a(b) accessing a data structure containing stored data relating to user authorisations for using the vehicle-sharing facility to verify whether each of the vehicle booking requests relates to a customer authorised to use the vehicle-sharing facility; and\u000afor those vehicle booking requests relating to customers identified as being authorised to use the vehicle-sharing facility:\u000a(c) automatically selecting customers to share a vehicle and calculating a suggested route for the vehicle using the pick-up location and drop-off locations of the customers and one or more stored vehicle-share criteria.
p4472
aVAbstract\u000aEquipment and methods which combine the use of wave powered vehicles and unmanned aerial vehicles (UAVs or drones). A UAV can be launched from a wave-powered vehicle, observe another vessel and report the results of its observation to the wave-powered vehicle and the waves-powered vehicle can report the results of the observation to a remote location. The UAV can land on water and can then be recovered by the wave-powered vehicle.
p4473
aVAbstract\u000aMethods, devices, systems, and non-transitory process-readable storage media for a computing device of an autonomous vehicle to generate real-time mappings of nearby vehicles. An embodiment method executed by a computing device may include operations for obtaining origin point coordinates via a first satellite-based navigation functionality, obtaining termination point coordinates via a second satellite-based navigation functionality, calculating a unit vector based on the obtained origin point coordinates and the obtained termination point coordinates, identifying a position, a direction, and an occupancy of the autonomous vehicle based on the obtained origin point coordinates, the calculated unit vector, and stored vehicle dimensions data (e.g., length, width, height), and transmitting a message using DSRC with the origin point coordinates, the stored vehicle dimensions data, and data for identifying the vehicle's direction. The computing device may compare the direction, position, and occupancy to data of nearby vehicles based on incoming messages received via DSRC.
p4474
aVAbstract\u000aAn open architecture control system is provided that may be used for remote and semi-autonomous operation of commercial off the shelf (COTS) and custom robotic systems, platforms, and vehicles to enable safer neutralization of explosive hazards and other services. In order to effectively deal with rapidly evolving threats and highly variable operational environments, the control system is built using an open architecture and includes a high level of interoperability. The control system interfaces with a large range of robotic systems and vehicles, autonomy software packages, perception systems, and manipulation peripherals to enable prosecution of complex missions effectively. Because the control system is open and does not constrain the end user to a single robotics system, mobile platform, or peripheral hardware and software, the control system may be used to assist with a multitude of missions beyond explosive hazard detection and clearance.
p4475
aVAbstract\u000aMethods, media, and node-enabled autonomous transport vehicles are described for navigating to a shipping location using a plurality of nodes in a wireless node network. A node associated with the autonomous transport vehicle, such as a mobile master node, detects a signal broadcast from an ID node associated with the shipping location, and instructs the ID node to lower a power level of the broadcast signal. The mobile master node identifies the signal broadcast from the ID node with the lowered power level, and determines a direction of the ID node relative to the mobile master node based upon the detected signal with the lowered power level. The mobile master node then navigates to the ID node associated with the shipping location based upon the determined direction, which may involve providing the determined direction to an input for the vehicle's control system.
p4476
aVAbstract\u000aThe use of self-powered, autonomous vehicles in agricultural and other domestic applications is provided. The vehicles include a self-propelled drive system, tracks or wheels operatively connected to the drive system, a power supply operatively connected to the drive system, an attachment mechanism for attaching equipment to the vehicle, and an intelligent control operatively connected to the drive system, power supply, and attachment mechanism. The vehicle is configured to connect to the equipment to perform agricultural operations based upon the equipment. Multiple vehicles can be used in a field at the same time. Furthermore, the invention includes the ability to move one or more of the autonomous vehicles from field to field, home to field, or from generally any first location to a second location.
p4477
aVAbstract\u000aA traffic light detection system for a vehicle is provided. The system may include at least one processing device programmed to receive, from at least one image capture device, a plurality of images representative of an area forward of the vehicle, the area including a traffic light fixture having at least one traffic light. The at least one processing device may also be programmed to analyze at least one of the plurality of images to determine a status of the at least one traffic light, and determine an estimated amount of time until the vehicle will reach an intersection associated with the traffic light fixture. The at least one processing device may further be programmed to cause a system response based on the status of at least one traffic light and the estimated amount of time until the vehicle will reach the intersection.
p4478
aVAbstract\u000aAn aerial operations system for performing various tasks such as painting is provided. The modular aerial operations system includes an aerial vehicle capable of vertically taking off and landing, hovering and precisely maneuvering near walls and other structures. The aerial vehicle may be a rotorcraft such as a multicopter. In an aspect, as aerial vehicle paints one or more designated surfaces using detachable arms and equipment. The system may paint the designated surface in one of several available techniques using paint provided in a container such as an attached reservoir, a base station, a paint can, or the like. The aerial operations system provided may also be configured to perform a variety of other tasks.
p4479
aVAbstract\u000aA base station for automated battery pack or payload exchange and methods for using the same. The base station provides a landing surface for receiving a mobile platform and includes a manipulator controlled by a manipulator compartment for accessing resource storage. The base station is operable to ascertain a location of the mobile platform on the landing surface and move the manipulator to the mobile platform. Thereby, the base station system advantageously accommodates low-accuracy landing of the mobile platform and further enables extended and autonomous operation of the mobile platform without the need for user intervention for exchanging battery packs and payloads.
p4480
aVAbstract\u000aApparatus and methods for controlling attention and training of autonomous robotic devices. In one approach, attention of the robot may be manipulated by use of a spot-light device illuminating a portion of the aircraft undergoing inspection in order to indicate to inspection robot target areas requiring more detailed inspection. The robot guidance may be aided by way of an additional signal transmitted by the agent to the robot indicating that the object has been illuminated and attention switch may be required. Responsive to receiving the additional signal, the robot may initiate a search for the signal reflected by the illuminated area requiring its attention. Responsive to detecting the illuminated object and receipt of the additional signal, the robot may develop an association between the two events and the inspection task. The light guided attention system may influence the robot learning for subsequent actions.
p4481
aVAbstract\u000aTechniques are provided for providing position estimations in an autonomous multi-vehicle convoy. Those techniques include initializing a convoy state, selecting a next sensor reading; predicting a convoy state, updating the convoy state, and broadcasting the convoy state to vehicles in the multi-vehicle convoy.
p4482
aVAbstract\u000aAccording to one aspect, the disclosed subject matter describes herein a method that includes navigating, by a plurality of unmanned aerial vehicles (UAVs), a service coverage area associated with a wireless communications network, wherein the service coverage area includes a plurality of wireless access points and assigning, by at least one of the UAVs, wireless access points to one or more of the UAVs for wireless traffic testing. The method further includes executing, for each of the wireless access points, a wireless traffic test including test traffic data communicated between at least one of the UAVs and a tested wireless access point and determining, for each of the wireless access points to be tested, performance metric information associated with traffic data being wirelessly communicated between the tested wireless access point and the at least one of the UAVs.
p4483
aVAbstract\u000aA method and apparatus for associating parking areas with destinations may include a vehicle identifying transportation network information including a primary destination and parking area information representing a plurality of parking areas, such that the parking area information includes automatically generated parking area association information describing an association between at least one parking area and the primary destination. The vehicle may determine a target parking area from the plurality of parking areas for the primary destination based on the transportation network information, and identify a route from an origin to the target parking area in the vehicle transportation network using the transportation network information. The vehicle may include a trajectory controller configured to operate the vehicle to travel from the origin to the target parking area using the route.
p4484
aVAbstract\u000aA driven vehicle receives position data of a subject vehicle nearby the driven vehicle, and associates the position data of the subject vehicle with a driving model. The driving model is updated by incorporating latest position data of the subject vehicle, and a future position of the subject vehicle is predicted using the updated driving model. The predicted future position of the subject vehicle can be transmitted to other processing systems of the driven vehicle, including a collision avoidance or warning system, which provides a driver notification, and an autonomous driving system, which provides vehicle actuation. A determination is made as to whether the position data of the subject vehicle fits a currently stored and available driving model, and generates a new driving model no model fits. The new model is a multi-mode predictive state representation (MMPSR) which marginalizes unknown modes of history.
p4485
aVAbstract\u000aMethods, devices, systems, and non-transitory process-readable media for evaluating operating conditions of an autonomous aircraft before performing a mission by executing brief near-flight testing maneuvers at a low elevation. A processor of the autonomous aircraft may receive near-flight testing maneuver instructions that indicate a near-flight testing maneuver to be executed by the autonomous aircraft. The processor may control motors to cause the aircraft to execute a near-flight testing maneuver within a testing area, obtain data indicating stability and performance information while executing the near-flight testing maneuvers, and take an action in response to the obtained data. Actions may include adjusting a position of a payload, a weight, or a portion of the aircraft based on the obtained data, and adjusting a flight plan. The near-flight testing maneuvers may include a sequence of moves for testing stability of the aircraft and payload executing a flight path under anticipated flying conditions.
p4486
aVAbstract\u000aA method and apparatus for predicting vehicle speed during an indirect vision driving task. A further method and apparatus for optimizing the display of a camera return during an indirect vision driving task based on operator perceived vehicle speed as set by the display characteristics and the field-of-view of the camera. A further method and apparatus for using the perceived speed as a driving task aid, in particular, as an electronic aider for optimizing the driving scene display characteristics of scene compression and camera field-of view. In this manner, the invention adjusts the perceived speed in order to match the operator's cognitive flow to the control dynamics needed from the operator for the task. The invention has application to autonomous driving where manual intervention is incorporated during critical events for particular tasks; and with limited display space within the vehicle, the display format is adjusted by the invention according to the operator's task needs.
p4487
aVAbstract\u000aA method performed by a positioning system of a vehicle is disclosed for determining a position of the vehicle along a road including one or several road markings arranged on a surface of the road. The positioning system detects road markings, matches detected road markings with mapped road markings of stored map data based on comparing characteristics of the detected road markings with mapped characteristics of the mapped road markings. The positioning system furthermore identifies a mapped identified road marking determined to correspond with a detected identified road marking, and determines a positioning estimate of the vehicle along the road based on a mapped road marking position associated with the mapped identified road marking. A positioning system, a vehicle including such a positioning system, and a mapping unit and a mapping method performed therein for creating map data to be utilized by the above mentioned positioning system are also disclosed.
p4488
aVAbstract\u000aA method and apparatus for managing a recreational water area. A recreational water area management system comprises a water area manager. The water area manager is configured to receive information about a recreational water area from a group of autonomous vehicles, analyze the information to identify an event, and coordinate the group of autonomous vehicles to perform a mission in the recreational water area based on the event.
p4489
aVAbstract\u000aProvided are a method and apparatus for continuously establishing a boundary for autonomous driving availability, in a vehicle having autonomous driving capabilities and comprising at least one remote sensor for acquiring vehicle surrounding information and at least one vehicle dynamics sensor for determining vehicle dynamics parameters. The method and apparatus include at least one of a positioning arrangement that provides map data with associated information, a route planning arrangement that enables route planning, a vehicle driver monitoring arrangement that provides driver monitoring information, and a real time information acquiring arrangement that acquires at least one of traffic information and weather information. The boundary is calculated based on a planned route and at least one of vehicle surrounding information, vehicle dynamics parameters, driver monitoring information, map data, traffic information and weather information, for the planned route. Changes in the calculated boundary are output to a human machine interface in the vehicle.
p4490
aVAbstract\u000aMethods and systems based on Dedicated Short Range Communications (DSRC) determine that a vehicle occupies a parking spot. A road-side system checks in the vehicle having an on-board DSRC system into a parking system. The system provides the on-board DSRC system with a parking rate and the on-board DSRC system provides the road-side system with payment data. A final parking fee is determined and is charged after the vehicle has left the parking spot. Parking rates are determined dynamically based on existing and/or expected conditions. A planning system provides a vehicle with a parking spot at a scheduled time. Navigation data is provided to the vehicle to reach the scheduled parking spot. Traffic and environmental policies are enforced by applying the methods and systems.
p4491
aVAbstract\u000aA light detection and ranging (LIDAR) device that scans through a scanning zone while emitting light pulses and receives reflected signals corresponding to the light pulses is disclosed. The LIDAR device scans the scanning zone by directing light toward a rotating mirror to direct the light pulses through the scanning zone. The rotating mirror is driven by a conductive coil in the presence of a magnetic field. The conductive coil is coupled to the rotating mirror and arranged in a plane perpendicular to the axis of rotation of the mirror. The axis of rotation of the mirror is oriented substantially parallel to a reflective surface of the mirror and passes between the reflective surface and the conductive coil.
p4492
aVAbstract\u000aVarious embodiments relate to creating and utilizing a vehicle surveillance network to monitor objects and/or events. Messages may be broadcasted from at least one communication system of a surveillance network which is communicating with one or more vehicles of the surveillance network and received in a vehicle. Instructions may be transmitted to at least one vehicle camera to capture one or more images of objects or events outside of the vehicle in response to receiving the at least one broadcasted message. At least one vehicle camera in each of the vehicles of the surveillance network may capture the images of the object and/or events. Further instructions may include transmitting the captured images from the one or more vehicles to one or more event responders.
p4493
aVAbstract\u000aA computer-implemented method for the automated driving of a vehicle. The method may include coordinating a planned vehicle path using a path planner application. The path planner application may receive information based on inputs to sensors disposed on the vehicle. The method may include sending a command to one or more vehicle systems to control the vehicle to follow the planned vehicle path. While the vehicle follows the planned vehicle path, the method may include receiving an indication that the path planner application is not meeting a threshold performance level. After receiving the indication that the path planner application is not meeting the threshold performance level, a command is sent to one or more vehicle systems to control the vehicle to follow a temporary and irregular full vehicle movement to alert a vehicle driver. The temporary and irregular full vehicle movement may be a full vehicle side-to-side wobbling movement.
p4494
aVAbstract\u000aAn automated driving system and methods are disclosed. The automated driving system includes a perception system disposed on an autonomous vehicle. The automated driving system can detect an intersection including a yield scenario and identify a check point between the autonomous vehicle and the yield scenario. Prior to the autonomous vehicle reaching the check point, the automated driving system can send a command to one or more vehicle systems to control the autonomous vehicle to stop at the yield scenario. After the autonomous vehicle reaches the check point, the automated driving system can detect, using the perception system, information for the intersection. If the information indicates clear passage through the intersection for the autonomous vehicle, the automated driving system can send a command to the one or more vehicle systems to drive the autonomous vehicle through the intersection.
p4495
aVAbstract\u000aA light detection and ranging (LIDAR) device scans through a scanning zone while emitting light pulses and receives reflected signals corresponding to the light pulses. The LIDAR device scans the emitted light pulses through the scanning zone by reflecting the light pulses from an array of oscillating mirrors. The mirrors are operated by a set of electromagnets arranged to apply torque on the mirrors, and an orientation feedback system senses the orientations of the mirrors. Driving parameters for each mirror are determined based on information from the orientation feedback system. The driving parameters can be used to drive the mirrors in phase at an operating frequency despite variations in moments of inertia and resonant frequencies among the mirrors.
p4496
aVAbstract\u000aInstructions are provided to at least one vehicle control for autonomous operation of a vehicle. A change in position is detected of at the least one vehicle control. A determination is made whether to modify operation of the vehicle at least in part according to the change in position of the at least one vehicle control. The autonomous operation of the vehicle is modified according to the change in position.
p4497
aVAbstract\u000aA vehicle device includes a controller configured to: receive a signal indicative of a travelling environment of the vehicle; and output a display signal to a display device to instruct the display device to display a mark at a position in the vehicle where safety should be confirmed by a driver of the vehicle, the display signal being output in accordance with the travelling environment. Accordingly, it is possible to prompt a user to confirm the safety at suitable positions and at proper timing.
p4498
aVAbstract\u000aMethods and systems for real-time road flare detection using templates and appropriate color spaces are described. A computing device of a vehicle may be configured to receive an image of an environment of the vehicle. The computing device may be configured to identify a given pixels in the plurality of pixels having one or more of: (i) a red color value greater than a green color value, and (ii) the red color value greater than a blue color value. Further, the computing device may be configured to make a comparison between one or more characteristics of a shape of an object represented by the given pixels in the image and corresponding one or more characteristics of a predetermined shape of a road flare; and determine a likelihood that the object represents the road flare.
p4499
aVAbstract\u000aAn apparatus and method for control of at least one of a plurality of semiautonomous marine vessels are provided. The system includes a control station with a communications system for network communication with marine vessels, and provides diagnostics and control for control and monitoring of the marine vessels, according to a mission plan.
p4500
aVAbstract\u000aAn autonomous vehicle configured to avoid pedestrians using hierarchical cylindrical features. An example method involves: (a) receiving, at a computing device, range data corresponding to an environment of a vehicle, and the range data comprises a plurality of data points; (b) detecting, by the computing device, one or more subsets of data points from the plurality of data points that are indicative of an upper-body region of a pedestrian, and the upper-body region may comprise parameters corresponding to one or more of a head and a chest of the pedestrian; and (c) in response to detecting the one or more subsets of data points, determining a position of the pedestrian relative to the vehicle.
p4501
aVAbstract\u000aA vehicle, vehicle system and method for increasing at least one of safety and comfort during autonomous driving is provided. The vehicle system includes an autonomous drive arrangement with multiple sensors, and a vehicle control arrangement. The vehicle system is configured to determine an estimated probability that at least one sensor will become unavailable, or an estimated time/distance ahead until at least one sensor is determined to become unavailable. The vehicle system is further configured to activate at least one countermeasure based on at least one of the estimated probability, the estimated time and the estimated distance.
p4502
aVAbstract\u000aA method for controlling a vehicle system, which is designed for autonomous operation of a motor vehicle is described, wherein setting information for the vehicle system is determined from location information describing a current position of the motor vehicle and from at least one location-related permission information item relating to the permission of use of the vehicle system, and at least one operating parameter of the vehicle system is selected as a function of the setting information.
p4503
aVAbstract\u000aA method for controlling an autonomous vehicle includes obtaining information describing a roadway; defining a plurality of layers along the roadway between a starting position and a goal position, each layer having a first width, and each layer having a plurality of nodes that are spaced from one another transversely with respect to the roadway within the first width; and determining a first trajectory from the starting position to the goal position, by minimizing a cost value associated with traversing the layers. Determining the first trajectory includes, for each layer, determining layer-specific weighting factors for each of a plurality of cost components, based on information associated with the respective layer, and determining, for each node of the respective layer, a cost for travelling to one or more of the nodes in a subsequent layer based on the plurality of cost components and the layer-specific weighting factors.
p4504
aVAbstract\u000aSystems and methods for vertical takeoff and/or landing are disclosed herein. An aerial vehicle may include a first propulsion unit and a second propulsion each rotatably connected to a body. The aerial vehicle may include a first wing and a second wing each rotatably connected to the body. And the aerial vehicle may include a control system configured to: position the first propulsion unit, the second propulsion unit, the first wing, and the second wing; operate the first propulsion unit and the second propulsion unit; and rotate the first propulsion unit, the second propulsion unit, the first wing, and the second wing.
p4505
aVAbstract\u000aA vehicle may receive one or more images of an environment of the vehicle. The vehicle may also receive a map of the environment. The vehicle may also match at least one feature in the one or more images with corresponding one or more features in the map. The vehicle may also identify a given area in the one or more images that corresponds to a portion of the map that is within a threshold distance to the one or more features. The vehicle may also compress the one or more images to include a lower amount of details in areas of the one or more images other than the given area. The vehicle may also provide the compressed images to a remote system, and responsively receive operation instructions from the remote system.
p4506
aVAbstract\u000aAn autonomous transporting tool is adapted to travel along a guiding line. The tool comprises two transporting elements. Each of the transporting elements comprise autonomous propulsion means, a control system and an optical system. The optical system comprises two cameras and two lighting units. The system is adapted to identify the location of the image of a guiding line within a received image of the floor and to provide steering commands adapted to steer the transporting tool so that the image of the guiding line is located substantially in the center of the received image.
p4507
aVAbstract\u000aA roadway projection system integrated into a vehicle is configured to identify a specific driving scenario encountered by a driver of the vehicle, and to then project an image onto a roadway along which the vehicle travels based on that scenario. The image is intended to provide guidance to the driver in negotiating the identified scenario and/or to visualize potential driving actions of the driver for the benefit of others. The image could be, for example, and without limitation, an indicator that the driver should follow to perform a specific driving or navigation action, or a preference that the driver wishes to share with other drivers. In addition, the roadway projection system may detect images projected by other roadway projection systems in other vehicles and to determine mutual preferences shared between drivers. When a shared preference is violated, the roadway projection system may alert the driver of the vehicle.
p4508
aVAbstract\u000aIn an autonomous driving system in which a plurality of autonomous driving vehicles drive under the control by occlusion control, such a situation is prevented that a vehicle is disabled to drive by a failure of an external world sensor for recognizing an obstacle and stops in an occlusion region thereby to obstruct advancement of overall succeeding vehicles to remarkably degrade the efficiency of the overall transportation work. In the autonomous driving system of the present invention, an autonomous driving vehicle which detects an obstacle or a driving road by a sensor and performs autonomous driving includes sensor state evaluation means configured to evaluate a state of performance degradation of the sensor, speed and steering angle control value setting means configured to provide limit values to the driving speed and the steering angle based on a state of performance degradation of the sensor, and movement obstacle evaluation means configured to evaluate an influence on movement of other vehicles when the vehicle stops at a position at present. When the sensor suffers from performance degradation, the vehicle stops after it drives within the set limit values to the speed and the steering angle to a point at which the vehicle does not obstruct movement of other vehicles.
p4509
aVAbstract\u000aSystems and methods are provided for detecting an object and causing a vehicle to brake based on the detection. In one implementation, an object detecting and braking system for a vehicle includes at least one image capture device configured to acquire a plurality of images of an area including an object in front of the vehicle. The system includes at least one processing device programmed to perform a first image analysis to determine a first estimated time-to-collision of the vehicle with the object, and to perform a second image analysis to determine a second estimated time-to-collision of the vehicle with the object. The processing device is also programmed to calculate a difference between the first estimated time-to-collision and the second estimated time-to-collision, to determine that the difference does not exceed a predetermined threshold, and to cause the vehicle to brake based on the determination that the difference does not exceed the predetermined threshold.
p4510
aVAbstract\u000aA method for controlling an autonomous vehicle includes determining whether a primary user is present in an autonomous vehicle, allowing use of a plurality of functions of the autonomous vehicle in response to determining that the primary user is present in the autonomous vehicle, and receiving and storing preferences input by the primary user, wherein the preferences identify a limitation on one or more of the plurality of functions of the autonomous vehicle that should be enforced during use of the autonomous vehicle if the primary user is not present in the autonomous vehicle. The method further includes limiting use of the one or more of the plurality of functions of the autonomous vehicle as specified by the preferences in response to determining that the primary user is not present in the autonomous vehicle.
p4511
aVAbstract\u000aMulti-level navigation monitoring and control is provided. A system includes a lane marking manager determining a first boundary line, a second boundary line, and a centerline of a current lane of travel. The system also includes a confidence level determiner assigning a first confidence level to the first boundary line, a second confidence level to the second boundary line, and a third confidence level to the centerline. Further, the system includes a user interface outputting representations of the first boundary line, the second boundary line, and the centerline based, at least in part, on the first confidence level, the second confidence level, and the third confidence level.
p4512
aVAbstract\u000aA system for facilitating automated landing and takeoff of an autonomous or pilot controlled hovering air vehicle with a cooperative underbody at a stationary or mobile landing place and an automated storage system used in conjunction with the landing and takeoff mechanism that stores and services a plurality of UAVs is described. The system is primarily characterized in that the landing mechanism is settable with 6 axes in roll, pitch, yaw, and x, y and z and becomes aligned with and intercepts the air vehicle in flight and decelerates the vehicle with respect to vehicle's inertial limits. The air vehicle and capture mechanism are provided with a transmitter and receiver to coordinate vehicle priority and distance and angles between landing mechanism and air vehicle. The landing and takeoff system has means of tracking the position and orientation of the UAV in real time. The landing mechanism will be substantially aligned to the base of the air vehicle. With small UAVs, their lifting capacity is limited. Reducing sensing and computation requirements by having the landing plate perform the precision adjustments for the landing operation allows for increased flight time and/or payload capacity.
p4513
aVAbstract\u000aExample methods and systems for detecting reflective markers at long range are provided. An example method includes receiving laser data collected from successive scans of an environment of a vehicle. The method also includes determining a respective size of the one or more objects based on the laser data collected from respective successive scans. The method may further include determining, by a computing device and based at least in part on the respective size of the one or more objects for the respective successive scans, an object that exhibits a change in size as a function of distance from the vehicle. The method may also include determining that the object is representative of a reflective marker. In one example, a computing device may use the detection of one reflective marker to help detect subsequent reflective markers that may be in a similar position.
p4514
aVAbstract\u000aA UAV is provided to cancel background noise from audio data collected by the UAV. The UAV is provided with one or more background microphones in a proximity of one or more background noise-producing components. The UAV is also provided with one or more audio source collecting microphones. The audio data collected by the background microphones may be used to reduce or cancel interfering background noise from the audio signal detected by the audio source collecting microphone. The target audio may be captured or recorded with little or no background noise.
p4515
aVAbstract\u000aVarious exemplary embodiments relate to a command interpreter for use in a vehicle control system in a vehicle for interpreting user commands, a vehicle interaction system including such a command interpreter, a vehicle including such a vehicle interaction system, and related method and non-transitory machine-readable storage medium, including: a memory and a processor, the processor being configured to: receive, from at least one human via a first input device, a first input having a first type; receive a second input having a second type via a second input device, wherein the second type comprises at least one of sensed information describing a surrounding environment of the vehicle and input received from at least one human; interpret both the first input and the second input to generate a system instruction; and transmit the system instruction to a different system of the vehicle.
p4516
aVAbstract\u000aAn apparatus and a method are provided for recognizing driving environment for an autonomous vehicle. The apparatus includes a controller configured to receive navigation information from a satellite navigation receiver. The controller is further configured to receive map data from a map storage and image data from an image sensor regarding captured images from around a vehicle and distance information from a distance sensor regarding sensed objects positioned around the vehicle. The controller is also configured to determine a fusion method for information measured by the image sensor and the distance sensor based on a receiving state of the satellite navigation receiver and precision of the map data to recognize the driving environment.
p4517
aVAbstract\u000aA method/system of wireless payment of parking fees for a vehicle, applicable to both open street and closed garage parking, wherein the user and checker experiences are enhanced relative to the prior art by a number of means, including: autonomous sensing of the user's/vehicle's location and allowing the user to correct the indicated location if required; enabling a handset to automatically sense the ID of the vehicle in which it is located; enabling rapid and facile enforcement by providing the Checker with information about the location, parking session status and other attributes of parked vehicles and displaying the information on a portable terminal in a manner facilitating rapid validation; and further facilitating the identification of vehicles with expired sessions by a method/system of RF interrogation involving RF tags located in/on the vehicles and the checking terminal querying the RF tags.
p4518
aVAbstract\u000aMethods, systems, and devices are provided for displaying flight information related to a UAV. The UAV may carry a payload via a carrier that may permit the payload to move relative to the UAV. UAV related information including UAV state information and payload state information can be provided to a remote display terminal. The UAV state information can include position information as well as attitude information of the UAV. The payload state information can include attitude information of the payload relative to the UAV. The remote display terminal can be configured to simultaneously display the UAV state information and the payload state information so as to provide the user with an intuitive, comprehensive, yet efficient user interface.
p4519
aVAbstract\u000aVarious systems, methods, for unmanned aerial vehicles (UAV) are disclosed. In one aspect, UAVs operation in an area may be managed and organized by UAV corridors, which can be defined ways for the operation and movement of UAVs. UAV corridors may be supported by infrastructures and/or systems supported UAVs operations. Support infrastructures may include support systems such as resupply stations and landing pads. Support systems may include communication UAVs and/or stations for providing communications and/or other services, such as aerial traffic services, to UAV with limited communication capabilities. Further support systems may include flight management services for guiding UAVs with limited navigation capabilities as well as tracking and/or supporting unknown or malfunctioning UAVs.
p4520
aVAbstract\u000aThe present invention provides methods and systems related to determine a state of the UAV by updating a determined state of UAV with a relative proportional relationship. The UAV may be provided with a monocular camera, a proximity sensor and a processor. The processor may determine external state information of the UAV based on image data captured by the monocular camera, and calculate a relative proportional relationship to be applied to the determined external state information. The updated external state information of the UAV may be more precise or even equal to the actual state information of the UAV, thus enabling more accurate control and navigation for the autonomous flight.
p4521
aVAbstract\u000aSystems and methods are described herein for launching, recovering, and handling a large number of vehicles on a ship to enable lower cost ocean survey. In one aspect, the system may include a shipping container based system with an oil services vessel. The vessel may include rolling systems through end to end shipping containers. One or more columns of containers may be accessed using a crane, an A-frame, or any other suitable transportation system. The system may enable the ability to launch or recover more than one vehicle using the launch and recovery system (e.g., AUVs, buoys, seaplanes, autonomous surface vessels, etc.). In one configuration, the system includes a stacking/elevator system to place the vehicles onto a second or higher layer of containers. The system may allow for modularized deployment of the vehicles, launch and recovery system, operation center, and more from self-contained shipping containers.
p4522
aVAbstract\u000aAn agricultural planting system and method comprising a soil sampling and analysis means, wherein soil samples are taken and analyzed in real-time during a planting operation (or, optionally, via a separate, prior operation) to determine the conditions and nutrient content of the soil, and a planting system, wherein the planting system is capable of planting seeds in any arbitrary position on an X-Y plane directly beneath the planting system, whereby the data gathered from the analyzed soil samples is used to determine the optimal placement of seeds or plants in a field in order to take advantage of the soil conditions present and to optimize crop yield.
p4523
aVAbstract\u000aA vehicular gesture control system includes a plurality of cameras mounted in a cabin to detect edges of an object; and a processor to translate the edges as mouse movement and mouse clicks to control the vehicle by moving hands. In implementations, the smart vehicle has a number of sensors such as IoT (internet of things) sensors that can share data with other vehicles and that can communicate with the cloud to provide intelligent handling of the vehicle.
p4524
aVAbstract\u000aAutonomous data machines and systems may be provided, which may be deployed in an environment. The machines may roam within the environment and collect data with aid of one or more sensors. The data may be sent to a control center, which may optionally receive information from additional data sources, such as other on-site sensors, existing static data, or real-time social data. The control center may send instructions to the machines to perform one or more reaction based on the received information. The autonomous data machines may be capable of reacting autonomously to one or more detected condition. In some instances, the autonomous data machines may be employed for security or surveillance.
p4525
aVAbstract\u000aA lane departure control system is provided which steers a vehicle toward the center of a lane of a road at a first yaw rate by a controlled angle when the vehicle is determined to be about to deviate from the lane. Afterwards, when the vehicle is determined to be traveling toward a virtual line defined near a lane boundary, the system steers the vehicle by a correction angle so as to orient the vehicle parallel to the virtual line at a second yaw rate. The system changes the value of the first yaw rate at a first rate within the controlled angle and also changes the value of the second yaw rate at a second rate within the correction angle. An absolute value of the second rate is set smaller than that of the first rate, thereby minimizing an undesirable physical load on a driver of the vehicle.
p4526
aVAbstract\u000aThe present invention is directed to a steering apparatus for a vehicle having a including a light element providing indication and warning light signals to the user of the vehicle. The light element can be associated with a PCB mounted to the steering wheel grip for controlling the operation of the light element.
p4527
aVAbstract\u000aApparatuses, methods and storage medium associated with computerized assist or autonomous driving of vehicles are disclosed herein. In embodiments, a method may include receiving, by a computing device, a plurality of data associated with vehicles driving at various locations within a locality; and generating, by the computing device, one or more locality specific policies for computerized assisted or autonomous driving of vehicles at the locality, based at least in part on the data associated with vehicles driving at various locations within the locality. Other embodiments may be described and claimed.
p4528
aVAbstract\u000aAn apparatus for guiding an autonomous vehicle towards a docking station including an autonomous vehicle with a camera-based sensing system, a drive system for driving the autonomous vehicle, and a control system for controlling the drive system. The apparatus includes a docking station including a first fiducial marker and a second fiducial marker, wherein the second fiducial marker is positioned on the docking station to define a predetermined relative spacing with the first fiducial marker, wherein the control system is operable to receive an image provided by the camera-based sensing system, the image including a representation of the first and second fiducial markers, and to control the drive system so as to guide the autonomous vehicle towards the base station based on a difference between the representation of the first and second fiducial markers in the received image and the predetermined relative spacing between the first and second fiducial markers.
p4529
aVAbstract\u000aMethods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA.
p4530
aVAbstract\u000aApparatus and methods for learning in response to temporally-proximate features. In one implementation, an image processing apparatus utilizes bi-modal spike timing dependent plasticity in a spiking neuron network. Based on a response by the neuron to a frame of input, the bi-modal plasticity mechanism is used to depress synaptic connections delivering the present input frame and to potentiate synaptic connections delivering previous and/or subsequent frames of input. The depression of near-contemporaneous input prevents the creation of a positive feedback loop and provides a mechanism for network response normalization.
p4531
aVAbstract\u000aMixed autonomous and manual control of a vehicle is provided. The vehicle can include an operational mode in which the vehicle operates autonomously but is influenced by a mix of autonomous control inputs and manual control inputs. A first weight can be assigned to manual control inputs, and a second weight can be assigned to autonomous control inputs. The assigned first and second weights can be applied to a vehicle system. Responsive to receiving a manual control input, the autonomous operation of the vehicle can be caused to be influenced by the received manual control input in an amount corresponding to the first weight without deactivating the autonomous operation of the vehicle.
p4532
aVAbstract\u000aSystems, methods, and apparatus embodiments for electric power grid and network registration and management of physical and financial settlement for participation of active grid elements in supply and/or curtailment of power. Settlement is provided for grid elements that participate in the electric power grid following initial registration of each grid element with the system, preferably through network-based communication between the grid elements and a coordinator, either in coordination with or outside of an IP-based communications network router. A multiplicity of active grid elements function in the grid for supply capacity, supply and/or load curtailment as supply or capacity, and are compensated through settlement for their functional participation in the electric power grid. Also, messaging related to settlement is managed through a network by a Coordinator using IP messaging for communication with the grid elements, with the energy management system (EMS), and with the utilities, market participants, and/or grid operators.
p4533
aVAbstract\u000aAn autonomous vehicle, an overtake assessment arrangement, and an overtake assessment system are provided. The overtake assessment arrangement is configured to receive, from at least one external source, real time traffic information on one or more surrounding vehicles outside a sensor monitoring area, assess whether to overtake at least one preceding vehicle within the sensor monitoring area or not, based on the real time traffic information received via the communication unit, and provide a vehicle drive arrangement with input indicative of the assessment, such that the vehicle drive arrangement is able to control the host vehicle to overtake the at least one preceding vehicle or not in accordance with the input.
p4534
aVAbstract\u000aMethod and apparatus for providing autonomous control of a vehicle. A vehicle can be manually controlled by an operator. An autonomous system can monitor the operator's control inputs and the environment of the vehicle to determine whether the control inputs result in safe operation of the vehicle. If control inputs are not safe, then the autonomous system can modify the operator's unsafe inputs into safe inputs. In various instances, the autonomous system can operate the vehicle without operator input. In the event an operator attempts to apply control inputs to the vehicle while the autonomous system is otherwise in control, the autonomous system can check to see whether the operator's inputs result in safe operation of the vehicle. If the operator's control inputs are safe, then the autonomous system can replace its autonomous commands with the operator's commands.
p4535
aVAbstract\u000aApparatus and methods for detecting salient features. In one implementation, an image processing apparatus utilizes latency coding and a spiking neuron network to encode image brightness into spike latency. The spike latency is compared to a saliency window in order to detect early responding neurons. Salient features of the image are associated with the early responding neurons. A dedicated inhibitory neuron receives salient feature indication and provides inhibitory signal to the remaining neurons within the network. The inhibition signal reduces probability of responses by the remaining neurons thereby facilitating salient feature detection within the image by the network. Salient feature detection can be used for example for image compression, background removal and content distribution.
p4536
aVAbstract\u000aA hitch assist system for a vehicle comprises a camera mounted to view a reverse path of a vehicle, an input device connected for the hitch assist system, and a controller. The controller includes instructions for detecting a trailer proximate to a vehicle with the camera, determining a vehicle hitch ball location, determining a trailer hitch location, and calculating a vehicle path from an initial position to a final position. The vehicle hitch ball is laterally aligned with the trailer hitch in the final position. The controller also includes instructions for calculating the steering and braking maneuvers necessary to move the vehicle along the path to the final position and sending instructions to a vehicle steering system and a vehicle brake system to perform the calculated maneuvers.
p4537
aVAbstract\u000aTechnology is described for providing advertisements to an autonomous vehicle. A starting location and a destination for the autonomous vehicle may be received. A route for the autonomous vehicle to drive from the starting location to the destination may be generated. The route may be in proximity to one or more business entities that provide a product or service of interest to a passenger within the autonomous vehicle. The route may be sent to the autonomous vehicle. The autonomous vehicle may be configured to provide commands to drive the autonomous vehicle to the destination according to the route. Advertisements may be selected for the one or more business entities in proximity to the route. The advertisements for the business entities may be transmitted when the autonomous vehicle is within a defined distance from the business entities when driving on the route to the destination.
p4538
aVAbstract\u000aA parking management system that facilitates motorist guidance, payment, violation detection, and enforcement using highly accurate space occupancy detection, unique vehicle identification, guidance displays, payment acceptance, violation detection, enforcement data generation, electronic booting, and towing management is described. The system enables reduced time to find parking, congestion mitigation, accurate violation detection, and easier enforcement, and increased payment and enforcement revenues to cities.
p4539
aVAbstract\u000aA method for apprising a driver to a change in automation level of an automated self-drive system for a vehicle includes identifying an expected automation level change and communicating a required engagement level. The driver is thereby apprised of an appropriate level of engagement with each of a multiple of manual vehicle controls.
p4540
aVAbstract\u000aA seismic survey system records seismic signals during a marine seismic survey. The system includes first and second clusters, each including a set of autonomous underwater vehicles (AUVs); each cluster being associated with a corresponding first or second unmanned surface vehicle (USV); and a central control unit located on a floating platform and configured to control the first and second USVs. The first USV follows its own path and the first cluster follows the first USV independent of the second USV or the second cluster.
p4541
aVAbstract\u000aMethods and systems are provided for monitoring use of a vehicle having one or more autonomous (and/or semi-autonomous) operation features to determine and respond to incidents, such as collisions, thefts, or breakdowns. According to certain aspects, operating data from sensors within or near the vehicle may be used to determine when an incident has occurred and determine an appropriate response. The responses may include contacting a third party to provide assistance, such as local emergency services. In some embodiments, occurrence of the incident may be verified by automated communication with the vehicle operator.
p4542
aVAbstract\u000aData streams from multiple image sensors may be combined in order to form, for example, an interleaved video stream. The video stream may be encoded using a motion estimation encoder. Output of the video encoder may be processed (e.g., parsed) in order to extract motion information present in the encoded video. The motion information may be utilized in order to determine a depth of visual scene, such as by using binocular disparity between two or more images by an adaptive controller in order to detect one or more objects salient to a given task. In one variant, depth information is utilized during control and operation of mobile robotic devices.
p4543
aVAbstract\u000aApparatuses, methods and storage medium associated with computerized assist or autonomous driving (CA/AD) of vehicles are disclosed herein. In various embodiments, an apparatus may include a CA/AD system to: receive an identifier identifying a driver/passenger of a vehicle; request or retrieve, using the identifier, individual driving preferences of the driver/passenger; and apply the individual driving preferences of the driver/passenger to policies for CA/AD of the vehicle, to customize the policies for CA/AD of the vehicle for the driver/passenger. The CA/AD system may further receive data for policy parameters of the customized policies; and CA/AD the vehicle, in a manner that is adapted for the individual, in accordance with the customized policies, based at least in part on the data for the policy parameters of the customized policies. Other embodiments may be described and claimed.
p4544
aVAbstract\u000aMethods, systems are provided for controlling a travel path of a vehicle. The method includes the steps of detecting a braking of the vehicle by a computing device, calculating a friction ellipse for the vehicle based on the current state of the vehicle, defecting an intended travel path of the vehicle, detecting an actual travel path of the motor vehicle during the braking and determining if there is a path error where the actual travel path is outside the intended travel path when the braking is detected. When the actual travel path is outside the intended travel path then the method calculates a prospective friction ellipse for the vehicle, determines a compensating yaw moment to correct the path error, determines a maximum acceleration based on the prospective friction ellipse, and transmits a command to the autonomous braking system based on the maximum acceleration and the compensating yaw moment.
p4545
aVAbstract\u000aApparatus and methods for contrast enhancement and feature identification. In one implementation, an image processing apparatus utilizes latency coding and a spiking neuron network to encode image brightness into spike latency. The spike latency is compared to a saliency window in order to detect early responding neurons. Salient features of the image are associated with the early responding neurons. A inhibitory neuron receives salient feature indication and provides inhibitory signal to the other neurons within an area of influence of the inhibitory neuron. The inhibition signal reduces probability of responses by the other neurons to stimulus that is proximate to the feature thereby increasing contrast within the encoded data. The contrast enhancement may facilitate feature identification within the image. Feature detection may be used for example for image compression, background removal and content distribution.
p4546
aVAbstract\u000aA driving mode changing method and apparatus of an autonomous navigation vehicle that allows a driver to stably operate the autonomous navigation vehicle. The autonomous navigation vehicle may be stably operated by mounting an apparatus (a touch pad, a joystick, or the like) to operate the autonomous navigation vehicle on seats (a passenger seat and a rear seat) other than a driver seat of the autonomous navigation vehicle and providing various information (a near around view, a far around view, a critical level, vehicle information, and the like) to drive the autonomous navigation vehicle.
p4547
aVAbstract\u000aSystems, methods, and apparatus embodiments for electric power grid and network registration and management of active grid elements. Grid elements are transformed into active grid elements following initial registration of each grid element with the system, preferably through network-based communication between the grid elements and a coordinator, either in coordination with or outside of an IP-based communications network router. A multiplicity of active grid elements function in the grid for supply capacity, supply and/or load curtailment as supply or capacity. Also preferably, messaging is managed through a network by a Coordinator using IP messaging for communication with the grid elements, with the energy management system (EMS), and with the utilities, market participants, and/or grid operators.
p4548
aVAbstract\u000aTechniques are disclosed that can be implemented as a light-based communications network exhibiting gossip network topology. In some embodiments, the network may include a plurality of mobile and/or fixed communicating nodes (peers) configured for light-based communications with one another. To that end, a node may host a transmitter (e.g., laser, LED, or other solid-state light source) configured to emit light-based communication signals and/or a receiver (e.g., a photosensor or other light-based data input device) configured to sense such signals. In some cases, the network may be used to propagate or otherwise disseminate strategic, tactical, and/or other vehicle-to-X (V2X) communications between vehicles and infrastructure in a vehicle/roadway environment. In some instances, the gossip topology may provide for relay and aggregation of information from node to node, improving reliability and availability of information propagated within the network. In some embodiments, the network may be autonomous (e.g., self-forming and/or self-serving).
p4549
aVAbstract\u000aThe invention provides a control interface configured to cooperate with a vehicle, such as a wheelchair or mobile robot, said interface comprising at least one sensor is adapted to detect the presence of at least one finger of a user and to act as a switching mechanism between manual and autonomous control of the vehicle. The invention provides a highly intuitive and effective means of switching between automatic and manual vehicle control-no user training required. The control interface allows for user to be comfortable in an autonomous vehicle\u2014users can instantly gain full control when needed.
p4550
aVAbstract\u000aAn automated driving system and methods are disclosed. The automated driving system includes a perception system disposed on an autonomous vehicle. The automated driving system can detect, based on an audio recording captured by the perception system, an emergency vehicle operating in an emergency mode. After detection, an image of the environment surrounding the autonomous vehicle can be captured by the perception system. Based on at least one of the audio recording and the image of the environment surrounding the autonomous vehicle, a location of the emergency vehicle in respect to the autonomous vehicle can be determined. If the location of the emergency vehicle is such that the autonomous vehicle is required to comply with a traffic regulation, the automated driving system can send a command to one or more vehicle systems of the autonomous vehicle to implement one or more maneuvers to comply with the traffic regulation.
p4551
aVAbstract\u000aArrangements related to mitigating risk for an autonomous vehicle with respect to oncoming objects are described. An oncoming object in an external environment of the autonomous vehicle can be detected. It can be determined whether the oncoming object exhibits a hazardous behavior. Responsive to determining that the oncoming object exhibits a hazardous behavior, an altered travel route for the autonomous vehicle while maintaining safe operation of the autonomous vehicle can be determined. At least a portion of the altered travel route can safely violate a traffic rule. The autonomous vehicle can be caused to implement the altered travel route.
p4552
aVAbstract\u000aAn autonomous vehicle includes an input unit configured to receive selection input of at least one of a time mode for driving to a set destination, a fuel efficiency mode, a safety mode, or a comfort mode. The autonomous vehicle further includes a power source driver configured to control an engine comprising a supercharger or a turbocharger or both and a controller configured to control the power source driver to turn the supercharger or the turbocharger on or off according to the selected mode.
p4553
aVAbstract\u000aA vehicle can include a navigation unit configured to determine a position of the vehicle. A detection unit can be configured to recognize position and features of objects external to the vehicle. An identification unit can be configured to identify objects expected to be detected based on a determined position of the vehicle, by comparing the recognized features to feature data of object reference data stored in a local database. When the identification unit is unable to identify an object, the identification unit can compare recognized or stored object features to the additional feature data received from a remote database. A navigation unit can update the position of the vehicle based on position data of identified objects and more accurate and safe autonomous operation of a vehicle can be achieved.
p4554
aVAbstract\u000aA method and an apparatus for changing a motor vehicle in an autonomous travel mode to a safe state when the driver of the motor vehicle is not able to monitor the autonomous travel mode and to assume control of the motor vehicle. The vehicle driver is warned using warning signals of increasing intensity; other road users in the area surrounding the motor vehicle are warned using optical and/or acoustic signals; the motor vehicle is braked and/or accelerated repeatedly such that parts of the body of the vehicle driver noticeably move in the direction of travel owing to inertia (the braking and/or acceleration being so brief that the travel speed of the motor vehicle changes relatively little); and the motor vehicle is brought to a standstill or is kept at a standstill by automatic braking in order to change the vehicle to a safe state.
p4555
aVAbstract\u000aA modular autonomous agricultural vehicle includes a drive module having a frame, a ground-engaging element rotatably coupled to the frame, a power source, and a drive motor receiving power from the power source and coupled to the ground-engaging element for rotating the ground engaging element. At least one toolbar module is detachably coupled to the frame for coupling the drive module to an agricultural implement or another modular toolbar segment. The modular toolbar preferably includes multiple toolbar modules coupled to each other in series to form the modular toolbar.
p4556
aVAbstract\u000aSome embodiments described herein include a method for generating scaled terrain information with an unmanned autonomous gardening vehicle. In some embodiments the gardening vehicle includes a driving unit comprising a set of at least one drive wheel and a motor connected to the at least one drive wheel for providing movability of the gardening vehicle, a gardening-tool and a camera for capturing images of a terrain, the camera being positioned and aligned in known manner relative to the gardening vehicle. In context of the method the gardening vehicle is moved in the terrain while concurrently generating a set of image data by capturing an image series of terrain sections so that at least two (successive) images of the image series cover an amount of identical points in the terrain, wherein the terrain sections are defined by a viewing area of the camera at respective positions of the camera while moving.
p4557
aVAbstract\u000aIn a method for coordinating operation of motor vehicles driving fully automated, a trajectory described by a driving intervention is determined for each motor vehicle from status information of the motor vehicle, whereafter it is determined by an on-board vehicle system whether a coordination condition exists that requires coordination. If a coordination condition exists, trajectory data describing the trajectory are exchanged between the motor vehicles via a communication link through an on-board communication device and the trajectory is checked for conflicts caused by spatial and temporal overlap of the trajectories of at least two motor vehicles and/or because at least one of the motor vehicles did not reach its destination. If a conflict exists, the trajectory of a motor vehicle participating in the conflict is adjusted based on an arbitration rule evaluated by an arbitration device, whereafter the driving interventions described by the trajectory are performed by each motor vehicle.
p4558
aVAbstract\u000aA vehicle, vehicle system and method for increasing at least one of safety and comfort during autonomous driving is provided. The vehicle system includes an autonomous drive arrangement with multiple sensors, a vehicle control arrangement and a positioning system. The vehicle system is configured to determine an estimated probability that at least one sensor will become unavailable, or an estimated time/distance ahead until at least one sensor is determined to become unavailable. The vehicle system is further configured to activate at least one countermeasure based on at least one of the estimated probability, the estimated time and the estimated distance.
p4559
aVAbstract\u000aA method for identifying roadway curvature that includes determining a range of interest and collecting shape points from a map database from a current position of the vehicle to an end of the range of interest that define the location of the roadway. The method converts the shape points from World Geodetic System 84 (WGS84) coordinates to UTM coordinates, and then fits a single set of polynomial equations to define a curve using the converted shape points. The method determines whether the single set of polynomial equations exceeds a predetermined curvature accuracy threshold, and if so, fits multiple sets of polynomial equations to multiple roadway segments over the range of interest using the converted shape points. The method then determines the roadway curvature at any roadway location using solutions to the multiple sets of polynomial equations.
p4560
aVAbstract\u000aSystems, apparatus and methods implemented in algorithms, hardware, software, firmware, logic, or circuitry may be configured to process data and sensory input to determine whether an object external to an autonomous vehicle (e.g., another vehicle, a pedestrian, road debris, a bicyclist, etc.) may be a potential collision threat to the autonomous vehicle. The autonomous vehicle may be configured to implement interior active safety systems to protect passengers of the autonomous vehicle during a collision with an object or during evasive maneuvers by the autonomous vehicle, for example. The interior active safety systems may be configured to provide passengers with notice of an impending collision and/or emergency maneuvers by the vehicle by tensioning seat belts prior to executing an evasive maneuver and/or prior to a predicted point of collision.
p4561
aVAbstract\u000aExample systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.
p4562
aVAbstract\u000aA vehicle controlling method which includes detecting an engagement of a vehicle tire with a rumble strip of a road, and performing first and second vehicle controls. The first vehicle control includes operating a controller to control movement of the vehicle after the vehicle tire has disengaged from the rumble strip to bring the vehicle tire back into engagement with the rumble strip. The second vehicle control includes operating the controller to continue to control movement of the vehicle to maintain the vehicle tire in engagement with the rumble strip after the vehicle tire has been brought back into engagement with the rumble strip.
p4563
aVAbstract\u000aA method for determining a suitable landing area for an aircraft includes receiving signals indicative of Light Detection And Ranging (LIDAR) information for a terrain via a LIDAR perception system; receiving signals indicative of image information for the terrain via a camera perception system; evaluating, with the processor, the LIDAR information and generating information indicative of a LIDAR landing zone candidate region; co-registering in a coordinate system, with the processor, the LIDAR landing zone candidate region and the image information; segmenting, with the processor, the co-registered image and the LIDAR landing zone candidate region to generate segmented regions; classifying, with the processor, the segmented regions into semantic classes; determining, with the processor, contextual information in the semantic classes; and ranking and prioritizing the contextual information.
p4564
aVAbstract\u000aA lane departure control system is provided which works to control a lane departure of a vehicle. The lane departure control system determines a controlled angle between a heading direction and a target direction of the vehicle running in a lane. When the vehicle is expected to unintentionally leave the lane, the system steers the vehicle toward the center of the lane by the controlled angle at at least a first yaw rate in a first angular range and a second yaw rate in a second angular range following the first angular range. Each of the first and second yaw rates is changed at a constant rate. This results in simplified calculation of the schedule of changing the first and second yaw rates.
p4565
aVAbstract\u000aA method of controlling steering of a vehicle through setting wheel angles of a plurality of modular electronic corner assemblies (eModules) is provided. The method includes receiving a driving mode selected from a mode selection menu. A position of a steering input device is determined in a master controller. A velocity of the vehicle is determined, in the master controller, when the determined position of the steering input device is near center. A drive mode request corresponding to the selected driving mode to the plurality of steering controllers is transmitted to the master controller. A required steering angle of each of the plurality of eModules is determined, in the master controller, as a function of the determined position of the steering input device, the determined velocity of the vehicle, and the selected first driving mode. The eModules are set to the respective determined steering angles.
p4566
aVAbstract\u000aData is obtained concerning at least one attribute of a vehicle operator. The attribute is used to determine an instruction for positioning a vehicle component during autonomous operation of the vehicle. Autonomous operation of the vehicle, including positioning the vehicle component according to the instruction, is performed.
p4567
aVAbstract\u000aA method of controlling autonomous or driverless vehicles in a specific control zone or in a convoy is disclosed. The vehicles enter the zone or form a convoy and come under the control of a zone authority or escort vehicle that coordinates the movements of the vehicles until they leave the zone or convoy. Escort vehicle communicate with central control facilities, each other or escorted vehicles. The behavior of the escorted or controlled vehicles is modified to insure that it matches a set of rules established by the zone authority. Possible zones include parking areas, indoor passages and areas with security concerns. The zone authority or escort vehicle may simultaneously control multiple autonomous vehicles and possible additional driver operated vehicles. Messages establishing control or providing continuing administration of rules or movements of escorted or controlled vehicles may be delivered by any type of communications link.
p4568
aVAbstract\u000aSystems and methods use cameras to provide autonomous navigation features. In one implementation, a driver-assist system is provided for a vehicle. The system may include one or more image capture devices configured to acquire images of an area forward of the vehicle. The system may also include at least one processing device configured to receive, via one or more data interfaces, the images. The at least one processing device may be further configured to analyze the images acquired by the one or more image capture devices and cause at least one navigational response in the vehicle based on monocular and/or stereo image analysis of the images.
p4569
aVAbstract\u000aA vehicle sensor diagnosis system and method, and a vehicle including such a system are provided. The vehicle sensor diagnosis system is configured to predict upcoming vehicle surrounding conditions along at least a section of a host vehicle route based on database information on the host vehicle surroundings along the section and information on a current host vehicle surrounding, estimate an expected level of sensor performance for the route section based on the prediction, assess the level of sensor performance detected during host vehicle travel along the host vehicle route section, assess if a difference between the estimated level of sensor performance and the detected level of sensor performance for the host vehicle route section exceeds a first threshold difference and, if so, initiate a diagnose result communication.
p4570
aVAbstract\u000aA code for a parking location for a vehicle is identified. The code may be encoded in a scannable image. A processor analyzes the code for metadata for the parking location. The metadata is sent from a mobile device to a parking server along with data indicative of a beginning of a parking duration and/or data indicative of an ending of the parking duration. A parking payment may be calculated based on the parking duration by the mobile device or the parking server. An account for the vehicle may be automatically charged according to the parking payment.
p4571
aVAbstract\u000aA vehicle, a vehicle system and a method for allowing a host vehicle to autonomously avoid road irregularities are provided. The system communicates vehicle sensor data relating to detected road irregularities and host vehicle position information with an external database. A processor is arranged to determine a trajectory for the host vehicle for which all wheels of the host vehicle are laterally displaced from one or more road irregularities ahead of the host vehicle, and to autonomously steer the host vehicle along the determined trajectory. The system is also arranged to evaluate whether all wheels of the host vehicle were laterally displaced from all detected road irregularities and to send the result of the evaluation to the external database.
p4572
aVAbstract\u000aA method of guiding a vehicle to a region for initiating a parallel parking maneuver. A region of feasible starting locations for successfully performing a parallel parking maneuver is determined by a processor. A position of the vehicle relative to the region of feasible starting locations is determined. A determination is made whether the vehicle is in a zero heading position. The vehicle is guided along an initial target path by controlling a steering actuator until the vehicle is in a zero heading position relative to the road of travel in response to the vehicle is not in the zero heading position. A planned path is generated that includes two arc-shaped trajectories extending between the vehicle at the zero heading position and a position within the region of feasible starting locations as determined by the processor. The steering actuator is controlled to follow the planned path to the feasible region.
p4573
aVAbstract\u000aA method and system of distributed communication of independent autonomous vehicles to provide redundancy and performance are disclosed. In one embodiment, a set of autonomous vehicles operates in a geographically proximate area through which peer-to-peer communication sessions are established between nearby ones of the set of autonomous vehicles through an ad-hoc network based on a present geo-spatial location of each one of the set of autonomous vehicles in communication proximity to preferred adjacent ones of the set of autonomous vehicles. A central server directly coupled to each of the set of autonomous vehicles establishes centralized communication paths with each of the set of autonomous vehicles through a wide area network. The centralized server processes a communication from adjacent ones of the set of autonomous vehicles when an error condition is detected in an operational mode of a non-functional vehicle that has lost communication with the central server.
p4574
aVAbstract\u000aSystems, methods, and messages of the present invention provides IP-based messages associated with the grid elements, wherein each IP-based message includes an internet protocol (IP) packet that is generated autonomously and/or automatically by the grid elements, intelligent messaging hardware associated with the grid elements, at least one coordinator, and/or a server associated with the electric power grid and its operation, energy settlement, and/or financial settlement for electricity provided or consumed, transmitted, and/or curtailed or reduced. The IP packet preferably includes a content including raw data and/or transformed data, a priority associated with the IP-based message, a security associated with the IP packet, and/or a transport route for communicating the IP-based message via the network.
p4575
aVAbstract\u000aA refueling device for use in in-flight refueling operation between a tanker aircraft and a receiver aircraft includes a selectively steerable body and a controller. The selectively steerable body configured for being towed by a tanker aircraft via a fuel hose at least during in-flight refueling, and includes a boom member having a boom axis and configured to enable fuel to be transferred from the fuel hose to a receiver aircraft along the boom axis during the in-flight refueling operation. The controller is configured for selectively steering the body to an engagement enabling position spaced with respect to the receiver aircraft and for aligning the boom axis in an engagement enabling orientation at the spaced position, and for subsequently moving the boom member along the boom axis towards the receiver aircraft for enabling fuel communication therebetween.
p4576
aVAbstract\u000aSystems and methods implemented in algorithms, software, firmware, logic, or circuitry may be configured to process data and sensory input to determine whether an object external to an autonomous vehicle (e.g., another vehicle, a pedestrian, road debris, a bicyclist, etc.) may be a potential collision threat to the autonomous vehicle. The autonomous vehicle may be configured to implement active safety measures to avoid the potential collision and/or mitigate the impact of an actual collision to passengers in the autonomous vehicle and/or to the autonomous vehicle itself. Interior safety systems, exterior safety systems, a drive system or some combination of those systems may be activated to implement active safety measures in the autonomous vehicle.
p4577
aVAbstract\u000aAn unmanned autonomous traveling service apparatus and method based on driving information database that allows an unmanned autonomous traveling vehicle to be autonomously operated stably without performing a large scale computing process in real time by allowing the unmanned autonomous traveling vehicle to be autonomously operated based on driving information generated in a database and allowing the unmanned autonomous traveling vehicle to be autonomously operated based on an installed sensor at the time of a traffic lane change or an unexpected situation. In particular, the driving information is collected from drivers throughout the world to create the database for the driving information.
p4578
aVAbstract\u000aParking spaces are optimized by orchestrating the movement of one or more autonomous vehicles or shared vehicles. A computing device monitors locations of multiple vehicles. The computing device receives a request for a parking space from a user at or in route to a geographic location. The computing device selects one of the monitors vehicles based on the geographic location of the parking request. The computing device generates an instruction to make available a parking space of the selected one of the vehicles. In the case of autonomous vehicles, the vehicle drives away from the parking space. In the case of shared vehicles, a rental appointment is modified to make the parking space available.
p4579
aVAbstract\u000aA base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device.
p4580
aVAbstract\u000aA control device for an autonomous land vehicle, in particular truck or passenger car, which controls actuators of the vehicle to perform autonomous navigation on the basis of surroundings data acquired by sensors. The control device controls the actuators in accordance with input from the sensors and with a desired driving behavior selected by a vehicle occupant from among several available driving behaviors, such as defensive driving, moderate driving, economical driving or sporty driving.
p4581
aVAbstract\u000aAn autonomous vehicle platform and system for selectively performing an in-season management task in an agricultural field while self-navigating between rows of planted crops, the autonomous vehicle platform having a vehicle base with a width so dimensioned as to be insertable through the space between two rows of planted crops, the vehicle base having a first portion and a second portion, wherein the first portion is pivotably coupled to the second portion, and each of portion is operably coupled to at least one ground engaging wheel.
p4582
aVAbstract\u000aA carrying autonomous vehicle system, comprising: a carrying autonomous vehicle and at least one carried autonomous vehicle. The carrying autonomous vehicle has a main frame and at least one flipper. The carried autonomous vehicle uses at least one flipper to load and/or unload at least one carried autonomous vehicle on the main frame.
p4583
aVAbstract\u000aAn autonomous flapping wing aerial vehicle can have a vehicle body, a pair of flapping wings, tunable wing hinges, and elastic drive mechanisms. The tunable wing hinges can be coupled to the flapping wings. Each wing hinge can be constructed to deliver a force to a respective one of the flapping wings to alter end points of a stroke thereof. The elastic drive mechanisms can rotate the flapping wings about pivot points to produce the strokes of the flapping wings. The elastic drive mechanism can be driven at or near a resonance thereof. Alterations to the strokes of the flapping wings produced by the combined effect of the tunable wing hinges and the elastic drive mechanisms, operating in parallel, can provide steering control of the aerial vehicle.
p4584
aVAbstract\u000aA steering wheel in a vehicle can be in one of an operating position and a stowed position. Crash sensor data is monitored to detect a first and second frontal collision. Upon detecting the first frontal collision, a selected one of a first airbag and a second airbag is deployed depending on whether the steering wheel is in the stowed position or the operational position. When the steering wheel is in the operational position and a second collision is detected both the first and second airbags may be deployed.
p4585
aVAbstract\u000aA computer-readable detailed map format is disclosed. The detailed map format includes a lane segment and one or more border segments. A distance to an edge of the lane segment can be determined at a location along the lane segment by measuring a distance between the location and a portion of the border segment closest to the location. A lane width of the lane segment can be determined at a location along the lane segment by measuring a distance between two of the border segments positioned proximate to and on opposite sides of the lane segment.
p4586
aVAbstract\u000aA vehicle may operate in an autonomous mode in an environment during a test period. The vehicle may include at least one sensor coupled to the vehicle, configured to acquire sensor data during the test period. The sensor data may include data representative of a target object in the environment. The vehicle may operate the sensor to obtain the sensor data. The vehicle may define a movement of the vehicle, determine a predicted movement of the target object in the sensor data based on the defined movement, initiate the defined movement of the vehicle at an initiation time during the test period, complete the defined movement of the vehicle at a completion time during the test period, analyze the sensor data obtained during the test period, and determine a latency of the at least one sensor based on the analyzed data.
p4587
aVAbstract\u000aA vehicle which is adaptable for both flight and water travel includes: a body; a wing, a stabilizer, or a first propelling member; and at least one attachment member. The body is configured to fly through air and to move through water. The at least one attachment member attaches the wing, the stabilizer, or the first propelling member to the body while the body is in flight. The at least one attachment member detaches at least a portion of the wing, at least a portion of the stabilizer, or at least a portion of the first propelling member from the body when the body is in the water.
p4588
aVAbstract\u000aTechnologies for optimized vehicle parking include a parking management computing device and a number of advanced vehicles, each having an in-vehicle computing system. The parking management computing device establishes a secure control channel with each of the in-vehicle computing systems. Each of the in-vehicle computing systems may send a parking request to park or access the vehicle to the parking management computing device. The parking management computing device queries a number of the advanced vehicles that are already parked for positional or sensor data and determines an optimized parking configuration based on the parking request. The parking management computing device transmits movement requests to the in-vehicle computing systems to implement the optimized parking configuration. Each in-vehicle computing system may perform the movement request by using an autonomous driving capability, by using a remote control capability, or by notifying an operator. Other embodiments are described and claimed.
p4589
aVAbstract\u000aA vehicle control system and method employs a sensing system and a controller. The sensing system is disposed on a host vehicle and configured to sense a visual condition of a driver of the host vehicle. The controller is configured to control an autonomous vehicle control system on board the host vehicle to stop the host vehicle at a stopping location based on the visual condition and at least one point of interest external to the host vehicle.
p4590
aVAbstract\u000aSystems and methods may calibrate an indicator of speed of an autonomous vehicle. In one implementation, a system may include at least one processor programmed to: receive from a camera at least a plurality of images representative of an environment of the vehicle; analyze the plurality of images to identify at least two recognized landmarks; determine, based on known locations of the two recognized landmarks, a value indicative of a distance between the at least two recognized landmarks; determine, based on an output of at least one sensor associated with the autonomous vehicle, a measured distance between the at least two landmarks; determine a correction factor for the at least one sensor based on a comparison of the value indicative of the distance between the at least to recognized landmarks and the measured distance between the at least two landmarks.
p4591
aVAbstract\u000aA vehicle includes at least one autonomous driving sensor and an autonomous mode controller configured to receive signals generated by the autonomous driving sensor. The autonomous mode controller controls at least one vehicle subsystem based at least in part on the signals received. Furthermore, the autonomous mode controller is configured to shade at least one vehicle window when the vehicle is operating in an autonomous mode.
p4592
aVAbstract\u000aDisclosed are various embodiments for coordination of autonomous vehicles in a roadway. A roadway management system can generate lane configurations for a roadway or a portion of the roadway. The roadway management system can determine the direction of travel for lanes in a roadway and direct autonomous automobiles to enter the roadway in a particular lane.
p4593
aVAbstract\u000aSensory encoder may be implemented. Visual encoder apparatus may comprise spiking neuron network configured to receive photodetector input. Excitability of neurons may be adjusted and output spike may be generated based on the input. When neurons generate spiking response, spiking threshold may be dynamically adapted to produce desired output rate. The encoder may dynamically adapt its input range to match statistics of the input and to produce output spikes at an appropriate rate and/or latency. Adaptive input range adjustment and/or spiking threshold adjustment collaborate to enable recognition of features in sensory input of varying dynamic range.
p4594
aVAbstract\u000aAn autonomous vehicle which includes multiple independent control systems that provide redundancy as to specific and critical safety situations which may be encountered when the autonomous vehicle is in operation.
p4595
aVAbstract\u000aExamples described herein include an autonomous vehicle that receives guide assistance from a human driven vehicle in response to a determination that the autonomous vehicle cannot progress safely on its route.
p4596
aVAbstract\u000aThe invention provides an autonomous vehicle capable of driving independently through a path of intense traffic and transporting objects or people, even on rough surfaces, while ensuring safety of the vehicle and general road safety. The autonomous vehicle includes at least one variable pitch camera for producing images to be used for a computer vision to control the autonomous vehicle. The invention facilitates changing the pitch of the variable pitch camera to maximize camera image clarity and/or resolution as the autonomous vehicle moves. The images can be used for lane detection, pedestrian detection, three-dimensional (3D) reconstruction of an environment and/or pothole detection. With the invention, at least one image from the variable pitch camera is used in controlling the movement and/or the trajectory of the autonomous vehicle.
p4597
aVAbstract\u000aA folding vehicle structure includes a frame having a plurality of members. A first member intersects a second member at a first pivot point. A third member, spaced from the first and second members, intersects a fourth member, which is also spaced from the first and second members, at a second pivot point. The frame includes a first cross-member extending between the first and second intersection points. The frame is collapsible.
p4598
aVAbstract\u000aAspects of the present disclosure relate to protecting the privacy of a user of a dispatching service for driverless vehicles. For example, a request for a vehicle identifying user information is received. A client computing device may be identified based on the user information. In response to the request, a driverless vehicle may be dispatched to the location of the client device. Signaling information may be generated based on a set of rules including a first rule that the signaling information does not identify, indirectly or directly, the user as well as a second rule that the signaling information does not identify, indirectly or directly, the user information. The location of the client computing device and the signaling information may be sent to the driverless vehicle for display. In addition, the signaling information may also be sent to the client computing device for display.
p4599
aVAbstract\u000aAn apparatus, method, and system of self-calibrating sensors and actuators for unmanned vehicles is provided, which includes an unmanned vehicle comprising: a chassis; a propulsion system; one or more sensors configured to sense features around the chassis; a memory; a communication interface; and a processor configured to: operate the propulsion system in a guided calibration mode; automatically switch operation of the propulsion system to an autonomous calibration mode when a degree of certainty on a calibration of one or more of sensor data and a position of the chassis is above a first threshold value associated with safe operation of the propulsion system in the autonomous calibration mode; thereafter, operate the propulsion system in the autonomous calibration mode; and, automatically switch operation of the propulsion system to an operational mode when the degree of certainty is above a second threshold value greater than the first threshold value.
p4600
aVAbstract\u000aA first vehicle may receive at least one message from a second vehicle, the message including data provided by the second vehicle. A computing device in the first vehicle is configured to analyze the data of the at least one message to determine that the second vehicle can operate as a lead vehicle. The computing device in the first vehicle is further configured to implement at least one operation in the first vehicle according to the data from the lead vehicle.
p4601
aVAbstract\u000aA system for controlling an unmanned vehicle is disclosed to facilitate remote-control operation of the unmanned vehicle from long distances. The system includes at least one ground control communication device having a transceiver configured for operation in a cellular communication network. The system also includes an unmanned vehicle comprising another transceiver configured for operation in the cellular communication network. The unmanned vehicle is further configured to be responsive to communications received via the transceiver from the communication device, wherein the communications received from the communication device includes operation commands. Additionally, the unmanned vehicle is configured to transmit video surveillance data and other monitoring data to the communication device via the cellular network.
p4602
aVAbstract\u000aA vehicle navigation route search system, method, and program search for a recommended route in the case where a vehicle travels by autonomous driving control in an autonomous driving section where autonomous driving control of the vehicle is permitted. The system, method, and program calculate a cost value by using a cost table for autonomous driving control which is set such that a route that is more suitable for traveling by autonomous driving control has a lower cost value, and search for the recommended route based on the calculated cost value.
p4603
aVAbstract\u000aVarious embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. More specifically, systems, devices, and methods are configured to initiate modification of trajectories to influence navigation of autonomous vehicles. In particular, a method may include receiving a teleoperation message via a communication link from an autonomous vehicle, detecting data from the teleoperation message specifying an event associated with the autonomous vehicle, identifying one or more courses of action to perform responsive to detecting the data specifying the event, and generating visualization data to present information associated with the event to a display of a teleoperator computing device.
p4604
aVAbstract\u000aA method and system for autonomous tracking of a following vehicle on the track of a leading vehicle. A lead message is received by the following vehicle and rejected by the following vehicle or confirmed with a follow message. After receipt of the follow message, a first element of coordination information for coordination of the autonomous tracking is sent to the following vehicle by the leading vehicle. A second element of coordination information is detected for coordination of the autonomous tracking by environment sensors of the following vehicle on the basis of movements of the leading vehicle. The first and second elements of coordination information are compared by the following vehicle. In the case of a matching comparison result, the autonomous tracking is performed corresponding to the first and second elements of coordination information and, in the case of a deviating comparison result, the autonomous tracking is ended.
p4605
aVAbstract\u000aThe present teachings provide for an active steering system for controlling a vehicle. The system can include at least one sensor and a control module. The at least one sensor can be configured to detect a leading obstacle. The control module can be configured to receive a signal from the at least one sensor, to determine a steering profile, and to execute a lane change maneuver based on the steering profile. The steering profile can include a plurality of steering angles and corresponding vehicle positions for maneuvering the vehicle from a current lane to an adjacent lane. The steering angles can be calculated to not increase the acceleration of the vehicle above an occupant comfort threshold value and to not cause the vehicle to cross an outer boundary of the adjacent lane.
p4606
aVAbstract\u000aA method controls a powertrain that directs power from an engine and a transmission to all four wheels or to just front wheels or to just rear wheels. The method includes monitoring information transmitted over a communications network. The method determines whether one or more components of the powertrain are in an active condition or in an inactive condition. The one or more components of the powertrain are in the inactive condition when not connected to the transmission and not connected to the front wheels or the rear wheels. The one or more components of the powertrain are in the active condition when connected to the transmission and connected to the front wheels and the rear wheels. The method switches the one or more components of the powertrain between the inactive condition and the active condition based at least in part on visual data provided by an on-board camera system.
p4607
aVAbstract\u000aA modular payload system for an autonomous water vehicle includes a hull formed with a recessed portion that extends longitudinally over a region where a transverse cross section of a lower portion of the recess is constant along the region. A plurality of payload boxes are sized to fit in the recess and be distributed along the longitudinal axis. A transverse cross section of a lower portion of each payload box is configured complementarily with the lower portion of the recess. The payload boxes can be sized so that one payload box has a longitudinal dimension that is an integral multiple of the longitudinal dimension of the second payload box. The payload boxes can have complementarily positioned external electrical connectors to allow a jumper cable to serially connect the payload boxes.
p4608
aVAbstract\u000aIdentifying cost-effective parking for an autonomous vehicle, including: identifying, by a vehicle parking module, a plurality of available parking spots for parking the autonomous vehicle; determining, by the vehicle parking module, a total cost associated with each of the plurality of available parking spots for parking the autonomous vehicle; and selecting, by the vehicle parking module, a target parking spot in dependence upon the total cost associated with each of the plurality of available parking spots for parking the autonomous vehicle.
p4609
aVAbstract\u000aA method and apparatus for autonomous vehicle lane routing and navigation are provided. Autonomous vehicle lane routing and navigation may include identifying vehicle transportation network information including road segment information and lane information, wherein the road segment information for at least one road segment from the plurality of road segments includes lane information representing at least two adjacent lanes, identifying an origin, identifying a destination, generating a plurality of candidate routes from the origin to the destination, wherein each route from the plurality of routes indicates a distinct combination of road segments and lanes, and wherein at least one candidate route from the plurality of candidate routes includes at least one of the adjacent lanes, identifying an optimal route from the plurality of candidate routes, the optimal route having a minimal route cost, and operating the autonomous vehicle to travel from the origin to the destination using the optimal route.
p4610
aVAbstract\u000aMethods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.
p4611
aVAbstract\u000aA method of delivering parcels in two stages. A vehicle transports the parcel to a transfer point using address information from a shipping party. The first vehicle is designed for operation on the pubic road system. The parcel is transferred to a secondary vehicle for delivery to the final delivery point. The second vehicle which may one vehicle or multiple vehicles with multiple parcels finishes the delivery. The second vehicle is autonomous and adapted to use off of public roads or in smaller spaces. It relies on information provided by the recipient or the location controller of the area for the second delivery segment. The information may define a geometric path for the vehicle to traverse or may be information to pass restrictions such as locked doors in the final delivery path. The method provides advantages of efficiency, security and late provision of final delivery information.
p4612
aVAbstract\u000aAn autonomous driving vehicle is configured to enable mutual switching between an autonomous driving state and a manual driving state. The autonomous driving vehicle includes a steering wheel, and a controller configured to control mechanical linkage or electrical linkage between the steering wheel and a directional vehicle wheel so as to be cut off based on whether the autonomous driving vehicle is in the autonomous driving state or the manual driving state.
p4613
aVAbstract\u000aAn underwater base handles an autonomous underwater vehicle. The underwater base includes a storing part configured to store the AUV; a control part configured to control the storing part; and a support part configured to support the control part and the storing part and to prevent a burial of the underwater base into the ocean bottom. The control part is further configured to guide the AUV while approaching a desired target position on the ocean bottom.
p4614
aVAbstract\u000aA traffic control system for allowing vehicles to travel unattended while maintaining their inter-vehicular distances without interfering with each other includes an onboard control apparatus mounted on the vehicles; and a traffic control apparatus which divides tracks for multiple vehicles into a plurality of sections and performs a blocking control to assign non-overlapping travelable sections to the multiple vehicles as a permitted travel section. The onboard control apparatus sets a travel permission request starting distance that is longer than a stoppable distance on the basis of the current speed of the vehicle and repeatedly transmits a travel permission request and current position information to the traffic control apparatus until the next travel permission is obtained when the remaining length of the permitted travel section has become shorter than the travel permission request starting distance in the advancing direction of the vehicle.
p4615
aVAbstract\u000aAspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.
p4616
aVAbstract\u000aAspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.
p4617
aVAbstract\u000aA control interface for a first vehicle operation of an autonomous vehicle. The control interface detects an autonomy activation signal to enable a first automated controller to control the first vehicle operation. The control interface then couples the first automated controller to a vehicle control platform configured to manage the first vehicle operation in response to input signals. For example, the control inter face may include a double-throw electromechanical relay that switchably couples the vehicle control platform to one of the first automated controller or a manual input mechanism. The control interface then provides the input signals to the vehicle control platform from the first automated controller.
p4618
aVAbstract\u000aAn event is detected that impairs a confidence level of the autonomous vehicle in progressing through a current route. In response to detecting the event, the autonomous vehicle communicates information about the event to a remote source of guidance. The autonomous vehicle can receive instructions from the remote source of guidance on how to handle the event. The autonomous vehicle can then implement the instructions to handle the event while it operates.
p4619
aVAbstract\u000aIn some embodiments, an Unmanned Aerial Vehicle (UAV) is configured to navigate to a first location point from a plurality of location points. The plurality of location points defines a flight pattern. The UAV is further configured to receive a set of location coordinates of a moving object. The UAV is configured to determine the distance between the moving object and the UAV based on the set of location coordinates of the moving object and the first location point of the UAV. When the distance between the moving object and the UAV reaches a pre-determined threshold, the UAV is configured to advance to a second location point from the plurality of location points.
p4620
aVAbstract\u000aTechnology is described for performing services on an autonomous vehicle. The autonomous vehicle may detect that a service is to be performed on the autonomous vehicle. The autonomous vehicle may select a service center to perform the service on the autonomous vehicle. The autonomous vehicle may provide commands to drive the autonomous vehicle to the service center to enable performance of the service on the autonomous vehicle.
p4621
aVAbstract\u000aA monitoring device receives an aerial image, data relating to a vehicle and a request for an image of the vehicle. The vehicle is located in the image. A portion of the aerial image that includes the vehicle and/or information based thereon is provided.
p4622
aVAbstract\u000aA system, device, and methods for image and map-based detection of vehicles at intersections. Once example computer-implemented method for detecting objects includes receiving, from the one or more sensors disposed on a vehicle, image data representative of an image and detecting an object on the image. The method further includes identifying a path extending from the vehicle to the detected object on the image and retrieving map data including lane information. The method further includes comparing the path to a representation of the lane information and determining the position of the detected object based on a comparison of the path, representation of the lane information, and the image.
p4623
aVAbstract\u000aA vehicle control system is provided that includes an internal communications system. The vehicle control system further includes a controller configured to communicate with a plurality of independent vehicle systems via the internal communications system. The controller stores and accesses a plurality of libraries of system processes having data associated with the plurality of vehicle components. The controller maintains an operational state for the vehicle during an operational failure of at least one of the plurality of independent vehicle systems.
p4624
aVAbstract\u000aAn automated driving system can determine, based on input from one or more sensors disposed on an autonomous vehicle, a required fuel level to complete a planned vehicle path and a current fuel level for the autonomous vehicle. If the current fuel level is below the required fuel level, the automated driving system can identify one or more refueling stations and send an indication to a driver of the autonomous vehicle requesting selection of one of the identified refueling stations. If a refueling station selection is received, the automated driving system can update the planned vehicle path to include a stop at the selected refueling station. If a refueling station selection is not received, the automated driving system can determine a critical fuel level. If the current fuel level falls below the critical fuel level, the automated driving system can drive the autonomous vehicle to a proximate refueling station.
p4625
aVAbstract\u000aProvided are an apparatus and method for sharing vehicle information among autonomous vehicles. According to the apparatus and method, not only current driving-related information and future driving-related information of a self vehicle but also current driving-related information and future driving-related information of another vehicle is acquired and used to control travel of the self vehicle. Accordingly, the safety of travel is improved, and efficient autonomous travel is enabled.
p4626
aVAbstract\u000aDescribed is a radiation dosimeter including multiple sensor devices (including one or more passive integrating electronic radiation sensor, a MEMS accelerometers, a wireless transmitters and, optionally, a GPS, a thermistor, or other chemical, biological or EMF sensors) and a computer program for the simultaneous detection and wireless transmission of ionizing radiation, motion and global position for use in occupational and environmental dosimetry. The described dosimeter utilizes new processes and algorithms to create a self-contained, passive, integrating dosimeter. Furthermore, disclosed embodiments provide the use of MEMS and nanotechnology manufacturing techniques to encapsulate individual ionizing radiation sensor elements within a radiation attenuating material that provides a \u201cfiltration bubble\u201d around the sensor element, the use of multiple attenuating materials (filters) around multiple sensor elements, and the use of a software algorithm to discriminate between different types of ionizing radiation and different radiation energy.
p4627
aVAbstract\u000aA collision avoidance system for a vehicle includes an electronic brake system capable of applying wheel brakes to decelerate the vehicle, a steering system capable of changing a steering angle for the vehicle, and a controller. The controller instructions for performing a pedestrian avoidance maneuver including at least one of steering the vehicle to the maximum available separation distance and braking the vehicle to the maximum safe speed while the vehicle is passing the pedestrian.
p4628
aVAbstract\u000aEmbodiments herein use a real-time closed-loop system to optimize a wireless network. The system includes a drone controlled by a self-organizing network (SON) to retrieve RF data corresponding to the wireless network. In one embodiment, the SON provides the drone with a predetermined path through the coverage area of the wireless network. As the drone traverses the path, a RF scanner mounted on the drone collects RF data. The drone transmits this data to the SON which processes the RF data to identify problems in the wireless network (e.g., cell tower interference). The SON generates one or more actions for correcting the identified problem and transmits these actions to a wireless network controller. Once the wireless network controller performs the action, the SON instructs the drone to re-traverse the portion of the path to determine if the problem has been resolved.
p4629
aVAbstract\u000aAn autonomous vehicle system is configured to receive vehicle commands from one or more parties and to execute those vehicle commands in a way that prevents the execution of stale commands. The autonomous vehicle system includes a finite state machine and a command counter or stored vehicle timestamp, which are used to help reject invalid or stale vehicle commands.
p4630
aVAbstract\u000aAn identification of a vehicle is received. An identification of a first user to receive delegation of control of the vehicle is received. Authentication information for the first user for the vehicle is determined. A request to authenticate the first user for delegation of control of the vehicle to the first user is received. The request to authenticate includes at least the authentication information for the first user is determined. Responsive to the determination, control of the vehicle is delegated to the first user.
p4631
aVAbstract\u000aAspects of an autonomous delivery transportation network for the delivery of items are described. The network includes a central management system that directs the operation of a network of vehicles for delivering items. In one embodiment, the system receives a request for transportation including a pickup location, a delivery location, and item attribute data. The system analyzes the existing service routes of vehicles in the network to identify a vehicle compatible with the request. The system also estimates a delay to the existing service route of the vehicle with reference to the pickup and delivery locations and, when determining that the delay is acceptable, assigns the vehicle to service the request. When determining that the delay is unacceptable, the system may dispatch a new vehicle to join the network. The system may also communicate various aspects of service, such as estimated pickup and/or drop off times, to client devices.
p4632
aVAbstract\u000aMethods and systems for correcting an estimated heading using a map are disclosed. Map data indicative of a map of an environment of a vehicle and data indicative of an estimated heading the vehicle is received. A sensor obtains first spatial data indicative of locations of objects in the environment relative to the vehicle at a first time. A first location of the vehicle on the map is determined based on the first spatial data. The sensor obtains second spatial data indicative of locations of objects in the environment relative to the vehicle at a second time. A second location of the vehicle on the map is determined based on the second spatial data. A heading correction of the vehicle is determined based on the estimated heading, the first location, the first time, the second location, and the second time, and a speed of the vehicle.
p4633
aVAbstract\u000aA driver assistance system for intervening in the control of at least one of a drive system, a controller, or signaling devices of a motor vehicle includes: a radar control unit having a radar sensor; and a mobile device having a video sensor for ascertaining surroundings information, the mobile device being a mobile phone or a smart phone, for example. In this case, the mobile device transmits the ascertained surroundings information to the radar control unit via a first wireless connection.
p4634
aVAbstract\u000aIn an example method, a vehicle configured to operate in an autonomous mode could predict an output of the vehicle based on an input provided to control the vehicle and a state of the vehicle. The method could include receiving an indication of an input from at least one input-indication sensor and an indication of an output from at least one output-indication sensor. A predicted output value could be calculated based on the indication of the input and a state of the vehicle. The predicted output value could be compared with the indication of the output. If the comparison is not within a threshold range, an alert indicator could be created. Upon creating the alert indicator, an alert action could be activated.
p4635
aVAbstract\u000aPackage delivery platform. An autonomous road vehicle is operative to receive destination information, and to drive to a destination based on the destination information. A package securing subsystem is attached to the autonomous road vehicle and comprises at least one securable compartment. Each securable compartment is operative to secure at least one package therein. Each securable compartment is associated with compartment access information. An access subsystem comprising at least one access information interface. The access subsystem is operative, upon receipt through the access information interface of compartment access information, to permit access to the compartment associated with the received compartment access information.
p4636
aVAbstract\u000aAn autonomous vehicle comprises at least one distance measurement means for measuring a distance to a road surface disposed in a vehicle main body, inclination calculation means for calculating an inclination of the vehicle main body based on the distance measured by the distance measurement means, posture calculation means including a sensor that detects at least one of an angular speed and an acceleration of the vehicle main body, the posture calculation means being configured to calculate the inclination of the vehicle main body based on a sensor value detected by the sensor, and failure determination means for determining a failure in each distance measurement means and the posture calculation means by comparing the inclination of the vehicle main body calculated by the inclination calculation means with the inclination of the vehicle main body calculated by the posture calculation means.
p4637
aVAbstract\u000aA trailer backup assist system includes a sensor that measures a hitch angle between a vehicle and a trailer. A steering system controls a steering angle of the vehicle between physical angle limits. A controller of the trailer backup assist system generates adaptive angle limits based on a maximum hitch angle rate and generates a steering command within the physical and adaptive angle limits for the vehicle to guide the trailer on a desired curvature.
p4638
aVAbstract\u000aAn autonomous vehicle environment detection method, for use by an autonomous vehicle having autonomous features for allowing a destination to be set by a user and then piloting the vehicle to that destination without human intervention by the user. Environmental sensors, which may be contained in or around the vehicle, or in a portable electronic device possessed and carried by the user, perform a sniff test prior to, and during automated vehicle operation. If hazardous materials are detected that indicate the presence of a weapon of mass destruction, autonomous features are disabled while manual operation of the vehicle may be permitted.
p4639
aVAbstract\u000aAdministering a recall by an autonomous vehicle, including: receiving, by a vehicle management module, a recall message identifying a component of the autonomous vehicle that is subject to the recall; adjusting, by the vehicle management module, a vehicle capability in dependence upon the component of the autonomous vehicle that is subject to the recall; determining, by the vehicle management module, a recall response plan in dependence upon the adjusted vehicle capability; and executing, by the vehicle management module, the recall response plan.
p4640
aVAbstract\u000aA radar system in an autonomous vehicle may be operated in various modes and with various configurations. In one example, the radar system determines a target range for further interrogation. The target range may be determined based on the radar system transmitting a first electromagnetic radiation signal and receiving a first reflected electromagnetic signal radiation signal. After the radar system determines a target range, it transmits an electromagnetic radiation signal according to a Frequency Modulated Continuous-wave (FMCW) operating mode. Additionally, the radar system receives a reflected electromagnetic signal radiation based on the transmission. After receiving the reflected signal, the radar system can process the reflected signal to only have components associated with the target range. The processing of the reflected signal may create a processed signal. Finally, the radar system may determine at least one parameter of a target object based on the processed signal.
p4641
aVAbstract\u000aA vehicle includes a passenger compartment with an instrument panel located near a front of the passenger compartment. The vehicle further includes at least one seat located in the passenger compartment. The seat can be stowed under the instrument panel for when the vehicle is operating in an autonomous mode.
p4642
aVAbstract\u000aA method for autonomous controlling of a remote controlled aerial vehicle, wherein a flight operator commands the aerial vehicle, comprising the steps of: initializing a data link between the aerial vehicle and a ground segment; determining an operation condition of the data link during use of the data link; and issuing at least one autonomous controlling command, if, as a result of the determining, a loss of the data link is determined.
p4643
aVAbstract\u000aDuring a self-driving control, when an acquisition failure occurs in traveling environment information acquisition required for performing self-driving, and a failure of a steering system of a vehicle equipped with the vehicle driving control apparatus is detected, a brake controller sets an evacuation course along which the vehicle is to travel safely within traveling environment, based on traveling environment information detected last time before the acquisition failure of the traveling environment information, and executes a deceleration of the vehicle and a yaw brake control that applies a yaw moment to the vehicle based on the evacuation course.
p4644
aVAbstract\u000aArrangements relating to the transfer of data from an autonomous vehicle to a remote operation computing system while the autonomous vehicle is operating in a remote operational mode are described. A driving environment of the autonomous vehicle can be sensed using a sensor system to acquire driving environment data. The sensor system includes a plurality of different types of sensors. A driving environment complexity can be determined. The availability of a communication channel between the autonomous vehicle and the remote operation computing system can be determined. A subset of the plurality of different types of sensors can be selected based on the determined driving environment complexity and/or the determined communication channel availability and/or its quality. Driving environment data acquired by the selected subset of the plurality of different types of sensors can be sent to the remote operation computing system.
p4645
aVAbstract\u000aArrangements related to the mitigation of risk for an autonomous vehicle relative to turning objects are presented. An object in an external environment of the autonomous vehicle that is turning toward the autonomous vehicle can be detected. It can be determined whether the detected object will impinge upon the autonomous vehicle. Responsive to determining that the detected object will impinge upon the autonomous vehicle, a driving maneuver for the autonomous vehicle can be determined to avoid being impinged upon by the detected object. The autonomous vehicle can be caused to implement the determined driving maneuver.
p4646
aVAbstract\u000aMethods and systems are provided for controlling a steering system of a vehicle is provided. A detection unit is configured to obtain one or more of the following values: a compass heading, a global positioning system (GPS) heading, a yaw velocity, and a difference in tire angular velocities. A processor is coupled to the detection unit, and is configured to determine whether a vehicle is on a straight line path using one or more of the compass heading, the GPS heading, the yaw velocity, and the difference in tire angular velocities, activate the steering system if it is determined that the vehicle is on a straight line path, and disable the feature of the steering system if it is determined that the vehicle is not on a straight line path.
p4647
aVAbstract\u000aEmbodiments of the present invention disclose a method, computer program product, and a computer system for modifying regional driving habits. A computer determines a first value associated with a regional driving habit for a region. The computer determines a second value associated with a target driving habit, wherein the second value is not substantially equivalent to the first value. The computer determines that a number of at least semi-autonomous vehicles in an area is above a threshold value. The computer transmits information instructing the number of at least semi-autonomous vehicles to operate based on the second value.
p4648
aVAbstract\u000aVarious embodiments of a controller, system and method of preventing vehicle rollaway for a heavy vehicle are disclosed. The controller receives a service brake signal indicating an operator has engaged the service brakes, a parking brake signal indicating the operator intent to actuate the parking brake and a signal indicative of motion. The controller transmits a control signal to at least two braking system components in response the service brake signal, the parking brake signal, and the motion of the vehicle to maintain engagement of the vehicle service brakes after the service brake pressure signal begins to decrease.
p4649
aVAbstract\u000aThe present disclosure relates to a device and a method for self-automated parking lots for autonomous vehicles based on vehicular networking, advantageous in reducing parking movements and space. It is described a device for self-automated parking lot for autonomous vehicles based on vehicular networking, comprising: a vehicle electronic module for receiving, executing and reporting vehicle movements, a parking lot controller for managing and coordinating a group of vehicles in parking and unparking maneuvers, the vehicle module and controller comprising a vehicular ad hoc networking communication system. It is also described a method comprising moving autonomously in platoon one or more rows of already parked vehicles in order to make available a parking space for a vehicle arriving to the parking space; and moving autonomously in platoon one or more rows of parked vehicles in order to make a parked vehicle able to exit the parking space.
p4650
aVAbstract\u000aA vehicle traveling control apparatus includes a first information obtaining unit, a second information obtaining unit, a traveling controller, a detector, and a calculator. The first information obtaining unit obtains information on a traveling environment of an own vehicle as traveling environment information. The second information obtaining unit obtains information on traveling of the own vehicle as traveling information. The traveling controller performs an evacuation traveling control, based on the traveling environment information and the traveling information. The evacuation traveling control causes an evacuation traveling of the own vehicle to be executed. The detector detects an abnormal state of a driver of the own vehicle. The calculator calculates waiting time during which waiting is performed from the detection of the abnormal state of the driver to starting of the evacuation traveling control, when the abnormal state of the driver is detected by the detector.
p4651
aVAbstract\u000aIn an example method, a vehicle is configured with a radar system used to aid in vehicle guidance. The method could include an array of antennas plurality of antennas configured to receive a radar signal. The array of antennas has a respective spacing between the given antenna and an adjacent antenna; however, the plurality of spacings includes at least two different spacings. A portion of the method may be performed by a processor configured to calculate a detection channel, based on a difference between differential phases associated with two antenna pairs in the array. The processor may also calculate an unambiguous angle based on the detection channel and the plurality of antenna spacings. Additionally, the processor may control the radar unit based on the calculated unambiguous angle.
p4652
aVAbstract\u000aA method for controlling an autonomous vehicle includes obtaining, by one or more processors, information describing a current state of the autonomous vehicle and a goal state of the autonomous vehicle; determining, by the one or more processors, an initial vehicle trajectory from the current state of the autonomous vehicle to the goal state of the autonomous vehicle; determining, by the one or more processors, an optimized vehicle trajectory based the initial trajectory and a velocity profile by applying numerical minimization to minimize a trajectory length value and a lateral acceleration value; and controlling the autonomous vehicle to traverse the optimized vehicle trajectory.
p4653
aVAbstract\u000aA method of controlling a vehicle braking system, includes: (i) detecting whether a collision has occurred; (ii) detecting whether a predetermined condition follows the collision; (iii) determining whether a driver has applied the brakes; and (iv) when a driver has not applied the brakes, autonomously initiating braking.
p4654
aVAbstract\u000aThe proposed method outlines a new control mechanism well-suited for small, unmanned aerial vehicles traversing in a GPS-denied areas. It has the strong advantage of simplifying the interface, so that even an untrained operator can handle the difficult, dynamic problems encountered in closed quarters. The proposed system seamlessly integrates point-and-click control with way-point navigation, in an intuitive interface. An additional advantage of the proposed system is that it adds minimal hardware to the payload of the UAV, and can possibly, strongly diminish the bandwidth and delay effects of the communication channel.
p4655
aVAbstract\u000aSystems, vehicles, and methods for controlling an application of a plurality of trailer brakes are disclosed. A system for controlling an application of a plurality of trailer brakes includes a processor, a memory module communicatively coupled to the processor, a trailer brake output circuit operatively coupled to the plurality of trailer brakes and communicatively coupled to the processor, a cornering attitude input communicatively coupled to the processor, and machine readable instructions stored in the memory module. When executed by the processor, the machine readable instructions cause the system to receive a cornering attitude signal from the cornering attitude input, determine when an understeer cornering attitude exists based on the received cornering attitude signal, and prevent the application of the plurality of trailer brakes by the trailer brake output circuit when the understeer cornering attitude is determined to exist.
p4656
aVAbstract\u000aA vehicle includes a passenger compartment and a bench seat located in the passenger compartment. The bench seat has a bottom portion and a back portion and is configured to move from a front-facing position to a rear-facing position by moving the back portion toward a front of the passenger compartment for when the vehicle is operating in an autonomous mode.
p4657
aVAbstract\u000aInstructions are provided to a vehicle braking mechanism for autonomous operation of the braking mechanism. At least one first parameter is retrieved for governing control of the braking mechanism. The first parameter is applied to operation of the braking mechanism. Data is collected relating to operation of the vehicle. At least one second parameter is determined for governing control of the braking mechanism.
p4658
aVAbstract\u000aA vehicle behavior control apparatus mounted in a vehicle to control steering of the vehicle. A virtual road outline, which is an outline of a drivable road region where the vehicle will travel, is determined on the basis of detection results from a location sensor. The virtual road outline is reconstructed as a sequence of road segments, such as straight road segments, and right- and left-hand curved road segments. When a current road segment where the vehicle is currently present is a right- or left-hand curved road segment, a subsequent road segment where the vehicle will be present subsequently is tentatively set to a straight road segment until the vehicle reaches the subsequent road segment. The steering angle is controlled so that a virtual-road boundary distance is adapted to a proper distance from the vehicle to a boundary of the virtual road outline situated in front of the vehicle.
p4659
aVAbstract\u000aA control unit for a vehicle is set up to receive environment data from one or more ambient sensors of the vehicle. The control unit is additionally set up to take the environment data as a basis for detecting at least one road user in an environment of the vehicle, and to take the environment data and a driving strategy as a basis for determining whether there is a need for communication between road user and vehicle and what content needs to be communicated in what way. The control unit is set up, when it has been determined that there is a need for communication between road user and vehicle, to prompt one or more acoustic communication devices of the vehicle to generate an acoustic output in order to communicate with the road user.
p4660
aVAbstract\u000aA dual-powered utility vehicle is provided that includes a gasoline engine and an electrical motor. The gasoline engine is configured to drive at least a first wheel at first revolutions per minute. The electrical motor is configured to drive at least a second wheel at second revolutions per minute. A throttle is configured to affect the gasoline engine and the electric motor separately, or both the gasoline engine and electric motor simultaneously.
p4661
aVAbstract\u000aArrangements related to operating an autonomous vehicle in view-obstructed environments are described. At least a portion of an external environment of the autonomous vehicle can be sensed to detect one or more objects located therein. An occupant viewable area of the external environment can be determined. It can be determined whether one or more of the detected one or more objects is located outside of the determined occupant viewable area. Responsive to determining that a detected object is located outside of the determined occupant viewable area, one or more actions can be taken. For instance, the action can include presenting an alert within the autonomous vehicle. Alternatively or in addition, the action can include causing a current driving action of the autonomous vehicle to be modified.
p4662
aVAbstract\u000aPerforming a geophysical survey beneath a surface obstruction, or around a fixed object or formation. At least some of the example embodiments include: programming a towing pattern into an autonomous underwater vehicle; and towing a sensor streamer under the surface obstruction, or around the fixed object or formation by the autonomous underwater vehicle. In some of the embodiments, the sensor streamer comprises a distributed sensor in the form of an optical fiber. In some of the embodiments, the optical fiber is encapsulated in an outer covering of resilient material, the resilient material exposed to the water during the towing.
p4663
aVAbstract\u000aA method is provided for determining a maximum speed limit for a reversing vehicle combination that includes a towing vehicle and at least one towed trailer. The method includes determining a manoeuvre that is to be performed by the vehicle combination, simulating the complete manoeuvre in advance by using a control algorithm and a state space model, thereby obtaining the steering behaviour of the vehicle combination during the manoeuvre, and calculating the maximum speed limit for the vehicle combination during the manoeuvre by using at least one predefined limiting condition. A maximum speed limit for a reverse assistance function can be estimated in advance, which allows for a faster and more efficient reversing of the vehicle combination, and at the same time allows for an improved comfort for the driver.
p4664
aVAbstract\u000aA method and apparatus for synchronously updated vehicle transportation network information for autonomous vehicle routing and navigation are provided. Synchronously updated vehicle transportation network information for autonomous vehicle routing and navigation may include an autonomous vehicle identifying vehicle transportation network information, identifying an origin, identifying a destination, generating a plurality of candidate routes from the origin to the destination based on the vehicle transportation network information, receiving, from an off-vehicle sensor, current vehicle transportation network state information indicating a state of at least a portion of the vehicle transportation network, identifying an optimal route from the plurality of candidate routes based at least in part on the current vehicle transportation network state information, the optimal route having a minimal route cost, and operating the autonomous vehicle to travel from the origin to the destination using the optimal route.
p4665
aVAbstract\u000aA vehicle, method, control arrangement, and autonomous drive arrangement are provided. The control arrangement is for controlling an autonomous drive arrangement in a host vehicle including an autonomous drive arrangement configured to control steering and velocity of the host vehicle up to an autonomous drive maximum velocity of the host vehicle, a speed limit determination unit, and a communication unit arranged to receive, from at least one external source, real time preceding vehicle velocity for one or more preceding vehicles. The control arrangement is configured to control the autonomous drive arrangement in dependence on a difference between the autonomous drive maximum velocity and at least one of a speed limit and at least one preceding vehicle velocity.
p4666
aVAbstract\u000aAspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.
p4667
aVAbstract\u000aA vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.
p4668
aVAbstract\u000aAn incident light meter on an autonomous vehicle receives ambient light and outputs an incident light measurement in response the ambient light. One or more image sensors of the autonomous vehicle image the environment of the autonomous vehicle. An exposure setting is generated at least in part on the incident light measurement. The one or more image sensors capture a digital image at the exposure setting.
p4669
aVAbstract\u000aVarious embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include receiving data associated with a sensor measurement of a perceived object, determining a label associated with the perceived object based on an initial calibration, retrieving log file data associated with the label, determining a calibration parameter associated with the sensor measurement based on the retrieved log file data, and storing the calibration parameter in association with a sensor associated with the sensor measurement. Sensors may be calibrated on the fly while the autonomous vehicle is in operation using one or more other sensors and/or fused data from multiple types of sensors.
p4670
aVAbstract\u000aVarious embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include receiving, from a user device, a ride request to transport a user to a destination from an origin location through an autonomous vehicle system service. Based on the origin location associated with the request, an autonomous vehicle system may be selected from a fleet of autonomous vehicles to execute the ride request. The fleet may be managed by the autonomous vehicle system service. The ride request may then be provided to the autonomous vehicle system, and information about the autonomous vehicle system may also be provided to the user device.
p4671
aVAbstract\u000aSystems, apparatus and methods to multiple levels of redundancy in torque steering control and propulsion control of an autonomous vehicle include determining that a powertrain unit of the autonomous vehicle is non-operational and disabling propulsion operation of the non-operational powertrain unit and implementing torque steering operation in another powertrain unit while propelling the autonomous vehicle using other powertrain units that are configured to implement torque steering operation and propulsion operation.
p4672
aVAbstract\u000aA method and apparatus for probabilistic autonomous vehicle routing and navigation are disclosed. Probabilistic autonomous vehicle routing and navigation may include an autonomous vehicle identifying transportation network information, identifying an origin, identifying a destination, generating a plurality of candidate routes from the origin to the destination based on the transportation network information, wherein each route from the plurality of routes indicates a distinct combination of road segments and lanes, generating an action cost probability distribution for each action in each candidate route, generating a route cost probability distribution based at least in part on the action cost probability distribution, identify an optimal route from the plurality of candidate routes based at least in part on the route cost probability distribution, and operate the autonomous vehicle to travel from the origin to the destination using the optimal route.
p4673
aVAbstract\u000aApparatuses, systems, and methods for the deployment of a plurality of autonomous underwater seismic vehicles (AUVs) on or near the seabed based on acoustic communications with an underwater vehicle, such as a remotely operated vehicle. In an embodiment, the underwater vehicle is lowered from a surface vessel along with a subsea station with a plurality of AUVs. The AUVs are configured to acoustically communicate with the underwater vehicle or a second surface vessel for deployment and retrieval operations. The underwater vehicle and/or second surface vessel is configured to instruct the AUVs to leave the subsea station or underwater vehicle and to travel to their intended seabed destination. The underwater vehicle and/or second surface vessel is also configured to selectively instruct the AUVs to leave the seabed and return to a seabed location and/or a subsea station for retrieval.
p4674
aVAbstract\u000aThis application describes an automated driving system and methods. The automated driving system includes a perception system disposed on an autonomous vehicle. The automated driving system can detect, using the perception system, information for an environment proximate to the autonomous vehicle. The information for the environment includes current behavior of an object of interest and traffic density information. The automated driving system can also determine a classifier for the environment based on a prediction of future behavior of the object of interest. Based on the classifier, the automated driving system can identify a transition between vehicle states, the vehicle states being associated with a planned action for the autonomous vehicle. The automated driving system can also send a command to one or more vehicle systems to control the autonomous vehicle to execute the planned action according to the transition.
p4675
aVAbstract\u000aA method for a semi-autonomous driving of a vehicle with a steer-by-wire system having a steering wheel mechanically decoupled from vehicle wheels determines values for the steering angle and the wheels angle tracking a target value of the wheels angle received from a semi-autonomous driving planning (SADP) system. The method determines the values for the steering angle and the wheels angle subject to constraints, including a constraint on a motion of the vehicle wheels, a constraint on a motion of a steering wheel, a constraint on an actuation of the steering wheel and the vehicle wheels, and a constraint on a relative motion of the steering wheel with respect to the motion of the vehicle wheels. The control commands to the column motor and the rack motor are generated according to the values for the steering angle and the wheels angle.
p4676
aVAbstract\u000aA parking system adaptively controlling a vehicle during a parking maneuver using a park assist system, for example an active park assist (APA) or trailer backup assist (TBA). Control of the park assist system based on previous speed profiles at a geographic location where the same park assist system was previously activated. The parking system including an activation system that, based on vehicle speed and geographic location, activates the park assist system when preconditions for park assist system operation are met. The activation system may cooperate with the park assist system based on default or previously stored drive history profiles associated with the current geographic location.
p4677
aVAbstract\u000aA steering system for an autonomous vehicle includes a steering mechanism having a pinion gear and a rack, the steering mechanism being configured to translate rotation of the pinion gear into movement of the rack which is configured to affect the position of a steer tire of the autonomous vehicle, thereby affecting the lateral position of the autonomous vehicle; a steering wheel which provides a mechanical input to the pinion gear from an operator of the autonomous vehicle; a steering actuator which rotates to apply torque to the steering mechanism, thereby inducing movement of the rack which affects the position of the steer tire of the autonomous vehicle; and a variable coupling member operatively between the steering actuator and the steering mechanism which is configured to vary the torque that can be transmitted from the steering actuator to the steering mechanism.
p4678
aVAbstract\u000aMethods and systems for implementing steering-based scrub braking are described. A computing device or system assisting in the control of a vehicle may be configured to make a determination to reduce a speed of the vehicle or enhance the stability of a vehicle that is traveling in a given direction. The computing device may provide instructions to turn a pair of wheels or any combination of wheels of the vehicle in a direction away from parallel to the given direction in which the vehicle is traveling and in opposite directions to each other so as to reduce the speed of the vehicle. In an example, the computing device may estimate a range to execute speed reduction of the vehicle.
p4679
aVAbstract\u000aA driving assist device 1 includes: an information acquisition unit 20 that detects a driving operation of a driver for the vehicle; a driving skill evaluation unit 24 that evaluates a driving skill of the driver on the basis of a history of the driving operation of the driver; and a driving assist control unit 28 that performs the driving assist control for the vehicle on the basis of the traveling state of the vehicle and the target traveling state. When the information acquisition unit 20 detects the driving operation of the driver during the driving assist control, the driving assist control unit 28 limits the amount of driving assist control for the vehicle according to the driving skill of the driver evaluated and reflects the driving operation amount of the driver in traveling control for the vehicle.
p4680
aVAbstract\u000aMethods and devices for controlling a vehicle in an autonomous mode are disclosed. In one aspect, an example method is disclosed that includes obtaining, by a computer system, lane information that provides an estimated location of a lane of a road on which a vehicle is travelling, where the computer system is configured to control the vehicle in an autonomous mode. The example method further includes determining, by the computer system, that the lane information has become unavailable or unreliable and, in response to determining that the lane information has become unavailable or unreliable, the computer system selecting a predetermined trajectory from a plurality of predetermined trajectories and controlling the vehicle to travel along the selected predetermined trajectory.
p4681
aVAbstract\u000aDisclosed herein is an autonomous solar panel for use in winter conditions. The panel includes at least one energy transfer member associated with the solar panel. A sensor is in communication with the energy transfer member. A power supply is connected to the energy transfer member. A network interconnects the energy transfer member, the sensor, and the power supply, and is configured so that when the sensor senses an accumulation of winter precipitation on the solar panel, a portion of stored power in the power supply activates the energy transfer member and the winter precipitation is removed from the solar panel.
p4682
aVAbstract\u000aAspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.
p4683
aVAbstract\u000aA system for controlling an autonomous vehicle having cameras for obtaining image data of neighboring vehicles in a proximity of the autonomous vehicle and for identifying physical characteristics of the neighboring vehicles, including makes, models, and trims of neighboring vehicles, colors of the neighboring vehicles, and exposed cargo being carried by the neighboring vehicles. The system maps the identified physical characteristics into predicted potential on-road events in the proximity of the autonomous vehicle, and makes driving decisions based on the predicted potential on-road event.
p4684
aVAbstract\u000aArrangements related to mitigating risk for autonomous vehicles in occupant view and vehicle sensor obstructed environments are presented. An information critical area in an external environment can be identified relative to a future planned driving maneuver of the autonomous vehicle. If at least a portion of the information critical area is outside of a determined occupant viewable area and a determined sensor detection area due to the presence of an obstructing object, it can be determined whether the obstructing object is moving favorably relative to the future planned driving maneuver. If the obstructing object is moving favorably relative to the future planned driving maneuver, the autonomous vehicle can be caused to implement the future planned driving maneuver while moving relative to the obstructing object so as to be shielded by the detected obstructing object from any potential objects located in the at least a portion of the information critical area.
p4685
aVAbstract\u000aAspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.
p4686
aVAbstract\u000aMethods, systems, and vehicles are provided for facilitating control of steering in autonomous vehicles. In accordance with one embodiment, an autonomous vehicle includes one or more wheel sensors and a processor. The one or more sensors are configured to obtain sensor data pertaining to a side slip of the autonomous vehicle. A dual mandate of desired path tracking & stability is achieved by using a combination of two linear controllers. The first controlled facilitates tracking whereas the second controller facilitates vehicle stability. When the stability event occurs a gradual shift towards the second controller occurs and with recovery from stability event gradual shift towards the first controller. Mimicking of driver behavior by changing the desired trajectory and dynamic control gain adaptation are also added.
p4687
aVAbstract\u000aA method for operating a motor vehicle when the driver thereof needs to accomplish a series of tasks (such as delivery and/or pick-up of items) along a route that each require the driver to park the motor vehicle, to leave it and to cover certain distances on foot. The motor vehicle is able to operate both under the control of a human driver aboard the motor vehicle or autonomously without driver intervention. When the driver parks the motor vehicle for the purpose of task accomplishment, an electronic plan of the tasks is checked to determine whether it is more efficient for task accomplishment if the driver returns to the motor vehicle at the first parking location or if the vehicle drives autonomously to a next stopping point situated in the direction of travel and the human driver walks to meet it at the next stopping point.
p4688
aVAbstract\u000aHuman driving performance can be assessed using an autonomous vehicle. An autonomous vehicle can have a manual operational mode and one or more autonomous operational modes. While the vehicle is operating in the manual operational mode, driving data relating to a manual driving maneuver can be acquired. The acquired driving data can be evaluated relative to a driving scene model to determine whether the manual driving maneuver is acceptable or unacceptable based on the acquired driving data. Responsive to determining that the manual driving maneuver is unacceptable, feedback can be provided to a user. In some instances, the feedback can be active feedback or passive feedback. In some instance, the user can be the human driver of the vehicle, or some other person related to the driver in some manner.
p4689
aVAbstract\u000aA destination request may specify a destination location for an autonomous vehicle identified by a vehicle identifier. The request may be for uniqueness of a timestamp of the destination request. An encrypted payload of the request may be decrypted to identify the destination location using a long key associated with the vehicle identifier and indexed to a key offset determined using the timestamp. A driving command may be sent to the autonomous vehicle specifying the destination location.
p4690
aVAbstract\u000aThe invention relates to a device for controlling the braking and/or steering and/or acceleration in a motor vehicle, wherein the device has a number of different sensor components, two diverse sensor fusion components, a man/machine interface component and a preferably intelligent actuator controller component, wherein each of these components constitutes a fault-containment unit and has a TTEthernet communications interface, and wherein all components are connected to a central TTEthernet message distribution unit, and wherein the components communicate with one another exclusively with use of standardised Ethernet messages, and wherein a diagnosis unit for time-correct monitoring of the exchanged messages can be connected to the TTEthernet message distribution unit.
p4691
aVAbstract\u000aAn autonomous vehicle control system includes a sensing system, a remote vehicle determination system and a controller. The sensing system is disposed on a host vehicle and is configured to sense a visual condition of a driver of the host vehicle. The remote vehicle determination system is disposed on the host vehicle, and is configured to determine a position of a remote vehicle in an area adjacent the host vehicle. The controller is configured to control the autonomous vehicle control system to move the host vehicle relative to a lane marker based on the visual condition and the position of a remote vehicle.
p4692
aVAbstract\u000aSystems and methods for calibrating sensors for an autonomous vehicle are disclosed. A calibration guide disposed on the vehicle can indicate to a user the correct location for a calibration object to be placed for a calibration procedure. In one implementation, a laser guide can project an image indicating the correct location and orientation for the calibration object. In another implementation, an extendible arm disposed on the vehicle can suspend the calibration object at the correct location and orientation. In another implementation, an autonomous robot carrying the calibration object can autonomously bring the calibration object to the correct location. The calibration guide can be unobtrusively stored within the vehicle when not in use.
p4693
aVAbstract\u000aOperations of an autonomous vehicle while waiting to make a turn from a center turn lane are described. In response to determining that the detected object intends on turning through the center turn lane from a transverse direction, it can be determined whether an object turning path for the detected object would impinge upon the autonomous vehicle in the center turn lane. If the object turning path would impinge upon the autonomous vehicle, determining a driving maneuver for the autonomous vehicle that would move the autonomous vehicle to a new position within the center turn lane to allow the autonomous vehicle to make the turn according to an adjusted vehicle turning path while also allowing the detected object to turn through the center turn lane according to an adjusted object turning path without impinging upon the autonomous vehicle. The autonomous vehicle can be caused to implement the determined driving maneuver.
p4694
aVAbstract\u000aThere is provided a method and system for acoustic signature health monitoring of an unmanned autonomous vehicle (UAV). The method positions an acoustic signature health monitoring system proximate to and off-board a UAV to be monitored for mechanical health of one or more sound producing structures. The method obtains and analyzes with the system a baseline acoustic signature for each of the sound producing structures, and transmits each baseline acoustic signature to a data processing system for processing. The method obtains and analyzes one or more subsequent acoustic signatures for each of the sound producing structures, and transmits the one or more subsequent acoustic signatures to the data processing system. The method compares the processed baseline acoustic signature with the one or more processed subsequent acoustic signatures for the sound producing structures, in order to detect any change in the processed baseline acoustic signature over time.
p4695
aVAbstract\u000aAn onboard computing device of autonomous vehicle interacts with computers utilized by one or more merchants to enable users to pre-purchase items from the one or more merchants while en route to a destination. Merchant computing devices may employ dynamic promotions to incent the user to prep-purchase items and to reroute to a destination of the respective merchant. Once a user pre-purchases an item from a merchant, the merchant may prepare the item for the user's arrival by, for example, prepackaging the item, or manufacturing or assembling the item, while the customer is en route (i.e., before the user's autonomous vehicle arrives at the destination). The merchant computing device may send a pre-purchase confirmation to the onboard computing device of the user, which may indicate where the user's autonomous vehicle should park and/or where the pre-purchased items are being held for pick up.
p4696
aVAbstract\u000aVarious manners of changing travel lanes for an autonomous vehicle are described. A target gap between a pair of neighboring vehicles located in a travel lane that is adjacent to the current travel lane of the autonomous vehicle can be identified. It can be determined whether the size of the first target gap is acceptable or unacceptable. Responsive to determining that the size of the first target gap is unacceptable, an alternative lane changing maneuver for the autonomous vehicle can be determined. The autonomous vehicle can be caused to implement the alternative lane changing maneuver.
p4697
aVAbstract\u000aA method of controlling an illumination system for an autonomous vehicle is provided. The method includes: storing, in a memory, a plurality of lighting pattern definitions for controlling the illumination system; receiving, at a processor connected to the memory and the illumination system, state data defining a current state of the autonomous vehicle; at the processor, determining whether each of a plurality of ranked sub-states is active in the autonomous vehicle, based on the state data; at the processor, selecting one of the lighting pattern definitions corresponding to the highest ranked sub-state determined to be active in the autonomous vehicle; and controlling the illumination system according to the selected lighting pattern definition.
p4698
aVAbstract\u000aAn autonomous vehicle may operate in an environment in which there is an unexpected dynamic object. The autonomous vehicle can detect the dynamic object. The dynamic object can have an associated movement. The movement of the dynamic object can be tracked. The movement of the dynamic object can be classified as being one ballistic or non-ballistic. It can be determined whether the dynamic object is on a collision course with the autonomous vehicle. Responsive to determining that the dynamic object is on a collision course with the autonomous vehicle, a driving maneuver for the autonomous vehicle can be determined. The driving maneuver can be based at least in part on the movement of the dynamic object. The autonomous vehicle can be caused to implement the determined driving maneuver.
p4699
aVAbstract\u000aA subject tracking system to track a subject is provided. The subject tracking system may include a sensor system, a transmitting unit and a processor. The transmitting unit may be configured to be located with the subject during use and comprising at least one first dedicated high frequency oscillator. The sensor system may include at least one second dedicated high frequency oscillator to continually synchronize the transmitting unit and the sensor system. The processor may continually determine changes in the distance between the subject and the subject tracking system so that a distance between the subject and the autonomous vehicle can be maintained.
p4700
aVAbstract\u000aSystems and method are provided for charging batteries of a vehicle. In one embodiment, a method includes: determining, by a processor, a state of charge of batteries of the vehicle; autonomously controlling, by a processor, the vehicle to a slot of a charging station based on the state of charge; and communicating, by a processor, with the charging station to coordinate autonomous charging of the batteries of the vehicle.
p4701
aVAbstract\u000aThe technology relates to facilitating transportation services between a user and a vehicle having an autonomous driving mode. For instance, one or more server computing devices having one or more processors may information identifying the current location of the vehicle. The one or more server computing devices may determine that the user is likely to want to take a trip to a particular destination based on prior location history for the user. The one or more server computing devices may dispatch the vehicle to cause the vehicle to travel in the autonomous driving mode towards a location of the user. In addition, after dispatching, the one or more server computing devices sending a notification to a client computing device associated with the user indicating that the vehicle is currently available to take the passenger to the particular destination.
p4702
aVAbstract\u000aA system and method is provided for the establishment of a fleet of networked unmanned vehicles. The system provides at least one vehicle control device configured to interface with a third party unmanned vehicle and establish communications with other unmanned vehicles and with remote control stations. A plurality of vehicle control devices may be used with a plurality of remote control stations to establish a networked fleet of unmanned vehicles. Communication between the networked vehicles may include control information, sensor information, and mission information.
p4703
aVAbstract\u000aA system for operating a vehicle is disclosed. The vehicle is operated in a first driving state corresponding to a first set of logic for operating the vehicle, the first set of logic including logic for performing a first action at the vehicle in response to a determination that a first condition exists in the surroundings of the vehicle. That state change criteria for transitioning from the first driving state to a second driving state are satisfied is determined. In response to the determination, the vehicle is operated in the second driving state corresponding to a second set of logic, different from the first set of logic, for operating the vehicle, the second set of logic including logic for performing a second action, different from the first action, at the vehicle in response to a determination that the first condition exists in the surroundings of the vehicle.
p4704
aVAbstract\u000aAn unmanned vehicle system, having at least one autonomous ground vehicle (A-GV) and at least one remote controlled aerial vehicle (RC-AV). The A-GV autonomously navigates across the ground, and on-board perception sensors, whose field of view that contains at least a portion of the ground ahead of the direction of travel of the ground vehicle as well as the RC-GV. The RC-AV flies in response to commands received from the control system of the A-GV. The RC-AV has on-board in-sky perception sensors having a field of view that contains at least a portion of the ground path to be followed by the ground vehicle. The control system of the A-GV locate the aerial vehicle, receives perception data from the on-ground perception sensors and the in-sky perception sensors, and uses combined perception data to determine a ground path for itself and for the RC-AV.
p4705
aVAbstract\u000aSystems for controlling autonomous vehicles are disclosed. Using one or more location detection resources, the system can receive vehicle data from an autonomous vehicle as the autonomous vehicle progresses towards a pickup location of a requesting user and receive requester data from a mobile computing device of the requester. The system can determine when the autonomous vehicle and the requester are at or within a threshold distance of the pickup location. Subsequently, the system can instruct the autonomous vehicle to perform one or more non-driving operations to facilitate use of the autonomous vehicle by the requester.
p4706
aVAbstract\u000aA system, method, and computer program product for determining lane information in a road segment to drive a first vehicle to minimize travel time. According to an embodiment, navigation data of the first vehicle and at least one other vehicle in a road segment is sent to a computer server system via their respective clique leaders through a communication network. The lane information may include whether a change of lane is required, a lane to avoid, an optimum lane, and rank order of drivable lanes according to increasing order of travel time for the first vehicle to minimize travel time. The determined lane information is sent to the appropriate user device through its clique leader. The user device presents the lane information to a human driver and/or autonomous vehicle driving system of the first vehicle appropriately.
p4707
aVAbstract\u000aThe present invention relates to a method for assistance in the parking of a vehicle from a roadway into a free parking space, by one or more maneuvers of the slot parking type, comprising the following steps:\u000adetermination of the length of the free parking space,\u000adetermination of an optimum path to be followed by the movement of the vehicle by successive arcs of a circle,\u000acharacterized in that it comprises a step for determining the number of maneuvers Nm needed in order to bring the vehicle into the parking space and in that these maneuvers are implemented when this number of maneuvers Nm is less than a threshold S2.
p4708
aVAbstract\u000aAt least one datum is received relating to a condition of a window in the vehicle. A determination is made to change a parameter based on the at least one datum, the parameter governing clearing the window. An instruction is provided to initiate or change operation of a vehicle component based on the change of the parameter.
p4709
aVAbstract\u000aA method determines iteratively a motion of the vehicle from an initial location and a target location. An iteration of the method determines a location between the initial location and the target location that satisfies spatial constraints on locations of the vehicle and determines state transitions of the vehicle moved to the location from a set of neighboring locations determined during previous iterations. The method selects a neighboring location resulting in an optimal state transition of the vehicle and updates a graph of state transitions of the vehicle determined during previous iterations with the optimal state transition. The motion of the vehicle is determined a sequence of state transitions connecting the initial location with the target location and the vehicle is controlled according to the determined motion.
p4710
aVAbstract\u000aAn autonomous vehicle can transition between operational modes. The readiness of a vehicle driver for a transition can be assessed, particularly when transitioning from a first operational mode to a second operational mode that has a greater degree of manual involvement than the first operational mode. It can be determined whether an operational mode transition event has occurred while the vehicle is operating in the first operational mode. Responsive to determining that an operational mode transition event has occurred, an audial sample from a vehicle driver can be collected. It can be determined whether the vehicle driver is ready or non-ready to provide the greater degree of manual involvement for the second operational mode based on the collected audial sample.
p4711
aVAbstract\u000aA vehicle, a vehicle parking assist system, and a parking method, is provided. A powertrain and a steering system may be operated to guide the vehicle into a parking location to complete a drive cycle based on a default tire radius, a tire angular velocity acquired during a drive cycle in response to a steering angle of the steering system exceeding a threshold value, and wheel and GPS vehicle speeds for the drive cycle.
p4712
aVAbstract\u000aVarious embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. More specifically, systems, devices, and methods are configured to simulate navigation of autonomous vehicles in various simulated environments. In particular, a method may include receiving data representing characteristics of a dynamic object, calculating a classification of a dynamic object to identify a classified dynamic object, identifying data representing dynamic-related characteristics associated with the classified dynamic object, forming a data model of the classified dynamic object, simulating a predicted range of motion of the classified dynamic object in a simulated environment to form a simulated dynamic object, and simulating a predicted response of a data representation of a simulated autonomous vehicle.
p4713
aVAbstract\u000aAn automated driving system for an autonomous vehicle may include a perception system and a computing device for detecting and tracking a location of an object within an obstructed viewing region blocked from view of sensors associated with the perception system. The computing device and perception system may identify an obstructed viewing region and detect an external imaging assist device located within a sensor field of the perception system. The imaging assist device is capable of transmitting images of the obstructed viewing region to the perception system. The computing device analyzes the images received from the imaging assist device for purposes of detecting an object within the obstructed viewing region and tracking its location relative to the autonomous vehicle. The computing device may transmit a command to an autonomous vehicle system to implement an autonomous vehicle maneuver based at least in part on the tracked location of the hidden object.
p4714
aVAbstract\u000aSystems and methods for performing automated movement of a vehicle. One method includes obtaining a current position of the vehicle including a first location point and a second location point, transmitting the first location point and the second location point to a server over at least one network, and receiving from the server an altitude for the first location point and an altitude for the second location point. The method also includes determining a slope of a driving surface of the vehicle based on the altitude of the first location point, the altitude of the second location point, and a longitudinal distance between the first location point and the second location point. In addition, the method includes determining a vehicle load based on the slope and determining a braking force for automatically stopping the vehicle at a target position based on the slope and the vehicle load.
p4715
aVAbstract\u000aAspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.
p4716
aVAbstract\u000aA system and strategy for reducing rapid steering wheel movement at the end of an autopark maneuver. The strategy includes maintaining or ramping-out power-steering motor torque to reduce steering wheel movement that may occur due to tire windup that has occurred up to that point in the autopark maneuver. The strategy may include the stopping of an autopark maneuver at any time during the maneuver, or functioning at the end of an autopark maneuver. The autopark event may be a park-out maneuver.
p4717
aVAbstract\u000aA method for assisting the reversal of an articulated vehicle includes recording a predefined number of positions for a first articulated vehicle for a specified path, recording the articulation angle of each articulation joint of the articulated vehicle at the predefined number of positions, recording the heading for the first articulated vehicle at the predefined number of positions, saving the recorded values for the specified path in a memory, calculating the swept area of the first vehicle for the specified path by using the recorded values and size information of the articulated vehicle, and using the swept area to control the steering of the articulated vehicle when reversing the articulated vehicle along the specified path, such that the articulated vehicle does not extend outwards of the swept area during the reversal. The area covered by the articulated vehicle when travelling forwards can be used to control the steering of the vehicle when reversing along the same path, such that the articulated vehicle substantially does not extend outward the swept area when reversing. In this way, an assisted reversing functionality can be used, which allows for a faster and more efficient reversing of the articulated vehicle, and at the same time allows for an improved comfort for the driver.
p4718
aVAbstract\u000aA method for providing a warning to a vehicle driver when a lane keeping and/or lane centering system will be unable to negotiate a tight curve at the present vehicle speed prior to the vehicle reaching the curve. The method obtains lane information at a predetermined number of sample times in the future and generates a desired path for the vehicle. The method also obtains vehicle motion information and determines steering angles for the vehicle for the vehicle to track the desired path based on the desired path and vehicle motion. The method determines the steering torque for each of the steering angles and determines whether any of the steering torques exceed the predetermine torque limit. The method issues an alert if any of the steering torques do exceed the predetermined torque limit prior to the lane keeping system being required to provide that torque to steer the vehicle.
p4719
aVAbstract\u000aThe invention relates to collecting different images using different camera parameters. As an example, a single camera may capture two different types of images: a dark exposure for light emitting objects and a normal exposure for passive objects. The camera may first capture an image. This first image may be processed to determine the ideal camera settings for capturing the average intensity of the environment. Fixed offset values may be added to these ideal camera settings and the dark exposure may be captured. The ideal camera settings are then used to capture a normal exposure, which in turn may be processed to determine new ideal camera settings. Again, the fixed offset values may be added to the new ideal camera settings and a dark exposure is captured. This process may repeat continuously and periodically, and the resulting images may be processed to identify emissive and passive objects.
p4720
aVAbstract\u000aPositioning autonomous vehicles based on field of view, including: identifying, by a vehicle management module, one or more critical sight lines for a subject vehicle, each critical sight line representing a boundary of an area of space surrounding the subject vehicle; determining, by the vehicle management module, physical location information for one or more surrounding vehicles; determining, by the vehicle management module in dependence upon the physical location information for one or more surrounding vehicles, whether one or more surrounding vehicles are located within the area of space surrounding the subject vehicle; and responsive to determining that one or more surrounding vehicles are located within the area of space surrounding the subject vehicle, altering a location of the subject vehicle relative to at least one of the surrounding vehicles.
p4721
aVAbstract\u000aDevices such as vehicles, remote sensors, and so forth consume energy during operation. Described herein are systems, devices, and methods for transferring energy from an uncrewed autonomous vehicle to a vehicle such as a car. The uncrewed autonomous vehicle may locate the vehicle at a rendezvous location, and connect with the vehicle while the vehicle moves. Once the uncrewed autonomous vehicle connects to the vehicle, the uncrewed autonomous vehicle may transfer the energy to the vehicle.
p4722
aVAbstract\u000aA vehicle configured to operate in an autonomous mode may operate a sensor to determine an environment of the vehicle. The sensor may be configured to obtain sensor data of a sensed portion of the environment. The sensed portion may be defined by a sensor parameter. Based on the environment of the vehicle, the vehicle may select at least one parameter value for the at least one sensor parameter such that the sensed portion of the environment corresponds to a region of interest. The vehicle may operate the sensor, using the selected at least one parameter value for the at least one sensor parameter, to obtain sensor data of the region of interest, and control the vehicle in the autonomous mode based on the sensor data of the region of interest.
p4723
aVAbstract\u000aAn imaging system of a vehicle is provided herein. A camera is configured to capture images of a rear vehicle scene containing a trailer attached to the vehicle. A device is configured to remove contaminants on a lens of the camera. A controller is configured to analyze the captured images and activate the device based on the image quality of the captured images and a motion of the trailer relative to the vehicle.
p4724
aVAbstract\u000aA system to monitor vehicle accidents using a network of aerial based monitoring systems, terrestrial based monitoring systems and in-vehicle monitoring systems is described. Aerial vehicles used for this surveillance include manned and unmanned aircraft, satellites and lighter than air craft. Aerial vehicles can also be deployed from vehicles. The deployment is triggered by sensors registering a pattern in the data that is indicative of an accident that has happened or an accident about to happen.
p4725
aVAbstract\u000aSystems and methods relating to the operation of an autonomous vehicle relative to forward objects in an external environment are described. At least a forward portion of the external environment can be sensed to detect an object therein. A size adjustment factor can be determined to predict a laterally innermost point of the detected object relative to the autonomous vehicle. A driving maneuver for the autonomous vehicle can be determined based at least partially on the predicted laterally innermost point of the detected object relative to the autonomous vehicle.
p4726
aVAbstract\u000aA driving support device for a first trailer coupling vehicle including a first trailer and a first towing vehicle includes: a leading vehicle driving status obtaining device for obtaining a driving status of a second trailer coupling vehicle; a first towing vehicle driving status obtaining device for successively obtaining a driving status of the first towing vehicle; a first trailer driving status obtaining device for successively obtaining a driving status of the first trailer; and a support device for supporting a driver of the first trailer coupling vehicle so as to bring the driving status of the first towing vehicle and the driving status of the first trailer closer to the driving status of a second towing vehicle and the driving status of a second trailer, respectively, when the first trailer coupling vehicle changes in direction.
p4727
aVAbstract\u000aIn one embodiment, a method for controlling an actuator for a door of an autonomous vehicle comprises obtaining data pertaining to a current ride of an autonomous vehicle during operation of the autonomous vehicle; identifying, via a processor using the data, whether one or more circumstances are present that would require an adjustment of a baseline instruction for an automatic opening of the door by the autonomous vehicle via the actuator based on instructions provided to the actuator by the processor; determining an adjustment of the baseline instruction when one or more of the circumstances are present; receiving a request to open the door; and, upon receiving the request: providing the baseline instruction for the actuator to open the door, when none of the circumstances are present; and providing an alternate instruction for the actuator, based on the adjustment, when one or more of the circumstances are present.
p4728
aVAbstract\u000aAn automated driving system and methods are disclosed. The automated driving system includes a perception system disposed on an autonomous vehicle. The automated driving system can detect, based on images captured using the perception system, a traffic officer wielding a traffic signal device such as the traffic officer's hand, or a wand, sign, or flag. The automated driving system can also determine whether the traffic officer is directing a traffic signal to the autonomous vehicle with the traffic signal device, and if so, determine whether content of the traffic signal is recognized. If the content of the traffic signal is recognized, the autonomous vehicle can respond in a manner consistent with the content of the traffic signal. If the content of the traffic signal is not recognized, the autonomous vehicle can respond by treating the traffic signal as a stop signal.
p4729
aVAbstract\u000aAspects of the present disclosure relate to a system having a memory, a plurality of self-driving systems for controlling a vehicle, and one or more processors. The processors are configured to receive at least one fallback task in association with a request for a primary task and at least one trigger of each fallback task. Each trigger is a set of conditions that, when satisfied, indicate when a vehicle requires attention for proper operation. The processors are also configured to send instructions to the self-driving systems to execute the primary task and receive status updates from the self-driving systems. The processors are configured to determine that a set of conditions of a trigger is satisfied based on the status updates and send further instructions based on the associated fallback task to the self-driving systems.
p4730
aVAbstract\u000aA backend system can store a network resource map that indicates network coverages areas for a plurality of base stations over a given region. The system can receive a pick-up request from a requesting user seeking transportation from a pick-up location to a destination, and instruct an automated vehicle (AV) to service the pick-up request. The system can further determine a plurality of possible routes from the pick-up location to the destination, and perform an optimization operation to determine an optimal route by utilizing the network resource map. The system can then transmit route data for the optimal route to the selected AV.
p4731
aVAbstract\u000aA system includes a first battery configured to power at least one vehicle subsystem and a second battery configured to power an electric motor to propel a vehicle. A processing device is configured to detect an inadequate power level provided from the first battery to the at least one vehicle subsystem and selectively partition the second battery to power the at least one vehicle subsystem.
p4732
aVAbstract\u000aA method of controlling a differential lock. The method may include determining a target point for disengaging the differential lock and disengaging the differential lock when the vehicle reaches the target point.
p4733
aVAbstract\u000aA system and method for autonomous vehicle driving behavior modification include: receiving passenger driving behavior preferences for setting a driving behavior of an autonomous vehicle; generating driving behaviors controls based on the passenger driving behavior preferences; setting an initial driving behavior of the autonomous vehicle using the driving behavior controls, wherein setting the initial driving behavior comprises providing the driving behavior controls to be implemented by the autonomous vehicle during one or more routes involving the passenger; aggregating vehicle behavior feedback relating to a driving behavior of the autonomous vehicle during the one or more routes; and modifying the driving behavior of the autonomous vehicle based on the vehicle behavior feedback.
p4734
aVAbstract\u000aA method is disclosed for mitigating the risks associated with operating an autonomous or semi-autonomous vehicle by using calculated route traversal values to select less risky travel routes and/or modify vehicle operation. Various approaches to achieving this risk mitigation are presented. A computing device is configured to generate a database of route traversal values. This device may receive a variety of historical route traversal information, real-time vehicle information, and/or route information from one of more data sources and calculate a route traversal value for the associated driving route. Subsequently, the computing device may provide the associated route traversal value to other devices, such as a vehicle navigation device associated with the autonomous or semi-autonomous vehicle. An insurance company may use this information to help determine insurance premiums for autonomous or semi-autonomous vehicles by analyzing and/or mitigating the risk associated with operating those vehicles.
p4735
aVAbstract\u000aAn autonomous self-leveling vehicle is provided that includes a controller and an RF antenna. A platform is attached to articulating legs with joint actuators for leveling or maintaining said platform at a defined angle. A set of wheels are powered by wheel actuators mounted to the distal ends of the articulating legs to provide self-leveling. A system for a self-leveling vehicle includes at least three or more base stations. A vehicle with a platform having articulating legs with joint actuators for leveling or maintaining the platform at a defined angle is provided above and operates with an RF antenna mounted to the vehicle and a controller with a tracking module in the range of the base stations.
p4736
aVAbstract\u000aA method for notifying a third party or a third party device (e.g., a mobile phone or a second vehicle) as to whether a first vehicle is operating in an autonomous mode or a semi-autonomous mode. The method includes receiving, at a first electronic control unit, notification information including whether the first vehicle is operating in the autonomous mode or the semi-autonomous mode and a description of or details about the first vehicle and transmitting from a transmitter of the first vehicle to a receiver of the third party device, the notification information. The method also includes displaying, using a display screen of the third party device, the notification information including whether the first vehicle is operating in the autonomous mode or the semi-autonomous mode and the description of or the details about the first vehicle.
p4737
aVAbstract\u000aA method for transitioning vehicle control includes obtaining a one or more operator vehicle control inputs, analyzing the one or more operator vehicle control inputs to determine operator compliance with one or more autonomous vehicle control inputs that are actively controlling motion of a vehicle, and based on the analysis of the one or more operator vehicle control inputs, allowing an operator to assume manual control of the vehicle when the operator vehicle control inputs match the one or more autonomous vehicle control inputs to within a threshold value.
p4738
aVAbstract\u000aMethod for maintaining active control of an autonomous vehicle can involve confirming the active presence of a human in a semi-autonomous vehicle. The human's active physical control and monitoring of the semi-autonomous vehicle can be verified by detecting that a throttle pedal on the semi-autonomous vehicle is depressed relative to a non-actuated position. The vehicle can then continue semi-autonomously as long as the active physical control and monitoring by the human is confirmed. Once the throttle pedal is found to no longer be depressed, the vehicle can be returned to normal human control.
p4739
aVAbstract\u000aA vehicle system includes an autonomous mode controller that controls a vehicle in an autonomous mode and an entertainment system controller that presents media content while the vehicle is operating in the autonomous mode. The entertainment system actuates a projection screen inside a passenger compartment of the vehicle and enables a projector to project media content onto the projection screen. A method includes determining whether a vehicle is operating in an autonomous mode, and if so, actuating a projection screen inside a passenger compartment of the vehicle and enabling a projector to project media content onto the projection screen.
p4740
aVAbstract\u000aA system includes a computing device programmed to receive a set of goals for a vehicle and identify a travel area for the vehicle for a time period. The computing device receives data indicating predictability of driving conditions of the travel area and determines that the predictability is sufficient to control the vehicle according to model predictive control. Controlling the vehicle includes determining instructions to control actuators related to the steering, propulsion and braking of the vehicle to minimize a cost function. The instructions are implemented for a first time slot. The time period is updated to remove the first time slot at the beginning and include an additional time slot at the end of the predetermined time period. The computing device determines an updated control solution, and implements the updated control solution for a second time slot.
p4741
aVAbstract\u000aAutonomous diesel vehicles and control methods thereof are disclosed. An autonomous vehicle may include a peripheral information collecting unit configured to collect peripheral information necessary for autonomous travelling through an image camera and a laser scanner, a main control unit configured to control the autonomous travelling with reference to the peripheral information collected by the peripheral information collecting unit, a passenger monitoring unit configured to check whether a passenger exists inside the vehicle through a sensor and transmit a result of the check to the main control unit, and an engine control unit configured to control driving of an engine and injection of fuel of an injector according to a control instruction of the main control unit. When the passenger is inside the vehicle, the main control unit performs a pilot injection control, and when the passenger is not inside the vehicle, the main control unit omits the pilot injection control.
p4742
aVAbstract\u000aA MEUV that is able to navigate aerial, aquatic, and terrestrial environments through the use of different mission mobility attachments is disclosed. The attachments allow the MEUV to be deployed from the air or through the water prior to any terrestrial navigation. The mobility attachments can be removed or detached by and from the vehicle during a mission.
p4743
aVAbstract\u000aApparatus and method for employing autonomous air vehicles to perform high risk observation, interaction, and interrogation with individuals. Invention comprises an autonomously controlled air vehicle with mounting and transporting means being attachable to automobiles and other first responder vehicle types. Mounting and transporting means serves also as a base station for commanding autonomous air vehicle and relaying communications to and from autonomous air vehicle to and from remote data base sources. Autonomously controlled air vehicle is equipped with a variety of sensors which air in observation and detection of suspects, their vehicles and possessions therein, and any documentation produced during the interrogation.
p4744
aVAbstract\u000aVehicle operating systems are autonomously operated. A transient in an upcoming path of the vehicle is determined from a comparison of vehicle path data and vehicle status data to a threshold of mechanism first operating system. Operational parameters for one of first and second operating systems are selected according to the comparison. The selected operational parameters are applied to the operation of the one of the first and second operating systems.
p4745
aVAbstract\u000aVarious embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include receiving, at an autonomous vehicle system, a command to control an ambient feature associated with the autonomous vehicle system. One or more courses of action may be determined based on the command. In addition, one or more probabilistic models associated with the one or more courses of action may also be determined. Based on the one or more probabilistic models, confidence levels may also be determined to form a subset of the one or more courses of action. A course of action from the subset of the one or more courses of action may then be executed at the autonomous vehicle system responsive to the command.
p4746
aVAbstract\u000aA passenger comfort system determines a travel time to a pickup location, detects a present cabin environment, determines a target cabin environment, and determines an environment adjustment time to adjust the present cabin environment to the target cabin environment. The passenger comfort system activates at least one vehicle climate control in accordance with the environment adjustment time and the travel time.
p4747
aVAbstract\u000aVarious embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include identifying a location of a user device associated with a user, transmitting a command to an autonomous vehicle system associated with an autonomous vehicle service to transit to the location, and providing information associated with the user device to the autonomous vehicle system, where the information includes configuration data to adapt one or more sub-systems of the autonomous vehicle. Sub-systems of the autonomous vehicle may include interior lighting, ambient sound, road handling, seating configuration, communication synchronization, and temperature control systems.
p4748
aVAbstract\u000aAn automated driving system and methods are disclosed. The automated driving system includes a perception system disposed on an autonomous vehicle. The automated driving system can detect, using the perception system, a neighboring vehicle proximate to an intersection, identify two or more potential paths through the intersection for the neighboring vehicle, determine a path priority for each of the two or more potential paths, and determine a path priority for a planned path through the intersection for the autonomous vehicle. If the path priority of at least one of the potential paths is higher than the path priority of the planned path, the automated driving system can send a command to one or more vehicle systems configured to allow the neighboring vehicle to proceed through the intersection before the autonomous vehicle.
p4749
aVAbstract\u000aA miniature autonomous vehicle for operation on the public roads is disclosed. The small size allows efficiency for small payloads, but produces a danger of being overlooked by other vehicles. The size of the vehicle is less than driver operated vehicles and may be restricted to less than 200 pounds. Sensors determine the vehicles speed and the presence of environmental vehicles and use a processor to calculate the need for additional visibility. A visibility structure and support structure with lights or markers is controlled by the processor. The markers are controlled in their operation or position by the processor on the basis of the sensor data. Extending or raising and retracting or lowering the structure affects the air resistance and stability of the vehicle. The structure can be raised when the vehicle stops or is in traffic and lowered at road speeds in light or absent traffic.
p4750
aVAbstract\u000aA stowing steering column is provided for use with an autonomous vehicle that is capable of traveling at a slower rate of speed and a higher rate of speed, depending on the situation. a high range of travel at a high rate of speed. The slower speed, that of about 20 mm/sec, is the \u201cstandard\u201d speed that is utilized during regular stowage and unstowage of the steering wheel under ordinary conditions. The higher rate of speed is necessary in a situation where a possible impact event is sensed and the steering wheel must be extended back to the original design intent position in case the airbags need to be deployed or the vehicle operator needs to over-ride the system for an evasive maneuver. The slower rate of speed is preferably about 20 mm/sec while the higher rate of speed is preferably about 40 mm/sec.
p4751
aVAbstract\u000aProvided is an autonomous driving vehicle, and an infrastructure for supporting autonomous driving thereof. The autonomous driving vehicle of the present invention receives information obtained by converging sensor information (for example, infrastructure sensor information and traffic information) based on an infrastructure and vehicle sensor information selected by the infrastructure from the infrastructure positioned at the outside. Accordingly, the autonomous driving vehicle of the present invention may overcome a limitation of vehicle-based autonomous driving, thereby improving obstacle avoidance performance, solving inaccuracy of a sensor, and decreasing frequent setting of a path.
p4752
aVAbstract\u000aAspects of the present disclosure relate to a vehicle for maneuvering a passenger to a destination autonomously. The vehicle includes a computing system and a set of user input buttons for communicating requests to stop the vehicle and to initiate a trip to the destination with the computing system The vehicle has no steering wheel and no user inputs for the steering, acceleration, and deceleration of the vehicle other than the set of user input buttons. In order to safely test the vehicle, a removable manual control system may be used. The system may include a housing having an electronic connection to a computing system of the vehicle. The housing includes a steering input configured to allow a passenger to control the direction of the vehicle. The system also includes one or more computing devices configured to receive input from the steering input and send instructions the computing system.
p4753
aVAbstract\u000aThis disclosure relates to a system and method for determining vehicle operator preparedness for vehicles that support both autonomous operation and manual operation. The system includes sensors configured to generate output signals conveying information related to vehicles and their operation. During autonomous vehicle operation, the system gauges the level of responsiveness of an individual vehicle operator through challenges and corresponding responses. Based on the level of responsiveness, a preparedness metric is determined for each vehicle operator individually.
p4754
aVAbstract\u000aSystems and methods disclosed relate to autonomous vehicle technology. A follow vehicle having driving controls for use by humans may be equipped with a wireless transceiver, controller, sensors, and interfaces for use with control systems such that the follow vehicle may be caused to follow the lead vehicle without human interaction with the follow vehicle. The follow vehicle may wirelessly receive information from the lead vehicle regarding position, movement, acceleration or deceleration, steering, or other information relevant to following the lead vehicle. The follow vehicle may include sensors for sensing the position, movement, acceleration, deceleration, steering, or other properties of the lead vehicle. The lead vehicle may be equipped with RF transmitters that provide indicators to the follow vehicle, such that the sensors can more readily sense the lead vehicle. Multiple follow vehicles may be wirelessly linked to form a train that is not mechanically linked.
p4755
aVAbstract\u000aA method for controlling a semi-autonomous vehicle modifies a current path for the vehicle desired by a driver of the vehicle. The current path starts at a current position of the vehicle and ends in a target position of the vehicle and the method modifies the current path while preserving the current position and the target position of the vehicle in the modified path. The method overrides the actions of the driver to control a movement of the vehicle according to the modified path.
p4756
aVAbstract\u000aA method for controlling the position and speed of a vehicle having steered wheels includes, determining an overall path comprising a plurality of points and defining the course of the vehicle between a starting point and an endpoint; determining the current position of the vehicle; if the current position does not correspond to a point on the overall path, generating a local path connecting the current position of the vehicle to a point on the overall path; and generating control signals in order to steer the steered wheels and control the speed of the vehicle so that the vehicle moves along the local path. The control signals are generated by convex optimization of linear matrix inequalities.
p4757
aVAbstract\u000aA system and method for control of the system, with a plurality of autonomous vehicles having intersecting routes, a control, an operational area, and a predefined place with positions provided with a vehicle presence detection device. The method includes detecting the presence of the vehicles in a detection device, and beginning to travel with a first vehicle according to a travel action. The travel action is chosen from travelling of a route through the operational area from a predefined place, and an advancing action within a predefined place from a first detection device to a second detection device which is not yet occupied. Beginning to travel is carried out only if each of the vehicles has been detected as present at one of the predefined places, or, at most one vehicle has the status \u201cnot present at one of the predefined places\u201d if the travel action relates to an advancing action.
p4758
aVAbstract\u000aAn automated driving system is disclosed. The automated driving system includes an elevated perception system disposed above a vehicle and a computing device in communication with the elevated perception system. The computing device includes one or more processors for controlling the operations of the computing device and a memory for storing data and program instructions used by the one or more processors. The one or more processors are configured to execute instructions stored in the memory to detect, based on one or more images captured by the elevated perception system, a traffic condition proximate the vehicle. The one or more processors are further configured to send a command to one or more vehicle systems to implement one or more vehicle maneuvers based on the detected traffic condition. The time to detection of the traffic condition is shorter than is possible using a traditional perception system disposed on the vehicle.
p4759
aVAbstract\u000aThe present invention relates to vehicles, specifically to an improved navigation system. In order to provide a technology, which will permit drivers of vehicles to better predict consumption and to conserve energy, for example energy in the form of electric battery power or fuel, and to extend the vehicle's driving range, a method for optimizing a driving range of a vehicle, the method typically comprising the following steps: a) predicting driving routes based on a determined start and target route points based on a stored road network model; b) providing additional situation related data comprising environmental factors; c) calculating energy consumption of energy stored on board the vehicle for the predicted driving routes based on the situation related data; and d) determining a most economical route with regards to a minimized energy consumption.
p4760
aVAbstract\u000aA vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.
p4761
aVAbstract\u000aA method includes continuously recording, by the autonomous driving safety or driver assistance system, at least one of vehicle-related data and vehicle surroundings-related data, continuously repeatedly deciding, based on the recorded data, whether a driving safety or driver assistance system process is to be autonomously initiated or carried out, and carrying out a checking process, during which sensor data and parameter settings that are necessary for the operation of the driving safety or driver assistance system are checked for the plausibility thereof. The checking process is carried out immediately following a start of travel of the motor vehicle. In a period of time between the start of travel of the motor vehicle and a start of operation of the driving safety or driver assistance system, an auxiliary process for an immediate and safe auxiliary mode of the driving safety or driver assistance system is used during a checking period.
p4762
aVAbstract\u000aAutonomous vehicle safety systems and methods are disclosed, which detect and consider occupant reactions to potential hazards to suggest or incorporate safety procedures. Also disclosed are systems for controlling autonomous vehicles based on occupant sentiment and other occupant data in order to improve the occupant driving experience. The disclosed embodiments may include an occupant monitoring system obtaining occupant data for an occupant of the autonomous vehicle. A learning engine can process occupant data received from the occupant monitoring system to identify one or more suggested driving aspects based on the occupant data. A vehicle interface can communicate the one or more suggested driving aspects to the autonomous vehicle, such as a defensive action that can enhance safety of the occupant(s).
p4763
aVAbstract\u000aSystems and apparatuses for receiving data from a plurality of sensors and using the data, as well as other data, to generate a parking recommendation for an autonomous vehicle and instruct the autonomous vehicle to travel to the recommended parking location are provided. Data may be received from a plurality of sensors within a first autonomous vehicle, as well as from other vehicles and/or structures. Historical parking data associated with the first autonomous vehicle may also be extracted. In some examples, an expected future trip of the first autonomous vehicle may be determined. The system may then evaluate the data to generate a parking recommendation for the first autonomous vehicle. The system may generate and transmit instructions for traveling from a current location to the recommended parking location and may cause the first autonomous vehicle to travel to the recommended parking location.
p4764
aVAbstract\u000aA method for parking a vehicle enables a driver to park a vehicle easily and quickly by using a parking assistant system. Based on the distance from the vehicle to an adjacent vehicle detected or calculated by the parking assistant system, and the virtual parking path calculated based on the virtual parking position selected by the target parking frame and the specification of the vehicle, the only thing that the driver needs to do during parking, simply involves turning the steering wheel to the extreme left, right and to the center, and driving the vehicle forward and backward, therefore, the parking operation is very simple and easy.
p4765
aVAbstract\u000aA vehicle determines a traction value for a surface of a road segment, and associates the traction value with a location of the surface. The vehicle stores the traction value and location as part of a traction map.
p4766
aVAbstract\u000aSignals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.
p4767
aVAbstract\u000aA trailer backup assist system, according to one embodiment, provides a sensor that senses a hitch angle between a trailer and a vehicle. The trailer backup assist system also provides a selection device for selecting a longitudinal direction of the trailer or the vehicle in a static orientation. Further, the trailer backup assist system provides a controller that generates a steering command to the vehicle when reversing based on the hitch angle to guide the trailer in the selected longitudinal direction. The controller determines a kinematic relationship of the trailer and the vehicle based on a length of the trailer and a wheelbase of the vehicle, whereby the steering command is generated based on the kinematic relationship.
p4768
aVAbstract\u000aSystems and methods are provided for remotely assisting an autonomous vehicle. The method includes: aggregating sensor data from the autonomous vehicle; identifying an assistance-desired scenario; generating an assistance request based on the sensor data; transmitting the assistance request to a remote assistance interface; and receiving and processing a response to the assistance request. The remote assistance interface includes a remote assistance interface that is used in generating the response to the assistance request.
p4769
aVAbstract\u000aA method controls a motion of a vehicle using a model of the motion of the vehicle that includes an uncertainty. The method samples a control space of possible control inputs to the model of the motion of the vehicle to produce a set of sampled control inputs and determines a probability of each sampled control input to move the vehicle into state satisfying constraints on the motion of the vehicle. The method determines, using the probabilities of the sampled control inputs, a control input having the probability to move the vehicle in the state above a threshold. The control input is mapped to a control command to at least one actuator of the vehicle to control the motion of the vehicle.
p4770
aVAbstract\u000aSystems, apparatus and methods implemented in algorithms, software, firmware, logic, or circuitry may be configured to process data and sensory input to determine whether an object external to an autonomous vehicle (e.g., another vehicle, a pedestrian, a bicyclist, etc.) may be a potential collision threat to the autonomous vehicle. The autonomous vehicle may include a light emitter positioned external to a surface of the autonomous vehicle and being configured to implement a visual alert by emitting light from the light emitter. Data representing a light pattern may be received by the light emitter and the light emitted by the display may be indicative of the light pattern. The light pattern may be selected to gain the attention of the object (e.g., a pedestrian, a driver of a car, a bicyclists, etc.) in order to avoid the potential collision or to alert the object to the presence of the autonomous vehicle.
p4771
aVAbstract\u000aThe invention concerns a towable road motor vehicle (20) comprising: \u2014at least three wheels (42, 44), capable of driving the motor vehicle on a level road (22), distributed between two front and rear wheel trains of the motor vehicle; \u2014a chassis, comprising an articulation device, interposed between front and rear portions of the chassis and enabling the front portion to pivot, relative to the rear portion, in such a way as to modify an articulation angle of the vehicle; \u2014front (34) and rear (36) hitches, respectively positioned at the front and rear of the motor vehicle. The motor vehicle further comprises a steering device (32), capable of modifying the steering angle of each wheel of the front train in response to a command by a driver of the vehicle, said steering device being capable of being actuated independently of the articulation device.
p4772
aVAbstract\u000aAn object detection system for an autonomous vehicle processes sensor data, including one or more images, obtained for a road segment on which the autonomous vehicle is being driven. The object detection system compares the images to three-dimensional (3D) environment data for the road segment to determine pixels in the images that correspond to objects not previously identified in the 3D environment data. The object detection system then analyzes the pixels to classify the objects not previously identified in the 3D environment data.
p4773
aVAbstract\u000aIn one embodiment, a utility vehicle includes a plurality of ground-engaging members configured to contact a ground surface, and a powertrain assembly operably coupled to the ground-engaging members. The utility vehicle also includes a frame supported by the ground-engaging members and extending along a longitudinal axis of the utility vehicle. The utility vehicle further includes a tunnel member coupled to the frame and extending along the longitudinal axis. The tunnel member is positioned at a first height from the ground surface. Additionally, the utility vehicle includes a cargo portion supported by the frame and positioned generally rearward of the tunnel member. The cargo portion has a cargo surface substantially aligned with the tunnel member and positioned at a second height from the ground surface. The first height is approximately equal to the second height.
p4774
aVAbstract\u000aA method for operating a shock-absorber system with shock-absorber devices, in particular switching shock-absorber devices, wherein discretely selectable shock-absorber characteristic curves are provided. The method determines a driving behavior of the driver and/or of the motor vehicle on the basis of one or more driving state data items and/or one or more operating variables and, in automatic mode, automatically sets a shock-absorbing behavior of the shock-absorber system by selecting one of the selectable shock-absorber characteristic curves of the shock-absorber devices as a function of the determined driving behavior.
p4775
aVAbstract\u000aMethods and systems for steering-based oscillatory braking are described herein. A method may involve making a determination, by a computing device, to reduce a speed of a vehicle. The vehicle may include a pair of wheels. The method may further involve providing instructions to turn the pair of wheels of the vehicle in an oscillatory manner, such that each wheel of the pair of wheels is turned in substantially the same direction and turning of the pair of wheels oscillates each wheel of the pair of wheels between given directions about a direction of travel of the vehicle so as to reduce the speed of the vehicle.
p4776
aVAbstract\u000aAn autonomous driving vehicle, an autonomous driving management apparatus, and a method of controlling the same. The autonomous driving vehicle includes: a wireless communication unit configured to receive position information about the vehicle; a storage unit configured to store an electronic map; an input unit configured to receive a destination; a driving unit configured to adjust a travelling speed and a travelling direction; and a controller configured to search for a path from a point corresponding to the position information to a point corresponding to the destination in the electronic map, and control the vehicle to travel the approved section through the driving unit when receiving an approval of an occupation right for one or more sections included in the path through the wireless communication unit.
p4777
aVAbstract\u000aVarious embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include monitoring a fleet of vehicles, at least one of which is configured to autonomously transit from a first geographic region to a second geographic region, detecting data indicating an event associated with the vehicle having a calculated confidence level, receiving data representing a subset of candidate trajectories responsive to detecting the event, which is associated with a planned path for the vehicle, identifying guidance data to select from one or more of the candidate trajectories as a guided trajectory, receiving data representing a selection of a candidate trajectory, and transmitting the selection of the candidate trajectory as of the guided trajectory to the vehicle.
p4778
aVAbstract\u000aSystems and method are provided for controlling a vehicle. In one embodiment, a method includes: selecting, by a controller onboard the vehicle, first data for a region from a first device onboard the vehicle based on a relationship between a time associated with the first data and a frequency associated with a second device, obtaining, by the controller, second data from the second device, the second data corresponding to the region, correlating, by the controller, the first data and the second data, and determining, by the controller, a command for operating one or more actuators onboard the vehicle in a manner that is influenced by the correlation between the first data and the second data.
p4779
aVAbstract\u000aAccording to an aspect, an autonomous loading and transfer pad includes a frame having driver assembly configured to transport the frame. The frame includes a surface configured to receive a container. A communications interface is communicatively coupled to the autonomous loading and transfer pad. The autonomous loading and transfer pad also includes an order control system communicatively coupled to the communications interface. The order control system is configured to direct movement of the autonomous loading and transfer pad, via the communications interface, to a pickup point in a storage facility. The autonomous loading and transfer pad receives an item at the pickup point, directs movement of the autonomous loading and transfer pad, via the communications interface, to a transfer point external to the storage facility, and directs an autonomous pick-up and delivery vehicle, via the communications interface, to the transfer point.
p4780
aVAbstract\u000aDisclosed is a system for automatically navigating a vehicle, which system comprises: a data storage containing one or more maps of one or more areas;\u000aelectronic interfaces for: (i) receiving data relating to the one or more areas from external data sources; (ii) receiving parameters relating to motion of the vehicle from physical sensors; and (iii) receiving a location of the vehicle from a positioning device;\u000aa navigation processor comprising processing circuitry adapted to determine an initial optimal route for traversing the vehicle from a given point in the one or more areas to another point in the one or more areas by computationally resolving a constrained minimization problem.
p4781
aVAbstract\u000aThe approach involves determining vision capability information for one or more occupants of at least one vehicle. The approach also involves processing and/or facilitating a processing of the vision capability information to determine an estimated comfortable operational configuration for the at least one vehicle. The approach involves determining a maximum operational configuration for the at least one vehicle. The approach also involves determining a recommended operational configuration for the at least one vehicle based, at least in part, on the estimated comfortable operational configuration and the maximum operational configuration.
p4782
aVAbstract\u000aAn autonomous vehicle driving assist system, method, and program set a planned route of a vehicle, the planned route including an autonomous driving section where autonomous driving control of the vehicle is permitted, and set a transition exclusion section of the planned route where a transition from autonomous driving control to manual driving is determined to be difficult. The system, method, and program set a transition section of the planned route where the transition from autonomous driving control to manual driving is made, and which excludes the transition exclusion section. Based on the transition section, the system, method, and program determine a section where autonomous driving control is performed in the planned route.
p4783
aVAbstract\u000aA vehicle control system for a vehicle includes a plurality of sensors disposed at a vehicle and having respective fields of sensing exterior of the vehicle. A processor is operable to process data captured by the sensors, and a control, responsive to processing by the processor of data captured by the sensors, controls a plurality of vehicle systems and is capable of autonomous control of the vehicle to autonomously drive the vehicle along a road. The vehicle control system includes a user input that is selectively actuatable by an occupant of the vehicle so that the occupant can select one of at least (i) a non-autonomous mode where the occupant has driving control of the vehicle and non-autonomously drives the vehicle along the road, and (ii) an autonomous mode where said control autonomously drives the vehicle along the road.
p4784
aVAbstract\u000aThis disclosure provides a device and a system for retrofitting a vehicle for unmanned operation. The system can have a navigation computer that can provide commands to a plurality of actuators for manipulating the onboard controls of a vehicle. The navigation computer can receive input from one or more remote operators and from a variety of sensors. The plurality of actuators can include a steering actuator that surrounds a steering column or a steering column housing to engage with a steering wheel of the vehicle. The steering actuator can have tongs that engage the steering wheel. The tongs can be coupled to an inner gear ring that can rotate within an outer housing of the steering actuator. Rotation of the tongs can interact with and move the steering wheel in response to commands from the navigation computer.
p4785
aVAbstract\u000aA detector (110) for determining a position of at least one object (112) is proposed. The detector (110) comprises:\u000aat least one transversal optical sensor (130), the transversal optical sensor (130) being adapted to determine a transversal position of at least one light beam (138) traveling from the object (112) to the detector (110), the transversal position being a position in at least one dimension perpendicular to an optical axis (116) of the detector (110), the transversal optical sensor (130) being adapted to generate at least one transversal sensor signal;\u000aat least one longitudinal optical sensor (132), wherein the longitudinal optical sensor (132) has at least one sensor region (136), wherein the longitudinal optical sensor (132) is designed to generate at least one longitudinal sensor signal in a manner dependent on an illumination of the sensor region (136) by the light beam (138), wherein the longitudinal sensor signal, given the same total power of the illumination, is dependent on a beam cross-section of the light beam (138) in the sensor region (136);\u000aat least one evaluation device (142), wherein the evaluation device (142) is designed to generate at least one item of information on a transversal position of the object (112) by evaluating the transversal sensor signal and to generate at least one item of information on a longitudinal position of the object (112) by evaluating the longitudinal sensor signal.
p4786
aVAbstract\u000aA motor vehicle control system operable in a steering assist mode in which the system is configured to: detect steering angle; and control a distribution of torque to one or more wheels of the vehicle in dependence on the detected steering angle thereby to induce a turning moment in the direction of turn indicated by the steering angle.
p4787
aVAbstract\u000aAn aerodynamic component is provided in the form of one or more ground skirt sections attached to one or more underbody fairings (e.g., trailer side skirts, tractor side fairings, etc.) of a vehicle. In use, the ground effects skirt sections improve air flow underneath the vehicle, thereby reducing drag.
p4788
aVAbstract\u000aVarious embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include receiving an indication of a sensor anomaly, determining one or more sensor recovery strategies based on the sensor anomaly, and executing a course of action that ensures the autonomous vehicle system operates within accepted parameters. Alternative sensors may be relied upon to cover for the sensor anomaly, which may include a failed sensor while the autonomous vehicle is in operation.
p4789
aVAbstract\u000aMinimizing incorrect associations of sensor data for an autonomous vehicle are described. A driving environment of the autonomous vehicle includes a stationary object and a dynamic object. Such objects can be detected by radar sensors and/or lidar sensors. In one example, a history of radar observation can be used to minimize incorrect sensor data associations. In such case, the location of a stationary object in the driving environment can be determined. When a dynamic object passes by the stationary object, lidar data of the dynamic object is prevented from being associated with radar data obtained substantially at the determined location of the stationary object. In another example, identifiers assigned to radar data can be used to minimize incorrect sensor data associations. In such case, lidar data of an object can be associated with radar data having a particular identifier.
p4790
aVAbstract\u000aA method and apparatus for marker aided autonomous vehicle localization are disclosed. Marker aided autonomous vehicle localization may include an autonomous vehicle identifying transportation network information, identifying an origin, identifying a destination, generating a plurality of candidate routes from the origin to the destination based on the transportation network information, wherein each route from the plurality of routes indicates a distinct combination of road segments and lanes, generating an action cost probability distribution for each action in each candidate route, generating a route cost probability distribution based at least in part on the action cost probability distribution, identify an optimal route from the plurality of candidate routes based at least in part on the route cost probability distribution, and operate the autonomous vehicle to travel from the origin to the destination using the optimal route.
p4791
aVAbstract\u000aA dispatch system for autonomous vehicle is provided. The dispatch system includes a plurality of autonomous vehicles respectively including a communication unit and a control unit. The communication unit obtains a vehicle location information of itself, and communicates with other autonomous vehicles. The control unit obtains a vehicle available information of itself. One of the autonomous vehicles is selected as a dispatch control center for controlling scheduling of all autonomous vehicles. When the dispatch control center receives a transportation request massage, the dispatch control center performs an optimized scheduling assignment and thus generates a scheduling signal. The scheduling signal is transmitted to the other autonomous vehicles by the communication unit, so as to assign one of the autonomous vehicles as a designated vehicle for transportation.
p4792
aVAbstract\u000aThere are provided an apparatus and method for generating a global path for an autonomous vehicle. The apparatus for generating a global path for an autonomous vehicle includes a sensor module including one or more sensors installed in the vehicle, a traffic information receiver configured to receive traffic information through wireless communication, a path generator configured to generate one or more candidate paths based on the traffic information, a difficulty evaluator configured to evaluate a difficulty of driving in the one or more candidate paths in each section of the one or more candidate paths using recognition rates of the one or more sensors and the traffic information, and an autonomous driving path selector configured to finally select an autonomous driving path by evaluating the one or more candidate paths based on the evaluation of the difficulty of driving.
p4793
aVAbstract\u000aA system of one or more computers can be configured to perform particular operations or actions by virtue of having software, firmware, hardware, or a combination of them installed on the system that in operation causes or cause the system to perform the actions. One general aspect includes a system, including a server computer having a processor and a memory, the memory storing instructions executable by the processor such that the computer is programmed to detect a first vehicle in a first lane adjacent to a second lane and plan a first vehicle trajectory for the first vehicle to be placed in a queue in the first lane and, from the queue, transition from the first lane to the second lane based upon at least one determined characteristic of the first vehicle and a second vehicle trajectory and control the first vehicle based upon the first vehicle trajectory.
p4794
aVAbstract\u000aMethods and systems for assisting autonomous vehicles are provided. The methods and systems can help increase safety and consumer satisfaction with autonomous vehicles and help bridge the gap towards completely autonomy. A method for assisting autonomous vehicles can include providing an autonomous vehicle having sensory inputs and providing a remote control center having two-way communication with the autonomous vehicle. The autonomous vehicle can send its sensory input information to the control center and the control center can send control information to the autonomous vehicle.
p4795
aVAbstract\u000aThe virtual reality navigation system can display the position of an autonomous vehicle at a predetermined amount of time in the future via virtual reality. A virtual reality display can display a virtual reality autonomous vehicle, as if the virtual reality autonomous vehicle is the autonomous vehicle operating at the predetermined amount of time in the future. Additionally, a virtual reality interface can provide an interface for an operator to interact with the environment of the autonomous vehicle. The virtual reality interface can receive an alternate route selection, and display in virtual reality the one or more maneuvers that would be required to reach the selection.
p4796
aVAbstract\u000aAn autonomous vehicle including a chassis, a conveyance system carrying the chassis, and a controller configured to steer the conveyance system. The controller is further configured to execute the steps of receiving steering radius information from a source; and creating steering instructions for the vehicle dependent upon the steering radius information from the source. The source not being from the vehicle itself.
p4797
aVAbstract\u000aA system includes an vehicle having functionality for autonomous operation, a vehicle network disposed within the vehicle, and an earpiece comprising an earpiece housing, a physiological monitoring sensor, an intelligent control system operatively connected to the physiological monitoring sensor and disposed within the ear piece housing, and a wireless transceiver disposed within the earpiece housing and operatively connected to the intelligent control system. The vehicle is configured to receive health data from the ear piece and in response to the health data perform one or more functions independent of a vehicle occupant using the earpiece.
p4798
aVAbstract\u000aVarious systems and methods for managing autonomous vehicles are described herein. A system for managing an autonomous vehicle, the system comprises a driving behavior collection module to collect driving behavior of a driver while driving an autonomous vehicle in manual mode; a driving profile module to build a driving profile based on the driving behavior; and a configuration module to configure the autonomous vehicle to operate according to the driving profile when operating in autonomous mode.
p4799
aVAbstract\u000aA method for determining a tire tread depth during operation of a vehicle includes determining an instantaneous rotational speed of a vehicle wheel having the tire based on data determined by at least one first sensor, then determining a vehicle speed based on data determined by at least one different second sensor, then determining an instantaneous dynamic wheel radius based on the determined instantaneous rotational speed and the determined instantaneous speed. At least one first tire parameter selected from an instantaneous tire temperature, tire pressure and tire load is determined. An instantaneous dynamic inner wheel radius is determined based on the at least one determined first parameter, wherein the inner wheel radius is the distance between the center of the wheel and the tire-side start or seam of the tread. A tire tread depth is determined based on the determined instantaneous dynamic radius and the determined instantaneous dynamic inner radius.
p4800
aVAbstract\u000aMethods, devices, and circuits are disclosed for managing a high energy density battery and a high power density battery during operational modes in an autonomous vehicle. A power input may be provided from a first battery to a power converter element. A first power output may be provided from the power converter element to power to a second battery and the autonomous vehicle during a first operational mode. A control input to the power converter element may be provided to reduce the first power output in response to determining that one or both of a maximum discharge current threshold and a minimum voltage threshold of the first battery have been exceeded. A second power output may be increased from the second battery to power the autonomous vehicle during a second one of the plurality of operational modes in response to the reduction of the first power output.
p4801
aVAbstract\u000aThe driver preferences system can determine driver habits and preferences based on output from a plurality of sensors. Utilizing the output from the plurality of sensors, an autonomous vehicle can operate according to the learning habits and preferences of the driver. The operator of the driver preferences system can finely adjust any habits or preferences via a driver preferences interface, as well as select preset modes including an aggressive driving mode or a cautious driving mode. Additionally, one or more driver profiles can be stored and selected via the driver preferences interface so that more than one driver can have an autonomous vehicle operator according to their personal driving habits and/or preferences.
p4802
aVAbstract\u000aA method and system for controlling driving of an autonomous vehicle by: (a) determining whether the autonomous vehicle is performing unmanned driving; (b) setting a maximum threshold speed, a minimum threshold speed, and a fuel efficient driving section when the autonomous vehicle determined to be performing unmanned driving; (c) determining whether the autonomous vehicle is driving in the fuel efficient driving section; (d) comparing a vehicle speed with the maximum threshold speed and the minimum threshold speed when the autonomous vehicle is driving in the fuel efficient driving section; (e) controlling the autonomous vehicle to accelerate when the vehicle speed is less than the minimum threshold speed; (f) controlling the autonomous vehicle to coast when the vehicle speed is greater than or equal to the maximum threshold speed; and (g) repeating the steps (e) to (f) while the autonomous vehicle is driving in the fuel efficient driving section.
p4803
aVAbstract\u000aA computing device is configured for communication with at least one autonomously controllable vehicle system or component. The computing device includes one or more processors for controlling operation of the computing device, and a memory for storing data and program instructions usable by the one or more processors. The one or more processors are configured to execute instructions stored in the memory to control the vehicle so as to execute one of an autonomous passing operation, an autonomous road exit operation, and an autonomous exit search operation responsive to manual actuation of an associated control mechanism.
p4804
aVAbstract\u000aA system for automating the control of a Remotely Piloted Vehicle (RPV) includes a computer having a processor and a memory, a display operatively coupled to the computer and configured to display a future operating condition of the RPV and an input device operatively coupled to the computer. A predicted noodle tool is executed by the processor and configured to indicate a predicted future path of the RPV by generating a predicted noodle segment on the display. A directed noodle tool is executed by the processor to indicate a pilot-adjustable proposed future flight path of the RPV by generating a directed noodle segment on the display. Further, an input device mode selector is operatively coupled to the processor and configured to selectively map the input device to either manipulate a control surface of the RPV, or to manipulate the directed noodle segment.
p4805
aVAbstract\u000aA method for controlling vehicle powertrain operation includes activating all-wheel-drive or 44-operation provided one of an environmental condition, vehicle use condition and vehicle electrical condition exceeds a corresponding reference, deactivating fuel saving operation provided all-wheel-drive or 44-operation is activated, activating fuel saving operation provided none of said conditions indicates need for AWD/44-operation, deactivating all-wheel-drive or 44-operation provided fuel saving operation is activated.
p4806
aVAbstract\u000aAspects of the disclosure relate to arranging a pickup between a driverless vehicle and a passenger. For instance, dispatch instructions dispatching the vehicle to a predetermined pickup area in order to pick up the passenger are received by the vehicle which begins maneuvering to the predetermined pickup area. While doing so, the vehicle receives from the passenger's client computing device the device's location. An indication that the passenger is interested in a fly-by pickup is identified. The fly-by pickup allows the passenger to safely enter the vehicle at a location outside of the predetermined pickup area and prior to the one or more processors have maneuvered the vehicle to the predetermined pickup area. The vehicle determines that the fly-by pickup is appropriate based on at least the location of the client computing device and the indication, and based on the determination, maneuvers itself in order to attempt the fly-by pickup.
p4807
aVAbstract\u000aA sensory stimulation system for autonomous vehicle (AV) can monitor a set of maneuvers of the AV. Based on each respective maneuver, the sensory stimulation system can determine a set of sensory stimulation outputs to provide a rider of the AV with sensory indications of the respective maneuver. The sensory stimulation system can then output the set of sensory stimulation outputs via an interior output system.
p4808
aVAbstract\u000aAspects of the disclosure relate to providing information about a vehicle dispatched to pick up the user. In one example, a request for the vehicle to stop at a particular location is sent. In response, information identifying a current location of the vehicle is received. A map is generated. The map includes a first marker identifying the received location of the vehicle, a second marker identifying the particular location, and a shape defining an area around the second marker at which the vehicle may stop. The shape has an edge at least a minimum distance greater than zero from the second marker. A route is displayed on the map between the first marker and the shape such that the route ends at the shape and does not reach the second marker. Progress of the vehicle towards the area along the route is displayed based on received updated location information for the vehicle.
p4809
aVAbstract\u000aA system and method for interfacing an autonomous or remote control drive-by-wire controller with a vehicle's control modules. Vehicle functions including steering, braking, starting, etc. are controllable by wire via a control network. A CAN architecture is used as an interface between the remote/autonomous controller and the vehicle's control modules. A CAN module interface provides communication between a vehicle control system and a supervisory, remote, autonomous, or drive-by-wire controller. The interface permits the supervisory control to control vehicle operation within pre-determined bounds and using control algorithms.
p4810
aVAbstract\u000aVarious embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. More specifically, systems, devices, and methods are configured to manage a fleet of autonomous vehicles. In particular, a method may include determining destination locations for autonomous vehicles, calculating, at an autonomous vehicle service platform, delivery locations to which the autonomous vehicles are directed, identifying data to implement a delivery location associated with an autonomous vehicle, and transmitting data representing a command to the autonomous vehicle. The command may be configured to cause navigation of the autonomous vehicle to the delivery location.
p4811
aVAbstract\u000aA route risk mitigation system and method using real-time information to improve the safety of vehicles operating in semi-autonomous or autonomous modes. The method mitigates the risks associated with driving by assigning real-time risk values to road segments and then using those real-time risk values to select less risky travel routes, including less risky travel routes for vehicles engaged in autonomous driving over the travel routes. The route risk mitigation system may receive location information, real-time operation information, (and/or other information) and provide updated associated risk values. In an embodiment, separate risk values may be determined for vehicles engaged in autonomous driving over the road segment and vehicles engaged in manual driving over the road segment.
p4812
aVAbstract\u000aA sidepod stereo camera system for an autonomous vehicle (AV) includes a sidepod housing mounted to the AV, a view pane coupled to the sidepod housing, and a stereo camera mounted within the sidepod housing. The stereo camera has a field of view extending outward from the sidepod housing through the view pane. A control system of the sidepod stereo camera system or the AV can conditionally activate and deactivate the sidepod stereo camera system when needed.
p4813
aVAbstract\u000aThe disclosed embodiments include a trailer for an autonomous vehicle controlled by a command and control interface. The trailer includes a trailer body configured to retain the autonomous vehicle in an undeployed configuration. The trailer also anchors the autonomous vehicle in a deployed configuration. A tether is provided having a first end coupled to the trailer body and a second end that is configured to couple to the autonomous vehicle. A winch is utilized to adjust a length of the tether to move the autonomous vehicle between the undeployed configuration and deployed configuration. Further, a communication system communicates with the command and control interface and the autonomous vehicle to control movement of the autonomous vehicle between the undeployed configuration and deployed configuration.
p4814
aVAbstract\u000aAn autonomous vehicle can operate with respect to other vehicles at a multi-stop intersection. One or more other objects (e.g., vehicles) approaching the multi-stop intersection from a different direction than the autonomous vehicle can be detected. An arrival time of the autonomous vehicle and the detected one or more other objects at the multi-stop intersection can be determined. In response to determining that the arrival time of the autonomous vehicle and the detected one or more other objects at the multi-stop intersection is substantially the same, a driving maneuver for the autonomous vehicle can be determined. As an example, the driving maneuver can include stopping short of an originally intended stopping point and/or decelerating so that the arrival time of the autonomous vehicle is not substantially the same as the other objects at the multi-stop intersection. The autonomous vehicle can be caused to implement the determined driving maneuver.
p4815
aVAbstract\u000aA device and method for safety stoppage of an autonomous road vehicle having a localization system and sensors for monitoring the vehicle surroundings and motion, and a signal processing system for processing sensor signals enabling an autonomous drive mode. A processor continuously predicts where a drivable space exists, calculates and stores a safe trajectory to a stop within the drivable space, determines a current traffic situation, and determines any disturbances in sensor data, vehicle systems or components enabling the autonomous drive mode. If an incapacitating disturbance is determined, a request for a driver to take control is signaled and it is determined if the driver has assumed control. If not, the vehicle is controlled to follow the most recent safe trajectory to a stop in a safe stoppage maneuver during which, or after, one or more risk mitigation actions adapted to the determined current traffic situation are performed.
p4816
aVAbstract\u000aA vehicle steering mechanism is autonomously operated. At least one first parameter for governing control of a steering mechanism is retrieved. The first parameter is applied to operation of the steering mechanism. Data is collected relating to operation of the vehicle. At least one second parameter for governing control of the steering mechanism is determined.
p4817
aVAbstract\u000aAn autonomous-capable vehicle which can be operated in a transitional state from manual vehicle operation to autonomous vehicle operation. In the transitional state, the vehicle operates autonomously and overrides manual interaction of the user. To maintain the transitional state, the driver performs a continuous action, such as providing a continuous interaction with a switching mechanism.
p4818
aVAbstract\u000aSystems and methods for autonomous vehicle parking includes: identifying parking parameters for parking an autonomous vehicle; receiving parking space data of one or more parking spaces; identifying a parking space of the one or more parking spaces for parking the autonomous vehicle; determining autonomous vehicle controls for controlling the autonomous vehicle to park at a parking space associated with the parking space data; implementing the autonomous vehicle controls for parking the autonomous vehicle in the parking space.
p4819
aVAbstract\u000aA steering system for an autonomous vehicle includes an autonomous driving assist steering system for controlling steering of the autonomous vehicle in a primary steering mode. Also included is an alternate steering mechanism controlling steering of the autonomous vehicle in a secondary steering mode, wherein the alternate steering mechanism is not a steering wheel.
p4820
aVAbstract\u000aAn autonomous vehicle is operable to follow a primary trajectory that forms a portion of a route. While controlling the autonomous vehicle, the autonomous vehicle calculates a failsafe trajectory to follow as a response to a predetermined type of event.
p4821
aVAbstract\u000aAn autonomous vehicle control system for use on a vehicle, such as a motorcycle or an all-terrain vehicle (ATV) to autonomously control the vehicle without a driver during vehicle testing is provided. The vehicle control system comprises a moment generator coupleable to the vehicle and configured to selectively generate a moment in either of first and second directions. The vehicle control system also includes a control system operably coupled to the moment generator and configured to control the moment generator to selectively impart moments on the vehicle to stabilize the vehicle or to introduce disturbances on the vehicle.
p4822
aVAbstract\u000aDisclosed are an autonomous vehicle driving system and method that increase probability that a signal of a traffic light will be recognized by using map information built in an autonomous vehicle driving system and a traffic light infrastructure, determine which travel route is allowed according to a camera recognition result and signal information delivered through V2X communication (traveling is allowed from which entrance lane to which exit lane), and enable an autonomous driving vehicle and a traffic light infrastructure to exchange intersection passage route information in order to allow the autonomous driving vehicle to efficiently pass through an intersection.
p4823
aVAbstract\u000aArrangements relate to the interaction between an autonomous vehicle and an external environment of the autonomous vehicle. Such interaction can occur in various ways. For example, a non-verbal human gesture in the external environment can be detected. The non-verbal human gesture can be identified. A future driving maneuver can be determined based on the identified non-verbal human gesture. The autonomous vehicle can be caused to implement the determined future driving maneuver. As another example, the external environment of the autonomous vehicle can be detected to identify a person (e.g. a human pedestrian, a human bicyclist, a human driver or occupant of another vehicle, etc.) therein. The identified person can be located. It can be determined whether the person is potentially related to a future driving maneuver of the autonomous vehicle. The autonomous vehicle can be caused to send a directional message to the person.
p4824
aVAbstract\u000aMethods, systems, and devices for providing data from a server to a UAV enable the UAV to navigate with respect to areas of restricted air space (\u201crestricted areas\u201d). A server may receive from a UAV, a request for restricted area information based on a position of the UAV. The server may determine boundaries of a surrounding area containing the position of the UAV and a number of restricted areas. The server may transmit coordinate information to the UAV defining the restricted areas contained within the surrounding area.
p4825
aVAbstract\u000aA vehicle configured to operate in an autonomous mode may engage in an obstacle evaluation technique that includes employing a sensor system to collect data relating to a plurality of obstacles, identifying from the plurality of obstacles an obstacle pair including a first obstacle and a second obstacle, engaging in an evaluation process by comparing the data collected for the first obstacle to the data collected for the second obstacle, and in response to engaging in the evaluation process, making a determination of whether the first obstacle and the second obstacle are two separate obstacles.
p4826
aVAbstract\u000aA path planning apparatus and method for an autonomous vehicle are provided. The apparatus includes a surrounding information detector that detects surrounding information around the vehicle and a vehicle information detector that detects vehicle information regarding driving states of the vehicle. A vehicle behavior determiner determines vehicle behavior based on the surrounding information and the vehicle information and a driving path generator generates a driving path and a velocity profile for a lane change using the surrounding information and the vehicle information when receiving a lane change signal from the vehicle behavior determiner.
p4827
aVAbstract\u000aA system can analyze accelerometer data and location data from a mobile computing device to determine a set of user attributes for a user of the mobile computing device. In certain implementations, the set of user attributes can be utilized by a backend transport facilitation system to configure an autonomous vehicle's seat for the user prior to being picked up for transport.
p4828
aVAbstract\u000aAn autonomous vehicle (AV) can receive a pick-up location from a backend transport facilitation system to service a pick-up request from a requesting user. The AV can further process sensor data from a sensor array of the AV to dynamically identify potential hazards while autonomously operating the AV along a current route to the pick-up location. The AV can receiving, from the backend transport facilitation system, a set of configuration instructions to configure adjustable components of an interior of the AV based on comfort preferences of the requesting user, and determine an optimal timing schedule to implement each of the set of configuration instructions. Thus, the AV can execute the set of configuration instructions based on the optimal timing schedule to configure the adjustable components of the configurable interior system prior to arriving at the pick-up location.
p4829
aVAbstract\u000aA vehicle control system and a method for self-control driving thereof are provided. The method includes: adjusting, by a controller, steering based on lane information and sensing a driving situation of the vehicle based on the steering adjustment. In addition, the controller is configured to determine an intervention in an altitude control based on the driving situation and in response to determining the intervention, operate a braking system to adjust the altitude of the vehicle.
p4830
aVAbstract\u000aA vehicle includes at least one side view mirror assembly configured to move to a folded position. A processing device is configured to command the at least one side view mirror assembly to move to the folded position when the vehicle is operating in an autonomous mode. A method includes determining whether a vehicle is operating in an autonomous mode and commanding at least one side view mirror assembly to move to a folded position if the vehicle is operating in the autonomous mode.
p4831
aVAbstract\u000aA maneuvering drive (24, 30) for a trailer (10) has a central unit (30), at least two drive units (24) by which wheels (16) of the trailer (10) can be driven and which are controlled by the central unit (30), each drive unit (24) including a checking module (40) by which drive specifications of the central unit (30) can be checked as to whether they can be fulfilled, and a feedback channel being provided by which the drive units (24) can feed back to the central unit (30) if the drive specifications cannot be fulfilled.
p4832
aVAbstract\u000aOne or more techniques and/or systems are provided for operating an autonomous vehicle based upon a driving preference. For example, a driving profile, comprising a driving preference (e.g., a speed preference, a route preference, etc.) of a user, may be provided to an automated driving component of the autonomous vehicle. An operational parameter for the autonomous vehicle may be generated based upon the driving preference of the user. The autonomous vehicle may be operated based upon the operational parameter. In an example, a condition of the user traveling in the autonomous vehicle may be determined, and the operational parameter for the autonomous vehicle may be adjusted based upon the condition of the user not corresponding to the driving preference.
p4833
aVAbstract\u000aMethods, devices, and systems of various embodiments are disclosed for exploiting opportunistic energy harvesting conditions for an unmanned autonomous vehicle (UAV). Various embodiments include determining mission power parameters for the UAV and accessing energy-harvesting data. A suitability of an energy-harvesting site for stationary energy harvesting by the UAV may be assessed based on the mission power parameters and the energy-harvesting data. In addition, an initial course of the UAV may be adjusted based on the assessment of the suitability of the energy-harvesting site. Stationary energy harvesting may include a process performed by the UAV that derives energy by conversion from an external power source while in a fixed position and/or in contact with an adjacent object.
p4834
aVAbstract\u000aVarious embodiments enable delivering an item using an unmanned autonomous vehicle (UAV) in response to receiving an electronic order for an item. Order parameters may be determined based on the electronic order identifying the item and details regarding delivery of the item. UAV components may be selected for operating the UAV based on UAV parameters meeting the order parameters. UAV-compliant packaging parameters may be determined for transporting the item carried by the UAV. Selected UAV-compliant packaging may enable the UAV to meet at least some of the order parameters and the UAV parameters. Assembly of the UAV may be coordinated to include the selected UAV components and selected UAV-compliant packaging with the item therein. The selected UAV-compliant packaging may meet the determined UAV-compliant packaging parameters. The assembled UAV and packaging may be dispatched for delivering the item.
p4835
aVAbstract\u000aComputer-implemented methods and systems are disclosed for automatically positioning a moving first vehicle relative to a moving second vehicle traveling in a given area. The method includes the steps of: (a) tracking the second vehicle and guiding the first vehicle to attain a given position relative to the second vehicle; and (b) controlling the first vehicle to maintain a generally constant speed such that an operator of the second vehicle can adjust the speed of the second vehicle to correspondingly adjust a relative position of the second vehicle to the first vehicle in a direction of movement of the first and second vehicles, and controlling the first vehicle to maintain a given distance from the second vehicle in a direction generally perpendicular to the direction of movement of the first and second vehicles by tracking the second vehicle.
p4836
aVAbstract\u000aOne embodiment includes a simulation system for an autonomous vehicle. The simulation system includes a user interface configured to facilitate user inputs comprising spontaneous simulated events in a simulated virtual environment during simulated operation of the autonomous vehicle via an autonomous vehicle control system. The system also includes a simulation controller configured to generate simulated sensor data based on model data and behavioral data associated with each of the simulated virtual environment and the spontaneous simulated events. The simulated sensor data corresponds to simulated sensor inputs provided to the autonomous vehicle control system via sensors of the autonomous vehicle. The simulation controller is further configured to receive simulation feedback data from the autonomous vehicle control system corresponding to simulated interaction of the autonomous vehicle within the simulated virtual environment. The simulated interaction includes reactive behavior of the autonomous vehicle control system in response to the spontaneous simulated events.
p4837
aVAbstract\u000aAn apparatus a method for generating a traveling path of a vehicle, may include a sensor device mounted in the vehicle and detecting a surrounding environment of the vehicle; and a controller determining a traveling space in which the vehicle is traveled by considering the surrounding environment of the vehicle, and generating the traveling path within the determined traveling space.
p4838
aVAbstract\u000aMethods, autonomous vehicles, and servers for passenger service in an autonomous vehicle are provided. A method includes receiving at least one signal indicating a status of at least one passenger of the autonomous vehicle. The method further includes processing the at least one signal to determine whether the at least one passenger has taken action consistent with completion of the passenger service reservation in the absence of an action that is inconsistent with completion of the passenger service reservation. The method yet further includes completing the reservation based on the processing the at least one signal. A server includes a processor and a non-transitory computer readable medium storing instructions that configure the server for performing the method.
p4839
aVAbstract\u000aA vehicle control system is configured for autonomous control of at least one actuatable vehicle system or component. The control system includes one or more sensors disposed on a vehicle, and a computing device in communication with the one or more sensors. The computing device is configured to acquire feedback relating to a ride quality feature from a vehicle occupant, identify vehicle control parameters affecting the ride quality feature; identify at least one autonomously controlled vehicle system affecting values of the identified vehicle control parameters; determine revisions to the vehicle control parameters necessary to implement the feedback relating to the ride quality feature; perform control parameter revisions necessary to implement the feedback relating to the ride quality feature, and control operation of the at least one autonomously controlled system or component so as to effect the control parameter revisions needed to implement the feedback.
p4840
aVAbstract\u000aVarious embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. More specifically, systems, devices, and methods are configured to generate trajectories to influence navigation of autonomous vehicles. In particular, a method may include receiving path data to navigate from a first geographic location to a second geographic location, generating data representing a trajectory with which to control motion of the autonomous vehicle based on the path data, generating data representing a contingent trajectory, monitoring generation of the trajectory, and implementing the contingent trajectory subsequent to an absence of the trajectory.
p4841
aVAbstract\u000aA laser diode firing circuit for a light detection and ranging device is disclosed. The firing circuit includes a laser diode coupled in series to a transistor, such that current through the laser diode is controlled by the transistor. The laser diode is configured to emit a pulse of light in response to current flowing through the laser diode. The firing circuit includes a capacitor that is configured to charge via a charging path that includes an inductor and to discharge via a discharge path that includes the laser diode. The transistor controlling current through the laser diode can be a Gallium nitride field effect transistor.
p4842
aVAbstract\u000aThe invention relates to a vehicle control system for autonomously guiding a vehicle, having a controller for autonomously guiding the vehicle on the basis of a sensor signal of a sensor of the vehicle, wherein the controller is designed to detect a malfunction of the sensor of the vehicle, and a communications interface, which is designed, in response to the detection of the malfunction of the sensor by the controller, to request an auxiliary sensor signal via a communications network and to receive the requested auxiliary sensor signal via the communications network, wherein the controller is designed to guide the vehicle autonomously on the basis of the received auxiliary sensor signal.
p4843
aVAbstract\u000aA vehicle control system configured to ensure running stability of a vehicle even if a vehicle weight is heavy is provided. The vehicle control system determines a travel locus of the vehicle within a planned route. If the vehicle tows another vehicle, or if a weight of the vehicle is heavier than a predetermined threshold value, the control system alters the travel locus of the vehicle in such a manner that a turning radius of the vehicle is increased.
p4844
aVAbstract\u000aMethod for operating a driver assistance system of a motor vehicle having a combined longitudinal and transverse guidance function, wherein, starting from the combined operation of the longitudinal and transverse guidance function, the longitudinal guidance function is disconnected in response to the presence of at least one determined first disconnection condition, whereas the transverse guidance function is maintained.
p4845
aVAbstract\u000aAn intention signaling system for an autonomous vehicle (AV) can monitor sensor information indicating a situational environment of the AV, and detect an external entity based, at least in part, on the sensor data. The intention signaling system can generate an output to signal one of an intent of the AV or an acquiescence of the AV to the external entity.
p4846
aVAbstract\u000aA vehicle implementing vehicle operation assistance information management for autonomous vehicle control transfer may identify a vehicle operation assistance information item indicating a location of an expected vehicle operation control transfer, and may, on a condition that an immanency for the vehicle operation assistance information item is within a maximum relevant immanence, determine an urgency based on the immanency, and present a representation of the vehicle operation assistance information item, which may include controlling a primary graphical display portion of the vehicle to present a graphical representation of the vehicle operation assistance information item, controlling a secondary graphical display portion of the vehicle to present the graphical representation, or a combination thereof. The vehicle may, control an auditory presentation device of the vehicle to present an auditory representation of the vehicle operation assistance information item.
p4847
aVAbstract\u000aA vehicle implementing vehicle operation assistance information management for autonomous vehicle control operation may identify a vehicle operation assistance information item, the vehicle operation assistance information item indicating a location of a candidate vehicle control operation. On a condition that the immanency is within the maximum relevant immanence, the vehicle may present a representation of the vehicle operation assistance information item, which may include controlling the primary graphical display portion to present a graphical representation of the vehicle operation assistance information item, wherein controlling the primary graphical display portion to present the graphical representation includes controlling the primary graphical display portion to present a first portion of the graphical representation, and controlling the secondary graphical display portion to present the graphical representation, wherein controlling the secondary graphical display portion to present the graphical representation includes controlling the secondary graphical display portion to present a second portion of the graphical representation.
p4848
aVAbstract\u000aA lane tracking system for a vehicle includes a front steering controller, a rear steering controller, and a lane tracking processor. The front steering controller is configured to rotate a front wheel of the vehicle through a front steering angle in response to a front steering torque command, and the rear steering controller is configured to rotate a rear wheel of the vehicle through a rear steering angle in response to a rear steering torque command. The lane tracking processor is configured to determine a desired course of the vehicle along a roadway, estimate a trajectory of the vehicle based on sensed vehicle motion, compute an error between the determined desired course and the estimated trajectory, and provide a front steering torque command to the front steering controller, and a rear steering torque command to the rear steering controller to minimize the computed error.
p4849
aVAbstract\u000aA method for warning a back side of a vehicle provided with a rear bumper multi carrier may include determining a carrier position by determining it is in a stowed state or drawing out state of a rear bumper multi carrier when a signal Reverse (R) step of a shift lever is produced, controlling ON or OFF operation of a detector of a rear side obstacle according to the stowed state or drawing out state of the carrier, and producing a warning signal when the rear side obstacle is detected in the detector operation controlling step.
p4850
aVAbstract\u000aA vehicle selectively operates in a plurality of operational modes. The operational modes carry with them different commands for operating a controlled suspension system such as a continuously controlled damping suspension system, a controlled steering system such as an electronic power-assist steering system, and a powertrain of the vehicle. For example, in one operational mode, the powertrain might be more sensitive to output torque from a motor or engine quickly with little hesitation. The vehicle includes a sensing system, such as a plurality of suspension height sensors and a corresponding controller programmed to receive suspension height signals indicating the characteristic of the road, to categorize the signals, and to compute categorized vehicle characteristics such as vehicle pitch, heave, roll, yaw, etc. The controller can discretize the categorized signals into a discrete number of index values, and then command the vehicle to change operational mode based on the discrete index value.
p4851
aVAbstract\u000aAn autonomous vehicle includes: a first sensor which obtains environmental information on surrounding environment of the autonomous vehicle; and a control unit which controls a drive unit based on a self position. The control unit includes: a first estimation unit which calculates a first estimate value indicating an estimated self position, by estimation using a probabilistic method based on the environmental information; and a second estimation unit which calculates a second estimate value indicating an estimated self position, by estimation using a matching method based on the environmental information, and the control unit changes, according to the first estimate value, a second estimate range for the calculating of the second estimate value by the second estimation unit, and controls the drive unit using the second estimate value as the self position.
p4852
aVAbstract\u000aA vehicle steering arrangement for a vehicle comprises a rack a position sensor, a steering column, a steering wheel, a torque sensor arranged to sense a torque applied onto the steering wheel and arranged to provide a torque signal representative thereof, an electronic control unit provided with a virtual steering model, a rack-mounted electromechanical actuator, and a force obtaining arrangement configured to obtain forces of steered wheels acting on the rack. The electronic control unit is configured to provide a virtual rack position based on the virtual steering model and at least a combination of the obtained forces and the torque signal, and is arranged to control the rack-mounted electromechanical actuator such that the current position of the rack is controlled towards the virtual rack position. The present disclosure also relates to an autonomous vehicle steering arrangement, a vehicle and a method of steering a vehicle.
p4853
aVAbstract\u000aA visual display for an autonomous vehicle, comprising a first display section that displays an external view of the autonomous vehicle, a second display section that displays vehicle actions that the autonomous vehicle will take and a third display section that displays alternative vehicle actions that an authorized passenger of the autonomous vehicle may select to override the vehicle actions. A decision system for an autonomous vehicle, comprising an input sensor to collect information from passengers to determine if a passenger is an authorized passenger and a display section that displays alternative vehicle actions that an authorized passenger of the autonomous vehicle may select to override vehicle actions of the autonomous vehicle.
p4854
aVAbstract\u000aA method of autonomous driving includes generating, with a 3D sensor, 3D points representing objects in the environment surrounding a vehicle. The method further includes, with a computing device, identifying, from the 3D points, a temporal series of clusters of 3D points representing the same object in the environment surrounding the vehicle as a track, identifying cluster-based classifiers for the object based on identified local features for the clusters in the track, identifying track-based classifiers for the object based on identified global features for the track, combining the cluster-based classifiers and the track-based classifiers to classify the object, with the cluster-based classifiers being weighted based on an amount of information on the clusters from which they are identified, and with the weight increasing with increasing amounts of information, and driving the vehicle along a route based on the object's classification.
p4855
aVAbstract\u000aVarious aspects and embodiments of the invention are directed to methods and compositions for reversing antibiotic resistance or virulence in and/or destroying pathogenic microbial cells such as, for example, pathogenic bacterial cells. The methods include exposing microbial cells to a delivery vehicle with at least one nucleic acid encoding an engineered autonomously distributed circuit that contains a programmable nuclease targeted to one or multiple genes of interest.
p4856
aVAbstract\u000aA system of computers configured to perform particular operations or actions by virtue of having software, firmware, hardware, or a combination of them on the system that in operation causes or cause the system to perform the actions. One general aspect includes a system, including a computer programmed to control each of an autonomous vehicle propulsion, steering, and braking, where the vehicle is subject to autonomous control. The system makes a first determination, based on data from a vehicle sensor, of availability of a vehicle parking area and makes a second determination, based on at least a geolocation of the vehicle, a system fault, a conditional boundary and availability of the parking area, to autonomously park in the parking area. Other embodiments of this aspect include corresponding computer systems, apparatus, and computer programs recorded on one or more computer storage devices, each configured to perform the actions of the methods.
p4857
aVAbstract\u000aA charging station can be autonomously coupled to an electric vehicle. Sensors on the vehicle determine a location of the vehicle, and the vehicle is positioned within a connection envelope. A travel path for bringing a charging connector into contact with a charging port on the vehicle can be determined, and then the travel path is autonomously carried out.
p4858
aVAbstract\u000aWhen driving support control starts, a control start condition is examined. It is examined whether or not all determination items set for the control start condition are OK, (whether the control start condition is established). If at least one of the determination items is NG, the determination condition is determined not to be established and the determination items determined to be NG are extracted. The determination item due to which a driver suspects that a fault has occurred is selected from the extracted determination items on the basis of a vehicle speed and a duration time in which the determination item is determined to be NG. The selected item is stored as an NG code.
p4859
aVAbstract\u000aIn embodiments of an autonomous vehicle platform and safety architecture, safety managers of a safety-critical system monitor outputs of linked components of the safety-critical system. The linked components comprise at least three components, each of which is configured to produce output indicative of a same event independent from the other linked components by using different input information than the other linked components. The safety managers also compare the outputs of the linked components to determine whether each output indicates the occurrence of a same event. When the output of one linked component does not indicate the occurrence of an event that is indicated by the outputs of the other linked components, the safety managers identify the one linked component as having failed. Based on this, the outputs of the other linked components are used to carry out operations of the safety-critical system without using the output of the failed component.
p4860
aVAbstract\u000aOne example includes an autonomous vehicle control system. The system includes an operational plan controller to maintain operational plans that each correspond to a predetermined set of behavioral characteristics of an associated autonomous vehicle based on situational awareness data provided from on-board sensors of the autonomous vehicle and mission control data provided from a user interface. The system also includes a decision-making algorithm to select one of the operational plans for operational behavior of the autonomous vehicle based on the situational awareness data and the mission control data at a given time and to provide an intent decision based on the situational awareness data and the selected one of the operational plans. The system further includes an execution engine to provide control outputs to operational components of the autonomous vehicle for navigation and control based on the selected one of the operational plans and in response to the intent decision.
p4861
aVAbstract\u000aThe present invention provided a sliding mode trajectory voting strategy module. The sliding mode trajectory voting strategy module integrates a reaction time and a relative distance into an obstacle feature sliding surface by utilize sliding mode control theory, and calculates the obstacle feature sliding surface and a road curvature value in combination with fuzzy theory to obtain an orientation angle of a safety path.
p4862
aVAbstract\u000aA system, device, and methods of automated driving. One example method includes determining a planned vehicle path using a path planner application receiving information based on inputs to one or more sensors disposed on a vehicle. The method further includes sending a command to one or more vehicle systems to control the vehicle to follow the planned vehicle path. While the vehicle follows the planned vehicle path, the method includes receiving an indication that the path planner application is not meeting a threshold performance level. After receiving the indication that the path planner application is not meeting the threshold performance level, the method further includes resending the previously sent command to the one or more vehicle systems to control the vehicle to follow the planned vehicle path.
p4863
aVAbstract\u000aExample embodiments presented herein are directed towards a seat assembly, and corresponding method and computer readable medium, for adjusting a seat in an autonomous vehicle. The adjustment is provided such that a seat occupant may control the adjustment may providing a natural pushing force once the vehicle is in an autonomous driving mode.
p4864
aVAbstract\u000aA travel control apparatus for a vehicle includes: a frontward environment recognition unit that obtains frontward environment information by recognizing a frontward environment of the vehicle; a frontward environment information reliability calculator that calculates a reliability of the frontward environment information; a map information storage unit that stores map information relating to a travel region of the vehicle on the basis of position information indicating a position of the vehicle; a map information updating unit that updates the map information while calculating a reliability of the map information; a control information selector that compares the reliability of the frontward environment information with update information relating to the map information, and selects either one of the frontward environment information and the map information as information to be used during automatic driving control; and an automatic driving control execution unit that executes the automatic driving control based on the selected information.
p4865
aVAbstract\u000aA vehicle system includes a sensor programmed to output an occupant or object detection signal indicating a presence of an unauthorized occupant or unauthorized object in a host vehicle. An autonomous mode controller is programmed to determine, from the occupant or object detection signal, whether to operate the host vehicle in an autonomous mode.
p4866
aVAbstract\u000aA transportation network is provided that utilizes autonomous vehicles (e.g., unmanned aerial vehicles) for identifying, acquiring, and transporting items between network locations without requiring human interaction. A travel path for an item through the transportation network may include a passing of the item from one autonomous vehicle to another or otherwise utilizing different autonomous vehicles for transporting the item along different path segments (e.g., between different network locations). Different possible travel paths through the transportation network may be evaluated, and a travel path for an item may be selected based on transportation factors such as travel time, cost, safety, etc., which may include consideration of information regarding current conditions (e.g., related to network congestion, inclement weather, etc.). Autonomous vehicles of different sizes, carrying capacities, travel ranges, travel speeds, etc. may be utilized for further improving the flexibility and efficiency of the system for transporting items.
p4867
aVAbstract\u000aA controller for an autonomous vehicle receives an image stream from one or more imaging devices. The controller identifies vehicle images in the image stream. Vehicle images are compared to the color, shape, badging, markings, license plate, and driver of the autonomous vehicle. If the vehicle image is determined to match the autonomous vehicle, then the vehicle image is ignored as a potential obstacle. The location of a reflective surface that generated the vehicle image may be determined and added to a set of potential obstacles. The color and shape of a vehicle in a vehicle image may be evaluated first. Only if the color and shape in the vehicle image match the autonomous vehicle are other factors such as badging, markings, license plate, and driver considered. Vehicle images not matching the autonomous vehicle are included in a set of potential obstacles.
p4868
aVAbstract\u000aA vehicle system includes communication circuitry programmed to communicate with a controller that is removable from an autonomous vehicle. The system further includes a processor programmed to receive control signals, which are associated with manually controlling the autonomous vehicle in a non-autonomous mode, transmitted from the controller. The processor is further programmed to output commands to at least one vehicle subsystem in accordance with the control signals transmitted from the controller while the vehicle is operating in a non-autonomous mode.
p4869
aVAbstract\u000aA driving support system for a vehicle that causes the vehicle to travel following a target travel route through steering and deceleration control includes: a target steering angle calculation unit that calculates a target steering angle at the time of passing through a curved section of the target travel route; a target deceleration calculation unit that calculates a target deceleration in the curved section; a deceleration correction value calculation unit that calculates, on the basis of the target steering angle and an actual steering angle, a corrected vehicle speed for correcting a target vehicle speed determined by the target deceleration; and a deceleration correction unit that corrects the target deceleration such that the target vehicle speed becomes the corrected vehicle speed.
p4870
aVAbstract\u000aTest cases for autonomous vehicles are generated automatically by using data which have been collected from vehicles participating in public road traffic. A test planning system for autonomous vehicle includes defined application cases for autonomous vehicles. The vehicles are configured to identify test cases with prediction analyses of a reference catalogue of driving situations and the defined application cases, and compare, via a comparative analyses, the test cases and the defined application cases to compile an expanded set of test cases, wherein the expanded set of test cases are compared to the defined application cases to output a complete set of test cases. The system also includes a central database configured to query the complete set of test cases.
p4871
aVAbstract\u000aAn autonomous driving display system includes: an autonomous driving control device to carry out autonomous driving; an autonomous driving display device display state of which is recognizable from outside a vehicle; and an in-vehicle device to make the autonomous driving control device carry out autonomous driving of the vehicle upon receiving an autonomous driving instruction signal instructing autonomous driving, monitor start of the autonomous driving of the vehicle by the autonomous driving control device, and control a display state of the autonomous driving display device to be in a display state different from a display state before the autonomous driving is started when the autonomous driving of the vehicle is started by the autonomous driving control device.
p4872
aVAbstract\u000aA trailer backup assist system includes a sensor that senses a hitch angle between a vehicle and a trailer. The trailer backup assist system also includes a steering input device that provides a backing path of the trailer. Further, the trailer backup assist system includes a controller that generates a steering command for the vehicle based on the hitch angle and the backing path. The controller generates a countermeasure for operating the vehicle when the steering input device fails to provide the desired backing path fails or the controller otherwise fails to sense the input signal from the steering input device.
p4873
aVAbstract\u000aA charging station can be autonomously coupled to an electric vehicle. Sensors on the vehicle determine a location of the vehicle, and the vehicle is positioned within a connection envelope. A travel path for bringing a charging connector into contact with a charging port on the vehicle can be determined, and then the travel path is autonomously carried out. A charging station may include a mount, a bracket, and a charging connection.
p4874
aVAbstract\u000aA method is provided, which includes scanning at least one radio frequency identification (RFID) tag to obtain an identifier of the RFID tag; querying a database using the identifier of the at least one RFID tag to collect information about a location of the at least one RFID tag; determining a bias of a vehicle relative to the location of the scanned at least one RFID tag; and calculating a location of the vehicle based on the bias and the location of the at least one RFID tag.
p4875
aVAbstract\u000aA system for a vehicle may include a motor assembly, a wiper and a switch. The motor assembly may be mounted to a spare tire carrier on a tailgate of the vehicle and may include an output shaft that is rotatable relative to the spare tire carrier. The wiper may be attached to the output shaft for rotation with the output shaft relative to a rear window pane of the vehicle. The switch may be electrically connected to the motor assembly and may be operable to allow electrical current to reach the motor assembly when the wiper is in contact with the rear window pane. The switch may be operable to prevent electrical current from reaching the motor assembly in response to the wiper and the rear window pane being spaced apart from each other.
p4876
aVAbstract\u000aControl of aircraft steering during ground travel is provided in an aircraft equipped with an engines-off wheel drive system controllable to move the aircraft autonomously on the ground without reliance on the aircraft's main engines or external tow vehicles. The wheel drive system is designed to interact with the aircraft's nose wheel hydraulic steering system to augment or replace the hydraulic steering system with the operation of the wheel drive system at taxi speeds, particularly at very low taxi speeds and even when the aircraft is stopped, to steer the aircraft as it maneuvers through turns during ground travel between landing and takeoff and at other times.
p4877
aVAbstract\u000aAn autonomous vehicle comprises an environment sensing means for sensing an environment of the autonomous vehicle, and a computing unit configured to perform a mapping function and a localization function. The mapping function is based upon signals supplied from the environment sensing means to build a map. The localization function localizes the autonomous vehicle within the map and generates localization information. The autonomous vehicle further comprises boundary distance sensing means configured to generate a distance signal correlated to a distance between the autonomous vehicle and boundary indication means. The computing unit is configured to receive the distance signal and to perform the mapping function or the localization function based upon a signal from the environment sensing means and the distance signal from the boundary distance sensing means. The system also comprises a boundary wire indicating a border of an area in which autonomous driving of the vehicle can be performed.
p4878
aVAbstract\u000aAn event is detected arising during autonomous operation of a vehicle. An index in media content associated with the event is identified. At least one instruction is provided to a media module to pause or modify play of the media content based on the event.
p4879
aVAbstract\u000aA trailer backup assist system for vehicles utilizes surface slope data to provide an alert to an operator if a problematic operating condition is present and/or imminent while the vehicle is backing up with a trailer attached thereto. The trailer backup assist system may also be configured to utilize surface slope data to control steering, braking, or other vehicle operating parameter while the vehicle is backing up with a trailer attached thereto. The trailer backup assist system may also be configured to generate a warning and/or control the vehicle if a jackknife condition is imminent. The surface slope data may be obtained utilizing sensors on the vehicle, or the surface slope data may be obtained utilizing a database that includes topographical data.
p4880
aVAbstract\u000aThe present disclosure is directed to an autonomous vehicle having a vehicle control system. The vehicle control system includes a vehicle detection system. The vehicle detection system includes receiving an image of a field of view of the vehicle and identifying a region-pair in the image with a sliding-window filter. The region-pair is made up of a first region and a second region. Each region is determined based on a color of pixels within the sliding-window filter. The vehicle detection system also determines a potential second vehicle in the image based on the region-pair. In response to determining the potential second vehicle in the image, the vehicle detection system performs a multi-stage classification of the image to determine whether the second vehicle is present in the image. Additionally, the vehicle detection system provides instructions to control the first vehicle based at least on the determined second vehicle.
p4881
aVAbstract\u000aArrangements herein relate to a method and system for selectively displaying surroundings of an autonomous vehicle. The system can include a display to display a plurality of images in which some of the images are images of an environment external to the autonomous vehicle and are images unrelated to the environment external. The system can include cameras to capture the images of the environment external. The system can further include a processor that can be configured to detect a handover event associated with the operation of the vehicle. In response to the detection of the handover event and if the display is displaying images unrelated to the environment external, the processor can also cause the display to display images of the environment external in the place of the images unrelated to the environment external.
p4882
aVAbstract\u000aAn autonomous vehicle includes a sensor interface coupled to a gyroscope system, a wireless communication interface, a processor, and memory. The memory has instructions stored thereon that, when executed by the processor, cause the autonomous vehicle to establish a plurality of wireless communication links with two or more vehicles in a group including the autonomous vehicle and the two or more vehicles. A signal strength of each of the wireless communication links is monitored to determine an observed signal strength of each of the wireless communication links. A desired position of the autonomous vehicle is determined based on an expected signal strength of each of the wireless communication links. A position adjustment of the autonomous vehicle is initiated based on a difference between the expected signal strength and the observed signal strength in combination with data from the gyroscope system.
p4883
aVAbstract\u000aA backup assist system for a vehicle reversing a trailer includes an input element, including a base and a rotary element rotatably coupled with the base. The system further includes a controller causing a rotation of the rotary element relative to the base to be constrained in a first rotational movement mode that is biased toward a center position. The controller further interprets a first instantaneous position of the rotary element as a trailer control commanding position and outputs a vehicle steering command based thereon.
p4884
aVAbstract\u000aA vehicle configured to operate in an autonomous mode may engage in a reverse-parallax analysis that includes a vehicle system detecting an object, capturing via a camera located at a first location a first image of the detected object, retrieving location data specifying (i) a location of a target object, (ii) the first location, and (iii) a direction of the camera, and based on the location data and the position of the detected object in the first image, predicting where in a second image captured from a second location the detected object would appear if the detected object is the target object.
p4885
aVAbstract\u000aA hitch angle warning system includes a camera-based hitch angle sensor that senses a hitch angle between a vehicle and a trailer. The hitch angle warning system also includes a controller that estimates an amount of time for the hitch angle to reach a threshold angle based on a rate of change of the hitch angle. The threshold angle may be set to a maximum hitch angle controllable by the vehicle based on a length of the trailer. The controller thereby generates a warning signal when the amount of time is less than a threshold time, which is configured to be greater or equal to than a response time of a driver of the vehicle to make a corrective action. The warning signal may be deactivated when the amount of time is greater than a second time that is greater than the threshold time.
p4886
aVAbstract\u000aA sensory stimulation system for autonomous vehicle (AV) can monitor AV data indicating actions to be performed by the AV. The sensory stimulation system can further provide a user interface the enables riders of the AV to adjust output parameters of the sensory stimulation system. Based at least in part on the AV data, the sensory stimulation system can generate a set of stimulation commands for one or more of the output systems. Based on adjustments made by the at least one rider on the user interface, the sensory stimulation system can execute the stimulation commands on individual output systems.
p4887
aVAbstract\u000aA trailer sway warning system, according to one embodiment, includes a hitch angle sensor for sensing a hitch angle between a vehicle and a trailer. The trailer sway warning system includes a vehicle sensor for sensing a dynamic parameter of the vehicle, such as a steering angle rate or a yaw rate of the vehicle. Further, the trailer sway warning system includes a controller that generates a warning signal when the hitch angle is oscillating at a magnitude that exceeds a warning threshold and the dynamic parameter is substantially constant.
p4888
aVAbstract\u000aA method is provided for propelling a vehicle having a power-train including a primary power source accompanied with a primary power torque curve and a secondary power source accompanied with a secondary power torque curve, the primary power source being adapted to deliver a maximum torque output in relation to rotational speed according to the primary power torque curve and the secondary power source being adapted to deliver a maximum torque output in relation to rotational speed according to the secondary power torque curve, the vehicle being adapted to be propelled by either one of the primary power source and the secondary power source or by both together, the powertrain further including a powertrain limit curve which is adapted to where applicable to restrict a current driver demand from a driver of the vehicle in relation to the primary power torque curve and the secondary power torque curve when propelling the vehicle. The method includes, when propelling the vehicle by both the primary power source and the secondary power source: determining a current driver demand, determining a current propulsion adaption condition for the vehicle, adjusting the powertrain limit curve according to a propulsion adaption torque factor depending on the current propulsion adaption condition, where applicable restricting the current driver demand according to the adjusted powertrain limit curve, and requesting the powertrain to propel the vehicle according to the thus possibly restricted current driver demand. A vehicle adapted to perform the method is also provided.
p4889
aVAbstract\u000aThe present invention provides a system for conducting agricultural operations in a field using autonomous vehicles in which a collision avoidance mechanism may be provided. The system may include providing a mission plan for autonomous vehicles to conduct agricultural operations, establishing a hierarchy for the vehicles, and monitoring for an event conditions indicating vehicles are traveling toward a collision with respect to one another. Upon receiving an event condition, the system may revise the mission plan to adjust a path of one of the vehicles based on the hierarchy in order to avoid the collision.
p4890
aVAbstract\u000aIn one embodiment, a first image of a physical object external to an autonomous vehicle is received, where the first image is captured by an image sensor attached to the autonomous vehicle. An image recognition is performed on the first image to derive one or more keywords related to the physical object. A list of one or more content items are identified based on the one or more keywords. A first content item selected from the list of content items is augmented onto the first image to generate a second image. The second image is displayed on a display device within the autonomous vehicle.
p4891
aVAbstract\u000aA vehicle control system is provided to propel a vehicle in a stabilized manner when switching an operating mode from an autonomous mode to a manual mode. The vehicle control system is configured to: control an operating condition of the vehicle; determine an execution of steering operation by the driver; and continue the autonomous control of the steering wheel if the steering wheel cannot be operated by the driver when the autonomous control of the vehicle is interrupted by a manual operation of a driver and hence the operating mode is switched from the autonomous mode to the manual mode.
p4892
aVAbstract\u000aA method and an apparatus for testing software for autonomous vehicles by means of a loop simulation involves hardware in the form of one or more real autonomous vehicles able to carry out autonomous test drives in the real world. In response to a work order given by a user, a check is automatically carried out in order to determine which vehicles, among a plurality of real autonomous vehicles which are able to carry out autonomous test drives on globally distributed test tracks in the real world, are currently available for one or more tests defined in the work order. The performance of the software tests and the test drives is then automatically planned and coordinated.
p4893
aVAbstract\u000aDescribed herein is an apparatus for semi-autonomous vehicle control of a vehicle includes a distributed mission module configured to modify a mission element of a group mission based on availability of data. The group mission involves a plurality of vehicles. The apparatus also includes a guidance module configured to compute a path for a local vehicle of the plurality of vehicles based on the modified mission element. The path is configured to achieve the modified mission element. Additionally, the apparatus includes a multi-protocol translator module configured to convert the path into one or more control commands for the local vehicle. The distributed mission module, guidance module, and multi-protocol translator are located on-board the vehicle.
p4894
aVAbstract\u000aThe disclosure includes a system, method and tangible memory for providing a graphical display output including a simulation for testing a design for a vehicle. The method includes extracting object data from accident data describing an object that contributed to a roadway accident occurring in a real world. The method includes extracting behavior data from the accident data describing the erroneous behavior of the object. The method includes constructing an error model that describes a virtual object that represents the object in the simulation based in part on the behavior data, a frequency input and a severity input. The method includes generating the graphical display output including the simulation based on a roadway model, a vehicle model and the error model. The simulation graphically depicts a virtual vehicle present on a virtual roadway system that includes the virtual object behaving dynamically in the simulation based on the error model.
p4895
aVAbstract\u000aA steering input apparatus for a trailer backup assist system includes a control element operable in a first movement mode into an instantaneous one of a plurality of curvature commanding positions and in a second movement mode to an input position of a plurality of menu command positions. The steering input further includes a control module generating a vehicle steering command based on the instantaneous one of the curvature commanding positions.
p4896
aVAbstract\u000aA parking assist system includes an electronic control unit. The electronic control unit is configured to detect an available parking area in an area around a vehicle, calculate a parking guidance path for guiding the vehicle from a current position of the vehicle to a parking target position included in the available parking area, execute guidance control for guiding the vehicle to the parking target position by executing at least steering control along the parking guidance path, and, when an end condition for ending guidance is satisfied in the middle of execution of the guidance control, end the guidance control and carry out at least one of steering to keep a steering angle at an end of the steering control for a predetermined period or steering to gradually reduce the steering angle from the steering angle at the end of the steering control toward a neutral position.
p4897
aVAbstract\u000aSystem and method for starting a turbine engine are disclosed. These systems and methods for starting a turbine engine may be located on a vehicle, such as such as a Class 8 vehicle, equipped with a turbine engine as the prime mover or as a generator in a hybrid powertrain. In that regard, a fluid forcing device may be employed to start the turbine engine, such as an electric pump/compressor. The fluid forcing device may already be located on the vehicle for other purposes, and can include an electrically powered steering pump (also referred to as an electric pump) or an electrically powered air brake compressor (also referred to as an electric compressor). In order to start the turbine engine, the output of the electric pump/compressor drives an associated fluid circuit, which in turn, supplies fluid over a portion of the turbine shaft, wheel or scroll in order to impart rotational motion thereto. The rotational motion imparted to the turbine shaft, wheel or scroll aims to start the turbine engine. Once started, the output of the electric pump/compressor is either inhibited or redirected to power other devices, such as one or more vehicle accessories (e.g., steering gear, air brakes, power take off (PTO), air conditioner, etc).
p4898
aVAbstract\u000aProvided are a vehicle steering device and the like, which are capable of converging a lateral displacement at a forward gazing-point distance to a target travel line with simple control. A target travel line for a vehicle to travel by following a travel path recognized from an image taken by a camera or the like is set. A lateral speed, which is a change amount of the lateral displacement that is a difference between a position of the target travel line at the forward gazing-point distance and a position of the vehicle, is controlled so that the lateral displacement is reduced. A target steering angle is calculated based on the lateral speed, and a steering angle of the vehicle is controlled based on the calculated target steering angle.
p4899
aVAbstract\u000aAn illustrative example system for developing an autonomous vehicle response includes a simulator that provides an at least visual simulation of a plurality of different situations that may be encountered while driving, a driver input device that allows the driver to respond to the simulation of the plurality of situations in a manner consistent with the driver's driving response to the situations, respectively, and a compute device including at least one processor and data storage associated with the processor. The compute device is configured to determine a profile of the driver based on information from the driver input device regarding the driver's driving responses to the simulation of the situations. The profile is at least temporarily stored in the data storage. The profile provides information for controlling the autonomous vehicle response to an actual situation corresponding to at least one of the simulated situations.
p4900
aVAbstract\u000aThe present disclosure is directed to autonomous vehicle having a vehicle control system. The vehicle control system includes a processing system that receives input values that indicate attributes of an object within a threshold distance of the autonomous vehicle and variance values indicating uncertainty associated with the input values. The processing system also provides a plurality of outcomes that are associated with combinations of split decisions. A given split decision indicates whether a particular input value is above or below a threshold value associated with the given split decision. The processing system further determines (i) a probability that the particular input value is above a threshold value and (ii) a probability that the particular input is below the threshold value for a given split decision. Additionally, the processing system determines one or more likelihoods associated with a given outcome. Further, the processing system provides instructions to control the autonomous vehicle.
p4901
aVAbstract\u000aA system and method for providing path planning and generation in a manually driven vehicle that provides a steering correction for collision avoidance purposes. The method includes determining a predicted path of the vehicle based on vehicle motion sensing data and vehicle parameters. The method also includes detecting a moving object in front of the vehicle and determining if a collision between the vehicle and the object will occur if the vehicle travels along the predicted path at the current vehicle speed. The method solves a fifth-order polynomial equation to define a collision avoidance path from the current vehicle position to a waypoint a safe distance from the object and a return path from the waypoint to the lane center that the vehicle is automatically steered along.
p4902
aVAbstract\u000aA vehicle control system to prevent a vehicle stopped in the autonomous mode from being started undesirably is provided. The vehicle control system is configured to select an operating mode from an autonomous mode and a manual mode, and to select a drive range from a drivable range and a non-drivable range. A controller is configured to detect a fact that a door is opened, that a door lock is unlocked, or that a seatbelt is unfastened. If at least any of those facts is detected, the controller shifts the drive range to the non-drivable range or shifts the operating mode to the manual mode.
p4903
aVAbstract\u000aA secure start system for an autonomous vehicle (AV) can include a compute stack and a communications router. The communications router can include an encrypted router drive and an input interface to receive a boot-loader that includes a basic decryption key to decrypt the encrypted router drive and enable network communications with a backend system. The secure start system can utilizes a tunnel key from the backend system to establish a private communications session with a backend data vault, and retrieve a set of decryption keys from the backend data vault, via the private communications session, to decrypt a plurality of encrypted drives of the AV.
p4904
aVAbstract\u000aA secure start system for an autonomous vehicle (AV) can detect startup of the AV and transmit credentials to a backend system. When the credentials are authenticated, the secure start system can receive a tunnel key from the backend system. Using the tunnel key, the secure start system can establish a private communications session with a backend vault of the backend system and retrieve a set of decryption keys from the backend vault. Using the set of decryption keys, the secure start system can verify and decrypt a cryptographically signed, encrypted, and compressed file system for execution by a compute stack of the AV\u2014where execution of the file system by the compute stack enables autonomous operation of the AV.
p4905
aVAbstract\u000aThe present invention relates to a steering control apparatus and a method of operating the apparatus. The steering control apparatus of the present invention includes a sensor unit for sensing movement of an autonomous driving vehicle or a limited autonomous driving vehicle, and calculating movement information. A determination unit determines a driver's steering intention using an actual steering torque value of the vehicle, calculated based on the movement information, and a reference value corresponding to speed of the vehicle, and decides on a driving control agent. A control unit transfers a driving control authority of the vehicle depending on the driving control agent.
p4906
aVAbstract\u000aA system, a multi-user scheduling unit comprised in the system, and corresponding methods are described for scheduling a video conference call for at least one autonomous vehicle. The system provides a means of scheduling such a call for various participants while minimizing driver interaction or need for attention while a vehicle is in a manual driving mode.
p4907
aVAbstract\u000aA vehicle includes a suspension corner connecting the vehicle's road wheel to the vehicle's body and characterized by a ride height at the suspension corner. An actuator at the suspension corner is configured to selectively extend and contract in response to a volume of received pressurized fluid to selectively increase and reduce the ride height. The actuator includes a locking device configured to selectively restrain the piston in a predetermined position and release the piston, and includes an actuation mechanism for activating the device to restrain the piston in the predetermined position. A controller is configured to determine if a change in the ride height is required and to assess if the piston is restrained by the locking device. If the piston is restrained by the locking device and the change in ride height is required, the controller releases the piston via the device and then changes the ride height.
p4908
aVAbstract\u000aA system and method for adjusting drive mode of a vehicle are disclosed. According to certain embodiments, the system may include a processor configured to: receive sensor data generated by one or more sensors in communication with the processor; determine motion of the vehicle based on the sensor data; determine, based on the motion of the vehicle, characteristics of the surface or driving behavior of a user of the vehicle; and determine a drive mode of the vehicle based on the determined characteristics of the surface or driving behavior of the user. The system may further include one or more actuators configured to implement the drive mode.
p4909
aVAbstract\u000aA sensor interface for an autonomous vehicle. The sensor interface generates a plurality of sensor pulses that are each offset in phase relative to a local clock signal by a respective amount. The sensor interface receives sensor data from a sensor apparatus and formats the sensor data based at least in part on the plurality of sensor pulses to enable the sensor data to be used for navigating the autonomous vehicle. For example, the sensor interface may add a timestamp to the sensor data indicating a timing of the sensor data in relation to the local clock signal.
p4910
aVAbstract\u000aDescribed herein is utilization of nontransparent Shock-Absorbing Energy Dissipation Padding (SAEDP) in an autonomous on-road vehicle. In one embodiment, the vehicle includes a side window located at eye level of an occupant who sits in the vehicle. The side window enables the occupant to see the outside environment. A motor is configured to move the SAEDP over a sliding mechanism between first and second states. A processor is configured to command the motor to move the SAEDP from the first state to the second state responsive to an indication that a probability of an imminent collision reaches a threshold. In the first state, the SAEDP does not block the occupant's eye level view to the outside environment, and in the second state, the SAEDP blocks the occupant's eye level view to the outside environment in order to protect the occupant's head against hitting the side window during collision.
p4911
aVAbstract\u000aThe present invention provides a system for conducting agricultural operations in a field using one or more autonomous vehicles in which the agricultural operations may be optimized during run time. The system includes providing a mission plan for an autonomous vehicle, receiving progress updates from the vehicle as it conducts an agricultural operation according to the mission plan, and monitoring for event conditions which may he reported by the vehicle. Event conditions may include, for example, detection of an obstacle, or an oncoming vehicle, or a disablement of the vehicle. Upon receiving an event condition, the system may revise the mission plan to resolve the event condition while providing an optimization based on current agricultural conditions.
p4912
aVAbstract\u000aA method of adjusting an air suspension system comprises detecting with a positioning system that the vehicle is approaching a park location and reporting the park location is approaching to an electronic control unit for the air suspension system. A vehicle speed is determined and compared to a predetermined speed threshold, with the electronic control unit. The electronic control unit selects a park mode for the suspensions system when the vehicle is approaching the park location and when the vehicle speed is below the predetermined threshold. Air supply for the air suspension system is controlled to adjust the corner assemblies for the air suspension system to lowered positions associated with the park mode.
p4913
aVAbstract\u000aA dual-powered utility vehicle that includes a gasoline engine configured to rotate a first axle that rotates at least a first wheel; an electrical motor configured to rotate a second axle that rotates at least a second wheel; and at least one battery. The at least second wheel also rotates the second axle. The at least one battery is connected to the electrical motor. The vehicle is configured such that when being moved under power from the gasoline engine, the at least second wheel of the electrical drive train is rotated by virtue of its ground contact when the gasoline engine rotates the at least first wheel. Energy created by the at least second wheel rotating is transferred to the at least one battery to recharge the battery and make available for use by the electrical motor to rotate the at least one second wheel when activated to do so.
p4914
aVAbstract\u000aA positive location system is disclosed for a locomotive consist including at least two locomotives. The system may include a first locator element on a first locomotive and a second locator element on a second locomotive. Each locator element may include a receiving device and a transmitting device communicatively coupled with each other locator element. Each locator element may be configured to determine its own location, relay information on its location to at least one other locator element on another locomotive, receive location information on the at least one other locator element, and determine its own location relative to the location of the at least one other locator element. Each locator element may also provide location information for the at least one other locator element as though it were the at least one other locator element when the at least one other locator element is non-functional.
p4915
aVAbstract\u000aA system for dual-attachment of a trailer to a vehicle by either manually or robotically so that the trailer becomes a laterally-stable extension of the vehicle.
p4916
aVAbstract\u000aA control system for a vehicle includes an input including a rotatable rotary element and a controller. The controller executes a trailer backup assist mode including interpreting a first instantaneous position of the rotary element as a trailer control commanding position and generating a vehicle steering command based thereon. The controller also executes a parking assist mode including implementing a parking assist action corresponding to a second instantaneous position of the rotary element.
p4917
aVAbstract\u000aAn apparatus includes a steering assist torque determination unit and a steering assist torque control unit. The steering assist torque determination unit determines a steering assist torque including a first component that is determined on the basis of a deviation between an actual steering angle and a target steering angle for achieving a target path determined irrespective of driver's steering. The steering assist torque control unit controls a steering assist mechanism such that the steering assist torque is applied. The ratio of the magnitude of the first component of the steering assist torque to the deviation between the target steering angle and the actual steering angle is determined on the basis of the magnitude of the deviation between the steering assist torque and the driver's steering torque in a past predetermined period.
p4918
aVAbstract\u000aA vehicle active suspension system, a vehicle, and a method of controlling a vehicle active suspension system are provided. The vehicle active suspension system may include a suspension actuator and a controller. The controller may be programmed to, in response to an object being detected within a predetermined range of a vehicle while a vehicle speed is greater than a threshold speed, categorize the object into at least one of a plurality of predefined categories. The controller may be further programmed to actuate the suspension actuator according to a predefined actuation profile.
p4919
aVAbstract\u000aAn autonomous vehicle support system, including a lighting network (100) having, a plurality of light units (106-1, . . . , 106-N) wherein at least one light unit includes at least one sensor type (110-1, . . . , 110-N), and a centralized or distributed controller (102, 105-1, . . . , 105-N), wherein a first light unit (106-1, . . . , 106-N) receives sensor data from its sensor type (110-1, . . . , 110-N), wherein the controller (105-1, . . . , 105-1) forms a local environmental perception of an area local to the first light unit (106-1, . . . , 106-N), using the received sensor data from light unit, and receives sensor measurement data from an autonomous vehicle relating to at least a portion of the area, and cross-validates the local environmental perception of the area and the sensor measurement data from the autonomous vehicle.
p4920
aVAbstract\u000aA method performed by an evasive maneuver system for providing a driver behavior adapted evasive maneuver to a vehicle at risk of an impending or probable collision. The evasive maneuver system detects a driving environment, determines that the vehicle is at risk of colliding with an obstacle, determines a drivable zone considered safe driving for the vehicle, detects a driver initiated collision avoidance maneuver, and intervenes in control of the vehicle, such that the vehicle is maintained within the drivable zone.
p4921
aVAbstract\u000aA method and a system to present samples of products to customers by transporting the samples to the customer's location with an autonomous vehicle. The sample can be a product, a component of a product, a material or a device to gather information in defining the product. The autonomous vehicle is adapted for off road travel and may enter buildings, it can be carried to a nearby location by a street adapted vehicle. Information may be transmitted electronically but physical presence is essential. The customer or the customer's agent receives a presentation of the product definer and a selection of a final product is made. In other cases the autonomous vehicle delivery separate or installed technical equipment to examine the presentation location and assist in the final product selection. For example, photographs from multiple locations can measure a room for installation of carpets or draperies, etc.
p4922
aVAbstract\u000aA trailer backup assist system includes a sensor that senses a hitch angle between a vehicle and a trailer. The trailer backup assist system also includes a steering input device that provides a backing path of the trailer. Further, the trailer backup assist system includes a controller that generates a steering command for the vehicle based on the hitch angle and the backing path. The controller generates a countermeasure for operating the vehicle when the sensor fails to sense the hitch angle.
p4923
aVAbstract\u000aA system for an autonomous vehicle is disclosed that combines information from single-channel encoders serving as wheel speed sensors on multiple wheels of the vehicle. A pattern of the outputs from the single-channel encoders is characterized while the vehicle is traveling in a first direction. A shift in the characterized pattern is associated with a change in direction of the autonomous vehicle. Such detection of changes in direction can be used to determine the position of the vehicle at low speeds or while starting and/or stopping where the vehicle can potentially rock back and forth.
p4924
aVAbstract\u000aA vehicle includes a steering system, a vehicle speed detector, a brake system, and a control system. The control system is coupled with steering system for implementing a backup mode for reversing a trailer including controlling the steering system to maintain the trailer along a path. The control system is further coupled with the speed detector and the brake system and selectively outputs a rate-limited brake torque demand to the brake system to maintain a vehicle speed below a threshold speed.
p4925
aVAbstract\u000aThe present disclosure is directed to an autonomous vehicle having a vehicle control system. The vehicle control system includes an image processing system. The image processing system receives an image that includes a light indicator. The light indicator includes an illuminated component. The image processing system determines a color of the illuminated component of the light indicator and an associated confidence level of the determination of the color of the illuminated component. The image processing system also determines a shape of the illuminated component of the light indicator and an associated confidence level of the determination of the shape of the illuminated component. The determined confidence levels represent an estimated accuracy of the determinations of the shape and color. Additionally, the image processing system provides instructions executable by a computing device to control the autonomous vehicle based on at least one of the determined confidence levels exceeding a threshold value.
p4926
aVAbstract\u000aThe transportation system in this invention provides vehicle coupling units which allow the electrical connections and reconfigurations of two or more vehicles together at highway speeds. The coupling unit provides for the bidirectional exchange of electrical power between these vehicles to meet the various power demands of each vehicle. The system is designed to permit coupling and decoupling process of the vehicles while they are traveling at highway speeds. To facilitate the coupling event, each vehicle will employ vehicle active steering, vehicle active suspension, and coupler joint articulation, which will be under vehicle computer control, and will employ vehicle to vehicle data communication. This transportation system allows the electric vehicles to electrically and mechanically couple together for flexible electrical power sharing to achieve the extension of the range of electrically powered vehicles to minimize the time needed for stationary re-charging of electrical vehicles required by electrical charging stations.
p4927
aVAbstract\u000aA control system for a vehicle includes a steering system, an input including a rotatable rotary element, and a controller. The controller receives a trailer backup assist mode initiation command from the input and activates a trailer backup mode including outputting a vehicle steering command based on a first instantaneous position of the rotary element to the steering system. The controller further receives a terrain management mode initiation command from the input and activating a terrain management mode.
p4928
aVAbstract\u000aA vehicle and method of operating a vehicle are provided. The method includes providing a vehicle and at least one drive element in operable communication with the vehicle for providing movement to the vehicle. A plurality of power sources are also provided for providing power to the drive element along with at least one power source securing member for releasably securing a desired number of power sources to the vehicle. The method further includes connecting a desired number of power sources to the vehicle via the securing member to provide power to the drive element, each power source being readily removable from the vehicle so that only the desired number of power sources are used for a particular vehicle use to minimize the weight and therefore power consumption of the vehicle.
p4929
aVAbstract\u000aA trailer backup assist system for a vehicle, according to one embodiment, includes a trailer coupled with the vehicle. The trailer of the trailer backup assist system has a braking system. The trailer backup assist system also includes a sensor that senses a hitch angle between the vehicle and the trailer. In addition, the trailer backup assist system includes a steering input device that provides a desired curvature of the trailer. The trailer backup assist system further includes a controller generating a steering command based on the hitch angle for the vehicle to guide the trailer on the desired curvature and an actuation command for the braking system to reduce a rearward travel distance for the trailer to achieve the desired curvature.
p4930
aVAbstract\u000aA spare tire monitoring system is provided. The spare tire monitoring system includes a controller programmed to output a signal indicating that a spare tire is currently being used in response to a difference between a radius of a first tire and a radius of a second tire exceeding a threshold.
p4931
aVAbstract\u000aMethods and systems are provided for implementing a lane control feature for vehicles having a passenger side, a driver side, one or more wheels on the passenger side, and one or more wheels on the driver side. A sensor is configured to obtain information pertaining to operation of a vehicle with respect to a lane of a roadway. The processor is coupled to the sensor, and is configured to at least facilitate determining, using the information, whether the lane control feature is activated, and providing differential torque between one or more driver side wheels and one or more passenger side wheels when the lane control feature is activated.
p4932
aVAbstract\u000aAn object detection system for autonomous vehicle, comprising a radar unit and at least one ultra-low phase noise frequency synthesizer, is provided. The radar unit configured for detecting the presence and characteristics of one or more objects in various directions. The radar unit may include a transmitter for transmitting at least one radio signal; and a receiver for receiving the at least one radio signal returned from the one or more objects. The ultra-low phase noise frequency synthesizer may utilize Clocking device, Sampling Reference PLL, at least one fixed frequency divider, DDS and main PLL to reduce phase noise from the returned radio signal. This proposed system overcomes deficiencies of current generation state of the art Radar Systems by providing much lower level of phase noise which would result in improved performance of the radar system in terms of target detection, characterization etc. Further, a method or autonomous vehicle is also disclosed.
p4933
aVAbstract\u000aA vehicle control system configured to suppress engine noise in an autonomous mode is provided. An operating mode of the vehicle can be switched between a manual mode in which a driving force and a braking force of the vehicle are controlled by a manual operation and an autonomous mode in which the driving force and the braking force of the vehicle are controlled autonomously. The vehicle control system is configured to shift an upshifting point for reducing a speed ratio of a transmission to a low speed side in the autonomous mode, in comparison with the upshifting point set in the manual mode.
p4934
aVAbstract\u000aA backup assist system for a vehicle and trailer combination includes a steering system and a first sensor detecting a first dynamic condition of the combination. The system further includes a controller receiving a value for the first dynamic condition from the first sensor at a plurality of instances. The controller further solves for a corresponding plurality of parameters in a kinematic model of the combination and controls the steering system using the plurality of parameters in the kinematic model.
p4935
aVAbstract\u000aArrangements herein relate to an adaptive-alert system for an autonomous vehicle. The system can include a communications circuit interface that can be configured to communicate with an occupant sensor and to receive from the sensor physical state information associated with the occupant. Some of the physical state information may be acquired by the sensor prior to the occupant engaging the vehicle. The system can also include a processor and a warning circuit that can be configured to generate alerts having different levels of severity. The processor can be configured to cause the warning circuit to generate the alerts in response to a detected operational hazard and receive from the communications circuit interface the physical state information associated with the occupant. The processor can also be configured to, based on the received physical state information, cause a level of severity for at least one of the alerts to be adjusted.
p4936
aVAbstract\u000aAn aft suspension system for a pickup truck comprises four corner assemblies, where one corner assembly is located at a suspension position corresponding to each of the wheel corners for the vehicle. An air supply unit includes a reservoir, a compressor, and an ECU is fluidly connected to the corner assemblies. The air supply unit is capable of independently adjusting the corner assemblies from one another. The air suspension system is operable to place the corner assemblies in a unloading position or a trailer, which corresponds to two of the corner assemblies in raised positions and the other of the two corner assemblies located in lowered positions to create a maximum height differential between the front and rear corner assemblies.
p4937
aVAbstract\u000aComputer-based systems and related operating methods for an autonomous vehicle transportation system are presented here. Various features, functions, and methodologies are utilized by the transportation system to enhance personal safety and security for passengers. Security, privacy, and safety features can be provided based on a ride reservation type, the identity or user profiles of passengers, and the like. A security alert feature can also be provided onboard the autonomous vehicles.
p4938
aVAbstract\u000aA fault-tolerant high-performance computer system is provided for executing control processes for autonomous maneuvering of a vehicle.
p4939
aVAbstract\u000aA vehicle includes an engine, a park assist system, a passenger detection system configured to detect at least one passenger, and a processing device. The processing device initiates a shutdown sequence when no passengers are present in the vehicle. The shutdown sequence includes commanding the park assist system to park the vehicle and turning off the engine after the vehicle is parked.
p4940
aVAbstract\u000aA steering input system for a trailer backup assist system includes an input apparatus having a housing and a user-manipulable input element coupled with the housing. The system further includes a controller determining a state of a use condition of the input apparatus and, based on the state of the use condition, one of implementing or disabling a trailer backup assist mode. The trailer backup assist mode generates a vehicle steering command based on an instantaneous position of the input element.
p4941
aVAbstract\u000aSystems and methods are provided for estimating a quality of air in proximity to a vehicle. In one embodiment, a method includes: determining a radius of the vehicle; estimating a number of vehicles within the radius of the vehicle; estimating the quality of air based on the number of vehicles; and selectively generating a control signal to an air inlet valve based on the quality of air.
p4942
aVAbstract\u000aA vehicle lifting and parking aid system having sidewinder wheel units mounted on the axles between the brakes and the spindle of each wheel of a vehicle controlled from a control module located within the vehicle is disclosed. In the deployed position, each sidewinder unit is against the ground surface and lifts the vehicle approximately 0.5\u2033 off the ground. Using joysticks on a control module located within the vehicle, the user is able to operate, i.e. direct, the sidewinders to the left or right at different variations in speed whereby the vehicle is moved to the left or right by way of a rotating gear train.
p4943
aVAbstract\u000aIn a truck vehicle, a controller controls a mechanism to apportion the sum total of weight borne by a tandem axle between a drive axle and a tag axle.
p4944
aVAbstract\u000aA travel control apparatus for a vehicle includes a frontward environment recognition unit, a map information storage unit, a vehicle position information obtaining unit, a traveling road information obtaining unit, a rut information detector, a first course setting unit, a second course setting unit, and a target course setting unit. A target course over a road surface on which a vehicle is to travel is set as a first course on the basis of map information, the target course over the road surface on which the vehicle is to travel is set as a second course or a third course on the basis of rut information, the first course is compared with the second and third courses, and the target course over the road surface on which the vehicle is to travel is set on the basis of traveling road information and the rut information.
p4945
aVAbstract\u000aA method for assisting a driver of a vehicle during a lane change, in which for this purpose, an activation signal which represents an activation of a turn signal of the vehicle, which faces a setpoint direction of travel, and a sensor signal which is provided by at least one sensor of the vehicle and which represents a steering movement for steering the vehicle and/or a change in position of the vehicle within a lane are read in. Using the activation signal and the sensor signal, a control signal for controlling a steering system of the vehicle is provided if the steering movement is counter to the setpoint direction of travel and/or the change in position represents a movement of the vehicle in a direction counter to the setpoint direction of travel.
p4946
aVAbstract\u000aA trailer backup assist system is provided herein. The trailer backup assist system includes a hitch angle sensor configured to determine a hitch angle between a vehicle and a trailer attached thereto. An input device is configured to accept an input command corresponding to a trailer path command curvature. A controller is configured to determine a vehicle threshold speed limit by determining a first vehicle speed limit based on the hitch angle and a second speed limit based on the command curvature. The controller generates a command to limit vehicle speed in a reverse direction below the threshold speed limit.
p4947
aVAbstract\u000aA travel control apparatus for a vehicle includes: a map information storage unit that stores map information; a vehicle position information obtaining unit that obtains position information indicating a position of the vehicle; a traveling road information obtaining unit that obtains traveling road information relating to a traveling road of the vehicle on the basis of the map information and the position information of the vehicle; a target traveling route setting unit that sets a target traveling route of the vehicle on the basis of the traveling road information of the vehicle; a vehicle traveling route estimating unit that estimates an traveling route of the vehicle on the basis of motion information relating to the vehicle; and a controller that performs control so as to reduce a deviation between the target traveling route of the vehicle and the estimated traveling route of the vehicle on the basis of the deviation.
p4948
aVAbstract\u000aA vehicle, a method, a secondary steering system unit and a secondary steering system are provided. The secondary steering system unit comprises: a fault determination arrangement arranged to determine the presence of a fault in the main steering system and a path controller arranged to generate an upcoming path for the host vehicle. The secondary steering system unit is arranged to steer the host vehicle along the path by differential braking upon determination that a fault is present in the main steering system. Furthermore, the secondary steering system is arranged to control the differential braking in dependence of both a yaw torque acting on the host vehicle as a result of the differential braking and a steering angle resulting from a generated alignment torque on a braked steerable wheel caused by the associated wheel suspension scrub radius.
p4949
aVAbstract\u000aA method of moving a vehicle from a start position to end position when the end position cannot be detected by the vehicle's built-in sensors involves determining the start position by a mobile terminal or by the vehicle and determining the end position by the mobile terminal. A driving trajectory of the vehicle is planned within the vehicle, a driving maneuver of the vehicle is initiated by the vehicle or the mobile terminal, and the planned driving maneuver is carried out to reach the end position.
p4950
aVAbstract\u000aA system for correcting steering wheel angle errors of a motor vehicle of the present disclosure may include a steering wheel angle sensor, an actuator angle sensor, and at least one of a wheel speed sensor and a lateral acceleration sensor. The system may further include a controller configured to receive signals from the steering wheel angle sensor, actuator angle sensor, and at least one of the wheel speed sensor and lateral acceleration sensor. The controller may be configured to calculate a correction angle based on the signals, and adjust a steering wheel angle of a steering wheel, as observed by a driver of the motor vehicle, based on the correction angle.
p4951
aVAbstract\u000aA method for loading a vehicle, wherein, based on a digital loading station map of a loading station and a digital transport vehicle map of a transport vehicle, the vehicle drives autonomously from the loading station onto the transport vehicle or vice versa. A loading management system, a loading station, and a computer program are also described.
p4952
aVAbstract\u000aA power system for short trains. In an embodiment, an over-the-road tractor is configured with drive gears on a drive axle to interface with driven gear systems on a rail car. By utilizing the apparatus, a method for efficient delivery of goods in containers on semi-trailers may be achieved, thus saving considerable time, and reducing costs.
p4953
aVAbstract\u000aA backup assist system for a vehicle reversing a trailer includes a trailer sensor module generating a trailer yaw rate and a vehicle sensor system generating a vehicle yaw rate and a vehicle speed. The system further includes a controller determining an estimated length of the trailer based on an estimated hitch angle, the vehicle yaw rate, the vehicle speed, and the trailer yaw rate in view of a kinematic relationship.
p4954
aVAbstract\u000aMethods and systems for monitoring a driver of a vehicle are provided. In accordance with one embodiment, a system includes a sensing unit and a processor. The sensing unit is configured to at least facilitate detecting whether a driver of a vehicle is looking or has recently looked in a direction with respect to the vehicle. The processor is coupled to the sensing unit, and is configured to at least facilitate providing an action based at least in part on whether the driver is looking or has recently looked in the direction.
p4955
aVAbstract\u000aA device may receive a request for imaging of a particular location. The device may identify one or more sensors associated with imaging the particular location. The device may select a sensor, of the one or more sensors, for imaging the particular location. The sensor may be associated with an autonomous vehicle. The device may cause the autonomous vehicle to move the sensor to the particular location. The device may receive imaging of the particular location based on causing the autonomous vehicle to move the sensor to the particular location. The device may selectively combine the imaging of the particular location with archived other imaging of the particular location. The device may provide imaging of the particular location to fulfill the request for imaging of the particular location based on selectively combining the imaging of the particular location with archived imaging of the particular location.
p4956
aVAbstract\u000aAn aspect of the disclosure includes a method, a system and a computer program product for scheduling a pickup of a passenger with an autonomous vehicle at a facility with a plurality of egress locations. The method includes receiving a pickup request for a passenger from a facility having a plurality of egress locations. A first pickup time is determined for each of the plurality of egress locations. A first egress location is selected from the plurality of egress locations based at least in part on the first pickup time at the first egress location, a position of the passenger and a queue time. A first signal is transmitted that includes a proposed pickup time and location to the passenger. An autonomous vehicle is moved from a first location to the first egress location. The passenger is picked up at the first egress location.
p4957
aVAbstract\u000aAn autonomous vehicle is configured to detect an active turn signal indicator on another vehicle. An image-capture device of the autonomous vehicle captures an image of a field of view of the autonomous vehicle. The autonomous vehicle captures the image with a short exposure to emphasize objects having brightness above a threshold. Additionally, a bounding area for a second vehicle located within the image is determined. The autonomous vehicle identifies a group of pixels within the bounding area based on a first color of the group of pixels. The autonomous vehicle also calculates an oscillation of an intensity of the group of pixels. Based on the oscillation of the intensity, the autonomous vehicle determines a likelihood that the second vehicle has a first active turn signal. Additionally, the autonomous vehicle is controlled based at least on the likelihood that the second vehicle has a first active turn signal.
p4958
aVAbstract\u000aVehicles are disclosed which have a lower center of gravity than existing all-terrain, amphibious, and unmanned ground vehicles due to the location of propulsion units and other vehicle components inside the wheels of the vehicle. The vehicles can climb over large obstacles yet are also able to corner at high speeds. The vehicles can be configured for direct manual operation or operation by remote control, and can also be configured for a wide variety of missions.
p4959
aVAbstract\u000aA vehicle steering system includes a first sensor sensing a pinion angle of a handwheel and a second sensor sensing a torsion bar windup angle. An autonomous steering module generates a steering command having an input torque signal. A steering angle controller is configured to determine a filtered handwheel acceleration based on the pinion angle and the windup angle. The steering angle controller also determines an offset torque based on the filtered handwheel acceleration. Further, the steering angle controller applies the offset torque to the input torque signal to define a refined torque signal that compensates for inertia and off-center mass of the handwheel.
p4960
aVAbstract\u000aA vehicle traveling control apparatus includes a vehicle parameter detector, a vehicle parameter estimator, a disturbance-suppressing parameter calculator, an addition rate changer, and a disturbance suppressor. The vehicle parameter detector detects a vehicle parameter. The vehicle parameter estimator estimates, by means of a vehicle model, a vehicle parameter to be outputted in response to an input value. The disturbance-suppressing parameter calculator estimates, based on the vehicle parameters detected by the vehicle parameter detector and estimated by the vehicle parameter estimator, a disturbance generated at a vehicle, and calculates a disturbance-suppressing parameter. The addition rate changer identifies, based on the vehicle parameters detected by the vehicle parameter detector and estimated by the vehicle parameter estimator, the disturbance generated at the vehicle, and variably sets, based on the identified disturbance, an addition rate of the disturbance-suppressing parameter. The disturbance suppressor adds the disturbance-suppressing parameter set by the addition rate changer.
p4961
aVAbstract\u000aA system for measuring and compensating for tire windup occurring in road wheels during parking events. A controller receives data comprising a steering motor current and steering system component movement, from that data determines the amount of tire windup is present, and controls the motor to turn a road wheel to an initial position that allows the tire windup to turn the road wheel to a final position. The final desired position of the road wheel may be one for the desired location of the road wheel itself, for the steering wheel, or for a combination of the two. Final desired angular positions of the steering wheel may be one such that an ignition may have greater visibility or one such that the steering wheel is not locked under load.
p4962
aVAbstract\u000aMethods, systems, and vehicles are provided for controlling an angle of a wheel assembly for vehicle events. In accordance with one embodiment, the vehicle includes a wheel assembly, a structural member, a detection unit, an actuator, and a processor. The detection unit is configured to detect an event for a vehicle that has a wheel assembly. The processor is coupled to the detection unit, and is configured to utilize an actuator to adjust an angle of the wheel assembly in a manner that guides energy absorption or transference from the event toward the structural member.
p4963
aVAbstract\u000aMethods and systems are provided for controlling braking for a trailer that is connected to a vehicle. In accordance with one embodiment, a trailer includes a connector, a parking brake, an actuator, and a processor. The connector is configured to connect the trailer to a vehicle. The parking brake is disposed onboard the trailer. The actuator is coupled to the parking brake. The processor is configured to cause the actuator to engage the parking brake in accordance with engagement instructions provided from the vehicle to the trailer.
p4964
aVAbstract\u000aSystems and method for assigning vehicle suspension dynamics are disclosed. Control signals that correspond to a current driving dynamic of a suspension system of a vehicle are generated. A vehicle state associated with the generated control signals is computed and a non-traditional suspension mode is selected. Based on the computed vehicle state and the selected suspension mode, a suspension height of the vehicle is adjusted.
p4965
aVAbstract\u000aThe invention relates to a method for the at least semi-autonomous manoeuvring of a motor vehicle (1), in which a relative position between the motor vehicle (1) and at least one object (10, 11) in a surrounding area (7) of the motor vehicle (1) is detected by means of a sensor device (9) of the motor vehicle (1), a travel trajectory (12) for travel of the motor vehicle (1) past the at least one object (10, 11) is determined on the basis of the detected relative position, and a collision distance, which describes a distance between the motor vehicle (1) and the at least one object (10, 11) during the travel along the determined travel trajectory (12), is determined, wherein before the travel of the motor vehicle (1) along the travel trajectory (12) an uncertainty area (a, a\u2032) is determined between the motor vehicle (1) and the at least one object (10, 11), and the collision distance is adjusted as a function of the determined uncertainty area (a, a\u2032), and the travel of the motor vehicle (1) along the travel trajectory (12) is controlled as a function of the adjusted collision distance.
p4966
aVAbstract\u000aAn apparatus and a method for controlling a driving mode of a vehicle are provided to control the driving mode according to a short term driving tendency and a long term driving tendency. The apparatus includes a driving information detector that detects driving information to determine driving tendency and a controller that calculates a short term driving tendency index based on the driving. The controller operates at least one of an engine and a transmission based on the short term driving tendency index and calculates a middle term driving tendency index using the short term driving tendency index. A delay time is then determined using the middle term driving tendency index. The controller enters a sport mode based on the short term driving tendency index and releases the sport mode after delaying the delay time when the short term driving tendency index satisfies releasing conditions of the sport mode.
p4967
aVAbstract\u000aA trailer vehicle function control system for a trailer. The system comprises an electronic control unit adapted to central the height of the trailer and communication means adapted to receive data concerning trailer height. In use, the communication means transmits data to the eieetronic control unit and the electronic control unit compares the actual tralier height with the received data concerning trailer height. If the actual trailer height is different to the remived data trailer height the electronic control unit adjusts the trailer height to the received data trailer height.
p4968
aVAbstract\u000aA method of performing an autonomous parking maneuver of a vehicle begins with a human vehicle operator/driver issuing a command to a parking assistance system that the parking maneuver requires at least one vehicle wheel to encounter a vertical obstruction (such as a curb) undetected by a sensor providing information to the system. In reaction to the command, the paring assistance system entering an operating mode wherein a setpoint speed of the vehicle during the maneuver is increased so that it is better adapted to deal with the vertical obstruction. A brake system condition may also be changed when in the operating mode, such as decreasing a brake disk/pad distance. The command may be issued by a vehicle operator standing outside of the vehicle.
p4969
aVAbstract\u000aIn a travel control apparatus for a vehicle, a travel environment information acquisition unit acquires travel environment information on a travel environment of the vehicle. A travel information detector detects travel information on the vehicle in order to execute automatic driving control based on such information pieces. A lateral force generator generates lateral force to be applied to the vehicle during the automatic driving control. A torsion bar is interposed on a torque transmission path of a steering system. A steering wheel angle detector detects a steering wheel angle. A lateral force detector detects the lateral force acting on the vehicle. An intervening steering operation determination unit determines that a driver has performed an intervening steering operation when a characteristic of the detected steering wheel angle and lateral force differs from a reference characteristic that varies univocally when the steering wheel is in a no load condition.
p4970
aVAbstract\u000aA vehicle includes a steering wheel and at least one road wheel. The steering wheel is rotatably connected to a steering-wheel actuator, and the at least one road wheel is movably connected to a steering system. A controller is in communication with the steering system and the steering-wheel actuator. The controller is programmed to determine a steering-wheel angle based on a road-wheel angle, an operation mode, and a steering-compensation type; and to instruct the steering-wheel actuator to rotate the steering wheel according to the steering-wheel angle.
p4971
aVAbstract\u000aA parking assistance system is provided for carrying out an automated parking maneuver of a motor vehicle into a perpendicular parking space transversely with respect to the roadway along a parking trajectory to a parked end position. The parking assistance system is configured to determine an offset between the extent of one object in the direction of the roadway on one side of the parking space and the extent of another object in the direction of the roadway on the other side of the space by way of a sensor system. The parking assistance system is configured to determine a parking trajectory with a parked end position based on the offset.
p4972
aVAbstract\u000aA vehicle includes one or more laser scanners and an on-board vehicle computer system communicatively coupled to the laser scanners. The computer system uses information (e.g., coordinate points) obtained from the laser scanners to calculate a trailer angle (e.g., a cab-trailer angle) for the vehicle. The computer system may include a shape detection module that detects a trailer based on the information obtained from the laser scanners and an angle detection module that calculates an angle of the detected trailer relative to a laser scanner, calculates the orientation of the detected trailer based on that angle and dimensions (e.g., width and length) of the trailer, and calculates a cab-trailer angle based on the orientation of the trailer. The computer system may include an autonomous operation module configured to use the cab-trailer angle in an autonomous or computer-guided vehicle maneuver, such as a parking maneuver or backing maneuver.
p4973
aVAbstract\u000aA radar system in an autonomous vehicle may be operated in various modes and with various configurations. The autonomous vehicle features a radar system having a waveguide with a first waveguide section, a second waveguide section, and a seam between the first and the second waveguide sections. The first waveguide section and the second waveguide section form a waveguide cavity. Additionally, the seam corresponds to a low surface current location of a propagation mode of the waveguide and is formed where the first waveguide section is coupled to the second waveguide section. The height of the first waveguide section may be equal to the height of the second waveguide section. The waveguide also may include a feed configured to introduce a wave with the propagation mode into the waveguide. Moreover, the waveguide may also include more than one cavity. Each cavity may lie on a plane defined by the seam.
p4974
aVAbstract\u000aThe invention relates to a control system for an autonomous vehicle, a method and an autonomous vehicle. The system comprises an image capturing means capable of capturing at least a first image of the environment of the vehicle and a second image of the environment, wherein the images are captured in a close time relationship but with different image capturing parameters. A processing means configured to obtain and process the images captured with different image capturing parameters separately and taking into consideration a first intensity threshold when processing the first image and a second, different intensity threshold when processing the second image. A control means for generating and outputting a control signal on the basis of a result of the at least one of the processed images.
p4975
aVAbstract\u000aA travel control apparatus for a vehicle includes a travel environment information acquisition unit, a travel information detection unit, and a control unit. The acquisition unit acquires travel environment information of the vehicle, which is on a traveling environment of the vehicle. The detection unit detects travel information of the vehicle. The control unit performs self-driving control, on the basis the information. The control unit detects a relative distance between an oncoming vehicle and the vehicle, and performs turn control to cause the vehicle to make a turn while crossing ahead of the oncoming vehicle, in a case where the relative distance is not smaller than a preset threshold value. When the vehicle makes the turn, in a case where a traction control for preventing tire slippage by decreasing a drive torque is operated, the control unit increasingly corrects the preset threshold value in accordance with at least a tire grip state.
p4976
aVAbstract\u000aA vehicle, a method and a vehicle brake-control-system are provided. The host vehicle comprises a steering wheel, a vehicle brake system, at least one sensor arranged to monitor a sensor monitoring area of a host vehicle surrounding and an autonomous operating arrangement which is arranged to control steering and velocity of the host vehicle in an autonomous operating mode at least partly based on information received from the at least one sensor. The vehicle brake-control-system is arranged to determine if the steering wheel is manually operated when the vehicle is operating in the autonomous driving mode, and if so control the vehicle brake system to perform braking of the host vehicle.
p4977
aVAbstract\u000aMethods and systems are provided for facilitating communications between a vehicle and a trailer. In accordance with one embodiment, a system includes a memory, and a processor, and a transceiver. The memory is disposed onboard a trailer that is configured to be connected to a vehicle. The memory stores trailer-specific information pertaining to the trailer. The processor is disposed onboard the trailer, and is coupled to the memory. The processor is configured to provide instructions to automatically transmit the trailer-specific information to the vehicle, for customization of vehicle operation based on the trailer-specific information. The transceiver is coupled to the processor. The transceiver is configured to automatically transmit, based on the instructions provided by the processor, the trailer-specific information to the vehicle, for customization of vehicle operation based on the trailer-specific information for when the trailer is connected to the vehicle.
p4978
aVAbstract\u000aAn apparatus designed to push a vehicle to a desired location with enhanced efficiency and reduce a likelihood of damage to the vehicle is provided. The apparatus includes a housing member, a compressible cushion member coupled to the front face of the housing member, a first pair of wheels coupled to the housing member proximate the front face, a second pair of wheels coupled to a bottom portion of the housing member, and a motor assembly disposed within the housing member and operably connected to the second pair of wheels. The motor assembly includes a motor that drives the second pair of wheels to permit the first pair of wheels to elevate above a ground surface beneath the housing member when the cushion member contacts an end of the vehicle, thereby permitting the apparatus to push the vehicle.
p4979
aVAbstract\u000aSystems and methods for automatically removing snow and/or ice from a portion of a vehicle exterior surface are provided. The automatic removal is in response to a determined driving distance or driving time to a destination. The systems include a vehicle navigation unit in communication with a snow removal element. When the navigation unit determines that the current driving distance or driving time to a destination is less than a pre-determined activation point, the frozen precipitate removal element is activated. The systems and methods of the present disclosure can have the benefit of removing snow or ice from a vehicle exterior surface before the vehicle arrives at a destination such as a storage garage, thereby minimizing the deposition of snow or ice at the destination.
p4980
aVAbstract\u000aAn automobile-RV trailer hitch, the first half of which is securely mounted to the rear underside of the automobile, and the second half of which is securely mounted to the underside of the trailer. When the trailer is attached to the automobile, the two hitch halves interlock. A locking rod is inserted horizontally to cause the hitch to act as a single unit. Horizontal rotation is prevented, but the trailer is able to pivot vertically around the locking rod to compensate for the trailer going over bumps in the road.
p4981
aVAbstract\u000aMethods and systems for controlling torque for a front axle and a rear axle of a vehicle with independent front and rear propulsion systems are provided. A data unit is configured to obtain data for one or more parameters of a vehicle while the vehicle is being driven. A processor is coupled to the data unit, and is configured to provide torque to at least facilitate providing torque the front axle and the rear axle independently based on the one or more parameters.
p4982
aVAbstract\u000aA motor vehicle for use in chauffeur operation, in particular a taxi or a limousine, has at least one driver's seat, at least one foot pedal and at least two front wheels. In order to design a vehicle to meet the specific requirements of short-distance chauffeur operation, the driver's seat is arranged between the front wheels in such a way that the foot pedal is positioned, viewed in the driving direction, between the axles, preferably in front of the front wheel axle.
p4983
aVAbstract\u000aDisclosed is a vehicle including a plurality of wheels mounted on at least one axle. Additionally, the vehicle includes a plurality of electric motors corresponding to the plurality of wheels. Further, each electric motor of the plurality of electric motors is operationally coupled to the at least one axle corresponding to a respective wheel of the plurality of wheels. Moreover, the vehicle includes at least one sensor configured to sense a state of at least one part of the vehicle. Further, the vehicle includes a controller configured to control operation of each of the plurality of electric motors based on the state of at least one part of the vehicle. Additionally, the controller is further configured to control operation of at least one electric motor independent of controlling operation of at least one other electric motor of the plurality of electric motors.
p4984
aVAbstract\u000aA method is provided for resuming the movement of a motor vehicle after unforeseen stopping in an automated parking process performed by a parking assistance system having automated longitudinal and transverse guidance. If the vehicle is stopped, a decision is made about a resumption of movement of the vehicle in the prior direction of travel that existed before the vehicle was stopped. The decision is made in dependence on the remaining travel path from the current position to the next planned stopping point of the trajectory lying in the prior direction of travel. A stopping point of the trajectory can be a reversal point or the final parking position, for example. If the decision is positive, the movement of the vehicle is resumed in the prior direction of travel. If the decision is negative, the movement of the vehicle is resumed against the prior direction of travel. Alternatively, in the case of a negative decision, the movement of the vehicle may not be resumed and the parking process may be ended.
p4985
aVAbstract\u000aAn aerodynamic component in the form of, for example, a fairing is provided. The fairing is attached or otherwise positioned at the entry of or within the fender well of the vehicle. In use, the fender well fairing aims to block entry of airflow into the interior area of the vehicle as well as reduces or eliminates direct impingement against interior surfaces of the fender well. This improves air flow, thereby reducing drag.
p4986
aVAbstract\u000aA vehicle traveling control apparatus includes an abnormality determining unit and a seat belt controller. The abnormality determining unit determines presence of impaired consciousness of a driver on a condition that the vehicle traveling control apparatus performs, to an own vehicle, automatic driving on a basis of traveling environment information on a traveling environment in which the own vehicle travels and traveling information of the own vehicle. The seat belt controller causes a seat belt of a driver's seat of the own vehicle to be retracted, when the abnormality determining unit determines the presence of the impaired consciousness.
p4987
aVAbstract\u000aAspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.
p4988
aVAbstract\u000aA system is provided that automatically assesses weight rating characteristics of a truck and trailer combination. The system coordinates movement and unloading functions of the grain cart to automatically load the trailer to correspond to a target total weight value and a target weight distribution value based on axle weight ratings of the axles of the truck and trailer combination.
p4989
aVAbstract\u000aA method for controlling a motor vehicle according to the invention includes steps of ascertaining a driving strategy as a function of an environment; detecting a driving strategy of a motor vehicle driving ahead; ascertaining that the driving strategies deviate from each other; and controlling the motor vehicle in accordance with the driving strategy of the motor vehicle driving ahead.
p4990
aVAbstract\u000aThe invention comprises an improved method and apparatus for securing a tractor-trailer or other powered vehicle to a flatbed railcar (flatcar). The vehicle is driven onto the flatcar until the powered wheels of the vehicle reach a set of rollers. The vehicle then drives these rollers (or a treadmill) which power a mechanical, hydraulic, and pneumatic system which latches the wheels of the vehicle to the flatcar.
p4991
aVAbstract\u000aA wiper blade with integral washer nozzles including a blade rubber for wiping a glass of a vehicle, a spoiler combined with a retainer of a wiper arm, secondary levers combined with the spoiler, and yokes combined with the secondary levers, respectively, and supporting the blade rubber, may have a washer nozzle module integrally combined with the spoiler and spraying washer fluid supplied through washer fluid hoses in two directions with respect to the spoiler, wherein the washer nozzle module has washer fluid channels formed therein in a longitudinal direction of the spoiler to spray the washer fluid in two directions, nozzles formed along the washer fluid channels and spraying the washer fluid supplied through the washer fluid channels, and inlets communicating with the washer fluid channels, respectively, and connected with the washer fluid hoses for supplying the washer fluid.
p4992
aVAbstract\u000aA camera system for a vehicle includes a body defining a cavity therein, and a camera including a lens. The camera is disposed in a deployed position such that the lens protrudes from the cavity. The camera system includes a debris region covering the lens and a duct disposed within the cavity. The duct defines a channel therein and has a first end spaced apart from the camera and a second end spaced apart from the first end. The duct is configured for directing an airstream through the channel from the first end to the debris region. A vehicle including the camera system is also disclosed.
p4993
aVAbstract\u000aAn apparatus and method for controlling autonomous vehicle platooning are disclosed. The apparatus for controlling autonomous vehicle platooning includes a frame format configuration unit, a synchronization unit, and a contention window assignment unit. The frame format configuration unit configures the format of a frame included in a communication channel applicable to the control of autonomous vehicle platooning. The synchronization unit synchronizes a plurality of vehicles with one another using the frame so that the vehicles can perform the autonomous vehicle platooning. The contention window assignment unit assigns the different contention window values of a slot for management of the frame to the respective synchronized vehicles. The control is performed using the assigned contention window values so that the vehicles can participate in the autonomous vehicle platooning.
p4994
aVAbstract\u000aMethods and systems for determining deviations is expected range, expected fuel economy, or both, for a vehicle. In accordance with one embodiment, a system includes a sensor unit and a processor. The sensor unit is configured to at least facilitate obtaining inputs for one or more factors having an effect on energy performance and/or fuel efficiency for a vehicle. The processor is coupled to the sensor unit, and is configured to at least facilitate determining a change in expected range for the vehicle from the one or more factors based on the inputs.
p4995
aVAbstract\u000aA utility vehicle includes a frame, a power source, and a plurality of steerable structures. Ground engaging members are connected to the steerable structures. An operator seating area includes a steering control and a speed control. Controllers receive input from the steering control and the speed control. Motors drive the ground engaging members at different speeds and in different directions. A controller integrates a steering input with a speed input to effect rotation of the steerable structures and effect rotation of the ground engaging members. The steering control, speed control, controllers, steerable structures, and motors are configured to work together to control the rotational speed of all of the ground engaging members based upon a steering angle input and the lateral side the ground engaging member is connected to. Other examples include braking mechanisms, adjustable track width, and a sealed tubular frame.
p4996
aVAbstract\u000aA window washer system for a vehicle may include a fluid reservoir and a nozzle. The fluid reservoir may be disposed on an exterior side of a tailgate of the vehicle and may be adapted to store a quantity of window washer fluid. The nozzle may be in fluid communication with the fluid reservoir and may be operable to deposit the window washer fluid onto a rear window of the vehicle. The window washer system may be disposed proximate a spare tire carrier.
p4997
aVAbstract\u000aDisclosed is a method for determining the axle load of a vehicle (10) having at least two tires on an axle. During cornering, the axle load is determined from a difference between wheel speeds at a wheel on the inside of the bend and wheel speeds at a wheel on the outside of the bend and by taking into account the lateral acceleration and track width.
p4998
aVAbstract\u000aA self-steering bogie for an elongate road vehicle having at least a first axle assembly at the front end of the vehicle and at least one trailing axle assembly disposed on the vehicle behind said first axle assembly. The trailing axle assembly is a set of tandem axles with associated wheels disposed below a structural frame of the vehicle, the bogie comprising a rotatable sub-frame borne on the set of tandem axles which supports the vehicle by means of a load bearing turntable. A rotational restraint assembly is mounted on the turntable and which in part interconnects the sub-frame, the structural frame and an upper portion of the turntable, the rotational restraint assembly having a plurality of compression air springs. The elongate road vehicle could be a truck and semitrailer where the trailing axle assembly is on the semitrailer, or a vehicle such as a bus.
p4999
aVAbstract\u000aA humanized steering system for an automated vehicle includes one or more steering-wheels operable to steer a vehicle, an angle-sensor configured to determine a steering-angle of the steering-wheels, a hand-wheel used by an operator of the vehicle to influence the steering-angle and thereby manually steer the vehicle, a steering-actuator operable to influence the steering-angle thereby steer the vehicle when the operator does not manually steer the vehicle, a position-sensor operable to indicate a relative-position an object proximate to the vehicle, and a controller. The controller is configured to receive the steering-angle and the relative-position, determine, using deep-learning techniques, a steering-model based on the steering-angle and the relative-position, and operate the steering-actuator when the operator does not manually steer the vehicle to steer the vehicle in accordance with the steering-model, whereby the vehicle is steered in a manner similar to how the operator manually steers the vehicle.
p5000
aVAbstract\u000aA method for detecting a vehicle collision includes a rear sensor provided at a rear of the vehicle figuring out a position of an obstacle, a controller of the vehicle accumulating the position of the obstacle recognized by the rear sensor to generate obstacle map data, and the controller signaling an alarm in the vehicle in the case in which a distance between the obstacle map data and the vehicle is a predetermined distance or less or in the case in which movement of the vehicle is decided through a current position of the vehicle, steering of the driver, a wheel speed, and a gear input and there is a collision risk between the vehicle and the obstacle.
p5001
aVAbstract\u000aA road trailer (1) includes, under a chassis (2) with fixed draw bar (4), a main wheelset (3) and a secondary wheelset (6). A retraction device (M, V, 6 d) allows the wheelset (6) to be moved in such a way that the trailer (1) rests on the ground (S) selectively either via the main wheelset (3) or via the secondary wheelset (6). An orientation device allows the secondary wheelset (6) to have its direction oriented according to a reversing path followed by a towing vehicle (5) to which the trailer (1) is hitched. Orienting the secondary wheelset (6) allows the trailer (1) to be kept always along the axis of the towing vehicle (5) during reversing.
p5002
aVAbstract\u000aA radar system in an autonomous vehicle may be operated in various modes and with various configurations. In one example, the radar system determines a target range for further interrogation. The target range may be determined based on the radar system transmitting a first electromagnetic radiation signal and receiving a first reflected electromagnetic signal radiation signal. After the radar system determines a target range, it transmits a second electromagnetic radiation signal. Additionally, the radar system receives a reflected electromagnetic signal radiation based on the transmission. After receiving the reflected signal, the radar system can process the reflected signal to only have components associated with the target range. The processing of the reflected signal may create a processed signal. Finally, the radar system may determine at least one parameter of a target object based on the processed signal.
p5003
aVAbstract\u000aA method for determining a lane-adaptation parameter for a lane-keeping system of a vehicle having at least one surround sensor. The method includes reading in, from a sensor signal from the at least one surround sensor, an obstacle-extension area of a visibility obstacle, caused by at least one vehicle driving in front, transversely to a course of a traffic lane on which the vehicle is to travel. The method also includes ascertaining the lane-adaptation parameter as a function of the read-in obstacle-extension area and a vehicle-extension area transversely to the course of the traffic lane in which the vehicle is to travel. The lane-adaptation parameter is determined so that when using the lane-adaptation parameter, the lane-keeping system is set up to reduce an overlap of the obstacle-extension area and the vehicle-extension area.
p5004
aVAbstract\u000aA method of controlling operation of an all-wheel-drive vehicle having independent power-sources includes driving the vehicle via at least one of a first power-source through a first set of wheels and a second power-source through a second set of wheels. The method also includes determining a rotating speed of each of the first and second sets of wheels relative to a road surface. The method additionally includes determining a road speed of the vehicle and determining a longitudinal acceleration of the vehicle. The method also includes determining a slip of the vehicle relative to the road surface using the determined rotating speed of each of the first and second sets of wheels and the speed of the vehicle. Furthermore, the method includes controlling the vehicle slip via regulating a torque output of the first and/or second power-source.
p5005
aVAbstract\u000aA method of providing automatic collision avoidance in a vehicle with a front wheel electric power steering (EPS) system and rear wheel active rear steering (ARS) system and an automatic collision avoidance system are described. The method includes generating a vehicle math model including the control variables, designing a steering control goal as a criterion to determine the control variables, and implementing a model predictive control to solve the steering control goal and determine the control variables. The method also includes providing the control variables to the EPS system and the ARS system to respectively control a front actuator associated with front wheels and a rear actuator associated with rear wheels.
p5006
aVAbstract\u000aDescribed embodiments include a system and method. A system includes a first and second digital imaging devices. Each digital imaging device is configured to capture digital images of a surface traveled by a vehicle. A digital image correlator is configured to (i) correlate a first digital image of the surface captured by a first digital imaging device at a first time and a second digital image of the surface captured by a second digital imaging device at a subsequent second time, and (ii) determine a correlation vector. The first and second imaging devices are separated by a known distance. A kinematics circuit is configured to determine in response to the correlation vector an incremental translation and rotation of the vehicle. The system includes a navigation circuit configured to combine at least two instances of the incremental translation and rotation into data indicative of travel by the vehicle.
p5007
aVAbstract\u000aA driver assist arrangement includes a first yaw rate controller, a hazard evaluation unit, a driver intention evaluation unit, and a second yaw rate controller. The first yaw rate controller is configured to control a yaw rate of a vehicle hosting the arrangement by comparing an expected yaw rate with an actual yaw rate, and in response thereto selectively apply brakes of respective wheels of the host vehicle. The second yaw rate controller is configured to intervene in the control of the first yaw rate controller in case the evaluated risk of an accident is above a threshold value and occurrence of an avoidance maneuver initiated by the driver is detected. A vehicle including a driver assist arrangement and a method of assisting a driver of a vehicle are also provided.
p5008
aVAbstract\u000aPower steering system including: an electric pump to supply fluid to a power steering unit; and an engine control unit (ECU) to control an amount of the fluid by a rotation speed of the electric pump. The ECU includes a first device for calculating an on-slope standby rotation speed and setting the electric pump to this speed when a vehicle is descending or ascending a slope. This speed is calculated by correcting a standby rotation speed of the electric pump corresponding to a vehicle speed with a slope correction value calculated according to a slope angle or a vehicle body angle. Accordingly, it is possible to supply the fluid with the electric pump and assist a steering operation to suppress both a jerky steering feeling due to insufficient steering force in slope descent and a lack of response in the steering operation due to excessive steering force in slope ascent.
p5009
aVAbstract\u000aA prevention safety device in course change of small-sized vehicle includes a rear vehicle detector, a detection state determining unit, and a vehicle's own information transmitting unit. The rear vehicle detector is configured to detect a rear vehicle travelling at a rear of one's own vehicle. The detection state determining unit is configured to determine whether the rear vehicle detects one's own vehicle or not when the rear vehicle detected by the rear vehicle detector is an autonomous vehicle. The vehicle's own information transmitting unit is configured to transmit vehicle's own information to the rear vehicle immediately before one's own vehicle changes a course when the detection state determining unit determines that the rear vehicle does not detect one's own vehicle.
p5010
aVAbstract\u000aA non-track-bound vehicle operates on a route electrified by an overhead contact system. The vehicle has a current collector for energy transfer between the vehicle and an overhead cable. It has a lowering mechanism for the transfer of the current collector from an upright operational position in which the current collector is in sliding contact with the contact wires into a lowered neutral position in which the current collector is arranged within a vehicle clearance profile. An actuating element is provided for the simultaneous activation of the lowering mechanism and an additional vehicle device. The activation of the actuating element is intended in a driving situation requiring the lowering of the current collector. The operation of non-track-bound vehicles is safer even in critical driving situations, such as for example, maneuvers to avoid or overtake other vehicles at high speed.
p5011
aVAbstract\u000aA method of prioritizing power output of first and second power-sources in a vehicle includes identifying, via a controller communicating with a satellite, the vehicle's position on a specific road course. The method also includes receiving a request for total amount of power from both power-sources and determining first power-source power and available second power-source target maximum power based on the vehicle position. The method also includes determining, based on the vehicle position, a minimum energy reserve of a source configured to energize the second power-source and available second power-source power based on the determined reserve. The method also includes subtracting the first power-source power from the requested total amount of power to determine a requested second power-source power. Furthermore, the method includes comparing the available and the requested second power-source power and generating the smaller power value to minimize the time for the vehicle to traverse the road course.
p5012
aVAbstract\u000aA steering input apparatus for a vehicle includes a grip position sensor configured to sense a grip position on a rim of a steering wheel of the vehicle. The steering input apparatus also includes at least one processor configured to, based on a determination that the grip position on the rim of the steering wheel sensed through the grip position sensor is improper for a driving situation of the vehicle, perform a control operation to output grip guide information for the rim of the steering wheel.
p5013
aVAbstract\u000aThe present disclosure is directed to an autonomous vehicle having a vehicle control system. The vehicle control system includes an image processing system. The image processing system receives an image that includes a plurality of image portions. The image processing system also calculates a score for each image portion. The score indicates a level of confidence that a given image portion represents an illuminated component of a traffic light. The image processing system further identifies one or more candidate portions from among the plurality of image portions. Additionally, the image processing system determines that a particular candidate portion represents an illuminated component of a traffic light using a classifier. Further, the image processing system provides instructions to control the autonomous vehicle based on the particular candidate portion representing an illuminated component of a traffic light.
p5014
aVAbstract\u000aMethods and systems are provided for controlling a remote start feature of an engine of a vehicle. A receiver is configured to receive a signal to initiate a remote start of the engine. A processor is coupled to the receiver, and is configured to initiate the remote start after receiving the signal; set a timer that measures an amount of time after which the remote start has been initiated, for a duration of the remote start; extend the remote start upon detection of an action by an individual proximate the vehicle before the amount of time exceeds a first predetermined threshold; and terminate the remote start after the amount of time exceeds the first predetermined threshold if no action has been detected during the duration of the remote start.
p5015
aVAbstract\u000aA method for adapting an actual steering wheel angle of a steering wheel and an actual wheel steering angle of a wheel steering system in a motor vehicle after an automated driving maneuver has been executed. The method includes detecting the actual steering wheel angle by a steering wheel angle-detection device and the actual wheel steering angle by a wheel steering angle-detection device, adapting the actual steering wheel angle by a steering wheel-actuation device and/or the actual wheel steering angle by a wheel steering-actuation device based on a transfer strategy within a predefined transfer time. Also disclosed is an associated device.
p5016
aVAbstract\u000aA method for providing a warning that a trailer being towed by a vehicle will cross out of a travel lane when in a curve for the current vehicle path prior to the vehicle entering the curve. The method determines that the vehicle is approaching the curve, determines a radius of curvature of the curve, determines a lane width of the travel lane, and identifying a length of the trailer. The method also determines a predicted steering angle of the vehicle necessary to follow the radius of curvature of the curve, a turn radius of the vehicle for traveling through the curve using the predicted steering angle, and a turn radius of the trailer using the turn radius of the vehicle. The method then determines whether the trailer will cross out of the travel lane based on the curvature of the curve and the turn radius of the trailer.
p5017
aVAbstract\u000aA control system or controller (190) for a vehicle (100), the vehicle (100) comprising: at least one energy-consuming subsystem (180), such as a battery cooling system (180), for controlling a or a respective first vehicle operating parameter, e.g. the battery operating temperature, and actuation means for the subsystem (180) for activating or deactivating it in accordance with vehicle operational requirements; wherein the control system (190) is configured to: determine a value of a or a respective second vehicle operating parameter which is dependent on a location of the vehicle (100), such as a distance (x, y) between a current location of the vehicle and a reference location, e.g. a driver's home or workplace, and control the actuation means of the subsystem (180) so as to deactivate the subsystem (180), optionally for a prescribed period of time, in dependence on the value of the determined vehicle location-dependent second vehicle operating parameter. Since the reference location is optionally a location at which the vehicle is expected to be parked and so will not require active battery cooling, when the vehicle is within easy reach of that destination, e.g. according to current battery temperature or predicted drive time to that destination, the battery cooling system (180) can be temporarily deactivated, in order to save energy wastage and battery drain, and improve fuel economy and electric range. Embodiments are applicable to other energy-hungry vehicle systems, e.g. heating or cooling systems (182, 184) of other vehicle components.
p5018
aVAbstract\u000aDescribed embodiments include a system and method. A digital imaging device is configured to capture images of a region of a contact between a wheel of a terrestrial vehicle and a surface (\u201ccontact region\u201d). A correlator is configured to correlate a first digital image of the contact region captured at a first time with a second digital image of the contact region captured at a second time. A kinematics circuit determines an incremental slide or slip of the wheel relative to the surface. A fraction status circuit combines at least two instances of the incremental slide or slip into data indicative of a slide or slip by the terrestrial vehicle relative to the surface. A communications circuit outputs an electronic signal indicative of the data indicative of a slide or slip by the terrestrial vehicle.
p5019
aVAbstract\u000aA vehicle charging system may include a drive system mounted to a chassis, a positionable electrical connector assembly, a position sensor, a proximity sensor, and a control module. The control module may be programmed to operate the drive system to place the chassis proximate a vehicle electrical connector and operate the positionable electrical connector assembly to releasably engage the vehicle electrical connector.
p5020
aVAbstract\u000aDisclosed herein are a vehicle configured to prevent a collision and a control method thereof. The vehicle includes a chassis; a steering unit configured to change a direction of the chassis; a brake unit configured to adjust a braking force of the chassis; a detector configured to detect movement information of the chassis; and a controller configured to confirm a variation rate of movement of the chassis based on the detected movement information and configured to automatically control an operation of the steering unit and the brake unit when the confirmed variation rate is out of a reference range. When a collision occurs, the vehicle may automatically perform at least one of steering control, side braking control, or a damping control, and thus a secondary collision may be prevented, the incidence of additional injury may be reduced, the speed of the vehicle may be stably reduced or stopped, and the vehicle may be moved to a safe lane so that a stabilization time of the vehicle may be reduced.
p5021
aVAbstract\u000aA vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.
p5022
aVAbstract\u000aTo achieve a general improvement in the driving stability of a motor vehicle, it is proposed to control the driving stability of the motor vehicle based on a continuously determined environment model, wherein the environment model is used for predictive adaptation of existing vehicle dynamics control systems.
p5023
aVAbstract\u000aA structure for reinforcing a rear vehicle body may include a roof side rail extending in the longitudinal direction of a vehicle and forming the roof of the vehicle which is overlapped and coupled to a quarter panel extending rearward in the longitudinal direction of the vehicle and coupled to the upper portions of a rear pillar, a rear wheel housing, and a rear combination, and the rear end of the roof side rail in the longitudinal direction of the vehicle is extended and coupled to the rear end of the quarter panel in the longitudinal direction of the vehicle.
p5024
aVAbstract\u000aA method for automatic activation of a vehicle turn indicator is disclosed. The method may include determining whether a lane change maneuver is impending in a specified direction. The method may also include determining whether the vehicle turn indicator has been activated through a driver interface. The vehicle turn indicator may be engaged when not activated through the driver interface.
p5025
aVAbstract\u000aAn image switching device for a vehicle includes: a reference distance determination device that determines a reference distance; and a determination device that prohibits an image display device from displaying an image captured by an on-board camera, based on a feature that a detection distance from an object to a vehicle is longer than the reference distance, and allows the image display device to display the image captured by the on-board camera, based on a feature that the detection distance is shorter than the reference distance. The reference distance determination device shortens the reference distance in a case where an absolute value of acceleration of the vehicle is a second value which is greater than a first value, compared to a case where the absolute value of acceleration of the vehicle is the first value.
p5026
aVAbstract\u000aA method and system for lane recognition including determining availability of vehicle position data obtained from more than one source including a GPS device source and an imaging device source. The method includes modifying a lane error threshold based on the availability of the vehicle position data. The lane error threshold is a lateral distance from a centerline of a lane. The method includes validating lane recognition data based on the lane error threshold.
p5027
aVAbstract\u000aAn automatic braking system for a vehicle is disclosed and includes an electronic brake system capable of applying wheel brakes to decelerate the vehicle and a controller. The controller includes instructions for maintaining the electronic brake system in a pre-charge condition when the vehicle is operating in a reverse gear, and applying the wheel brakes independent of a driver input.
p5028
aVAbstract\u000aA method for improving the safety and comfort of a vehicle driving over a railroad track, cattle guard, or the like. The method may include receiving, by a computer system, one or more inputs corresponding to one or more forward looking sensors. The computer system may also receive data characterizing a motion of the vehicle. The computer system may estimate, based on the one or more inputs and the data, a motion of a vehicle with respect to a railroad track, cattle guard, or the like extending across a road ahead of the vehicle. Accordingly, the computer system may change a suspension setting, steering setting, or the like of the vehicle to more safely or comfortably drive over the railroad track, cattle guard, or the like.
p5029
aVAbstract\u000aA lane shift indicating system for indicating a potential lane shift of a vehicle supporting at least partly automated steering and vehicle speed control, when the vehicle is travelling along a first driving lane of a road having a second driving lane separated from the first driving lane by one or more lane markings. The lane shift indicating system determines a driving environment of the vehicle at an initial vehicle position, and determines that the driving environment indicates that the vehicle is in a driving situation where a lane shift from the first driving lane to the second driving lane is considered appropriate, and adjusts the steering prior to a potential automated vehicle speed adjustment pertinent the determined driving situation, such that the vehicle continues its travel laterally closer to the one or more lane markings along the first driving lane, as compared to the initial vehicle position.
p5030
aVAbstract\u000aA method of operating a wheel chock for assisting an autonomous machine at a worksite is provided. The method includes receiving a signal indicative of one or more operating parameters of the autonomous machine. The method further includes determining if the one or more operating parameters of the autonomous machine indicate a non-operating state of the autonomous machine. The method further includes establishing a communication between the wheel chock and the autonomous machine, if the autonomous machine is in the non-operating state. The method further includes guiding the wheel chock to be placed adjacent with respect to a set of ground engaging members of the autonomous machine to restrict movement of the autonomous machine at the worksite. The wheel chock is guided by an assisting machine. The method further includes moving the wheel chock away from the autonomous machine when the autonomous machine is in an operating state.
p5031
aVAbstract\u000aA method comprises: a preliminary phase wherein a vehicle is aligned to be engaged toward a target position; a first phase wherein a reference trajectory is generated as a function of the status and target position of the vehicle, the status defined by the current position and orientation of the vehicle; a second phase wherein the reference trajectory being divided into sections, at the start of each section and before the vehicle begins a movement whether the reference trajectory can be followed is predicted as a function of imposed overall size constraints and estimated lateral and/or longitudinal slippages; a third phase, if the trajectory can be followed, wherein the turn angle of the wheels and the linear traction speed of the vehicle are controlled as a function of the status of the vehicle and the lateral and/or longitudinal slippages, to bring the centers of the wheels onto the reference trajectory.
p5032
aVAbstract\u000aA vehicle race track driving assistance system may include a location tracking system that tracks the location of the vehicle; a memory for holding race track data indicative of the shape and location of the race track, including a turn on the race track; a steering control system that controllably steers the vehicle; and a controller that causes the steering control system to controllably steer the vehicle into the turn on the race track when the location tracking system and race track data indicate that the vehicle is approaching the turn, the steering being in an amount that is insufficient to cause the vehicle to navigate through the turn without deviating from the race track.
p5033
aVAbstract\u000aA robotic cargo system provides an ability to move cargo without requiring the use of additional material handling equipment such as forklifts and K-loaders. The robotic cargo system may operate as a vehicle during drive maneuvering, and may operate to lockdown on an aircraft as a pallet during flight. The system may navigate over rough terrain while carrying heavy loads through the use of a track-based propulsion system. The system may provide a cargo loading system, ramp ascent and descent algorithms, and autonomous navigation.
p5034
aVAbstract\u000aA control system is configured to receive a first signal indicative of a current position of a vehicle and a second signal indicative of a desired path for the vehicle. The control system is configured to calculate a virtual path between the current position and a target position on the desired path and to output a third signal indicative of curvature command corresponding to an initial curvature of the virtual path to cause a steering control system of the vehicle to adjust a steering angle of the vehicle. The control is also configured to iteratively receive an updated current position, receive any updates to the desired path, calculate an updated target position, calculate an updated virtual path based on the updated current position and updated desired path, and output an updated curvature command corresponding to a respective initial curvature of the updated virtual path as the vehicle travels across a surface.
p5035
aVAbstract\u000aA system for estimating hitch angle offset is provided herein. A sensor system is configured to measure hitch angles between a vehicle and a trailer attached thereto. A controller is configured to calculate hitch angle offsets for a plurality of measured hitch angles, and extrapolate additional hitch angle offsets based on the calculated hitch angle offsets.
p5036
aVAbstract\u000aA vehicle includes a body, an aerodynamic element, a movement mechanism, a plurality of sensors, and a controller. The body is located along a longitudinal axis and a lateral axis. The aerodynamic element intersects ambient airflow, which generates an aerodynamic force. The movement mechanism moves the aerodynamic element, relative to the body, along the longitudinal and lateral axes. The sensors collectively generate input signals corresponding to an operating condition of the vehicle. The controller determines a current position of the movement mechanism, corresponding to a current location of the aerodynamic element on the axes and determines a desired position of the movement mechanism, corresponding to a desired location of the aerodynamic element on the axes. The controller transmits a movement signal to the movement mechanism to change position from the current position to the desired position, such that the aerodynamic element moves from the current location to the desired location.
p5037
aVAbstract\u000aA vehicle control system for operating an automated vehicle in a fashion more conducive to comfort of an occupant of the automated vehicle includes a sensor, an electronic-horizon database, vehicle-controls, and a controller. The sensor is used to determine a centerline of a travel-lane traveled by a host-vehicle. The electronic-horizon database indicates a shape of the travel-lane beyond where the sensor is able to detect the travel-lane. The vehicle-controls are operable to control motion of the host-vehicle. The controller is configured to determine when the database indicates that following the shape of the travel-lane beyond where the sensor is able to detect the travel-lane will make following the centerline by the host-vehicle uncomfortable to an occupant of the host-vehicle, and operate the vehicle-controls to steer the host-vehicle away from the centerline when following the centerline will make the occupant uncomfortable.
p5038
aVAbstract\u000aA target acceleration/deceleration setting unit (28) of a vehicle acceleration/deceleration controller (16) sets a target acceleration or deceleration at a location at which a curve starts to be a predetermined maximum deceleration, sets a target acceleration or deceleration at a location at which the curve ends to be a predetermined maximum acceleration, sets a target acceleration or deceleration at a predetermined intermediate location between the location at which the curve starts and the location at which the curve ends to be zero, and sets a target deceleration D (Ld) at a location to which the travelling distance from the location at which the curve starts is Ld and a target acceleration A (La) at a location to which the travelling distance from the predetermined intermediate location is La to satisfy respective predetermined relations.
p5039
aVAbstract\u000aA method for providing vehicle steering control through a curve in an autonomously driven or semi-autonomously driven vehicle that is towing a trailer. The method determines that the trailer will cross out of the travel lane based on the curvature of the curve and the turn radius of the trailer. The method calculates a start turn radius of the vehicle for a start location of the curve, an end turn radius of the vehicle for an end location of the curve, and a turn end point proximate the end location or a turn start point proximate the start location. The method provides initial and boundary conditions for determining a desired path of the vehicle through the curve that prevents the trailer from crossing out of the lane and determines the desired path based on the initial and boundary conditions by solving a polynomial equation.
p5040
aVAbstract\u000aSystems and method are provided for controlling an autonomous vehicle. In one embodiment, a method for controlling an autonomous vehicle comprises determining that assistance is required for continued movement of the autonomous vehicle; and facilitating movement of the autonomous vehicle via implementation, by a processor onboard the autonomous vehicle, of manual instructions provided from a remote user that is remote from the autonomous vehicle.
p5041
aVAbstract\u000aA ride height adjustment of a vehicle traveling along a roadway is controlled by a controller which uses data about overpass clearances and the height of the highest point on the vehicle to lower vehicle height when the height can be lowered sufficiently to avoid collision with an overpass.
p5042
aVAbstract\u000aAn apparatus as an aspect of the invention acquires a vehicle motion index value, a driving state index value of a driver, a driving characteristic value that is estimated based on the vehicle motion index value and the driving state index value, and a vehicle motion target value and a driving state target value that are determined regardless of the driver's driving. Using these values, the apparatus determines a target value of a steering assist torque and a target value of a difference in braking/driving force between right and left wheels that converge at least one of a difference between the vehicle motion target value and the vehicle motion index value and a difference between the driving state target value and the driving state index value. The apparatus controls the steering assist torque and the difference in braking/driving force between the right and left wheels to their respective target values.
p5043
aVAbstract\u000aA vehicle control system includes: a non-inertial sensor arrangement configured to detect a parameter indicative of a radius of turn for the vehicle that is desired by a driver of the vehicle; a speed detection arrangement operable to detect the forward speed of the vehicle; a friction estimation arrangement, configured to provide an estimated value for the coefficient of friction between at least one tire of the vehicle and a surface over which the vehicle is driven; and a processor connected to receive signals from the non-inertial sensor arrangement, the speed detection arrangement and the friction estimation arrangement.
p5044
aVAbstract\u000aA control unit for a vehicle includes: a vehicle additional yaw moment calculator that calculates a vehicle additional yaw moment to be applied to a vehicle based on a yaw rate of the vehicle; a steering torque instructing module that instructs an assist torque of a steering operation of a steering system; a left-right driving force torque instructing module that instructs a left-right wheel driving torque which applies a moment to the vehicle independently of the steering system; a charging state acquisition module that acquires a state of charge of a battery which stores an electric power serving as a driving source for applying the vehicle additional yaw moment; and an adjuster that adjusts the assist torque and the left-right wheel driving torque based on the state of charge to apply the vehicle additional yaw moment.
p5045
aVAbstract\u000aA vehicle traveling control apparatus for controlling following travel in which a host vehicle travels to follow a preceding vehicle traveling ahead, includes: a preceding vehicle biased travel determination unit calculating a lateral position inside a lane of the preceding vehicle, and determining whether the preceding vehicle biasedly travels while deviating from a setting range at a lane center; and a control target point setting unit setting, as a control target point of the following travel, a setting position in a vehicle width direction of the preceding vehicle in a case where it is determined that the preceding vehicle does not biasedly travel, and a position shifted as much as a predetermined shift amount from the setting position in a direction opposite to a direction in which the preceding vehicle deviates from the setting range in a case where it is determined that the preceding vehicle biasedly travels.
p5046
aVAbstract\u000aAn information collection system includes an on-vehicle device and a server, wherein the on-vehicle device includes a first transmission signal transmitting part configured to transmit a first transmission signal to the server when the vehicle event is detected, and an upload executing part configured to transmit the vehicle event data to the server when the upload demand is received. The server includes a determining part configured to determine, based on the determination purposes information, when the first transmission is received, whether the information acquisition condition is met, an upload demanding part configured to transmit the upload demand to the on-vehicle device when it is determined that the information acquisition condition is met, and a vehicle event data receiving part configured to receive the vehicle event data transmitted from the on-vehicle device.
p5047
aVAbstract\u000aA vehicle door control apparatus includes a sensor provided on a door of a vehicle. The vehicle door control apparatus also includes a processor configured to control opening or closing of the door based on information regarding an object sensed through the sensor.
p5048
aVAbstract\u000aAutonomous vehicles such as UAVs or cars provide network access points. User devices connect to the network access points and network access is monitored. User location data is also monitored. A profile of the user is generated from the gathered data. Advertisements are selected based on a profile of the user and the current location of the user. The autonomous vehicles may be distributed geographically to provide a network access to a geographic area. In response to detecting that a user device is moving out of a coverage area of an autonomous vehicle, nearby autonomous vehicles are identified. If the user device is in the coverage area of a nearby autonomous vehicle, the network connection to the user device is transferred to that vehicle.
p5049
aVAbstract\u000aA parking assist system for a vehicle is provided that includes a proximity sensor configured to sense a distance to an obstacle, a parking controller configured to output a distance to target signal and a scheduler configured to process the distance to target signal and output a distance error signal to a control module configured to longitudinally control the vehicle. The scheduler is configured to process both a static and a dynamic distance to target signal.
p5050
aVAbstract\u000aA fuel dispensing system is disclosed to be equipped to a vehicle and to dispense fuel from the vehicle. The system includes a fuel tank, a selectively activated dispensing pump, a retractable flexible fuel line connected to the pump enabling storage of the fuel line within a body of the vehicle, and a dispensing nozzle attached to the fuel line.
p5051
aVAbstract\u000aA hitch assist system is provided herein. An imaging device captures images of a scene rearward of a vehicle. A controller processes captured images and is configured to control a vehicle suspension system to adjust a height of the vehicle and control the deployment of a power tongue jack of a trailer.
p5052
aVAbstract\u000aA complex parent-subsidiary mobile carrier, which is manned or unmanned and remotely controllable. The complex carrier can operate in a combined mode and a separated mode. The complex carrier includes a parent carrier having a first connection section and a subsidiary carrier having a second connection section releasably mated and connected with the first connection section. At least one of the parent carrier and the subsidiary carrier has self-moving ability. The complex carrier includes a power control unit capable of controlling the moving speed and direction of the complex carrier. A remote control unit is disposed between the parent carrier and the subsidiary carrier for transmitting remote control signals to control the power control unit. The parent carrier and the subsidiary carrier can be integrally combined to move together. Alternatively, the parent carrier and the subsidiary carrier can be separated to respectively move.
p5053
aVAbstract\u000aA method provided for producing a model of the surroundings of a vehicle, wherein a lane is determined on the basis of objects, free space boundaries and/or roadway limitations. The lane indicates the zone around the vehicle in which the vehicle can drive freely. The lane includes at least one lane segment, the lane segment comprising at least one lane segment boundary, in particular a front lane segment boundary, a rear lane segment boundary, a left lane segment boundary and a right lane segment boundary. The distance from the vehicle to the lane segment boundary is determined, and the lane is made available to a driver assistance system.
p5054
aVAbstract\u000aA communication device for a motor vehicle has a plurality, but preferably two, communication modules that are configured in each case to communicate wirelessly with other motor vehicles and wirelessly with one another. A motor vehicle is equipped with a communication device of this type, and a method for communication between a plurality of motor vehicles is carried out.
p5055
aVAbstract\u000aA suspension assembly for a motorized vehicle includes a rotatable drive-unit driveshaft extending outwardly from an aperture of a drive unit. A first portion of a dropcase is pivotally coupled to the drive unit. A first end portion of a dropcase driveshaft is coupled to the drive-unit driveshaft such that rotation of the drive-unit driveshaft causes a corresponding rotation of the dropcase driveshaft. A second end portion of the dropcase driveshaft extends outwardly from a second portion of the dropcase and is suitable for coupling to a wheel hub. A pivotal-coupling assembly pivotally couples the dropcase to the drive unit. The pivotal-coupling assembly provides a pivot axis between the dropcase and the drive unit along a longitudinal length of the drive-unit driveshaft.
p5056
aVAbstract\u000aAn autonomous vehicle includes an automated driving system configured to automatically control vehicle steering, acceleration, and braking during a drive cycle without operator intervention. The vehicle additionally includes a wireless communication system configured to communicate with a remote communication device. The vehicle further includes a controller configured to communicate vehicle characteristics data via the wireless communication system. The vehicle characteristics data include a vehicle status identifier indicating automated driving system control of the vehicle. The controller is further configured to, in response to a remote override request from a remote communication device, command the automated driving system to perform a minimal risk condition maneuver to stop the vehicle.
p5057
aVAbstract\u000aA method of operating a vehicle wherein the method comprises:\u000ausing a distance sensor to determine the distance between a part of the vehicle and an object, and\u000aimplementing a speed control procedure if the distance detected by the distance sensor falls below a first predetermined value,\u000acharacterised in that the method further includes the step of operating at least one vehicle brake momentarily to apply a low level braking force pulse to the vehicle following the engagement of a reverse gear of the vehicle.
p5058
aVAbstract\u000aA driving mode switching system includes a driving mode detecting module, a steering wheel pressure sensor, an accelerator pedal pressure sensor, and a driving mode switching module. The driving mode detecting module can determine a driving mode of an automobile. The driving mode is one of a manual driving mode and an autonomous driving mode. In the manual driving mode, the automobile is controlled by a steering wheel and an accelerator pedal, and in the autonomous driving mode, the automobile is autonomously driven. The driving mode switching module is coupled to the driving mode detecting module and can switch the driving mode between the manual driving mode and the autonomous driving mode.
p5059
aVAbstract\u000aA control method includes calculating a roll angle and a roll angular velocity of a vehicle, setting damping forces applied to front and rear wheel dampers to execute first and second modes according to signs of the roll angle and roll angular velocity, and controlling the front and rear wheel dampers in consideration of the damping forces. Upon determination that the signs of the roll angle and the roll angular velocity are different, in the first mode, damping force greater than front wheel reference force and damping force smaller than rear wheel reference force are set to be applied to the front wheel dampers and the rear wheel dampers, respectively, and in the second mode, damping force smaller than the front wheel reference force and damping force greater than the rear wheel reference force are set to be applied to the front wheel dampers and the rear wheel dampers, respectively.
p5060
aVAbstract\u000aDescribed embodiments include a system and method. A computer-implemented method includes receiving electronic data indicative of at least two incremental movements of a vehicle moving over a stochastic surface during a period of time proximate to an event. The electronic data is responsive to a correlation vector between a feature of the stochastic surface in a first digital image captured at a first time by a first digital imaging device carried by the vehicle and the feature of the stochastic surface in a second digital image captured at a subsequent second time by a second digital imaging device carried by the vehicle. The method includes determining in response to the received electronic data a behavior of the vehicle during the period of time proximate to the event. The method includes electronically outputting data indicative of the determined behavior of the vehicle during the period of time proximate to the event.
p5061
aVAbstract\u000aThe invention relates to a method for assisting a driver of a motor vehicle (1). The motor vehicle (1) is moved past a longitudinal parking space (5) up to an initial position (16) and sensor data, describing a spatial dimension of the longitudinal parking space (5), of at least one motor-vehicle-side sensor device (3) are made available during the movement of the motor vehicle (1) past the longitudinal parking space (5). Furthermore, a target line (8) is predetermined within the longitudinal parking space (5) on the basis of the sensor data, and a first driving trajectory (17) for a first parking movement of the motor vehicle (1) is determined starting from the initial position (16) in the direction of the target line (8) as a function of the sensor data. Furthermore, a second driving trajectory (12) is also determined for a second parking movement of the motor vehicle (1) following the first, as a function of the sensor data, wherein an intermediate position (13) on the second driving trajectory (12) is determined as a function of the sensor data. A third driving trajectory (14) for a third parking movement of the motor vehicle (1), following the second, is also determined starting from the intermediate position (13) to a target position (15) as a function of the sensor data, wherein the intermediate position (13) and the third driving trajectory (14) are determined in such a way that a longitudinal axis (11) of the motor vehicle (1) in the target position (15) is essentially congruent with the target line (8).
p5062
aVAbstract\u000aAn automated guided vehicle system may include a plurality of automated guided vehicles arranged in a predetermined relationship with respect to each other for supporting a payload. Each of the automated guided vehicles has a plurality of rollers extending from the automated guided vehicle and engaging a ground surface. Furthermore, at least one locator extends from the automated guided vehicle and engages the payload. Each of the automated guided vehicles also has an on-board controller arranged within a housing thereof, with one on-board controller acting as a master controller and the remaining of the on-board controllers acting as slave controllers. The master controller communicates with the slave controllers to maintain position and speed control of each automated guided vehicle in both a lateral and a longitudinal direction. Furthermore, the slave controllers send feedback information to the master controller.
p5063
aVAbstract\u000aA semi-trailer includes a parallelpiped shaped van having front and rear axially elongated parallelepiped shaped modules. The front axially elongated parallelepiped module is dimensioned and configured for telescoping axial movement with respect to the rear axially elongated parallelepiped module to vary the overall length of the trailer.
p5064
aVAbstract\u000aA vehicle includes a parking assist system that identifies an inclination of the vehicle and an angle of wheels relative to a centerline of the vehicle. The vehicle also includes a controller that, in response activation of the vehicle, the inclination exceeding a first threshold, and the angle exceeding a second threshold, adjusts the angle to center the wheels relative to the centerline.
p5065
aVAbstract\u000aA vehicle system is arranged for allowing transition from an autonomous driving mode to a second driving mode in a road vehicle having autonomous driving capabilities and including a vehicle compartment, a steering wheel and at least one pedal. The vehicle system includes a control arrangement, a first switch arranged at a first position at the steering wheel, a second switch arranged at a second position within the vehicle compartment, and a first determination arrangement for determining if the at least one pedal is depressed. The control arrangement is configured to allow the transition when the at least one pedal of the vehicle is depressed when the first switch and the second switch are simultaneously activated.
p5066
aVAbstract\u000aA method of avoiding a collision while operating a vehicle in reverse comprises detecting an object proximate to a vehicle with at least one sensor including detecting objects located along side of a vehicle and determining a predicted vehicle path, including a tracking path for front wheels of the vehicle. A probability is determined with a controller located within the vehicle of collision of one of the front corner and a side of the vehicle with the object while the vehicle is travelling in reverse and at least one collision avoidance response is determined with the controller based on the probability of collision.
p5067
aVAbstract\u000aAn arrangement structure for a vicinity information detection sensor, the arrangement structure comprising: a vicinity information detection sensor provided on a roof of a fuel cell bus; and an obstruction portion provided between the vicinity information detection sensor and a hydrogen tank disposed on the roof, the obstruction portion obstructing the hydrogen tank from coming into contact with the vicinity information detection sensor.
p5068
aVAbstract\u000aThe anti slip device for automobile wheels with wheel discs arranged at inner side plain of the wheel, load-bearing part of which is attachable to the wheel from the outside. The extensible body is placed slidingly in the direction parallel to the wheel axis on the load-bearing part. There are arms fulcrumed on the extensible body around axes parallel to the wheel axis. The arms are fitted, at their ends, with surfaces of engagement, which bear against the tire peripheral surface in the working position. The extensible body is placed on the load-bearing part in the guidance, which comprises at least two pipes, with one outer pipe placed slidingly on each of the pipes and attached to the extensible body. There are tensile springs arranged in the pipes, and these springs are attached by one end to the load bearing part, and by the other end to the extensible body.
p5069
aVAbstract\u000aA method for controlling a mining truck travelling on a work site is disclosed. The method includes receiving payload information associated with a payload carried in a bed of the mining truck from sensors associated with the mining truck. The method further includes determining an imbalance of the payload based on the payload information. The method further includes receiving positioning data associated with the work site from a positioning system and determining an approaching terrain of the work site based on the positioning data. The method further includes planning a path for the mining truck based on the imbalance and the approaching terrain and controlling the mining truck based on the path.
p5070
aVAbstract\u000aA work vehicle includes: an engine; a plurality of drive wheels driven by the engine; and an operation controller executes first drive force control that brakes a slipping drive wheel out of the plurality of drive wheels and executes second drive force control that reduces output of the engine in accordance with the slip ratio of the slipping drive wheel during execution of the first drive force control.
p5071
aVAbstract\u000aProvided is a vehicle control device with which improved fuel economy and lowered exhaust gas emissions can be effectively achieved without adversely affecting the driver when traveling while following a leading vehicle. The present invention has: a following-determination means that, during travel while following a leading vehicle, determines, on the basis of the speed of the host vehicle, the speed of the leading vehicle, and the distance from the leading vehicle, whether the host vehicle will be able to follow the leading vehicle by coasting; and an idle stop determination means that, when the following-determination means has determined that the host vehicle will be able to follow the leading vehicle by coasting, and the driving/travel state of the host vehicle satisfies other traveling idle stop criteria, determines that a traveling idle stop should be performed; and is provided with a determination criteria updating means for updating the determination criteria for the idle stop determination means in regard to criteria such as the leading vehicle characteristics, road surface conditions, and weather. In the event that it has been determined, from the determination conditions that have been updated in regard to the leading vehicle characteristics, etc., that following by coasting is possible, a control to shut off the on-board engine is performed.
p5072
aVAbstract\u000aA method for determining an angle between a longitudinal axis of a first, leading component vehicle and a longitudinal axis of a second, trailing component vehicle. For at least one wheel axle or wheel axle group of the first, leading component vehicle a travel speed and/or an angular speed of the wheel axle or wheel axle group concerned is determined, and for at least one wheel axle or wheel axle group of the second, trailing component vehicle a travel speed and/or an angular speed of the wheel axle or wheel axle group concerned is determined. From the travel speeds and/or angular speeds determined for the wheel axles or wheel axle groups of the first, leading component vehicle and of the second, trailing component vehicle, the angle between the longitudinal axes of the first, leading component vehicle and the second, trailing component vehicle is then calculated.
p5073
aVAbstract\u000aA surrounding risk displaying apparatus includes an environment recognizer, a surrounding risk recognizer, and a display. The environment recognizer is capable of recognizing an environment around a vehicle. The surrounding risk recognizer is capable of extracting risk objects each having a risk potential not less than a predetermined risk potential, estimating a distribution of the risk potential around each of the risk objects, and calculating a risk approaching determination value that increases depending on relative approaching of the risk objects. The display is capable of displaying images in a superimposed fashion on the corresponding risk objects. The images each indicate the distribution of the risk potential around corresponding one of the risk objects. The display is capable of displaying, when the risk approaching determination value is not less than a predetermined threshold, a passage risk display indicating that passing through, by the vehicle, a clearance between the risk objects involves a risk.
p5074
aVAbstract\u000aA safety system for a vehicle comprises a sensing means which is arranged to determine the presence of a preceding vehicle and, where present, to produce at least one first output signal representative of one or more characteristics of the preceding vehicle, the sensing means also being arranged to determine the presence of an oncoming vehicle and, where present, to produce at least one second output signal representative of one or more characteristics of the oncoming vehicle, and a controller which is arranged to receive the output signals from the sensing means, and from the signals to generate a result signal indicative that it is possible for the vehicle to safely overtake the preceding vehicle before the oncoming vehicle blocks the path along which the vehicle must travel to complete the overtaking maneuver. The controller determines if it is safe to overtake by generating from the output signals and optionally vehicle information a target line representing a distal most boundary of a zone within which the vehicle will move back into lane after completing the overtake, and determine whether the oncoming vehicle will have crossed the target line before the overtake could be completed and also to determine if the target line is set to safe distance in front of the vehicle that is to be overtaken at the predicted end of the overtake maneuver.
p5075
aVAbstract\u000aA vehicle travel control device includes a preceding vehicle offset calculation unit and a control target point setting unit. The preceding vehicle offset calculation unit calculates a lateral offset amount of a center position of a preceding vehicle with respect to a center position of a travel lane, in a first state where a host vehicle recognizes the travel lane. The control target point setting unit sets the center position of the travel lane as a control target point of travel control to follow the travel lane, when the host vehicle is in the first state, and that sets a position shifted as much as the offset amount from the center position of the preceding vehicle as a control target point of travel control to follow the preceding vehicle, when the host vehicle shifts from the first state to a second state where the host vehicle does not recognize the travel lane.
p5076
aVAbstract\u000aA vehicle includes a speed detector detecting a vehicle speed, a brake system and a control system implementing a control mode including determining a threshold speed. The control system further derives an initial brake torque demand proportional to an error between the threshold speed and a vehicle speed exceeding the threshold speed and outputs to the brake system a rate-limited brake torque demand by applying a rate-limit operator based on the error to the initial brake torque demand.
p5077
aVAbstract\u000aMethods and apparatuses are presented for optimizing performance of a base vehicle platform (e.g. an automobile) and operating the base vehicle platform without human intervention. Some embodiments may receive base vehicle platform data indicative of at least one performance characteristic of the base vehicle platform. Some embodiments may also receive environmental conditions data indicative of at least one characteristic of at least one weather condition or terrain condition, and receive base sensor data from at least one base sensor indicative of at least one up-to-date environmental condition or base vehicle platform condition. Embodiments may then generate at least one module based on the base vehicle platform data, the environmental conditions data, and the base sensor data, such that the at least one module operates the base vehicle platform without human intervention, and dynamically modifies at least one base vehicle platform performance characteristic without human reconfiguration.
p5078
aVAbstract\u000aThe present disclosure generally relates to an obstacle avoidance system with active suspensions. The obstacle avoidance system uses one or more active suspensions to lift or jump one or more corresponding wheels over an obstacle in the vehicle's path to avoid contact with the obstacle when the vehicle cannot practically drive over, steer around, or stop before hitting the obstacle.
p5079
aVAbstract\u000aA drive assembly is provided and includes a rotatable housing, a motor disposed within and to rotate with the housing, the motor including a drive element and first and second drive shafts, which are independently rotatably drivable by the drive element, a first drivable element coupled to the first drive shaft such that rotation thereof is transmitted to the first drivable element and configured to propel the housing in a first direction during first drive shaft rotation and a second drivable element coupled to the second drive shaft such that rotation thereof is transmitted to the second drivable element and configured to propel the motor in a second direction, which is transversely oriented relative to the first direction, relative to the housing during second drive shaft rotation.
p5080
aVAbstract\u000aA system and method for correcting bias and angle misalignment errors in the angle rate and acceleration outputs from a 6-DOF IMU mounted to a vehicle. The method includes providing velocity and estimation attitude data in an inertial frame from, for example, a GNSS/INS, and determining an ideal acceleration estimation and an ideal rate estimation in a vehicle frame using the velocity and attitude data. The method then determines the IMU bias error and misalignment error using the ideal acceleration and rate estimations and the angle rate and acceleration outputs in an IMU body frame from the IMU.
p5081
aVAbstract\u000aA differential locking axle control system that can cause the axle to automatically lock and unlock at any vehicle speed, up to a predetermined maximum speed, or any wheel spin rate up to a predetermined maximum, when a vehicle is being steered either in a straight line or around a curve while taking traction and global positioning factors into account.
p5082
aVAbstract\u000aThe invention relates to a method of utilizing a system for monitoring the temperature and/or the pressure of the tires of a vehicle (C) comprising one or more rolling sub-assemblies (100, 200), noteworthy in that it consists in installing on each rolling sub-assembly (100, 200), an additional storage and communication module (300\u2032) comprising: a data storage means in which are recorded, during a learning phase, the set of unique identifiers and the locations of each measurement and communication pick-up module (300) of said rolling sub-assembly (100, 200), a means of communication at least with the reception and transmission modules (400) and installed on the rolling sub-assembly, a means of storing energy for the purposes of powering the communication means, so that said storage and communication module (300\u2032) can retain in memory the set of identifiers and associated locations of the same sub-assembly (100, 200) and can communicate it instantaneously. The invention also relates to the device allowing the method to be implemented. Applications: utilization of a system for monitoring tires.
p5083
aVAbstract\u000aA method for operating a driver assistance system for the automated guidance of a motor vehicle, comprising the steps:\u000aDetecting environmental data relating to the surroundings of the motor vehicle by environmental sensors of the motor vehicle as well as ego data relating to the motor vehicle,\u000aDetermining several trajectories that respectively describe a possible future movement of the motor vehicle depending on the environmental data and the ego data,\u000aSelecting a reference trajectory from the determined trajectories by analyzing several evaluation criteria, wherein at least one of the evaluation criteria is a detection range criterion that analyzes at least one predicted detection range of one of the environmental sensors or of a group of the environmental sensors of the motor vehicle during a predicted movement of the motor vehicle along the respective determined trajectory,\u000aControlling vehicle systems in order to move the motor vehicle along the reference trajectory.
p5084
aVAbstract\u000aA trailer backup assist system is provided herein. A plurality of imaging devices is configured to capture rear-vehicle images. A controller is configured to receive output from each imaging device. The controller processes the output from each imaging device to track a number of trailer features. The controller determines a confidence score for the output of each imaging device. The confidence score is determined based on the number of trailer features being tracked and a tracking quality of each trailer feature. The controller also determines a hitch angle between a vehicle and a trailer based on the output associated with whichever imaging device yielded the highest confidence score.
p5085
aVAbstract\u000aA current state of a vehicle can be identified. At least a minimum acceleration capability of the vehicle is determined. A desired acceleration profile to follow is determined based at least in part on the minimum acceleration capability. An acceleration of the vehicle is controlled based at least in part on the desired acceleration profile.
p5086
aVAbstract\u000aA current state of a vehicle is identified. Vehicle path curvature limits are determined. A curvature performance profile to follow is determined based at least in part the vehicle path curvature limits. A direction of the vehicle is controlled based at least in part the curvature performance profile.
p5087
aVAbstract\u000aA parking assist system for a vehicle is provided that includes a brake system having at least one wheel count encoder configured to output a wheel count signal and a controller configured to limit a velocity of the vehicle in a first mode. The controller is also configured to stop the vehicle at a target location in a second mode, and prevent overshoot of the target location by the vehicle in a third mode.
p5088
aVAbstract\u000aA method is provided for assisting a driver of a single-track motor vehicle during a drive in order to drive through a bend safely. In the method, at least one current driving state variable and driver-specific driving dynamics variables are compared with an approaching driving situation and, if a danger threshold value is reached or exceeded, a warning signal is output. The current speed of the motor vehicle is sensed by a speed sensor and transmitted to a computer-and memory unit as the current driving state variable. Both previously reached inclined positions of the single-track motor vehicle and previously reached brake pressures and/or brake pressure gradients are stored by the computer-and-memory unit as the driver-specific driving dynamics variables. In order to evaluate the approaching driving situation, a bend radius of a curve to be driven through next is determined via a navigation unit and is transmitted to the computer-and memory unit.
p5089
aVAbstract\u000aA method for ascertaining a setpoint trajectory of a motor vehicle, an initial setpoint trajectory being planned and transmitted to an evaluation unit, a curve of a power characteristic variable, which is implementable as a function of the initial setpoint trajectory, being received from the evaluation unit, and a corrected setpoint trajectory being determined therefrom as a function of the ascertained implementable curve of the power characteristic variable.
p5090
aVAbstract\u000aA method for operating a motor vehicle, and to a control device for carrying out the method and a computer program product having program code for carrying out the method. In order to improve the safety of use of the motor vehicle, it is provided that functions of the motor vehicle are enabled as a function of stored data relating to the driver.
p5091
aVAbstract\u000aThe present disclosure provides a vehicle movement control device including: a projection unit that causes a projecting member, that is capable of projecting to a lower side of a vehicle, to project to a position at which the projecting member touches a road surface; and a control unit that, in a case in which a collision of the vehicle is predicted by a prediction unit that predicts a collision of the vehicle, controls the projection unit such that the projecting member projects to the lower side of the vehicle and a predetermined vehicle attitude is adopted.
p5092
aVAbstract\u000aSteering boxes currently available on the market in order to convert the rotation of the steering wheel into the angular rotation of the wheels are not suitable to be partially built into the rim of the wheels of an electric car. In addition, existing boxes do not allow the independent rotation of the wheels or wide turning radii. These limitations are overcome using a system comprising: a body into which at least one motor is built using corresponding supports, which motor(s) actuate(s) the steering rotation axle of each steered wheel in the upper part of the body, and, in the lower part, a transmission gearbox and a stationary circular crown gear with which driving pinions mesh, said pinions rotating about the crown gear, thereby rotating the entire body and the rotation axle of the wheel built into the body together with suitable means.
p5093
aVAbstract\u000aA detection device is provided for a motor vehicle (10) for detecting wetness (18) on a roadway (20). The detection device has a moisture-detection unit (12) and an evaluation unit (40) designed to determine wetness (18) on the roadway (20) on the basis of a moisture value (42) detected by the moisture-detection unit (12). The moisture-detection unit (12) is embodied as a sensor unit and is arranged at a rear region of the motor vehicle (10).
p5094
aVAbstract\u000aEnhanced features of a vehicle-based transportation system are presented here. In accordance with one methodology, the transportation system receives a ride request that identifies a passenger, a pickup location, and a destination location. The transportation system determines that the passenger requires user-specific security clearance to access a secured area at or near the destination location, and coordinates with a security system to grant the user-specific security clearance to the passenger. The transportation system can also determine a vehicle drop-off location based on the passenger destination, and coordinate with a navigation system to obtain navigation instructions to guide the passenger from the vehicle drop-off location to the passenger destination.
p5095
atp5096
ba(lp5097
g15
(g16
(dp5098
g18
g19
(g20
(I0
tp5099
g22
tp5100
Rp5101
(I1
(I4
tp5102
g29
I00
(lp5103
g37
ag38
ag39
ag40
atp5104
bsg44
Nstp5105
Rp5106
ag15
(g16
(dp5107
g18
g19
(g20
(I0
tp5108
g22
tp5109
Rp5110
(I1
(I6
tp5111
g29
I00
(lp5112
g33
ag34
ag35
ag36
ag41
ag42
atp5113
bsg44
Nstp5114
Rp5115
a(dp5116
S'0.14.1'
p5117
(dp5118
S'axes'
p5119
g14
sS'blocks'
p5120
(lp5121
(dp5122
S'mgr_locs'
p5123
c__builtin__
slice
p5124
(I4
I8
I1
tp5125
Rp5126
sS'values'
p5127
g72
sa(dp5128
g5123
g19
(g20
(I0
tp5129
g22
tp5130
Rp5131
(I1
(I6
tp5132
g26
(S'i8'
p5133
I0
I1
tp5134
Rp5135
(I3
S'<'
p5136
NNNI-1
I-1
I0
tp5137
bI00
S'\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x02\x00\x00\x00\x00\x00\x00\x00\x03\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\t\x00\x00\x00\x00\x00\x00\x00'
p5138
tp5139
bsg5127
g78
sasstp5140
bsb.